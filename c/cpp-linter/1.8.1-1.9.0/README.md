# Comparing `tmp/cpp_linter-1.8.1-py3-none-any.whl.zip` & `tmp/cpp_linter-1.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,19 +1,20 @@
-Zip file size: 35598 bytes, number of entries: 17
--rw-r--r--  2.0 unx     3861 b- defN 24-Mar-27 21:39 cpp_linter/__init__.py
--rw-r--r--  2.0 unx    11668 b- defN 24-Mar-27 21:39 cpp_linter/cli.py
--rw-r--r--  2.0 unx    10856 b- defN 24-Mar-27 21:39 cpp_linter/common_fs.py
--rw-r--r--  2.0 unx     2916 b- defN 24-Mar-27 21:39 cpp_linter/loggers.py
--rw-r--r--  2.0 unx     6238 b- defN 24-Mar-27 21:39 cpp_linter/clang_tools/__init__.py
--rw-r--r--  2.0 unx     6955 b- defN 24-Mar-27 21:39 cpp_linter/clang_tools/clang_format.py
--rw-r--r--  2.0 unx     9640 b- defN 24-Mar-27 21:39 cpp_linter/clang_tools/clang_tidy.py
--rw-r--r--  2.0 unx     5208 b- defN 24-Mar-27 21:39 cpp_linter/git/__init__.py
--rw-r--r--  2.0 unx     4834 b- defN 24-Mar-27 21:39 cpp_linter/git/git_str.py
--rw-r--r--  2.0 unx    10175 b- defN 24-Mar-27 21:39 cpp_linter/rest_api/__init__.py
--rw-r--r--  2.0 unx    25162 b- defN 24-Mar-27 21:39 cpp_linter/rest_api/github_api.py
--rw-r--r--  2.0 unx     1067 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     2982 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       47 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       11 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1436 b- defN 24-Mar-27 21:39 cpp_linter-1.8.1.dist-info/RECORD
-17 files, 103148 bytes uncompressed, 33238 bytes compressed:  67.8%
+Zip file size: 36851 bytes, number of entries: 18
+-rw-r--r--  2.0 unx     3037 b- defN 24-May-06 22:40 cpp_linter/__init__.py
+-rw-r--r--  2.0 unx    12424 b- defN 24-May-06 22:40 cpp_linter/cli.py
+-rw-r--r--  2.0 unx     2916 b- defN 24-May-06 22:40 cpp_linter/loggers.py
+-rw-r--r--  2.0 unx     5940 b- defN 24-May-06 22:40 cpp_linter/clang_tools/__init__.py
+-rw-r--r--  2.0 unx     7012 b- defN 24-May-06 22:40 cpp_linter/clang_tools/clang_format.py
+-rw-r--r--  2.0 unx     9653 b- defN 24-May-06 22:40 cpp_linter/clang_tools/clang_tidy.py
+-rw-r--r--  2.0 unx     8183 b- defN 24-May-06 22:40 cpp_linter/common_fs/__init__.py
+-rw-r--r--  2.0 unx     8374 b- defN 24-May-06 22:40 cpp_linter/common_fs/file_filter.py
+-rw-r--r--  2.0 unx     4940 b- defN 24-May-06 22:40 cpp_linter/git/__init__.py
+-rw-r--r--  2.0 unx     4636 b- defN 24-May-06 22:40 cpp_linter/git/git_str.py
+-rw-r--r--  2.0 unx    11915 b- defN 24-May-06 22:40 cpp_linter/rest_api/__init__.py
+-rw-r--r--  2.0 unx    21680 b- defN 24-May-06 22:40 cpp_linter/rest_api/github_api.py
+-rw-r--r--  2.0 unx     1067 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2982 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       47 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       11 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1536 b- defN 24-May-06 22:41 cpp_linter-1.9.0.dist-info/RECORD
+18 files, 106445 bytes uncompressed, 34327 bytes compressed:  67.8%
```

## zipnote {}

```diff
@@ -1,52 +1,55 @@
 Filename: cpp_linter/__init__.py
 Comment: 
 
 Filename: cpp_linter/cli.py
 Comment: 
 
-Filename: cpp_linter/common_fs.py
-Comment: 
-
 Filename: cpp_linter/loggers.py
 Comment: 
 
 Filename: cpp_linter/clang_tools/__init__.py
 Comment: 
 
 Filename: cpp_linter/clang_tools/clang_format.py
 Comment: 
 
 Filename: cpp_linter/clang_tools/clang_tidy.py
 Comment: 
 
+Filename: cpp_linter/common_fs/__init__.py
+Comment: 
+
+Filename: cpp_linter/common_fs/file_filter.py
+Comment: 
+
 Filename: cpp_linter/git/__init__.py
 Comment: 
 
 Filename: cpp_linter/git/git_str.py
 Comment: 
 
 Filename: cpp_linter/rest_api/__init__.py
 Comment: 
 
 Filename: cpp_linter/rest_api/github_api.py
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/LICENSE
+Filename: cpp_linter-1.9.0.dist-info/LICENSE
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/METADATA
+Filename: cpp_linter-1.9.0.dist-info/METADATA
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/WHEEL
+Filename: cpp_linter-1.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/entry_points.txt
+Filename: cpp_linter-1.9.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/top_level.txt
+Filename: cpp_linter-1.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: cpp_linter-1.8.1.dist-info/RECORD
+Filename: cpp_linter-1.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cpp_linter/__init__.py

```diff
@@ -1,68 +1,65 @@
 """Run clang-tidy and clang-format on a list of files.
 If executed from command-line, then `main()` is the entrypoint.
 """
 
-import json
-import logging
 import os
-from .common_fs import list_source_files, CACHE_PATH
+from .common_fs import CACHE_PATH
+from .common_fs.file_filter import FileFilter
 from .loggers import start_log_group, end_log_group, logger
 from .clang_tools import capture_clang_tools_output
-from .cli import cli_arg_parser, parse_ignore_option
+from .cli import get_cli_parser, Args
 from .rest_api.github_api import GithubApiClient
 
 
 def main():
     """The main script."""
 
     # The parsed CLI args
-    args = cli_arg_parser.parse_args()
+    args = get_cli_parser().parse_args(namespace=Args())
 
     #  force files-changed-only to reflect value of lines-changed-only
     if args.lines_changed_only:
         args.files_changed_only = True
 
     rest_api_client = GithubApiClient()
     logger.info("processing %s event", rest_api_client.event_name)
     is_pr_event = rest_api_client.event_name == "pull_request"
+    if not is_pr_event:
+        args.tidy_review = False
+        args.format_review = False
 
     # set logging verbosity
     logger.setLevel(10 if args.verbosity or rest_api_client.debug_enabled else 20)
 
     # prepare ignored paths list
-    ignored, not_ignored = parse_ignore_option(args.ignore, args.files)
+    global_file_filter = FileFilter(
+        extensions=args.extensions, ignore_value=args.ignore, not_ignored=args.files
+    )
+    global_file_filter.parse_submodules()
 
     # change working directory
     os.chdir(args.repo_root)
     CACHE_PATH.mkdir(exist_ok=True)
 
-    if logger.getEffectiveLevel() <= logging.DEBUG:
-        start_log_group("Event json from the runner")
-        logger.debug(json.dumps(rest_api_client.event_payload))
-        end_log_group()
-
+    start_log_group("Get list of specified source files")
     if args.files_changed_only:
         files = rest_api_client.get_list_of_changed_files(
-            extensions=args.extensions,
-            ignored=ignored,
-            not_ignored=not_ignored,
+            file_filter=global_file_filter,
             lines_changed_only=args.lines_changed_only,
         )
         rest_api_client.verify_files_are_present(files)
     else:
-        files = list_source_files(args.extensions, ignored, not_ignored)
+        files = global_file_filter.list_source_files()
         # at this point, files have no info about git changes.
         # for PR reviews, we need this info
         if is_pr_event and (args.tidy_review or args.format_review):
             # get file changes from diff
             git_changes = rest_api_client.get_list_of_changed_files(
-                extensions=args.extensions,
-                ignored=ignored,
-                not_ignored=not_ignored,
+                file_filter=global_file_filter,
                 lines_changed_only=0,  # prevent filtering out unchanged files
             )
             # merge info from git changes into list of all files
             for git_file in git_changes:
                 for file in files:
                     if git_file.name == file.name:
                         file.additions = git_file.additions
@@ -74,38 +71,16 @@
     else:
         logger.info(
             "Giving attention to the following files:\n\t%s",
             "\n\t".join([f.name for f in files]),
         )
     end_log_group()
 
-    (format_advice, tidy_advice) = capture_clang_tools_output(
-        files=files,
-        version=args.version,
-        checks=args.tidy_checks,
-        style=args.style,
-        lines_changed_only=args.lines_changed_only,
-        database=args.database,
-        extra_args=args.extra_arg,
-        tidy_review=is_pr_event and args.tidy_review,
-        format_review=is_pr_event and args.format_review,
-        num_workers=args.jobs,
-    )
+    capture_clang_tools_output(files=files, args=args)
 
     start_log_group("Posting comment(s)")
-    rest_api_client.post_feedback(
-        files=files,
-        format_advice=format_advice,
-        tidy_advice=tidy_advice,
-        thread_comments=args.thread_comments,
-        no_lgtm=args.no_lgtm,
-        step_summary=args.step_summary,
-        file_annotations=args.file_annotations,
-        style=args.style,
-        tidy_review=args.tidy_review,
-        format_review=args.format_review,
-    )
+    rest_api_client.post_feedback(files=files, args=args)
     end_log_group()
 
 
 if __name__ == "__main__":
     main()
```

## cpp_linter/cli.py

```diff
@@ -1,27 +1,80 @@
-"""Setup the options for CLI arguments."""
+"""Setup the options for :doc:`CLI <../cli_args>` arguments."""
 
 import argparse
-import configparser
-from pathlib import Path
-from typing import Tuple, List, Optional
-
-from .loggers import logger
-
-
-cli_arg_parser = argparse.ArgumentParser(
-    description=(
-        "Run clang-tidy and clang-format on a list of changed files "
-        + "provided by GitHub's REST API."
-    ),
-    formatter_class=argparse.RawTextHelpFormatter,
-)
-cli_arg_parser.add_argument(
-    "-v",
-    "--verbosity",
+from collections import UserDict
+from typing import Optional, List, Dict, Any, Sequence
+
+
+class Args(UserDict):
+    """A pseudo namespace declaration. Each attribute is initialized with the
+    corresponding :doc:`CLI <../cli_args>` arg's default value."""
+
+    #: See :std:option:`--verbosity`.
+    verbosity: bool = False
+    #: See :std:option:`--database`.
+    database: str = ""
+    #: See :std:option:`--style`.
+    style: str = "llvm"
+    #: See :std:option:`--tidy-checks`.
+    tidy_checks: str = (
+        "boost-*,bugprone-*,performance-*,readability-*,portability-*,modernize-*,"
+        "clang-analyzer-*,cppcoreguidelines-*"
+    )
+    #: See :std:option:`--version`.
+    version: str = ""
+    #: See :std:option:`--extensions`.
+    extensions: List[str] = [
+        "c",
+        "h",
+        "C",
+        "H",
+        "cpp",
+        "hpp",
+        "cc",
+        "hh",
+        "c++",
+        "h++",
+        "cxx",
+        "hxx",
+    ]
+    #: See :std:option:`--repo-root`.
+    repo_root: str = "."
+    #: See :std:option:`--ignore`.
+    ignore: str = ".github"
+    #: See :std:option:`--lines-changed-only`.
+    lines_changed_only: int = 0
+    #: See :std:option:`--files-changed-only`.
+    files_changed_only: bool = False
+    #: See :std:option:`--thread-comments`.
+    thread_comments: str = "false"
+    #: See :std:option:`--step-summary`.
+    step_summary: bool = False
+    #: See :std:option:`--file-annotations`.
+    file_annotations: bool = True
+    #: See :std:option:`--extra-arg`.
+    extra_arg: List[str] = []
+    #: See :std:option:`--no-lgtm`.
+    no_lgtm: bool = True
+    #: See :std:option:`files`.
+    files: List[str] = []
+    #: See :std:option:`--tidy-review`.
+    tidy_review: bool = False
+    #: See :std:option:`--format-review`.
+    format_review: bool = False
+    #: See :std:option:`--jobs`.
+    jobs: Optional[int] = 1
+    #: See :std:option:`--ignore-tidy`.
+    ignore_tidy: str = ""
+    #: See :std:option:`--ignore-format`.
+    ignore_format: str = ""
+
+
+_parser_args: Dict[Sequence[str], Any] = {}
+_parser_args[("-v", "--verbosity")] = dict(
     type=lambda a: a.lower() in ["debug", "10"],
     default="info",
     help="""This controls the action's verbosity in the workflow's
 logs. Supported options are ``debug`` and ``info``.
 The numerical representations of these log levels
 defined by the `logging <logging-levels>`_ library
 (``10`` for ``debug``, and ``20`` for ``info``) are
@@ -29,17 +82,15 @@
 
 This option does not affect the verbosity of resulting
 thread comments, file annotations, nor log grouping
 markers.
 
 Defaults to level ``%(default)s``""",
 )
-cli_arg_parser.add_argument(
-    "-p",
-    "--database",
+_parser_args[("-p", "--database")] = dict(
     default="",
     help="""The path that is used to read a compile command
 database. For example, it can be a CMake build
 directory in which a file named compile_commands.json
 exists (set ``CMAKE_EXPORT_COMPILE_COMMANDS`` to
 ``ON``). When no build path is specified, a search
 for compile_commands.json will be attempted through
@@ -49,32 +100,28 @@
 tree.
 
 .. important::
     Builds using ninja should explicitly specify this
     path. Otherwise, cpp-linter will have difficulty
     parsing clang-tidy output.""",
 )
-cli_arg_parser.add_argument(
-    "-s",
-    "--style",
+_parser_args[("-s", "--style")] = dict(
     default="llvm",
     help="""The style rules to use.
 
 - Set this to ``file`` to have clang-format use the
   closest relative .clang-format file.
 - Set this to a blank string (``""``) to disable
   using clang-format entirely.
 
 See `clang-format docs <https://clang.llvm.org/docs/ClangFormat.html>`_ for more info.
 
 Defaults to ``%(default)s``""",
 )
-cli_arg_parser.add_argument(
-    "-c",
-    "--tidy-checks",
+_parser_args[("-c", "--tidy-checks")] = dict(
     default="boost-*,bugprone-*,performance-*,readability-*,portability-*,modernize-*,"
     "clang-analyzer-*,cppcoreguidelines-*",
     help="""A comma-separated list of globs with optional
 ``-`` prefix. Globs are processed in order of
 appearance in the list. Globs without ``-`` prefix
 add checks with matching names to the set, globs with
 the ``-`` prefix remove checks with matching names
@@ -90,91 +137,98 @@
 
 See also `clang-tidy docs <https://clang.llvm.org/extra/clang-tidy>`_ for more info.
 
 Defaults to:
     %(default)s
 """,
 )
-cli_arg_parser.add_argument(
-    "-V",
-    "--version",
+_parser_args[("-V", "--version")] = dict(
     default="",
     help="""The desired version of the clang tools to use.
 
 - Set this option to a blank string (``''``) to use
   the platform's default installed version.
 - This value can also be a path to where the clang
   tools are installed (if using a custom install
   location). All paths specified here are converted
   to absolute.
 
 Defaults to ``''``""",
 )
-cli_arg_parser.add_argument(
-    "-e",
-    "--extensions",
+_parser_args[("-e", "--extensions")] = dict(
     default="c,h,C,H,cpp,hpp,cc,hh,c++,h++,cxx,hxx",
     type=lambda i: [ext.strip().lstrip(".") for ext in i.split(",")],
     help="""The file extensions to analyze.
 This is a comma-separated string of extensions.
 Defaults to:
     %(default)s
 """,
 )
-cli_arg_parser.add_argument(
-    "-r",
-    "--repo-root",
+_parser_args[("-r", "--repo-root")] = dict(
     default=".",
     help="""The relative path to the repository root directory.
 This path is relative to the working directory from
 which cpp-linter was executed.
 Defaults to ``%(default)s``""",
 )
-cli_arg_parser.add_argument(
-    "-i",
-    "--ignore",
+_parser_args[("-i", "--ignore")] = dict(
     default=".github",
     help="""Set this option with path(s) to ignore (or not ignore).
 
 - In the case of multiple paths, you can use ``|`` to
   separate each path.
 - There is no need to use ``./`` for each entry; a
-  blank string (``''``) represents the repo-root
-  path.
+  blank string (``''``) represents the
+  :std:option:`--repo-root` path.
 - This can also have files, but the file's path
   (relative to the :std:option:`--repo-root`) has to
   be specified with the filename.
 - Submodules are automatically ignored. Hidden
   directories (beginning with a ``.``) are also
   ignored automatically.
 - Prefix a path with ``!`` to explicitly not ignore
   it. This can be applied to a submodule's path (if
   desired) but not hidden directories.
-- Glob patterns are not supported here. All asterisk
-  characters (``*``) are literal.""",
+- .. versionadded:: 1.9 Glob patterns are supported
+      here.
+      :collapsible:
+
+      All asterisk characters (``*``) are not literal
+      as they were before. See
+      :py:meth:`~pathlib.Path.glob()` for more details
+      about Unix style glob patterns.
+""",
+)
+_parser_args[("-M", "--ignore-format")] = dict(
+    default="",
+    help="""Set this option with path(s) to ignore (or not ignore)
+when using clang-format. See :std:option:`--ignore` for
+more detail.""",
+)
+_parser_args[("-D", "--ignore-tidy")] = dict(
+    default="",
+    help="""Set this option with path(s) to ignore (or not ignore)
+when using clang-tidy. See :std:option:`--ignore` for
+more detail.""",
 )
-cli_arg_parser.add_argument(
-    "-l",
-    "--lines-changed-only",
+_parser_args[("-l", "--lines-changed-only")] = dict(
     default="false",
     type=lambda a: 2 if a.lower() == "true" else int(a.lower() == "diff"),
     help="""This controls what part of the files are analyzed.
 The following values are accepted:
 
 - ``false``: All lines in a file are analyzed.
 - ``true``: Only lines in the diff that contain
   additions are analyzed.
 - ``diff``: All lines in the diff are analyzed
   including unchanged lines but not subtractions.
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-f",
-    "--files-changed-only",
+_parser_args[("-f", "--files-changed-only")] = dict(
     default="false",
     type=lambda input: input.lower() == "true",
     help="""Set this option to false to analyze any source
 files in the repo. This is automatically enabled if
 :std:option:`--lines-changed-only` is enabled.
 
 .. note::
@@ -185,33 +239,29 @@
     event.
 
     See `Authenticating with the GITHUB_TOKEN
     <https://docs.github.com/en/actions/reference/authentication-in-a-workflow>`_
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-g",
-    "--no-lgtm",
+_parser_args[("-g", "--no-lgtm")] = dict(
     default="true",
     type=lambda input: input.lower() == "true",
     help="""Set this option to true or false to enable or
 disable the use of a thread comment or PR review
 that basically says 'Looks Good To Me' (when all
 checks pass).
 
 .. seealso::
     The :std:option:`--thread-comments` option also
     notes further implications.
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-t",
-    "--thread-comments",
+_parser_args[("-t", "--thread-comments")] = dict(
     default="false",
     choices=["true", "false", "update"],
     help="""This controls the behavior of posted thread
 comments as feedback.
 The following options are supported:
 
 - ``true``: enable the use of thread comments.
@@ -230,38 +280,32 @@
     be declared as an environment variable.
 
     See `Authenticating with the GITHUB_TOKEN
     <https://docs.github.com/en/actions/reference/authentication-in-a-workflow>`_
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-w",
-    "--step-summary",
+_parser_args[("-w", "--step-summary")] = dict(
     default="false",
     type=lambda input: input.lower() == "true",
     help="""Set this option to true or false to enable or
 disable the use of a workflow step summary when the run
 has concluded.
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-a",
-    "--file-annotations",
+_parser_args[("-a", "--file-annotations")] = dict(
     default="true",
     type=lambda input: input.lower() == "true",
     help="""Set this option to false to disable the use of
 file annotations as feedback.
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-x",
-    "--extra-arg",
+_parser_args[("-x", "--extra-arg")] = dict(
     default=[],
     action="append",
     help="""A string of extra arguments passed to clang-tidy
 for use as compiler arguments. This can be specified
 more than once for each additional argument. Recommend
 using quotes around the value and avoid using spaces
 between name and value (use ``=`` instead):
@@ -269,37 +313,33 @@
 .. code-block:: shell
 
     cpp-linter --extra-arg="-std=c++17" --extra-arg="-Wall"
 
 Defaults to none.
 """,
 )
-cli_arg_parser.add_argument(
-    "files",
+_parser_args[("files",)] = dict(
     nargs="*",
-    help="""A space separated list of files to focus on.
+    help="""
+A space separated list of files to focus on.
 These files will automatically be added to the list of
 explicitly not-ignored files. While other filtering is
 done with :std:option:`--extensions`, the files
 specified as positional arguments will be exempt from
 explicitly ignored domains (see :std:option:`--ignore`).""",
 )
-cli_arg_parser.add_argument(
-    "-d",
-    "--tidy-review",
+_parser_args[("-d", "--tidy-review")] = dict(
     default="false",
     type=lambda input: input.lower() == "true",
     help="""Set to ``true`` to enable Pull Request reviews
 from clang-tidy.
 
 Defaults to ``%(default)s``.""",
 )
-cli_arg_parser.add_argument(
-    "-m",
-    "--format-review",
+_parser_args[("-m", "--format-review")] = dict(
     default="false",
     type=lambda input: input.lower() == "true",
     help="""Set to ``true`` to enable Pull Request reviews
 from clang-format.
 
 Defaults to ``%(default)s``.""",
 )
@@ -315,69 +355,29 @@
 
     if jobs <= 0:
         return None  # let multiprocessing.Pool decide the number of workers
 
     return jobs
 
 
-cli_arg_parser.add_argument(
-    "-j",
-    "--jobs",
+_parser_args[("-j", "--jobs")] = dict(
     default=1,
     type=_parse_jobs,
     help="""Set the number of jobs to run simultaneously.
 If set less than or equal to 0, the number of jobs will
 be set to the number of all available CPU cores.
 
 Defaults to ``%(default)s``.""",
 )
 
 
-def parse_ignore_option(
-    paths: str, not_ignored: List[str]
-) -> Tuple[List[str], List[str]]:
-    """Parse a given string of paths (separated by a ``|``) into ``ignored`` and
-    ``not_ignored`` lists of strings.
-
-    :param paths: This argument conforms to the input value of CLI arg
-        :std:option:`--ignore`.
-
-    :returns:
-        Returns a tuple of lists in which each list is a set of strings.
-
-        - index 0 is the ``ignored`` list
-        - index 1 is the ``not_ignored`` list
-    """
-    ignored = []
-
-    for path in paths.split("|"):
-        is_included = path.startswith("!")
-        if path.startswith("!./" if is_included else "./"):
-            path = path.replace("./", "", 1)  # relative dir is assumed
-        path = path.strip()  # strip leading/trailing spaces
-        if is_included:
-            not_ignored.append(path[1:])  # strip leading `!`
-        else:
-            ignored.append(path)
-
-    # auto detect submodules
-    gitmodules = Path(".gitmodules")
-    if gitmodules.exists():
-        submodules = configparser.ConfigParser()
-        submodules.read(gitmodules.resolve().as_posix())
-        for module in submodules.sections():
-            path = submodules[module]["path"]
-            if path not in not_ignored:
-                logger.info("Appending submodule to ignored paths: %s", path)
-                ignored.append(path)
-
-    if ignored:
-        logger.info(
-            "Ignoring the following paths/files:\n\t./%s",
-            "\n\t./".join(f for f in ignored),
-        )
-    if not_ignored:
-        logger.info(
-            "Not ignoring the following paths/files:\n\t./%s",
-            "\n\t./".join(f for f in not_ignored),
-        )
-    return (ignored, not_ignored)
+def get_cli_parser() -> argparse.ArgumentParser:
+    cli_parser = argparse.ArgumentParser(
+        description=(
+            "Run clang-tidy and clang-format on a list of changed files "
+            + "provided by GitHub's REST API."
+        ),
+        formatter_class=argparse.RawTextHelpFormatter,
+    )
+    for switches, kwargs in _parser_args.items():
+        cli_parser.add_argument(*switches, **kwargs)
+    return cli_parser
```

## cpp_linter/clang_tools/__init__.py

```diff
@@ -1,19 +1,21 @@
 from concurrent.futures import ProcessPoolExecutor, as_completed
 import json
-from pathlib import Path, PurePath
+from pathlib import Path
 import subprocess
 from textwrap import indent
 from typing import Optional, List, Dict, Tuple
 import shutil
 
 from ..common_fs import FileObj
+from ..common_fs.file_filter import TidyFileFilter, FormatFileFilter
 from ..loggers import start_log_group, end_log_group, worker_log_init, logger
 from .clang_tidy import run_clang_tidy, TidyAdvice
 from .clang_format import run_clang_format, FormatAdvice
+from ..cli import Args
 
 
 def assemble_version_exec(tool_name: str, specified_version: str) -> Optional[str]:
     """Assembles the command to the executable of the given clang tool based on given
     version information.
 
     :param tool_name: The name of the clang tool to be executed.
@@ -31,138 +33,124 @@
         return exe_path
     return shutil.which(tool_name)
 
 
 def _run_on_single_file(
     file: FileObj,
     log_lvl: int,
-    tidy_cmd,
-    checks,
-    lines_changed_only,
-    database,
-    extra_args,
-    db_json,
-    tidy_review,
-    format_cmd,
-    style,
-    format_review,
-):
+    tidy_cmd: Optional[str],
+    db_json: Optional[List[Dict[str, str]]],
+    format_cmd: Optional[str],
+    format_filter: Optional[FormatFileFilter],
+    tidy_filter: Optional[TidyFileFilter],
+    args: Args,
+) -> Tuple[str, str, Optional[TidyAdvice], Optional[FormatAdvice]]:
     log_stream = worker_log_init(log_lvl)
 
     tidy_note = None
-    if tidy_cmd is not None:
+    if tidy_cmd is not None and (
+        tidy_filter is None or tidy_filter.is_source_or_ignored(file.name)
+    ):
         tidy_note = run_clang_tidy(
-            tidy_cmd,
-            file,
-            checks,
-            lines_changed_only,
-            database,
-            extra_args,
-            db_json,
-            tidy_review,
+            command=tidy_cmd,
+            file_obj=file,
+            checks=args.tidy_checks,
+            lines_changed_only=args.lines_changed_only,
+            database=args.database,
+            extra_args=args.extra_arg,
+            db_json=db_json,
+            tidy_review=args.tidy_review,
         )
 
     format_advice = None
-    if format_cmd is not None:
+    if format_cmd is not None and (
+        format_filter is None or format_filter.is_source_or_ignored(file.name)
+    ):
         format_advice = run_clang_format(
-            format_cmd, file, style, lines_changed_only, format_review
+            command=format_cmd,
+            file_obj=file,
+            style=args.style,
+            lines_changed_only=args.lines_changed_only,
+            format_review=args.format_review,
         )
 
     return file.name, log_stream.getvalue(), tidy_note, format_advice
 
 
-def capture_clang_tools_output(
-    files: List[FileObj],
-    version: str,
-    checks: str,
-    style: str,
-    lines_changed_only: int,
-    database: str,
-    extra_args: List[str],
-    tidy_review: bool,
-    format_review: bool,
-    num_workers: Optional[int],
-) -> Tuple[List[FormatAdvice], List[TidyAdvice]]:
+def capture_clang_tools_output(files: List[FileObj], args: Args):
     """Execute and capture all output from clang-tidy and clang-format. This aggregates
     results in the :attr:`~cpp_linter.Globals.OUTPUT`.
 
     :param files: A list of files to analyze.
-    :param version: The version of clang-tidy to run.
-    :param checks: The `str` of comma-separated regulate expressions that describe
-        the desired clang-tidy checks to be enabled/configured.
-    :param style: The clang-format style rules to adhere. Set this to 'file' to
-        use the relative-most .clang-format configuration file.
-    :param lines_changed_only: A flag that forces focus on only changes in the event's
-        diff info.
-    :param database: The path to the compilation database.
-    :param extra_args: A list of extra arguments used by clang-tidy as compiler
-        arguments.
-    :param tidy_review: A flag to enable/disable creating a diff suggestion for
-        PR review comments using clang-tidy.
-    :param format_review: A flag to enable/disable creating a diff suggestion for
-        PR review comments using clang-format.
-    :param num_workers: The number of workers to use for parallel processing. If
-        `None`, then the number of workers is set to the number of CPU cores.
+    :param args: A namespace of parsed args from the :doc:`CLI <../cli_args>`.
     """
 
     def show_tool_version_output(cmd: str):  # show version output for executable used
         version_out = subprocess.run(
             [cmd, "--version"], capture_output=True, check=True
         )
         logger.info("%s --version\n%s", cmd, indent(version_out.stdout.decode(), "\t"))
 
     tidy_cmd, format_cmd = (None, None)
-    if style:  # if style is an empty value, then clang-format is skipped
-        format_cmd = assemble_version_exec("clang-format", version)
+    tidy_filter, format_filter = (None, None)
+    if args.style:  # if style is an empty value, then clang-format is skipped
+        format_cmd = assemble_version_exec("clang-format", args.version)
         assert format_cmd is not None, "clang-format executable was not found"
         show_tool_version_output(format_cmd)
-    if checks != "-*":  # if all checks are disabled, then clang-tidy is skipped
-        tidy_cmd = assemble_version_exec("clang-tidy", version)
+        tidy_filter = TidyFileFilter(
+            extensions=args.extensions,
+            ignore_value=args.ignore_tidy,
+        )
+    if args.tidy_checks != "-*":
+        # if all checks are disabled, then clang-tidy is skipped
+        tidy_cmd = assemble_version_exec("clang-tidy", args.version)
         assert tidy_cmd is not None, "clang-tidy executable was not found"
         show_tool_version_output(tidy_cmd)
+        format_filter = FormatFileFilter(
+            extensions=args.extensions,
+            ignore_value=args.ignore_format,
+        )
 
     db_json: Optional[List[Dict[str, str]]] = None
-    if database and not PurePath(database).is_absolute():
-        database = str(Path(database).resolve())
-    if database:
-        db_path = Path(database, "compile_commands.json")
+    if args.database:
+        db = Path(args.database)
+        if not db.is_absolute():
+            args.database = str(db.resolve())
+        db_path = (db / "compile_commands.json").resolve()
         if db_path.exists():
             db_json = json.loads(db_path.read_text(encoding="utf-8"))
 
-    with ProcessPoolExecutor(num_workers) as executor:
+    with ProcessPoolExecutor(args.jobs) as executor:
         log_lvl = logger.getEffectiveLevel()
         futures = [
             executor.submit(
                 _run_on_single_file,
                 file,
                 log_lvl=log_lvl,
                 tidy_cmd=tidy_cmd,
-                checks=checks,
-                lines_changed_only=lines_changed_only,
-                database=database,
-                extra_args=extra_args,
                 db_json=db_json,
-                tidy_review=tidy_review,
                 format_cmd=format_cmd,
-                style=style,
-                format_review=format_review,
+                format_filter=format_filter,
+                tidy_filter=tidy_filter,
+                args=args,
             )
             for file in files
         ]
 
         # temporary cache of parsed notifications for use in log commands
-        format_advice_map: Dict[str, Optional[FormatAdvice]] = {}
-        tidy_notes_map: Dict[str, Optional[TidyAdvice]] = {}
         for future in as_completed(futures):
-            file, logs, note, advice = future.result()
+            file_name, logs, tidy_advice, format_advice = future.result()
 
-            start_log_group(f"Performing checkup on {file}")
+            start_log_group(f"Performing checkup on {file_name}")
             print(logs, flush=True)
             end_log_group()
 
-            format_advice_map[file] = advice
-            tidy_notes_map[file] = note
-
-    format_advice = list(filter(None, (format_advice_map[file.name] for file in files)))
-    tidy_notes = list(filter(None, (tidy_notes_map[file.name] for file in files)))
-
-    return (format_advice, tidy_notes)
+            if tidy_advice or format_advice:
+                for file in files:
+                    if file.name == file_name:
+                        if tidy_advice:
+                            file.tidy_advice = tidy_advice
+                        if format_advice:
+                            file.format_advice = format_advice
+                        break
+                else:  # pragma: no cover
+                    raise ValueError(f"Failed to find {file_name} in list of files.")
```

## cpp_linter/clang_tools/clang_format.py

```diff
@@ -75,19 +75,21 @@
     def __repr__(self) -> str:
         return (
             f"<XMLFixit with {len(self.replaced_lines)} lines of "
             f"replacements for {self.filename}>"
         )
 
 
-def tally_format_advice(format_advice: List[FormatAdvice]) -> int:
+def tally_format_advice(files: List[FileObj]) -> int:
     """Returns the sum of clang-format errors"""
     format_checks_failed = 0
-    for advice in format_advice:
-        if advice.replaced_lines:
+    for file_obj in files:
+        if not file_obj.format_advice:
+            continue
+        if file_obj.format_advice.replaced_lines:
             format_checks_failed += 1
     return format_checks_failed
 
 
 def formalize_style_name(style: str) -> str:
     if style.startswith("llvm") or style.startswith("gnu"):
         return style.upper()
```

## cpp_linter/clang_tools/clang_tidy.py

```diff
@@ -106,19 +106,21 @@
             for fix_line in note.applied_fixes:
                 if fix_line in range(start, end + 1):  # range is inclusive
                     diagnostics += f"- {note.rationale} [{note.diagnostic_link}]\n"
                     break
         return diagnostics
 
 
-def tally_tidy_advice(files: List[FileObj], tidy_advice: List[TidyAdvice]) -> int:
+def tally_tidy_advice(files: List[FileObj]) -> int:
     """Returns the sum of clang-format errors"""
     tidy_checks_failed = 0
-    for file_obj, concern in zip(files, tidy_advice):
-        for note in concern.notes:
+    for file_obj in files:
+        if not file_obj.tidy_advice:
+            continue
+        for note in file_obj.tidy_advice.notes:
             if file_obj.name == note.filename:
                 tidy_checks_failed += 1
             else:
                 logger.debug("%s != %s", file_obj.name, note.filename)
     return tidy_checks_failed
```

## cpp_linter/git/__init__.py

```diff
@@ -16,15 +16,16 @@
     GIT_DELTA_RENAMED,
     GIT_STATUS_INDEX_NEW,
     GIT_STATUS_INDEX_MODIFIED,
     GIT_STATUS_INDEX_RENAMED,
     GitError,
 )
 from .. import CACHE_PATH
-from ..common_fs import FileObj, is_source_or_ignored, has_line_changes
+from ..common_fs import FileObj, has_line_changes
+from ..common_fs.file_filter import FileFilter
 from ..loggers import logger
 from .git_str import parse_diff as legacy_parse_diff
 
 
 def get_sha(repo: Repository, parent: Optional[int] = None) -> GitObject:
     """Uses ``git`` to fetch the full SHA hash of the current commit.
 
@@ -81,45 +82,37 @@
 
 
 ADDITIVE_STATUS = (GIT_DELTA_RENAMED, GIT_DELTA_MODIFIED, GIT_DELTA_ADDED)
 
 
 def parse_diff(
     diff_obj: Union[Diff, str],
-    extensions: List[str],
-    ignored: List[str],
-    not_ignored: List[str],
+    file_filter: FileFilter,
     lines_changed_only: int,
 ) -> List[FileObj]:
     """Parse a given diff into file objects.
 
     :param diff_obj: The complete git diff object for an event.
-    :param extensions: A list of file extensions to focus on only.
-    :param ignored: A list of paths or files to ignore.
-    :param not_ignored: A list of paths or files to explicitly not ignore.
+    :param file_filter: A `FileFilter` object.
     :param lines_changed_only: A value that dictates what file changes to focus on.
-    :returns: A `list` of `dict` containing information about the files changed.
+    :returns: A `list` of `FileObj` describing information about the files changed.
 
         .. note:: Deleted files are omitted because we only want to analyze updates.
     """
     file_objects: List[FileObj] = []
     if isinstance(diff_obj, str):
         try:
             diff_obj = Diff.parse_diff(diff_obj)
         except GitError as exc:
             logger.warning(f"pygit2.Diff.parse_diff() threw {exc}")
-            return legacy_parse_diff(
-                diff_obj, extensions, ignored, not_ignored, lines_changed_only
-            )
+            return legacy_parse_diff(diff_obj, file_filter, lines_changed_only)
     for patch in diff_obj:
         if patch.delta.status not in ADDITIVE_STATUS:
             continue
-        if not is_source_or_ignored(
-            patch.delta.new_file.path, extensions, ignored, not_ignored
-        ):
+        if not file_filter.is_source_or_ignored(patch.delta.new_file.path):
             continue
         diff_chunks, additions = parse_patch(patch.hunks)
         if has_line_changes(lines_changed_only, diff_chunks, additions):
             file_objects.append(
                 FileObj(patch.delta.new_file.path, additions, diff_chunks)
             )
     return file_objects
```

## cpp_linter/git/git_str.py

```diff
@@ -1,14 +1,15 @@
 """This was reintroduced to deal with any bugs in pygit2 (or the libgit2 C library it
 binds to). The `parse_diff()` function here is only used when
 :py:meth:`pygit2.Diff.parse_diff()` function fails in `cpp_linter.git.parse_diff()`"""
 
 import re
 from typing import Optional, List, Tuple, cast
-from ..common_fs import FileObj, is_source_or_ignored, has_line_changes
+from ..common_fs import FileObj, has_line_changes
+from ..common_fs.file_filter import FileFilter
 from ..loggers import logger
 
 
 DIFF_FILE_DELIMITER = re.compile(r"^diff --git a/.*$", re.MULTILINE)
 DIFF_FILE_NAME = re.compile(r"^\+\+\+\sb?/(.*)$", re.MULTILINE)
 DIFF_RENAMED_FILE = re.compile(r"^rename to (.*)$", re.MULTILINE)
 DIFF_BINARY_FILE = re.compile(r"^Binary\sfiles\s", re.MULTILINE)
@@ -34,25 +35,21 @@
             "\n".join(front_matter.splitlines()),
         )
     return None
 
 
 def parse_diff(
     full_diff: str,
-    extensions: List[str],
-    ignored: List[str],
-    not_ignored: List[str],
+    file_filter: FileFilter,
     lines_changed_only: int,
 ) -> List[FileObj]:
     """Parse a given diff into file objects.
 
     :param full_diff: The complete diff for an event.
-    :param extensions: A list of file extensions to focus on only.
-    :param ignored: A list of paths or files to ignore.
-    :param not_ignored: A list of paths or files to explicitly not ignore.
+    :param file_filter: A `FileFilter` object.
     :param lines_changed_only: A value that dictates what file changes to focus on.
     :returns: A `list` of `FileObj` instances containing information about the files
         changed.
     """
     file_objects: List[FileObj] = []
     logger.error("Using pure python to parse diff because pygit2 failed!")
     file_diffs = DIFF_FILE_DELIMITER.split(full_diff.lstrip("\n"))
@@ -64,15 +61,15 @@
         diff_front_matter = diff[:hunk_start]
         filename_match = _get_filename_from_diff(diff_front_matter)
         if filename_match is None:
             continue
         filename = cast(str, filename_match.groups(0)[0])
         if first_hunk is None:
             continue
-        if not is_source_or_ignored(filename, extensions, ignored, not_ignored):
+        if not file_filter.is_source_or_ignored(filename):
             continue
         diff_chunks, additions = _parse_patch(diff[first_hunk.start() :])
         if has_line_changes(lines_changed_only, diff_chunks, additions):
             file_objects.append(FileObj(filename, additions, diff_chunks))
     return file_objects
```

## cpp_linter/rest_api/__init__.py

```diff
@@ -1,28 +1,66 @@
+"""This base module holds abstractions common to using REST API.
+See other modules in ``rest_api`` subpackage for detailed derivatives.
+"""
+
 from abc import ABC
 from pathlib import PurePath
+import sys
+import time
+from typing import Optional, Dict, List, Any, cast, NamedTuple
 import requests
-from typing import Optional, Dict, List, Any
 from ..common_fs import FileObj
-from ..clang_tools.clang_format import FormatAdvice
-from ..clang_tools.clang_tidy import TidyAdvice
-from ..loggers import logger
+from ..common_fs.file_filter import FileFilter
+from ..cli import Args
+from ..loggers import logger, log_response_msg
 
 
 USER_OUTREACH = (
     "\n\nHave any feedback or feature suggestions? [Share it here.]"
     + "(https://github.com/cpp-linter/cpp-linter-action/issues)"
 )
 COMMENT_MARKER = "<!-- cpp linter action -->\n"
 
 
+class RateLimitHeaders(NamedTuple):
+    """A collection of HTTP response header keys that describe a REST API's rate limits.
+    Each parameter corresponds to a instance attribute (see below)."""
+
+    reset: str  #: The header key of the rate limit's reset time.
+    remaining: str  #: The header key of the rate limit's remaining attempts.
+    retry: str  #: The header key of the rate limit's "backoff" time interval.
+
+
 class RestApiClient(ABC):
-    def __init__(self) -> None:
+    """A class that describes the API used to interact with a git server's REST API.
+
+    :param rate_limit_headers: See `RateLimitHeaders` class.
+    """
+
+    def __init__(self, rate_limit_headers: RateLimitHeaders) -> None:
         self.session = requests.Session()
 
+        # The remain API requests allowed under the given token (if any).
+        self._rate_limit_remaining = -1  # -1 means unknown
+        # a counter for avoiding secondary rate limits
+        self._rate_limit_back_step = 0
+        # the rate limit reset time
+        self._rate_limit_reset: Optional[time.struct_time] = None
+        # the rate limit HTTP response header keys
+        self._rate_limit_headers = rate_limit_headers
+
+    def _rate_limit_exceeded(self):
+        logger.error("RATE LIMIT EXCEEDED!")
+        if self._rate_limit_reset is not None:
+            logger.error(
+                "Gitlab REST API rate limit resets on %s",
+                time.strftime("%d %B %Y %H:%M +0000", self._rate_limit_reset),
+            )
+        sys.exit(1)
+
     def api_request(
         self,
         url: str,
         method: Optional[str] = None,
         data: Optional[str] = None,
         headers: Optional[Dict[str, Any]] = None,
         strict: bool = True,
@@ -38,15 +76,53 @@
         :param strict: If this is set `True`, then an :py:class:`~requests.HTTPError`
             will be raised when the HTTP request responds with a status code greater
             than or equal to 400.
 
         :returns:
             The HTTP request's response object.
         """
-        raise NotImplementedError("Must be defined in the derivative")
+        if self._rate_limit_back_step >= 5 or self._rate_limit_remaining == 0:
+            self._rate_limit_exceeded()
+        response = self.session.request(
+            method=method or ("GET" if data is None else "POST"),
+            url=url,
+            headers=headers,
+            data=data,
+        )
+        self._rate_limit_remaining = int(
+            response.headers.get(self._rate_limit_headers.remaining, "-1")
+        )
+        if self._rate_limit_headers.reset in response.headers:
+            self._rate_limit_reset = time.gmtime(
+                int(response.headers[self._rate_limit_headers.reset])
+            )
+        log_response_msg(response)
+        if response.status_code in [403, 429]:  # rate limit exceeded
+            # secondary rate limit handling
+            if self._rate_limit_headers.retry in response.headers:
+                wait_time = (
+                    float(
+                        cast(str, response.headers.get(self._rate_limit_headers.retry))
+                    )
+                    * self._rate_limit_back_step
+                )
+                logger.warning(
+                    "SECONDARY RATE LIMIT HIT! Backing off for %f seconds",
+                    wait_time,
+                )
+                time.sleep(wait_time)
+                self._rate_limit_back_step += 1
+                return self.api_request(url, method=method, data=data, headers=headers)
+            # primary rate limit handling
+            if self._rate_limit_remaining == 0:
+                self._rate_limit_exceeded()
+        if strict:
+            response.raise_for_status()
+        self._rate_limit_back_step = 0
+        return response
 
     def set_exit_code(
         self,
         checks_failed: int,
         format_checks_failed: Optional[int] = None,
         tidy_checks_failed: Optional[int] = None,
     ):
@@ -73,45 +149,35 @@
             syntax.
         :returns: A `dict` to be used as headers in `requests` API calls.
         """
         raise NotImplementedError("must be implemented in the derivative")
 
     def get_list_of_changed_files(
         self,
-        extensions: List[str],
-        ignored: List[str],
-        not_ignored: List[str],
+        file_filter: FileFilter,
         lines_changed_only: int,
     ) -> List[FileObj]:
         """Fetch a list of the event's changed files.
 
-        :param extensions: A list of file extensions to focus on only.
-        :param ignored: A list of paths or files to ignore.
-        :param not_ignored: A list of paths or files to explicitly not ignore.
+        :param file_filter: A `FileFilter` obj to filter files.
         :param lines_changed_only: A value that dictates what file changes to focus on.
         """
         raise NotImplementedError("must be implemented in the derivative")
 
     @staticmethod
     def make_comment(
         files: List[FileObj],
-        format_advice: List[FormatAdvice],
-        tidy_advice: List[TidyAdvice],
         format_checks_failed: int,
         tidy_checks_failed: int,
         len_limit: Optional[int] = None,
     ) -> str:
         """Make an MarkDown comment from the given advice. Also returns a count of
         checks failed for each tool (clang-format and clang-tidy)
 
         :param files: A list of objects, each describing a file's information.
-        :param format_advice: A list of clang-format advice parallel to the list of
-            ``files``.
-        :param tidy_advice: A list of clang-tidy advice parallel to the list of
-            ``files``.
         :param format_checks_failed: The amount of clang-format checks that have failed.
         :param tidy_checks_failed: The amount of clang-tidy checks that have failed.
         :param len_limit: The length limit of the comment generated.
 
         :Returns: The markdown comment as a `str`
         """
         opener = f"{COMMENT_MARKER}# Cpp-Linter Report "
@@ -127,64 +193,64 @@
 
         if format_checks_failed or tidy_checks_failed:
             prefix = ":warning:\nSome files did not pass the configured checks!\n"
             len_limit = adjust_limit(limit=len_limit, text=prefix)
             if format_checks_failed:
                 comment += RestApiClient._make_format_comment(
                     files=files,
-                    advice_fix=format_advice,
                     checks_failed=format_checks_failed,
                     len_limit=len_limit,
                 )
             if tidy_checks_failed:
                 comment += RestApiClient._make_tidy_comment(
                     files=files,
-                    advice_fix=tidy_advice,
                     checks_failed=tidy_checks_failed,
                     len_limit=adjust_limit(limit=len_limit, text=comment),
                 )
         else:
             prefix = ":heavy_check_mark:\nNo problems need attention."
         return opener + prefix + comment + USER_OUTREACH
 
     @staticmethod
     def _make_format_comment(
         files: List[FileObj],
-        advice_fix: List[FormatAdvice],
         checks_failed: int,
         len_limit: Optional[int] = None,
     ) -> str:
         """make a comment describing clang-format errors"""
         comment = "\n<details><summary>clang-format reports: <strong>"
         comment += f"{checks_failed} file(s) not formatted</strong></summary>\n\n"
         closer = "\n</details>"
         checks_failed = 0
-        for file_obj, advice in zip(files, advice_fix):
-            if advice.replaced_lines:
+        for file_obj in files:
+            if not file_obj.format_advice:
+                continue
+            if file_obj.format_advice.replaced_lines:
                 format_comment = f"- {file_obj.name}\n"
                 if (
                     len_limit is None
                     or len(comment) + len(closer) + len(format_comment) < len_limit
                 ):
                     comment += format_comment
         return comment + closer
 
     @staticmethod
     def _make_tidy_comment(
         files: List[FileObj],
-        advice_fix: List[TidyAdvice],
         checks_failed: int,
         len_limit: Optional[int] = None,
     ) -> str:
         """make a comment describing clang-tidy errors"""
         comment = "\n<details><summary>clang-tidy reports: <strong>"
         comment += f"{checks_failed} concern(s)</strong></summary>\n\n"
         closer = "\n</details>"
-        for file_obj, concern in zip(files, advice_fix):
-            for note in concern.notes:
+        for file_obj in files:
+            if not file_obj.tidy_advice:
+                continue
+            for note in file_obj.tidy_advice.notes:
                 if file_obj.name == note.filename:
                     tidy_comment = "- **{filename}:{line}:{cols}:** ".format(
                         filename=file_obj.name,
                         line=note.line,
                         cols=note.cols,
                     )
                     tidy_comment += (
@@ -205,40 +271,29 @@
                     ):
                         comment += tidy_comment
         return comment + closer
 
     def post_feedback(
         self,
         files: List[FileObj],
-        format_advice: List[FormatAdvice],
-        tidy_advice: List[TidyAdvice],
-        thread_comments: str,
-        no_lgtm: bool,
-        step_summary: bool,
-        file_annotations: bool,
-        style: str,
-        tidy_review: bool,
-        format_review: bool,
+        args: Args,
     ):
         """Post action's results using REST API.
 
         :param files: A list of objects, each describing a file's information.
-        :param format_advice: A list of clang-format advice parallel to the list of
-            ``files``.
-        :param tidy_advice: A list of clang-tidy advice parallel to the list of
-            ``files``.
-        :param thread_comments: A flag that describes if how thread comments should
-            be handled. See :std:option:`--thread-comments`.
-        :param no_lgtm: A flag to control if a "Looks Good To Me" comment should be
-            posted. If this is `False`, then an outdated bot comment will still be
-            deleted. See :std:option:`--no-lgtm`.
-        :param step_summary: A flag that describes if a step summary should
-            be posted. See :std:option:`--step-summary`.
-        :param file_annotations: A flag that describes if file annotations should
-            be posted. See :std:option:`--file-annotations`.
-        :param style: The style used for clang-format. See :std:option:`--style`.
-        :param tidy_review: A flag to enable/disable creating a diff suggestion for
-            PR review comments using clang-tidy.
-        :param format_review: A flag to enable/disable creating a diff suggestion for
-            PR review comments using clang-format.
+        :param args: A namespace of arguments parsed from the :doc:`CLI <../cli_args>`.
         """
         raise NotImplementedError("Must be defined in the derivative")
+
+    @staticmethod
+    def has_more_pages(response: requests.Response) -> Optional[str]:
+        """A helper function to parse a HTTP request's response headers to determine if
+        the previous REST API call is paginated.
+
+        :param response: A HTTP request's response.
+
+        :returns: The URL of the next page if any, otherwise `None`.
+        """
+        links = response.links
+        if "next" in links and "url" in links["next"]:
+            return links["next"]["url"]
+        return None
```

## cpp_linter/rest_api/github_api.py

```diff
@@ -11,62 +11,64 @@
 
 import json
 import logging
 from os import environ
 from pathlib import Path
 import urllib.parse
 import sys
-import time
-from typing import Dict, List, Any, cast, Optional, Tuple, Union, Sequence
+from typing import Dict, List, Any, cast, Optional, Tuple, Union
 
 from pygit2 import Patch  # type: ignore
-import requests
 from ..common_fs import FileObj, CACHE_PATH
+from ..common_fs.file_filter import FileFilter
 from ..clang_tools.clang_format import (
     FormatAdvice,
     formalize_style_name,
     tally_format_advice,
 )
 from ..clang_tools.clang_tidy import TidyAdvice, tally_tidy_advice
-from ..loggers import start_log_group, logger, log_response_msg, log_commander
+from ..cli import Args
+from ..loggers import logger, log_commander
 from ..git import parse_diff, get_diff
-from . import RestApiClient, USER_OUTREACH, COMMENT_MARKER
+from . import RestApiClient, USER_OUTREACH, COMMENT_MARKER, RateLimitHeaders
+
+RATE_LIMIT_HEADERS = RateLimitHeaders(
+    reset="x-ratelimit-reset",
+    remaining="x-ratelimit-remaining",
+    retry="retry-after",
+)
 
 
 class GithubApiClient(RestApiClient):
+    """A class that describes the API used to interact with Github's REST API."""
+
     def __init__(self) -> None:
-        super().__init__()
+        super().__init__(rate_limit_headers=RATE_LIMIT_HEADERS)
         # create default headers to be used for all HTTP requests
         self.session.headers.update(self.make_headers())
 
         #: The base domain for the REST API
         self.api_url = environ.get("GITHUB_API_URL", "https://api.github.com")
         #: The ``owner``/``repository`` name.
         self.repo = environ.get("GITHUB_REPOSITORY", "")
         #: The triggering event type's name
         self.event_name = environ.get("GITHUB_EVENT_NAME", "unknown")
         #: The HEAD commit's SHA
         self.sha = environ.get("GITHUB_SHA", "")
         #: A flag that describes if debug logs are enabled.
         self.debug_enabled = environ.get("ACTIONS_STEP_DEBUG", "") == "true"
 
-        #: The event payload delivered as the web hook for the workflow run.
-        self.event_payload: Dict[str, Any] = {}
+        #: The pull request number for the event (if applicable).
+        self.pull_request = -1
         event_path = environ.get("GITHUB_EVENT_PATH", "")
         if event_path:
-            self.event_payload = json.loads(
+            event_payload: Dict[str, Any] = json.loads(
                 Path(event_path).read_text(encoding="utf-8")
             )
-
-        # The remain API requests allowed under the given token (if any).
-        self._rate_limit_remaining = -1  # -1 means unknown
-        # a counter for avoiding secondary rate limits
-        self._rate_limit_back_step = 0
-        # the rate limit reset time
-        self._rate_limit_reset: Optional[time.struct_time] = None
+            self.pull_request = cast(int, event_payload.get("number", -1))
 
     def set_exit_code(
         self,
         checks_failed: int,
         format_checks_failed: Optional[int] = None,
         tidy_checks_failed: Optional[int] = None,
     ):
@@ -77,104 +79,38 @@
                     f"clang-format-checks-failed={format_checks_failed or 0}\n"
                 )
                 env_file.write(f"clang-tidy-checks-failed={tidy_checks_failed or 0}\n")
         return super().set_exit_code(
             checks_failed, format_checks_failed, tidy_checks_failed
         )
 
-    def _rate_limit_exceeded(self):
-        logger.error("RATE LIMIT EXCEEDED!")
-        if self._rate_limit_reset is not None:
-            logger.error(
-                "Github REST API rate limit resets on %s",
-                time.strftime("%d %B %Y %H:%M +0000", self._rate_limit_reset),
-            )
-        sys.exit(1)
-
-    def api_request(
-        self,
-        url: str,
-        method: Optional[str] = None,
-        data: Optional[str] = None,
-        headers: Optional[Dict[str, Any]] = None,
-        strict: bool = True,
-    ) -> requests.Response:
-        if self._rate_limit_back_step >= 5 or self._rate_limit_remaining == 0:
-            self._rate_limit_exceeded()
-        response = self.session.request(
-            method=method or ("GET" if data is None else "POST"),
-            url=url,
-            headers=headers,
-            data=data,
-        )
-        self._rate_limit_remaining = int(
-            response.headers.get("x-ratelimit-remaining", "-1")
-        )
-        if "x-ratelimit-reset" in response.headers:
-            self._rate_limit_reset = time.gmtime(
-                int(response.headers["x-ratelimit-reset"])
-            )
-        log_response_msg(response)
-        if response.status_code in [403, 429]:  # rate limit exceeded
-            # secondary rate limit handling
-            if "retry-after" in response.headers:
-                wait_time = (
-                    float(cast(str, response.headers.get("retry-after")))
-                    * self._rate_limit_back_step
-                )
-                logger.warning(
-                    "SECONDARY RATE LIMIT HIT! Backing off for %f seconds",
-                    wait_time,
-                )
-                time.sleep(wait_time)
-                self._rate_limit_back_step += 1
-                return self.api_request(url, method=method, data=data, headers=headers)
-            # primary rate limit handling
-            if self._rate_limit_remaining == 0:
-                self._rate_limit_exceeded()
-        if strict:
-            response.raise_for_status()
-        self._rate_limit_back_step = 0
-        return response
-
     def get_list_of_changed_files(
         self,
-        extensions: List[str],
-        ignored: List[str],
-        not_ignored: List[str],
+        file_filter: FileFilter,
         lines_changed_only: int,
     ) -> List[FileObj]:
-        start_log_group("Get list of specified source files")
         if environ.get("CI", "false") == "true":
             files_link = f"{self.api_url}/repos/{self.repo}/"
             if self.event_name == "pull_request":
-                files_link += f"pulls/{self.event_payload['number']}"
+                files_link += f"pulls/{self.pull_request}"
             else:
                 if self.event_name != "push":
                     logger.warning(
                         "Triggered on unsupported event '%s'. Behaving like a push "
                         "event.",
                         self.event_name,
                     )
                 files_link += f"commits/{self.sha}"
             logger.info("Fetching files list from url: %s", files_link)
             response = self.api_request(
                 url=files_link, headers=self.make_headers(use_diff=True)
             )
-            files = parse_diff(
-                response.text,
-                extensions,
-                ignored,
-                not_ignored,
-                lines_changed_only,
-            )
+            files = parse_diff(response.text, file_filter, lines_changed_only)
         else:
-            files = parse_diff(
-                get_diff(), extensions, ignored, not_ignored, lines_changed_only
-            )
+            files = parse_diff(get_diff(), file_filter, lines_changed_only)
         return files
 
     def verify_files_are_present(self, files: List[FileObj]) -> None:
         """Download the files if not present.
 
         :param files: A list of files to check for existence.
 
@@ -206,134 +142,118 @@
         if gh_token:
             headers["Authorization"] = f"token {gh_token}"
         return headers
 
     def post_feedback(
         self,
         files: List[FileObj],
-        format_advice: List[FormatAdvice],
-        tidy_advice: List[TidyAdvice],
-        thread_comments: str,
-        no_lgtm: bool,
-        step_summary: bool,
-        file_annotations: bool,
-        style: str,
-        tidy_review: bool,
-        format_review: bool,
+        args: Args,
     ):
-        format_checks_failed = tally_format_advice(format_advice=format_advice)
-        tidy_checks_failed = tally_tidy_advice(files=files, tidy_advice=tidy_advice)
+        format_checks_failed = tally_format_advice(files)
+        tidy_checks_failed = tally_tidy_advice(files)
         checks_failed = format_checks_failed + tidy_checks_failed
         comment: Optional[str] = None
 
-        if step_summary and "GITHUB_STEP_SUMMARY" in environ:
+        if args.step_summary and "GITHUB_STEP_SUMMARY" in environ:
             comment = super().make_comment(
                 files=files,
-                format_advice=format_advice,
-                tidy_advice=tidy_advice,
                 format_checks_failed=format_checks_failed,
                 tidy_checks_failed=tidy_checks_failed,
                 len_limit=None,
             )
             with open(environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as summary:
                 summary.write(f"\n{comment}\n")
 
-        if file_annotations:
+        if args.file_annotations:
             self.make_annotations(
                 files=files,
-                format_advice=format_advice,
-                tidy_advice=tidy_advice,
-                style=style,
+                style=args.style,
             )
 
         self.set_exit_code(
             checks_failed=checks_failed,
             format_checks_failed=format_checks_failed,
             tidy_checks_failed=tidy_checks_failed,
         )
 
-        if thread_comments != "false":
+        if args.thread_comments != "false":
             if "GITHUB_TOKEN" not in environ:
                 logger.error("The GITHUB_TOKEN is required!")
                 sys.exit(1)
 
             if comment is None or len(comment) >= 65535:
                 comment = super().make_comment(
                     files=files,
-                    format_advice=format_advice,
-                    tidy_advice=tidy_advice,
                     format_checks_failed=format_checks_failed,
                     tidy_checks_failed=tidy_checks_failed,
                     len_limit=65535,
                 )
 
-            update_only = thread_comments == "update"
+            update_only = args.thread_comments == "update"
             is_lgtm = not checks_failed
             comments_url = f"{self.api_url}/repos/{self.repo}/"
             if self.event_name == "pull_request":
-                comments_url += f'issues/{self.event_payload["number"]}'
+                comments_url += f"issues/{self.pull_request}"
             else:
                 comments_url += f"commits/{self.sha}"
             comments_url += "/comments"
             self.update_comment(
                 comment=comment,
                 comments_url=comments_url,
-                no_lgtm=no_lgtm,
+                no_lgtm=args.no_lgtm,
                 update_only=update_only,
                 is_lgtm=is_lgtm,
             )
 
-        if self.event_name == "pull_request" and (tidy_review or format_review):
+        if self.event_name == "pull_request" and (
+            args.tidy_review or args.format_review
+        ):
             self.post_review(
                 files=files,
-                tidy_advice=tidy_advice,
-                format_advice=format_advice,
-                tidy_review=tidy_review,
-                format_review=format_review,
-                no_lgtm=no_lgtm,
+                tidy_review=args.tidy_review,
+                format_review=args.format_review,
+                no_lgtm=args.no_lgtm,
             )
 
     def make_annotations(
         self,
         files: List[FileObj],
-        format_advice: List[FormatAdvice],
-        tidy_advice: List[TidyAdvice],
         style: str,
     ) -> None:
         """Use github log commands to make annotations from clang-format and
         clang-tidy output.
 
         :param files: A list of objects, each describing a file's information.
-        :param format_advice: A list of clang-format advice parallel to the list of
-            ``files``.
-        :param tidy_advice: A list of clang-tidy advice parallel to the list of
-            ``files``.
         :param style: The chosen code style guidelines. The value 'file' is replaced
             with 'custom style'.
         """
         style_guide = formalize_style_name(style)
-        for advice, file in zip(format_advice, files):
-            if advice.replaced_lines:
+        for file_obj in files:
+            if not file_obj.format_advice:
+                continue
+            if file_obj.format_advice.replaced_lines:
                 line_list = []
-                for fix in advice.replaced_lines:
+                for fix in file_obj.format_advice.replaced_lines:
                     line_list.append(str(fix.line))
                 output = "::notice file="
-                name = file.name
+                name = file_obj.name
                 output += f"{name},title=Run clang-format on {name}::File {name}"
                 output += f" does not conform to {style_guide} style guidelines. "
                 output += "(lines {lines})".format(lines=", ".join(line_list))
                 log_commander.info(output)
-        for concerns, file in zip(tidy_advice, files):
-            for note in concerns.notes:
-                if note.filename == file.name:
+        for file_obj in files:
+            if not file_obj.tidy_advice:
+                continue
+            for note in file_obj.tidy_advice.notes:
+                if note.filename == file_obj.name:
                     output = "::{} ".format(
                         "notice" if note.severity.startswith("note") else note.severity
                     )
                     output += "file={file},line={line},title={file}:{line}:".format(
-                        file=file.name, line=note.line
+                        file=file_obj.name, line=note.line
                     )
                     output += "{cols} [{diag}]::{info}".format(
                         cols=note.cols,
                         diag=note.diagnostic,
                         info=note.rationale,
                     )
                     log_commander.info(output)
@@ -385,15 +305,15 @@
         """
         logger.debug("comments_url: %s", comments_url)
         comment_url: Optional[str] = None
         page = 1
         next_page: Optional[str] = comments_url + f"?page={page}&per_page=100"
         while next_page:
             response = self.api_request(url=next_page)
-            next_page = has_more_pages(response)
+            next_page = self.has_more_pages(response)
             page += 1
 
             comments = cast(List[Dict[str, Any]], response.json())
             if logger.level >= logging.DEBUG:
                 json_comments = Path(f"{CACHE_PATH}/comments-pg{page}.json")
                 json_comments.write_text(
                     json.dumps(comments, indent=2), encoding="utf-8"
@@ -419,21 +339,19 @@
                     if not delete:
                         comment_url = cast(str, comment["url"])
         return comment_url
 
     def post_review(
         self,
         files: List[FileObj],
-        tidy_advice: List[TidyAdvice],
-        format_advice: List[FormatAdvice],
         tidy_review: bool,
         format_review: bool,
         no_lgtm: bool,
     ):
-        url = f"{self.api_url}/repos/{self.repo}/pulls/{self.event_payload['number']}"
+        url = f"{self.api_url}/repos/{self.repo}/pulls/{self.pull_request}"
         response = self.api_request(url=url)
         url += "/reviews"
         pr_info = response.json()
         is_draft = cast(Dict[str, bool], pr_info).get("draft", False)
         is_open = cast(Dict[str, str], pr_info).get("state", "open") == "open"
         if "GITHUB_TOKEN" not in environ:
             logger.error("A GITHUB_TOKEN env var is required to post review comments")
@@ -443,22 +361,22 @@
             return  # don't post reviews
         body = f"{COMMENT_MARKER}## Cpp-linter Review\n"
         payload_comments = []
         total_changes = 0
         summary_only = (
             environ.get("CPP_LINTER_PR_REVIEW_SUMMARY_ONLY", "false") == "true"
         )
-        advice: Dict[str, Sequence[Union[TidyAdvice, FormatAdvice]]] = {}
+        advice: Dict[str, bool] = {}
         if format_review:
-            advice["clang-format"] = format_advice
+            advice["clang-format"] = False
         if tidy_review:
-            advice["clang-tidy"] = tidy_advice
-        for tool_name, tool_advice in advice.items():
+            advice["clang-tidy"] = True
+        for tool_name, tidy_tool in advice.items():
             comments, total, patch = self.create_review_comments(
-                files, tool_advice, summary_only
+                files, tidy_tool, summary_only
             )
             total_changes += total
             if not summary_only:
                 payload_comments.extend(comments)
                 if total and total != len(comments):
                     body += f"Only {len(comments)} out of {total} {tool_name} "
                     body += "concerns fit within this pull request's diff.\n"
@@ -482,49 +400,58 @@
             "comments": payload_comments,
         }
         self.api_request(url=url, data=json.dumps(payload), strict=False)
 
     @staticmethod
     def create_review_comments(
         files: List[FileObj],
-        tool_advice: Sequence[Union[FormatAdvice, TidyAdvice]],
+        tidy_tool: bool,
         summary_only: bool,
     ) -> Tuple[List[Dict[str, Any]], int, str]:
         """Creates a batch of comments for a specific clang tool's PR review"""
         total = 0
         comments = []
         full_patch = ""
-        for file, advice in zip(files, tool_advice):
-            assert advice.patched, f"No suggested patch found for {file.name}"
+        for file_obj in files:
+            tool_advice: Optional[Union[TidyAdvice, FormatAdvice]]
+            if tidy_tool:
+                tool_advice = file_obj.tidy_advice
+            else:
+                tool_advice = file_obj.format_advice
+            if not tool_advice:
+                continue
+            assert tool_advice.patched, f"No suggested patch found for {file_obj.name}"
             patch = Patch.create_from(
-                old=Path(file.name).read_bytes(),
-                new=advice.patched,
-                old_as_path=file.name,
-                new_as_path=file.name,
+                old=Path(file_obj.name).read_bytes(),
+                new=tool_advice.patched,
+                old_as_path=file_obj.name,
+                new_as_path=file_obj.name,
                 context_lines=0,  # trim all unchanged lines from start/end of hunks
             )
             full_patch += patch.text
             for hunk in patch.hunks:
                 total += 1
                 if summary_only:
                     continue
-                new_hunk_range = file.is_hunk_contained(hunk)
+                new_hunk_range = file_obj.is_hunk_contained(hunk)
                 if new_hunk_range is None:
                     continue
                 start_lines, end_lines = new_hunk_range
-                comment: Dict[str, Any] = {"path": file.name}
+                comment: Dict[str, Any] = {"path": file_obj.name}
                 body = ""
-                if isinstance(advice, TidyAdvice):
+                if tidy_tool and file_obj.tidy_advice:
                     body += "### clang-tidy "
-                    diagnostics = advice.diagnostics_in_range(start_lines, end_lines)
+                    diagnostics = file_obj.tidy_advice.diagnostics_in_range(
+                        start_lines, end_lines
+                    )
                     if diagnostics:
                         body += "diagnostics\n" + diagnostics
                     else:
                         body += "suggestions\n"
-                else:
+                elif not tidy_tool:
                     body += "### clang-format suggestions\n"
                 if start_lines < end_lines:
                     comment["start_line"] = start_lines
                 comment["line"] = end_lines
                 suggestion = ""
                 removed = []
                 for line in hunk.lines:
@@ -536,45 +463,45 @@
                     body += "\nPlease remove the line(s)\n- "
                     body += "\n- ".join([str(x) for x in removed])
                 else:
                     body += f"\n```suggestion\n{suggestion}```"
                 comment["body"] = body
                 comments.append(comment)
 
-        if tool_advice and isinstance(tool_advice[0], TidyAdvice):
             # now check for clang-tidy warnings with no fixes applied
-            for file, tidy_advice in zip(files, tool_advice):
-                assert isinstance(tidy_advice, TidyAdvice)
-                for note in tidy_advice.notes:
+            if tidy_tool and file_obj.tidy_advice:
+                for note in file_obj.tidy_advice.notes:
                     if not note.applied_fixes:  # if no fix was applied
                         total += 1
                         line_numb = int(note.line)
-                        if file.is_range_contained(start=line_numb, end=line_numb + 1):
+                        if file_obj.is_range_contained(
+                            start=line_numb, end=line_numb + 1
+                        ):
                             diag: Dict[str, Any] = {
-                                "path": file.name,
+                                "path": file_obj.name,
                                 "line": note.line,
                             }
-                            body = f"### clang-tidy diagnostic\n**{file.name}:"
+                            body = f"### clang-tidy diagnostic\n**{file_obj.name}:"
                             body += f"{note.line}:{note.cols}:** {note.severity}: "
                             body += f"[{note.diagnostic_link}]\n> {note.rationale}\n"
                             if note.fixit_lines:
-                                body += f'```{Path(file.name).suffix.lstrip(".")}\n'
+                                body += f'```{Path(file_obj.name).suffix.lstrip(".")}\n'
                                 for line in note.fixit_lines:
                                     body += f"{line}\n"
                                 body += "```\n"
                             diag["body"] = body
                             comments.append(diag)
         return (comments, total, full_patch)
 
     def _dismiss_stale_reviews(self, url: str):
         """Dismiss all reviews that were previously created by cpp-linter"""
         next_page: Optional[str] = url + "?page=1&per_page=100"
         while next_page:
             response = self.api_request(url=next_page)
-            next_page = has_more_pages(response)
+            next_page = self.has_more_pages(response)
 
             reviews: List[Dict[str, Any]] = response.json()
             for review in reviews:
                 if (
                     "body" in review
                     and cast(str, review["body"]).startswith(COMMENT_MARKER)
                     and "state" in review
@@ -585,21 +512,7 @@
                         url=f"{url}/{review['id']}/dismissals",
                         method="PUT",
                         data=json.dumps(
                             {"message": "outdated suggestion", "event": "DISMISS"}
                         ),
                         strict=False,
                     )
-
-
-def has_more_pages(response: requests.Response) -> Optional[str]:
-    """A helper function to parse a HTTP request's response headers to determine if the
-    previous REST API call is paginated.
-
-    :param response: A HTTP request's response.
-
-    :returns: The URL of the next page if any, otherwise `None`.
-    """
-    links = response.links
-    if "next" in links and "url" in links["next"]:
-        return links["next"]["url"]
-    return None
```

## Comparing `cpp_linter/common_fs.py` & `cpp_linter/common_fs/__init__.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,13 +1,17 @@
 from os import environ
-from os.path import commonpath
-from pathlib import PurePath, Path
-from typing import List, Dict, Any, Union, Tuple, Optional
+from pathlib import Path
+from typing import List, Dict, Any, Union, Tuple, Optional, TYPE_CHECKING
 from pygit2 import DiffHunk  # type: ignore
-from .loggers import logger, start_log_group
+from ..loggers import logger
+
+if TYPE_CHECKING:  # pragma: no covers
+    # circular import
+    from ..clang_tools.clang_tidy import TidyAdvice
+    from ..clang_tools.clang_format import FormatAdvice
 
 #: A path to generated cache artifacts. (only used when verbosity is in debug mode)
 CACHE_PATH = Path(environ.get("CPP_LINTER_CACHE", ".cpp-linter_cache"))
 
 
 class FileObj:
     """A class to represent a single file being analyzed.
@@ -35,14 +39,18 @@
         diff. This will be empty if not focusing on lines changed only."""
         self.lines_added: List[List[int]] = FileObj._consolidate_list_to_ranges(
             additions or []
         )
         """A list of line numbers that define the beginning and ending of ranges that
         have added changes. This will be empty if not focusing on lines changed only.
         """
+        #: The results from clang-tidy
+        self.tidy_advice: Optional["TidyAdvice"] = None
+        #: The results from clang-format
+        self.format_advice: Optional["FormatAdvice"] = None
 
     @staticmethod
     def _consolidate_list_to_ranges(numbers: List[int]) -> List[List[int]]:
         """A helper function that is only used after parsing the lines from a diff that
         contain additions.
 
         :param numbers: A `list` of integers representing the lines' numbers that
@@ -144,41 +152,14 @@
             start,
             end,
             self.name,
         )
         return None
 
 
-def is_file_in_list(paths: List[str], file_name: str, prompt: str) -> bool:
-    """Determine if a file is specified in a list of paths and/or filenames.
-
-    :param paths: A list of specified paths to compare with. This list can contain a
-        specified file, but the file's path must be included as part of the
-        filename.
-    :param file_name: The file's path & name being sought in the ``paths`` list.
-    :param prompt: A debugging prompt to use when the path is found in the list.
-
-    :returns:
-
-        - True if ``file_name`` is in the ``paths`` list.
-        - False if ``file_name`` is not in the ``paths`` list.
-    """
-    for path in paths:
-        result = commonpath([PurePath(path).as_posix(), PurePath(file_name).as_posix()])
-        if result.replace("\\", "/") == path:
-            logger.debug(
-                '"./%s" is %s as specified in the domain "./%s"',
-                file_name,
-                prompt,
-                path,
-            )
-            return True
-    return False
-
-
 def has_line_changes(
     lines_changed_only: int, diff_chunks: List[List[int]], additions: List[int]
 ) -> bool:
     """Does this file actually apply to condition specified by ``lines_changed_only``?
 
     :param lines_changed_only: A value that means:
 
@@ -192,68 +173,14 @@
     return (
         (lines_changed_only == 1 and len(diff_chunks) > 0)
         or (lines_changed_only == 2 and len(additions) > 0)
         or not lines_changed_only
     )
 
 
-def is_source_or_ignored(
-    file_name: str,
-    ext_list: List[str],
-    ignored: List[str],
-    not_ignored: List[str],
-):
-    """Exclude undesired files (specified by user input :std:option:`--extensions`).
-    This filtering is applied to the :attr:`~cpp_linter.Globals.FILES` attribute.
-
-    :param file_name: The name of file in question.
-    :param ext_list: A list of file extensions that are to be examined.
-    :param ignored: A list of paths to explicitly ignore.
-    :param not_ignored: A list of paths to explicitly not ignore.
-
-    :returns:
-        True if there are files to check. False will invoke a early exit (in
-        `main()`) when no files to be checked.
-    """
-    return PurePath(file_name).suffix.lstrip(".") in ext_list and (
-        is_file_in_list(not_ignored, file_name, "not ignored")
-        or not is_file_in_list(ignored, file_name, "ignored")
-    )
-
-
-def list_source_files(
-    extensions: List[str], ignored: List[str], not_ignored: List[str]
-) -> List[FileObj]:
-    """Make a list of source files to be checked.
-
-    :param extensions: A list of file extensions that should by attended.
-    :param ignored: A list of paths to explicitly ignore.
-    :param not_ignored: A list of paths to explicitly not ignore.
-
-    :returns: A list of `FileObj` objects.
-    """
-    start_log_group("Get list of specified source files")
-
-    root_path = Path(".")
-    files = []
-    for ext in extensions:
-        for rel_path in root_path.rglob(f"*.{ext}"):
-            for parent in rel_path.parts[:-1]:
-                if parent.startswith("."):
-                    break
-            else:
-                file_path = rel_path.as_posix()
-                logger.debug('"./%s" is a source code file', file_path)
-                if is_file_in_list(
-                    not_ignored, file_path, "not ignored"
-                ) or not is_file_in_list(ignored, file_path, "ignored"):
-                    files.append(FileObj(file_path))
-    return files
-
-
 def get_line_cnt_from_cols(file_path: str, offset: int) -> Tuple[int, int]:
     """Gets a line count and columns offset from a file's absolute offset.
 
     :param file_path: Path to file.
     :param offset: The byte offset to translate
 
     :returns:
```

## Comparing `cpp_linter-1.8.1.dist-info/LICENSE` & `cpp_linter-1.9.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `cpp_linter-1.8.1.dist-info/METADATA` & `cpp_linter-1.9.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cpp-linter
-Version: 1.8.1
+Version: 1.9.0
 Summary: Run clang-format and clang-tidy on a batch of files.
 Author-email: Brendan Doherty <2bndy5@gmail.com>, Peter Shen <xianpeng.shen@gmail.com>
 License: MIT License
 Project-URL: source, https://github.com/cpp-linter/cpp-linter
 Project-URL: tracker, https://github.com/cpp-linter/cpp-linter/issues
 Keywords: clang,clang-tools,linter,clang-tidy,clang-format
 Classifier: Development Status :: 5 - Production/Stable
```

## Comparing `cpp_linter-1.8.1.dist-info/RECORD` & `cpp_linter-1.9.0.dist-info/RECORD`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,18 @@
-cpp_linter/__init__.py,sha256=_QO2lXvoZ9V00xpGUM0m9QY81AqLR00Zr5NJJS3Dah4,3861
-cpp_linter/cli.py,sha256=1Ek9gXcMcvKuHrjhdpCSrHA4ZArDeEF3PPepNPMAS6s,11668
-cpp_linter/common_fs.py,sha256=gcjnF6GNaLeNNLO_uBv1v7pM1qIJ8zit79uM1aqHMJ0,10856
+cpp_linter/__init__.py,sha256=2UV43SMqb4FwisBuB-YAym5vQuCJSKh4E-JuLlYcBek,3037
+cpp_linter/cli.py,sha256=OqIVh1Ojz87Pz0582iMvRER1t67oHiijNoAYFgjo-DU,12424
 cpp_linter/loggers.py,sha256=T8KxdZFiUkUiX1njppDeeLXGfsQK02EJ3tcikJw3LRw,2916
-cpp_linter/clang_tools/__init__.py,sha256=VarIYrcXr7Si2Qb4mqEnHz-dtONLNUM7zw4FI1hc6lw,6238
-cpp_linter/clang_tools/clang_format.py,sha256=0MkZTgwGHBa8Cbp8R5gX15GE03Yrw5ekyMyVulDCEVs,6955
-cpp_linter/clang_tools/clang_tidy.py,sha256=UF4zdel0g3kEU0ZdkKoHtRFQjaYAhKkf4S2PssxhtVE,9640
-cpp_linter/git/__init__.py,sha256=bPhopQcXxhP-l_jS2MNFJ8ziCKyYGg6pqCN4l2wPrn4,5208
-cpp_linter/git/git_str.py,sha256=odj9tTggbo6N5K8-BbEUn26gl2VddP15f0LRAdr0-ME,4834
-cpp_linter/rest_api/__init__.py,sha256=q2ni-aUYxEjBrMFqm4Keu7onofpUnC_eN7-wZoMoV0U,10175
-cpp_linter/rest_api/github_api.py,sha256=YKuutHytMbvodpXlqpgneBOP3Qpzs1chwRMS8_4Nnos,25162
-cpp_linter-1.8.1.dist-info/LICENSE,sha256=jQ9ovcGO-7MCWam1lJKfGtUY7nKa7nEc9aIGN7wk6Lw,1067
-cpp_linter-1.8.1.dist-info/METADATA,sha256=CEQWw9riP8hrF8FZG_1qGlGzNrix_wKAmoZiV7tiYDA,2982
-cpp_linter-1.8.1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-cpp_linter-1.8.1.dist-info/entry_points.txt,sha256=M1Lrmr5t_H-90ppdDj3u4z-6gZkK6epIzlYJH5LfRM4,47
-cpp_linter-1.8.1.dist-info/top_level.txt,sha256=9revY4HSck6TvN-QcFh8296Gffnp80dHARWnRzUHmVE,11
-cpp_linter-1.8.1.dist-info/RECORD,,
+cpp_linter/clang_tools/__init__.py,sha256=X9yw0fZJEoFVLG6BJemkKR4DWMArb_xjdoHhqRX1dF0,5940
+cpp_linter/clang_tools/clang_format.py,sha256=rDmgkfavQtde_jfEReHM7a330Ev3HrgO0HXjVMNnGDo,7012
+cpp_linter/clang_tools/clang_tidy.py,sha256=_UH7iaPII77wiWnC6JrKbxjCLylOHCoS4qQ3X3A4blQ,9653
+cpp_linter/common_fs/__init__.py,sha256=Jzcno1ZPhDyL-vlXuDZSFjZ-UJJUo8WfijqXuarK_V4,8183
+cpp_linter/common_fs/file_filter.py,sha256=3pgAJXEJJlzEC-BzcoOKi4wvTI6z-1Re9zo1pwHMOt0,8374
+cpp_linter/git/__init__.py,sha256=euPecyntiAglhbUreyp7Is4gUoLefOmNQJXGJTzoh5A,4940
+cpp_linter/git/git_str.py,sha256=5hJvKuctLBh-pr7OqZTNRQZ5zjFv0ZWjtB0EEKjuR7c,4636
+cpp_linter/rest_api/__init__.py,sha256=Vcd5CEbsoirU5u0iWHzJfmY9l-F0gzBgRkMI2OWoAL4,11915
+cpp_linter/rest_api/github_api.py,sha256=qXvqydacnOczWEw61u8Rsd4CYoLGe_vnDJdPRNkTyI0,21680
+cpp_linter-1.9.0.dist-info/LICENSE,sha256=jQ9ovcGO-7MCWam1lJKfGtUY7nKa7nEc9aIGN7wk6Lw,1067
+cpp_linter-1.9.0.dist-info/METADATA,sha256=5yAu1W0ocFO0qjD13Zfnk-ScqX7OB-BXqWRA9y6USUA,2982
+cpp_linter-1.9.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+cpp_linter-1.9.0.dist-info/entry_points.txt,sha256=M1Lrmr5t_H-90ppdDj3u4z-6gZkK6epIzlYJH5LfRM4,47
+cpp_linter-1.9.0.dist-info/top_level.txt,sha256=9revY4HSck6TvN-QcFh8296Gffnp80dHARWnRzUHmVE,11
+cpp_linter-1.9.0.dist-info/RECORD,,
```

