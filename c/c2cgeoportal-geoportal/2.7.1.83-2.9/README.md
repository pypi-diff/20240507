# Comparing `tmp/c2cgeoportal_geoportal-2.7.1.83-py2.py3-none-any.whl.zip` & `tmp/c2cgeoportal_geoportal-2.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,187 +1,194 @@
-Zip file size: 2571051 bytes, number of entries: 185
--rw-r--r--  2.0 unx    32401 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/py.typed
--rw-r--r--  2.0 unx     2182 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/resources.py
--rw-r--r--  2.0 unx    10290 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/__init__.py
--rw-r--r--  2.0 unx     8997 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/authentication.py
--rw-r--r--  2.0 unx     1889 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/bashcolor.py
--rw-r--r--  2.0 unx     2948 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/cacheversion.py
--rw-r--r--  2.0 unx     6688 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/caching.py
--rw-r--r--  2.0 unx     3414 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/check_collector.py
--rw-r--r--  2.0 unx    12323 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/checker.py
--rw-r--r--  2.0 unx     6458 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/common_headers.py
--rw-r--r--  2.0 unx     9629 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/dbreflection.py
--rw-r--r--  2.0 unx    14172 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/filter_capabilities.py
--rw-r--r--  2.0 unx     2271 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/fulltextsearch.py
--rw-r--r--  2.0 unx     6293 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/functionality.py
--rw-r--r--  2.0 unx     2622 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/headers.py
--rw-r--r--  2.0 unx     1876 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/i18n.py
--rw-r--r--  2.0 unx     4655 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/layers.py
--rw-r--r--  2.0 unx    36888 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/lingua_extractor.py
--rw-r--r--  2.0 unx     2546 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/loader.py
--rw-r--r--  2.0 unx     4524 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/metrics.py
--rw-r--r--  2.0 unx    37216 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/oauth2.py
--rw-r--r--  2.0 unx    12423 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/wmstparsing.py
--rw-r--r--  2.0 unx     6043 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/lib/xsd.py
--rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/cookiecutter.json
--rw-r--r--  2.0 unx      592 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/ci/config.yaml
--rw-r--r--  2.0 unx      147 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.dockerignore
--rw-r--r--  2.0 unx      241 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.eslintrc.yaml
--rw-r--r--  2.0 unx      325 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.prospector.yaml
--rw-r--r--  2.0 unx     2567 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Dockerfile
--rw-r--r--  2.0 unx      147 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Makefile
--rw-r--r--  2.0 unx      985 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.ini
--rw-r--r--  2.0 unx      458 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.yaml
--rw-r--r--  2.0 unx     3068 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/development.ini
--rw-r--r--  2.0 unx     4129 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/gunicorn.conf.py
--rw-r--r--  2.0 unx       27 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/language_mapping
--rw-r--r--  2.0 unx      117 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-client.cfg
--rw-r--r--  2.0 unx      107 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-server.cfg
--rw-r--r--  2.0 unx     1137 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/production.ini
--rw-r--r--  2.0 unx       57 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/requirements.txt
--rw-r--r--  2.0 unx      694 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/setup.py
--rw-r--r--  2.0 unx      186 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tsconfig.json
--rw-r--r--  2.0 unx     1769 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.api.js
--rw-r--r--  2.0 unx     2438 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.apps.js
--rw-r--r--  2.0 unx      553 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.commons.js
--rw-r--r--  2.0 unx      643 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.config.js
--rw-r--r--  2.0 unx     1201 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tools/extract-messages.js
--rw-r--r--  2.0 unx     1587 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py
--rw-r--r--  2.0 unx      426 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/authentication.py
--rw-r--r--  2.0 unx      387 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/dev.py
--rw-r--r--  2.0 unx      284 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/models.py
--rw-r--r--  2.0 unx      158 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/multi_organization.py
--rw-r--r--  2.0 unx      270 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/resources.py
--rw-r--r--  2.0 unx     1352 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/subscribers.py
--rw-r--r--  2.0 unx      260 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/index.js
--rw-r--r--  2.0 unx      614 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/{{cookiecutter.package}}module.js
--rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/views/__init__.py
--rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_update/cookiecutter.json
--rw-r--r--  2.0 unx     4287 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/advance_update/{{cookiecutter.project}}/geoportal/CONST_Makefile
--rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/cookiecutter.json
--rw-r--r--  2.0 unx      351 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.dockerignore
--rw-r--r--  2.0 unx      297 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.editorconfig
--rw-r--r--  2.0 unx      449 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.gitignore
--rw-r--r--  2.0 unx        9 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierignore
--rw-r--r--  2.0 unx       43 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierrc.yaml
--rw-r--r--  2.0 unx     3360 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile
--rw-r--r--  2.0 unx      715 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Makefile
--rw-r--r--  2.0 unx      423 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst
--rwxr-xr-x  2.0 unx     6167 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build
--rw-r--r--  2.0 unx    12310 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml
--rw-r--r--  2.0 unx     2526 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml
--rw-r--r--  2.0 unx     2429 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml
--rw-r--r--  2.0 unx     2573 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default
--rw-r--r--  2.0 unx     1537 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.project
--rw-r--r--  2.0 unx      495 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/project.yaml
--rw-r--r--  2.0 unx       57 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/pyproject.toml
--rwxr-xr-x  2.0 unx      233 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/run_alembic.sh
--rw-r--r--  2.0 unx      221 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/setup.cfg
--rw-r--r--  2.0 unx       13 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/spell-ignore-words.txt
--rw-r--r--  2.0 unx     1257 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/main.yaml
--rw-r--r--  2.0 unx     1287 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/rebuild.yaml
--rw-r--r--  2.0 unx     2216 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml
--rw-r--r--  2.0 unx      532 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml
--rw-r--r--  2.0 unx       18 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt
--rw-r--r--  2.0 unx    10666 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml
--rw-r--r--  2.0 unx      162 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/locale/en/LC_MESSAGES/{{cookiecutter.package}}_geoportal-client.po
--rw-r--r--  2.0 unx       88 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/robot.txt.tmpl
--rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/desktop.css
--rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/iframe_api.css
--rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/mobile.css
--rw-r--r--  2.0 unx    13799 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_left.png
--rw-r--r--  2.0 unx     6018 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_right.png
--rw-r--r--  2.0 unx      259 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/blank.png
--rw-r--r--  2.0 unx      758 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-blue.png
--rw-r--r--  2.0 unx      703 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-gold.png
--rw-r--r--  2.0 unx      753 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-green.png
--rw-r--r--  2.0 unx      601 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker.png
--rw-r--r--  2.0 unx     7269 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/demo.map.tmpl
--rw-r--r--  2.0 unx      351 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts.conf
--rw-r--r--  2.0 unx     2716 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl
--rw-r--r--  2.0 unx      816 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/tinyows.xml.tmpl
--rw-r--r--  2.0 unx     2892 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt
--rw-r--r--  2.0 unx  1588593 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/TM_EUROPE_BORDERS-0.3.sql
--rw-r--r--  2.0 unx   275572 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arial.ttf
--rw-r--r--  2.0 unx   286620 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbd.ttf
--rw-r--r--  2.0 unx   224692 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbi.ttf
--rw-r--r--  2.0 unx   206132 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Ariali.ttf
--rw-r--r--  2.0 unx   415132 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Bold.ttf
--rw-r--r--  2.0 unx   290436 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-BoldItalic.ttf
--rw-r--r--  2.0 unx   279268 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Italic.ttf
--rw-r--r--  2.0 unx   414820 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Regular.ttf
--rw-r--r--  2.0 unx   139640 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdana.ttf
--rw-r--r--  2.0 unx   136032 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanab.ttf
--rw-r--r--  2.0 unx   154264 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanai.ttf
--rw-r--r--  2.0 unx   153324 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanaz.ttf
--rw-r--r--  2.0 unx    10002 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml
--rw-r--r--  2.0 unx     8707 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml
--rw-r--r--  2.0 unx     9562 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml
--rw-r--r--  2.0 unx     6880 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml
--rw-r--r--  2.0 unx     4774 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/config.yaml.tmpl
--rw-r--r--  2.0 unx     5310 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/legend.jrxml
--rw-r--r--  2.0 unx       98 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation.properties
--rw-r--r--  2.0 unx      102 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation_fr.properties
--rw-r--r--  2.0 unx    13799 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/logo.png
--rw-r--r--  2.0 unx     2925 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/north.svg
--rw-r--r--  2.0 unx     1309 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/results.jrxml
--rw-r--r--  2.0 unx      296 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/qgisserver/pg_service.conf.tmpl
--rwxr-xr-x  2.0 unx     4243 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup
--rwxr-xr-x  2.0 unx     4433 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore
--rw-r--r--  2.0 unx     6181 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl
--rw-r--r--  2.0 unx      539 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/update/cookiecutter.json
--rw-r--r--  2.0 unx     6781 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml
--rw-r--r--  2.0 unx    36854 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt
--rw-r--r--  2.0 unx    21112 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml
--rw-r--r--  2.0 unx    45687 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml
--rw-r--r--  2.0 unx     2863 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/__init__.py
--rw-r--r--  2.0 unx    36312 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/c2cupgrade.py
--rw-r--r--  2.0 unx     3081 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/create_demo_theme.py
--rw-r--r--  2.0 unx     5468 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/manage_users.py
--rw-r--r--  2.0 unx    11528 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/pcreate.py
--rw-r--r--  2.0 unx    11450 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/theme2fts.py
--rw-r--r--  2.0 unx     3299 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/scripts/urllogin.py
--rw-r--r--  2.0 unx     2475 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/templates/login.html
--rw-r--r--  2.0 unx     1528 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/templates/notlogin.html
--rw-r--r--  2.0 unx      369 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/templates/testi18n.html
--rw-r--r--  2.0 unx     2694 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/__init__.py
--rw-r--r--  2.0 unx     2533 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/dev.py
--rw-r--r--  2.0 unx     8589 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/dynamic.py
--rw-r--r--  2.0 unx     5995 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/entry.py
--rw-r--r--  2.0 unx     8330 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/fulltextsearch.py
--rw-r--r--  2.0 unx     2952 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/geometry_processing.py
--rw-r--r--  2.0 unx     5292 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/i18n.py
--rw-r--r--  2.0 unx    28850 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/layers.py
--rw-r--r--  2.0 unx    19104 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/login.py
--rw-r--r--  2.0 unx     8203 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/mapserverproxy.py
--rw-r--r--  2.0 unx     3627 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/memory.py
--rw-r--r--  2.0 unx     5065 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/ogcproxy.py
--rw-r--r--  2.0 unx     9576 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/pdfreport.py
--rw-r--r--  2.0 unx     5897 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/printproxy.py
--rw-r--r--  2.0 unx     5394 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/profile.py
--rw-r--r--  2.0 unx    10453 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/proxy.py
--rw-r--r--  2.0 unx     7570 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/raster.py
--rw-r--r--  2.0 unx     3181 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/resourceproxy.py
--rw-r--r--  2.0 unx     6206 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/shortener.py
--rw-r--r--  2.0 unx    51588 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/theme.py
--rw-r--r--  2.0 unx     8171 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/tinyowsproxy.py
--rw-r--r--  2.0 unx     3455 b- defN 24-May-07 15:28 c2cgeoportal_geoportal/views/vector_tiles.py
--rw-r--r--  2.0 unx     3752 b- defN 24-May-07 15:28 tests/__init__.py
--rw-r--r--  2.0 unx     2941 b- defN 24-May-07 15:28 tests/test_cachebuster.py
--rw-r--r--  2.0 unx    12493 b- defN 24-May-07 15:28 tests/test_caching.py
--rw-r--r--  2.0 unx     3638 b- defN 24-May-07 15:28 tests/test_checker.py
--rw-r--r--  2.0 unx     2223 b- defN 24-May-07 15:28 tests/test_decimaljson.py
--rw-r--r--  2.0 unx     2524 b- defN 24-May-07 15:28 tests/test_headerstween.py
--rw-r--r--  2.0 unx     1003 b- defN 24-May-07 15:28 tests/test_i18n.py
--rw-r--r--  2.0 unx     7357 b- defN 24-May-07 15:28 tests/test_init.py
--rw-r--r--  2.0 unx     3071 b- defN 24-May-07 15:28 tests/test_locale_negociator.py
--rw-r--r--  2.0 unx     3044 b- defN 24-May-07 15:28 tests/test_mapserverproxy_route_predicate.py
--rw-r--r--  2.0 unx    12074 b- defN 24-May-07 15:28 tests/test_raster.py
--rw-r--r--  2.0 unx     9135 b- defN 24-May-07 15:28 tests/test_wmstparsing.py
--rw-r--r--  2.0 unx     6010 b- defN 24-May-07 15:28 tests/xmlstr.py
--rw-r--r--  2.0 unx     2003 b- defN 24-May-07 16:11 c2cgeoportal_geoportal-2.7.1.83.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-May-07 16:11 c2cgeoportal_geoportal-2.7.1.83.dist-info/WHEEL
--rw-r--r--  2.0 unx     1414 b- defN 24-May-07 16:11 c2cgeoportal_geoportal-2.7.1.83.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       29 b- defN 24-May-07 16:11 c2cgeoportal_geoportal-2.7.1.83.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    24602 b- defN 24-May-07 16:11 c2cgeoportal_geoportal-2.7.1.83.dist-info/RECORD
-185 files, 5491542 bytes uncompressed, 2528687 bytes compressed:  54.0%
+Zip file size: 2571423 bytes, number of entries: 192
+-rw-r--r--  2.0 unx    34096 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/py.typed
+-rw-r--r--  2.0 unx     2158 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/resources.py
+-rw-r--r--  2.0 unx    10331 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/__init__.py
+-rw-r--r--  2.0 unx     8899 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/authentication.py
+-rw-r--r--  2.0 unx     1889 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/bashcolor.py
+-rw-r--r--  2.0 unx     2919 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/cacheversion.py
+-rw-r--r--  2.0 unx     7165 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/caching.py
+-rw-r--r--  2.0 unx     3408 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/check_collector.py
+-rw-r--r--  2.0 unx    12598 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/checker.py
+-rw-r--r--  2.0 unx     6488 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/common_headers.py
+-rw-r--r--  2.0 unx     9800 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/dbreflection.py
+-rw-r--r--  2.0 unx    14271 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/filter_capabilities.py
+-rw-r--r--  2.0 unx     2265 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/fulltextsearch.py
+-rw-r--r--  2.0 unx     6298 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/functionality.py
+-rw-r--r--  2.0 unx     2622 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/headers.py
+-rw-r--r--  2.0 unx     1852 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/i18n.py
+-rw-r--r--  2.0 unx     4943 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/layers.py
+-rw-r--r--  2.0 unx    37438 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/lingua_extractor.py
+-rw-r--r--  2.0 unx     2628 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/loader.py
+-rw-r--r--  2.0 unx     4847 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/metrics.py
+-rw-r--r--  2.0 unx    41090 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/oauth2.py
+-rw-r--r--  2.0 unx    12399 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/wmstparsing.py
+-rw-r--r--  2.0 unx     6173 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/lib/xsd.py
+-rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/cookiecutter.json
+-rw-r--r--  2.0 unx      592 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/ci/config.yaml
+-rw-r--r--  2.0 unx      147 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.dockerignore
+-rw-r--r--  2.0 unx      241 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.eslintrc.yaml
+-rw-r--r--  2.0 unx      325 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.prospector.yaml
+-rw-r--r--  2.0 unx     2561 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Dockerfile
+-rw-r--r--  2.0 unx      147 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Makefile
+-rw-r--r--  2.0 unx      985 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.ini
+-rw-r--r--  2.0 unx      458 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.yaml
+-rw-r--r--  2.0 unx     3042 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/development.ini
+-rw-r--r--  2.0 unx     4999 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/gunicorn.conf.py
+-rw-r--r--  2.0 unx       27 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/language_mapping
+-rw-r--r--  2.0 unx      117 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-client.cfg
+-rw-r--r--  2.0 unx      107 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-server.cfg
+-rw-r--r--  2.0 unx     1137 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/production.ini
+-rw-r--r--  2.0 unx       55 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/requirements.txt
+-rw-r--r--  2.0 unx      694 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/setup.py
+-rw-r--r--  2.0 unx      186 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tsconfig.json
+-rw-r--r--  2.0 unx     1966 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.api.js
+-rw-r--r--  2.0 unx     2472 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.apps.js
+-rw-r--r--  2.0 unx      553 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.commons.js
+-rw-r--r--  2.0 unx      643 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.config.js
+-rw-r--r--  2.0 unx     1282 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py
+-rw-r--r--  2.0 unx      426 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/authentication.py
+-rw-r--r--  2.0 unx      387 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/dev.py
+-rw-r--r--  2.0 unx      284 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/models.py
+-rw-r--r--  2.0 unx      158 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/multi_organization.py
+-rw-r--r--  2.0 unx      270 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/resources.py
+-rw-r--r--  2.0 unx     1352 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/subscribers.py
+-rw-r--r--  2.0 unx      260 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/index.js
+-rw-r--r--  2.0 unx      614 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/{{cookiecutter.package}}module.js
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/views/__init__.py
+-rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_update/cookiecutter.json
+-rw-r--r--  2.0 unx     3993 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/advance_update/{{cookiecutter.project}}/geoportal/CONST_Makefile
+-rw-r--r--  2.0 unx      524 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/cookiecutter.json
+-rw-r--r--  2.0 unx      351 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.dockerignore
+-rw-r--r--  2.0 unx      297 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.editorconfig
+-rw-r--r--  2.0 unx      449 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.gitignore
+-rw-r--r--  2.0 unx      773 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.pre-commit-config.yaml
+-rw-r--r--  2.0 unx        9 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierignore
+-rw-r--r--  2.0 unx       43 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierrc.yaml
+-rw-r--r--  2.0 unx     3163 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile
+-rw-r--r--  2.0 unx     3079 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Makefile
+-rw-r--r--  2.0 unx      423 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst
+-rwxr-xr-x  2.0 unx     7010 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build
+-rw-r--r--  2.0 unx      534 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-db.yaml
+-rw-r--r--  2.0 unx    12962 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml
+-rw-r--r--  2.0 unx      590 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-qgis.yaml
+-rw-r--r--  2.0 unx     2522 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml
+-rw-r--r--  2.0 unx     2396 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml
+-rw-r--r--  2.0 unx     3129 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default
+-rw-r--r--  2.0 unx     2070 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.project
+-rw-r--r--  2.0 unx      495 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/project.yaml
+-rw-r--r--  2.0 unx      107 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/pyproject.toml
+-rwxr-xr-x  2.0 unx      235 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/run_alembic.sh
+-rw-r--r--  2.0 unx      221 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/setup.cfg
+-rw-r--r--  2.0 unx       30 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/spell-ignore-words.txt
+-rw-r--r--  2.0 unx     1581 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/main.yaml
+-rw-r--r--  2.0 unx     1287 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/rebuild.yaml
+-rw-r--r--  2.0 unx     2243 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml
+-rw-r--r--  2.0 unx      488 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml
+-rwxr-xr-x  2.0 unx      615 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/docker-compose-check
+-rw-r--r--  2.0 unx       35 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt
+-rw-r--r--  2.0 unx    11877 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml
+-rw-r--r--  2.0 unx      162 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/locale/en/LC_MESSAGES/{{cookiecutter.package}}_geoportal-client.po
+-rw-r--r--  2.0 unx       88 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/robot.txt.tmpl
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/desktop.css
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/iframe_api.css
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/mobile.css
+-rw-r--r--  2.0 unx    13799 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_left.png
+-rw-r--r--  2.0 unx     6018 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_right.png
+-rw-r--r--  2.0 unx      259 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/blank.png
+-rw-r--r--  2.0 unx      758 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-blue.png
+-rw-r--r--  2.0 unx      703 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-gold.png
+-rw-r--r--  2.0 unx      753 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-green.png
+-rw-r--r--  2.0 unx      601 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker.png
+-rw-r--r--  2.0 unx     7269 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/demo.map.tmpl
+-rw-r--r--  2.0 unx      351 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts.conf
+-rw-r--r--  2.0 unx      187 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.conf
+-rw-r--r--  2.0 unx     2698 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl
+-rw-r--r--  2.0 unx      816 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/tinyows.xml.tmpl
+-rw-r--r--  2.0 unx     2891 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt
+-rw-r--r--  2.0 unx  1588593 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/TM_EUROPE_BORDERS-0.3.sql
+-rw-r--r--  2.0 unx   275572 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arial.ttf
+-rw-r--r--  2.0 unx   286620 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbd.ttf
+-rw-r--r--  2.0 unx   224692 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbi.ttf
+-rw-r--r--  2.0 unx   206132 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Ariali.ttf
+-rw-r--r--  2.0 unx   415132 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Bold.ttf
+-rw-r--r--  2.0 unx   290436 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-BoldItalic.ttf
+-rw-r--r--  2.0 unx   279268 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Italic.ttf
+-rw-r--r--  2.0 unx   414820 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Regular.ttf
+-rw-r--r--  2.0 unx   139640 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdana.ttf
+-rw-r--r--  2.0 unx   136032 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanab.ttf
+-rw-r--r--  2.0 unx   154264 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanai.ttf
+-rw-r--r--  2.0 unx   153324 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanaz.ttf
+-rw-r--r--  2.0 unx    10262 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml
+-rw-r--r--  2.0 unx     8967 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml
+-rw-r--r--  2.0 unx     9822 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml
+-rw-r--r--  2.0 unx     7096 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml
+-rw-r--r--  2.0 unx     4914 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/config.yaml.tmpl
+-rw-r--r--  2.0 unx     5310 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/legend.jrxml
+-rw-r--r--  2.0 unx       98 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation.properties
+-rw-r--r--  2.0 unx      102 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation_fr.properties
+-rw-r--r--  2.0 unx    13799 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/logo.png
+-rw-r--r--  2.0 unx     2925 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/north.svg
+-rw-r--r--  2.0 unx     1309 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/results.jrxml
+-rw-r--r--  2.0 unx      296 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/qgisserver/pg_service.conf.tmpl
+-rwxr-xr-x  2.0 unx     4274 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup
+-rwxr-xr-x  2.0 unx     4436 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore
+-rw-r--r--  2.0 unx        0 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/__init__.py
+-rw-r--r--  2.0 unx     1540 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/test_app.py
+-rw-r--r--  2.0 unx     6181 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl
+-rw-r--r--  2.0 unx      539 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/cookiecutter.json
+-rw-r--r--  2.0 unx     2559 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml
+-rw-r--r--  2.0 unx     8351 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt
+-rw-r--r--  2.0 unx     1796 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_create_template/tests/test_testapp.py
+-rw-r--r--  2.0 unx    21333 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml
+-rw-r--r--  2.0 unx    47879 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml
+-rw-r--r--  2.0 unx     2857 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/__init__.py
+-rw-r--r--  2.0 unx    36742 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/c2cupgrade.py
+-rw-r--r--  2.0 unx     3081 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/create_demo_theme.py
+-rw-r--r--  2.0 unx     5586 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/manage_users.py
+-rw-r--r--  2.0 unx    11580 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/pcreate.py
+-rw-r--r--  2.0 unx    13737 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/theme2fts.py
+-rw-r--r--  2.0 unx     3299 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/scripts/urllogin.py
+-rw-r--r--  2.0 unx     2475 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/templates/login.html
+-rw-r--r--  2.0 unx     1528 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/templates/notlogin.html
+-rw-r--r--  2.0 unx      369 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/templates/testi18n.html
+-rw-r--r--  2.0 unx     2639 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/__init__.py
+-rw-r--r--  2.0 unx     2533 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/dev.py
+-rw-r--r--  2.0 unx     8575 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/dynamic.py
+-rw-r--r--  2.0 unx     5727 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/entry.py
+-rw-r--r--  2.0 unx     8397 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/fulltextsearch.py
+-rw-r--r--  2.0 unx     2984 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/geometry_processing.py
+-rw-r--r--  2.0 unx     5292 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/i18n.py
+-rw-r--r--  2.0 unx    29623 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/layers.py
+-rw-r--r--  2.0 unx    22884 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/login.py
+-rw-r--r--  2.0 unx     8156 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/mapserverproxy.py
+-rw-r--r--  2.0 unx     3621 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/memory.py
+-rw-r--r--  2.0 unx     5244 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/ogcproxy.py
+-rw-r--r--  2.0 unx     9609 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/pdfreport.py
+-rw-r--r--  2.0 unx     5856 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/printproxy.py
+-rw-r--r--  2.0 unx     5375 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/profile.py
+-rw-r--r--  2.0 unx    10393 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/proxy.py
+-rw-r--r--  2.0 unx     7554 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/raster.py
+-rw-r--r--  2.0 unx     3181 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/resourceproxy.py
+-rw-r--r--  2.0 unx     6137 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/shortener.py
+-rw-r--r--  2.0 unx    54869 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/theme.py
+-rw-r--r--  2.0 unx     7913 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/tinyowsproxy.py
+-rw-r--r--  2.0 unx     3568 b- defN 24-May-07 15:29 c2cgeoportal_geoportal/views/vector_tiles.py
+-rw-r--r--  2.0 unx     3826 b- defN 24-May-07 15:29 tests/__init__.py
+-rw-r--r--  2.0 unx     2923 b- defN 24-May-07 15:29 tests/test_cachebuster.py
+-rw-r--r--  2.0 unx    12493 b- defN 24-May-07 15:29 tests/test_caching.py
+-rw-r--r--  2.0 unx     3638 b- defN 24-May-07 15:29 tests/test_checker.py
+-rw-r--r--  2.0 unx     2223 b- defN 24-May-07 15:29 tests/test_decimaljson.py
+-rw-r--r--  2.0 unx     2524 b- defN 24-May-07 15:29 tests/test_headerstween.py
+-rw-r--r--  2.0 unx      994 b- defN 24-May-07 15:29 tests/test_i18n.py
+-rw-r--r--  2.0 unx     7494 b- defN 24-May-07 15:29 tests/test_init.py
+-rw-r--r--  2.0 unx     3044 b- defN 24-May-07 15:29 tests/test_locale_negociator.py
+-rw-r--r--  2.0 unx     3043 b- defN 24-May-07 15:29 tests/test_mapserverproxy_route_predicate.py
+-rw-r--r--  2.0 unx    11948 b- defN 24-May-07 15:29 tests/test_raster.py
+-rw-r--r--  2.0 unx     9054 b- defN 24-May-07 15:29 tests/test_wmstparsing.py
+-rw-r--r--  2.0 unx     5985 b- defN 24-May-07 15:29 tests/xmlstr.py
+-rw-r--r--  2.0 unx     1922 b- defN 24-May-07 16:19 c2cgeoportal_geoportal-2.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-07 16:19 c2cgeoportal_geoportal-2.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx     1415 b- defN 24-May-07 16:19 c2cgeoportal_geoportal-2.9.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       29 b- defN 24-May-07 16:19 c2cgeoportal_geoportal-2.9.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    25572 b- defN 24-May-07 16:19 c2cgeoportal_geoportal-2.9.dist-info/RECORD
+192 files, 5492912 bytes uncompressed, 2527367 bytes compressed:  54.0%
```

## zipnote {}

```diff
@@ -132,17 +132,14 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.commons.js
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.config.js
 Comment: 
 
-Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tools/extract-messages.js
-Comment: 
-
 Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/authentication.py
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/dev.py
@@ -183,14 +180,17 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.editorconfig
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.gitignore
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.pre-commit-config.yaml
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierignore
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierrc.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile
@@ -201,17 +201,23 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-db.yaml
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-qgis.yaml
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default
@@ -243,14 +249,17 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/docker-compose-check
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/locale/en/LC_MESSAGES/{{cookiecutter.package}}_geoportal-client.po
@@ -291,14 +300,17 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/demo.map.tmpl
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts.conf
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.conf
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/tinyows.xml.tmpl
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt
@@ -381,26 +393,35 @@
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/__init__.py
+Comment: 
+
+Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/test_app.py
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/update/cookiecutter.json
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt
 Comment: 
 
+Filename: c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_create_template/tests/test_testapp.py
+Comment: 
+
 Filename: c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml
 Comment: 
 
 Filename: c2cgeoportal_geoportal/scripts/__init__.py
@@ -534,23 +555,23 @@
 
 Filename: tests/test_wmstparsing.py
 Comment: 
 
 Filename: tests/xmlstr.py
 Comment: 
 
-Filename: c2cgeoportal_geoportal-2.7.1.83.dist-info/METADATA
+Filename: c2cgeoportal_geoportal-2.9.dist-info/METADATA
 Comment: 
 
-Filename: c2cgeoportal_geoportal-2.7.1.83.dist-info/WHEEL
+Filename: c2cgeoportal_geoportal-2.9.dist-info/WHEEL
 Comment: 
 
-Filename: c2cgeoportal_geoportal-2.7.1.83.dist-info/entry_points.txt
+Filename: c2cgeoportal_geoportal-2.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: c2cgeoportal_geoportal-2.7.1.83.dist-info/top_level.txt
+Filename: c2cgeoportal_geoportal-2.9.dist-info/top_level.txt
 Comment: 
 
-Filename: c2cgeoportal_geoportal-2.7.1.83.dist-info/RECORD
+Filename: c2cgeoportal_geoportal-2.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## c2cgeoportal_geoportal/__init__.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,51 +24,55 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import importlib
 import logging
 import os
+import urllib.parse
 from functools import partial
-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, cast
-from urllib.parse import urlsplit
+from typing import TYPE_CHECKING, Any, Callable, Optional, cast
 
 import c2cgeoform
 import c2cwsgiutils
 import c2cwsgiutils.db
 import c2cwsgiutils.index
 import pyramid.config
 import pyramid.renderers
 import pyramid.request
 import pyramid.response
 import pyramid.security
+import sqlalchemy
+import sqlalchemy.orm
 import zope.event.classhandler
-from c2cgeoform import Form, translator
+from c2cgeoform import translator
 from c2cwsgiutils.broadcast import decorator
 from c2cwsgiutils.health_check import HealthCheck
-from c2cwsgiutils.metrics import MemoryMapProvider, add_provider
-from dogpile.cache import register_backend
+from c2cwsgiutils.prometheus import MemoryMapCollector
+from deform import Form
+from dogpile.cache import register_backend  # type: ignore[attr-defined]
 from papyrus.renderers import GeoJSON
+from prometheus_client.core import REGISTRY
 from pyramid.config import Configurator
-from pyramid.httpexceptions import HTTPException
+from pyramid.httpexceptions import HTTPBadRequest, HTTPException
 from pyramid.path import AssetResolver
 from pyramid_mako import add_mako_renderer
 from sqlalchemy.orm import Session, joinedload
 
 import c2cgeoportal_commons.models
 import c2cgeoportal_geoportal.views
 from c2cgeoportal_commons.models import InvalidateCacheEvent
 from c2cgeoportal_geoportal.lib import C2CPregenerator, caching, check_collector, checker
 from c2cgeoportal_geoportal.lib.cacheversion import version_cache_buster
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
 from c2cgeoportal_geoportal.lib.i18n import available_locale_names
 from c2cgeoportal_geoportal.lib.metrics import (
-    MemoryCacheSizeProvider,
-    RasterDataSizeProvider,
-    TotalPythonObjectMemoryProvider,
+    MemoryCacheSizeCollector,
+    RasterDataSizeCollector,
+    TotalPythonObjectMemoryCollector,
 )
 from c2cgeoportal_geoportal.lib.xsd import XSD
 from c2cgeoportal_geoportal.views.entry import Entry, canvas_view
 
 if TYPE_CHECKING:
     from c2cgeoportal_commons.models import static  # pylint: disable=ungrouped-imports,useless-suppression
 
@@ -83,40 +87,40 @@
 class AssetRendererFactory:
     """Get a renderer for the assets."""
 
     def __init__(self, info: Any):
         del info  # unused
         self.resolver = AssetResolver("c2cgeoportal_geoportal")
 
-    def __call__(self, value: Any, system: Dict[str, str]) -> bytes:
+    def __call__(self, value: Any, system: dict[str, str]) -> bytes:
         del value
         asset = self.resolver.resolve(system["renderer_name"])
         return cast(bytes, asset.stream().read())
 
 
 INTERFACE_TYPE_NGEO = "ngeo"
 INTERFACE_TYPE_CANVAS = "canvas"
 
 
-def add_interface_config(config: pyramid.config.Configurator, interface_config: Dict[str, Any]) -> None:
+def add_interface_config(config: pyramid.config.Configurator, interface_config: dict[str, Any]) -> None:
     """Add the interface (desktop, mobile, ...) views and routes with only the config."""
     add_interface(
         config,
         interface_config["name"],
         interface_config.get("type", INTERFACE_TYPE_NGEO),
         interface_config,
         default=interface_config.get("default", False),
     )
 
 
 def add_interface(
     config: pyramid.config.Configurator,
     interface_name: str = "desktop",
     interface_type: str = INTERFACE_TYPE_NGEO,
-    interface_config: Optional[Dict[str, Any]] = None,
+    interface_config: Optional[dict[str, Any]] = None,
     default: bool = False,
     **kwargs: Any,
 ) -> None:
     """Add the interface (desktop, mobile, ...) views and routes."""
     route = "/" if default else f"/{interface_name}"
     if interface_type == INTERFACE_TYPE_NGEO:
         add_interface_ngeo(
@@ -172,15 +176,15 @@
     )
 
 
 def add_interface_canvas(
     config: pyramid.config.Configurator,
     route_name: str,
     route: str,
-    interface_config: Dict[str, Any],
+    interface_config: dict[str, Any],
     permission: Optional[str] = None,
 ) -> None:
     """Add the ngeo interfaces views and routes."""
 
     renderer = f"/etc/geomapfish/interfaces/{route_name}.html.mako"
     config.add_route(route_name, route, request_method="GET")
     # Permalink theme: recover the theme for generating custom viewer.js URL
@@ -203,14 +207,17 @@
         renderer=renderer,
         permission=permission,
     )
 
 
 def add_admin_interface(config: pyramid.config.Configurator) -> None:
     """Add the administration interface views and routes."""
+
+    assert c2cgeoportal_commons.models.DBSession is not None
+
     if config.get_settings().get("enable_admin_interface", False):
         config.add_request_method(
             lambda request: c2cgeoportal_commons.models.DBSession(),
             "dbsession",
             reify=True,
         )
         config.add_view(c2cgeoportal_geoportal.views.add_ending_slash, route_name="admin_add_ending_slash")
@@ -244,66 +251,94 @@
         return request.accept_language.best_match(
             request.registry.settings.get("available_locale_names"),
             default_match=request.registry.settings.get("default_locale_name"),
         )
     return lang
 
 
-def _match_url_start(reference: str, value: List[str]) -> bool:
+def _match_url_start(reference: str, value: list[str]) -> bool:
     """Check that the val URL starts like the ref URL."""
     reference_parts = reference.rstrip("/").split("/")
     value_parts = value[0 : len(reference_parts)]
     return reference_parts == value_parts
 
 
-def is_valid_referrer(request: pyramid.request.Request, settings: Optional[Dict[str, Any]] = None) -> bool:
+def is_allowed_url(
+    request: pyramid.request.Request, url: str, allowed_hosts: list[str]
+) -> tuple[Optional[str], bool]:
+    """
+    Check if the URL is allowed.
+
+    Allowed if URL netloc is request host or is found in allowed hosts.
+    """
+
+    url_netloc = urllib.parse.urlparse(url).netloc
+    return url_netloc, url_netloc == request.host or url_netloc in allowed_hosts
+
+
+def is_valid_referrer(request: pyramid.request.Request, settings: Optional[dict[str, Any]] = None) -> bool:
     """Check if the referrer is valid."""
-    if request.referer is not None:
-        referrer = urlsplit(request.referer)._replace(query="", fragment="").geturl().rstrip("/").split("/")
+    if request.referrer is not None:
         if settings is None:
             settings = request.registry.settings
-        list_ = settings.get("authorized_referers", [])
-        return any(_match_url_start(e, referrer) for e in list_)
+        authorized_referrers = settings.get("authorized_referers", [])
+        referrer_hostname, ok = is_allowed_url(request, request.referrer, authorized_referrers)
+        if not ok:
+            LOG.info(
+                "Invalid referrer hostname '%s', "
+                "is not the current host '%s' "
+                "or part of authorized_referers: %s",
+                referrer_hostname,
+                request.host,
+                ", ".join(authorized_referrers),
+            )
+            return False
     return True
 
 
 def create_get_user_from_request(
-    settings: Dict[str, Any]
+    settings: dict[str, Any]
 ) -> Callable[[pyramid.request.Request, Optional[str]], Optional["static.User"]]:
     """Get the get_user_from_request function."""
 
     def get_user_from_request(
         request: pyramid.request.Request, username: Optional[str] = None
     ) -> Optional["static.User"]:
         """
         Return the User object for the request.
 
         Return ``None`` if:
         * user is anonymous
         * it does not exist in the database
-        * the referer is invalid
+        * it has been deactivated
+        * the referrer is invalid
         """
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
         from c2cgeoportal_commons.models.static import User  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         if not hasattr(request, "is_valid_referer"):
             request.is_valid_referer = is_valid_referrer(request, settings)
         if not request.is_valid_referer:
-            LOG.debug("Invalid referer for %s: %s", request.path_qs, repr(request.referer))
+            LOG.debug("Invalid referrer for %s: %s", request.path_qs, repr(request.referrer))
             return None
 
         if not hasattr(request, "user_"):
             request.user_ = None
             if username is None:
                 username = request.authenticated_userid
             if username is not None:
                 # We know we will need the role object of the
                 # user so we use joined loading
                 request.user_ = (
-                    DBSession.query(User).filter_by(username=username).options(joinedload("roles")).first()
+                    DBSession.query(User)
+                    .filter_by(username=username, deactivated=False)
+                    .options(joinedload(User.roles))
+                    .first()
                 )
 
         return cast(User, request.user_)
 
     return get_user_from_request
 
 
@@ -334,14 +369,16 @@
     This is c2cgeoportal's default user validator. Return None if we are anonymous, the string to remember
     otherwise.
     """
     del request  # unused
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
     from c2cgeoportal_commons.models.static import User  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     user = DBSession.query(User).filter_by(username=username).first()
     if user is None:
         LOG.info('Unknown user "%s" tried to log in', username)
         return None
     if user.deactivated:
         LOG.info('Deactivated user "%s" tried to log in', username)
         return None
@@ -439,46 +476,51 @@
     config.include("pyramid_mako")
     config.include("c2cwsgiutils.pyramid.includeme")
     health_check = HealthCheck(config)
     config.registry["health_check"] = health_check
 
     metrics_config = config.registry.settings["metrics"]
     if metrics_config["memory_maps_rss"]:
-        add_provider(MemoryMapProvider("rss"))
+        REGISTRY.register(MemoryMapCollector("rss"))
     if metrics_config["memory_maps_size"]:
-        add_provider(MemoryMapProvider("size"))
+        REGISTRY.register(MemoryMapCollector("size"))
     if metrics_config["memory_cache"]:
-        add_provider(MemoryCacheSizeProvider(metrics_config.get("memory_cache_all", False)))
+        REGISTRY.register(MemoryCacheSizeCollector(metrics_config.get("memory_cache_all", False)))
     if metrics_config["raster_data"]:
-        add_provider(RasterDataSizeProvider())
+        REGISTRY.register(RasterDataSizeCollector())
     if metrics_config["total_python_object_memory"]:
-        add_provider(TotalPythonObjectMemoryProvider())
+        REGISTRY.register(TotalPythonObjectMemoryCollector())
 
-    # Initialise DBSessions
+    # Initialize DBSessions
     init_db_sessions(settings, config, health_check)
 
     checker.init(config, health_check)
     check_collector.init(config, health_check)
 
     # dogpile.cache configuration
     if "cache" in settings:
-        register_backend("c2cgeoportal.hybrid", "c2cgeoportal_geoportal.lib.caching", "HybridRedisBackend")
+        register_backend(
+            "c2cgeoportal.hybrid",
+            "c2cgeoportal_geoportal.lib.caching",
+            "HybridRedisBackend",
+        )  # type: ignore[no-untyped-call]
         register_backend(
             "c2cgeoportal.hybridsentinel", "c2cgeoportal_geoportal.lib.caching", "HybridRedisSentinelBackend"
-        )
+        )  # type: ignore[no-untyped-call]
         for name, cache_config in settings["cache"].items():
             caching.init_region(cache_config, name)
 
-            @zope.event.classhandler.handler(InvalidateCacheEvent)  # type: ignore
-            def handle(event: InvalidateCacheEvent) -> None:
-                del event
-                caching.invalidate_region()
-                if caching.MEMORY_CACHE_DICT:
-                    caching.get_region("std").delete_multi(list(caching.MEMORY_CACHE_DICT.keys()))
-                caching.MEMORY_CACHE_DICT.clear()
+        @zope.event.classhandler.handler(InvalidateCacheEvent)  # type: ignore[misc]
+        def handle(event: InvalidateCacheEvent) -> None:
+            del event
+            caching.invalidate_region("std")
+            caching.invalidate_region("obj")
+            if caching.MEMORY_CACHE_DICT:
+                caching.get_region("std").delete_multi(list(caching.MEMORY_CACHE_DICT.keys()))
+            caching.MEMORY_CACHE_DICT.clear()
 
     # Register a tween to get back the cache buster path.
     if "cache_path" not in config.get_settings():
         config.get_settings()["cache_path"] = ["static", "static-geomapfish"]
     config.add_tween("c2cgeoportal_geoportal.lib.cacheversion.CachebusterTween")
     config.add_tween("c2cgeoportal_geoportal.lib.headers.HeadersTween")
 
@@ -492,16 +534,18 @@
     # Add the "xsd" renderer
     config.add_renderer("xsd", XSD(include_foreign_keys=True))
 
     # Add the set_user_validator directive, and set a default user validator
     config.add_directive("set_user_validator", set_user_validator)
     config.set_user_validator(default_user_validator)
 
+    config.add_route("oauth2introspect", "/oauth/introspect", request_method="POST")
     config.add_route("oauth2token", "/oauth/token", request_method="POST")
     config.add_route("oauth2loginform", "/oauth/login", request_method="GET")
+    config.add_route("oauth2revoke_token", "/oauth/revoke_token", request_method="GET")
     config.add_route("notlogin", "/notlogin", request_method="GET")
 
     config.add_route("dynamic", "/dynamic.json", request_method="GET")
 
     # Add routes to the mapserver proxy
     config.add_route_predicate("mapserverproxy", MapserverproxyRoutePredicate)
     config.add_route(
@@ -662,14 +706,16 @@
 
     # Dev
     config.add_route("dev", "/dev/*path", request_method="GET")
 
     # Used memory in caches
     config.add_route("memory", "/memory", request_method="GET")
 
+    config.add_route("ogc_server_clear_cache", "clear-ogc-server-cache/{id}", request_method="GET")
+
     # Scan view decorator for adding routes
     config.scan(
         ignore=[
             "c2cgeoportal_geoportal.lib",
             "c2cgeoportal_geoportal.scaffolds",
             "c2cgeoportal_geoportal.scripts",
         ]
@@ -737,31 +783,32 @@
                 '<a href="../{interface}">{interface}</a><br>'.format(interface=interface["name"])
             )
     c2cwsgiutils.index.additional_noauth.append('<a href="../apihelp/index.html">API help</a><br>')
     c2cwsgiutils.index.additional_noauth.append("</div></div><hr>")
 
 
 def init_db_sessions(
-    settings: Dict[str, Any], config: Configurator, health_check: Optional[HealthCheck] = None
+    settings: dict[str, Any], config: Configurator, health_check: Optional[HealthCheck] = None
 ) -> None:
     """Initialize the database sessions."""
     db_chooser = settings.get("db_chooser", {})
     master_paths = [i.replace("//", "/") for i in db_chooser.get("master", [])]
     slave_paths = [i.replace("//", "/") for i in db_chooser.get("slave", [])]
 
     slave_prefix = "sqlalchemy_slave" if "sqlalchemy_slave.url" in settings else None
 
-    c2cgeoportal_commons.models.DBSession, rw_bind, _ = c2cwsgiutils.db.setup_session(
+    c2cgeoportal_commons.models.DBSession, rw_bind, _ = c2cwsgiutils.db.setup_session(  # type: ignore[assignment]
         config, "sqlalchemy", slave_prefix, force_master=master_paths, force_slave=slave_paths
     )
-    c2cgeoportal_commons.models.Base.metadata.bind = rw_bind
+    c2cgeoportal_commons.models.Base.metadata.bind = rw_bind  # type: ignore[attr-defined]
+    assert c2cgeoportal_commons.models.DBSession is not None
     c2cgeoportal_commons.models.DBSessions["dbsession"] = c2cgeoportal_commons.models.DBSession
 
     for dbsession_name, dbsession_config in settings.get("dbsessions", {}).items():  # pragma: nocover
-        c2cgeoportal_commons.models.DBSessions[dbsession_name] = c2cwsgiutils.db.create_session(
+        c2cgeoportal_commons.models.DBSessions[dbsession_name] = c2cwsgiutils.db.create_session(  # type: ignore[assignment]
             config, dbsession_name, **dbsession_config
         )
 
     c2cgeoportal_commons.models.Base.metadata.clear()
     from c2cgeoportal_commons.models import main  # pylint: disable=import-outside-toplevel
 
     if health_check is not None:
@@ -782,11 +829,11 @@
                         alembic_ini_path=alembic_ini,
                         name="static",
                         version_schema=settings["schema_static"],
                         level=1,
                     )
             else:
 
-                def check(session_: Session) -> None:
-                    session_.execute("SELECT 1")
+                def check(session_: sqlalchemy.orm.scoped_session[sqlalchemy.orm.Session]) -> None:
+                    session_.execute(sqlalchemy.text("SELECT 1"))
 
                 health_check.add_db_session_check(session, query_cb=check, level=2)
```

## c2cgeoportal_geoportal/resources.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -21,27 +21,26 @@
 # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
-from typing import List
 
 import pyramid.request
 
 
 class Root:
     """The pyramid root object."""
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
 
 
-def defaultgroupsfinder(username: str, request: pyramid.request.Request) -> List[str]:
+def defaultgroupsfinder(username: str, request: pyramid.request.Request) -> list[str]:
     """
     Get the c2cgeoportal default group finder.
 
     To be used as the callback of the ``AuthTktAuthenticationPolicy`` or any callback-based authentication
     policy.
     """
     del username  # unused
```

## c2cgeoportal_geoportal/lib/__init__.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -27,16 +27,17 @@
 
 
 import datetime
 import ipaddress
 import json
 import logging
 import re
+from collections.abc import Iterable
 from string import Formatter
-from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union, cast
+from typing import Any, Optional, Union, cast
 
 import dateutil
 import pyramid.request
 import pyramid.response
 from pyramid.interfaces import IRoutePregenerator
 from zope.interface import implementer
 
@@ -45,27 +46,27 @@
 from c2cgeoportal_geoportal.lib.caching import get_region
 
 LOG = logging.getLogger(__name__)
 CACHE_REGION = get_region("std")
 CACHE_REGION_OBJ = get_region("obj")
 
 
-def get_types_map(types_array: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
+def get_types_map(types_array: list[dict[str, Any]]) -> dict[str, dict[str, Any]]:
     """Get the type name of a metadata or a functionality."""
     return {type_["name"]: type_ for type_ in types_array}
 
 
 def get_typed(
     name: str,
     value: str,
-    types: Dict[str, Any],
+    types: dict[str, Any],
     request: pyramid.request.Request,
-    errors: Set[str],
+    errors: set[str],
     layer_name: Optional[str] = None,
-) -> Union[str, int, float, bool, None, List[Any], Dict[str, Any]]:
+) -> Union[str, int, float, bool, None, list[Any], dict[str, Any]]:
     """Get the typed (parsed) value of a metadata or a functionality."""
     prefix = f"Layer '{layer_name}': " if layer_name is not None else ""
     type_ = {"type": "not init"}
     try:
         if name not in types:
             errors.add(f"{prefix}Type '{name}' not defined.")
             return None
@@ -104,15 +105,15 @@
             date = dateutil.parser.parse(value, default=datetime.datetime(1, 1, 1, 0, 0, 0))  # type: ignore
             return datetime.datetime.strftime(date, "%Y-%m-%dT%H:%M:%S")
         elif type_["type"] == "url":
             url = get_url2(f"{prefix}The attribute '{name}'", value, request, errors)
             return url.url() if url else ""
         elif type_["type"] == "json":
             try:
-                return cast(Dict[str, Any], json.loads(value))
+                return cast(dict[str, Any], json.loads(value))
             except Exception as e:
                 errors.add(f"{prefix}The attribute '{name}'='{value}' has an error: {str(e)}")
         elif type_["type"] == "regex":
             pattern = type_["regex"]
             if re.match(pattern, value) is None:
                 errors.add(
                     f"{prefix}The regex attribute '{name}'='{value}' "
@@ -137,37 +138,41 @@
         if value and p in value:
             value = value[p]
         else:
             return default
     return value if value else default
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
-def get_ogc_server_wms_url_ids(request: pyramid.request.Request) -> Dict[str, List[int]]:
+@CACHE_REGION_OBJ.cache_on_arguments()
+def get_ogc_server_wms_url_ids(request: pyramid.request.Request) -> dict[str, list[int]]:
     """Get the OGCServer ids mapped on the WMS URL."""
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
     from c2cgeoportal_commons.models.main import OGCServer  # pylint: disable=import-outside-toplevel
 
-    errors: Set[str] = set()
-    servers: Dict[str, List[int]] = {}
+    assert DBSession is not None
+
+    errors: set[str] = set()
+    servers: dict[str, list[int]] = {}
     for ogc_server in DBSession.query(OGCServer).all():
         url = get_url2(ogc_server.name, ogc_server.url, request, errors)
         if url is not None:
             servers.setdefault(url.url(), []).append(ogc_server.id)
     return servers
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
-def get_ogc_server_wfs_url_ids(request: pyramid.request.Request) -> Dict[str, List[int]]:
+@CACHE_REGION_OBJ.cache_on_arguments()
+def get_ogc_server_wfs_url_ids(request: pyramid.request.Request) -> dict[str, list[int]]:
     """Get the OGCServer ids mapped on the WFS URL."""
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
     from c2cgeoportal_commons.models.main import OGCServer  # pylint: disable=import-outside-toplevel
 
-    errors: Set[str] = set()
-    servers: Dict[str, List[int]] = {}
+    assert DBSession is not None
+
+    errors: set[str] = set()
+    servers: dict[str, list[int]] = {}
     for ogc_server in DBSession.query(OGCServer).all():
         url = get_url2(ogc_server.name, ogc_server.url_wfs or ogc_server.url, request, errors)
         if url is not None:
             servers.setdefault(url.url(), []).append(ogc_server.id)
     return servers
 
 
@@ -175,15 +180,15 @@
 class C2CPregenerator:
     """The custom pyramid pregenerator that manage the cache version."""
 
     def __init__(self, version: bool = True, role: bool = False):
         self.version = version
         self.role = role
 
-    def __call__(self, request: pyramid.request.Request, elements: Any, kw: Any) -> Tuple[Any, Any]:
+    def __call__(self, request: pyramid.request.Request, elements: Any, kw: Any) -> tuple[Any, Any]:
         query = {**kw.get("_query", {})}
 
         if self.version:
             query["cache_version"] = get_cache_version()
 
         if self.role and request.user:
             # The templates change if the user is logged in or not. Usually it is
@@ -194,33 +199,35 @@
         kw["_query"] = query
         return elements, kw
 
 
 _formatter = Formatter()
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
+@CACHE_REGION_OBJ.cache_on_arguments()
 def _get_intranet_networks(
     request: pyramid.request.Request,
-) -> List[Union[ipaddress.IPv4Network, ipaddress.IPv6Network]]:
+) -> list[Union[ipaddress.IPv4Network, ipaddress.IPv6Network]]:
     return [
         ipaddress.ip_network(network, strict=False)
         for network in request.registry.settings.get("intranet", {}).get("networks", [])
     ]
 
 
-@CACHE_REGION.cache_on_arguments()  # type: ignore
+@CACHE_REGION.cache_on_arguments()
 def get_role_id(name: str) -> int:
     """Get the role ID."""
     from c2cgeoportal_commons.models import DBSession, main  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     return cast(int, DBSession.query(main.Role.id).filter(main.Role.name == name).one()[0])
 
 
-def get_roles_id(request: pyramid.request.Request) -> List[int]:
+def get_roles_id(request: pyramid.request.Request) -> list[int]:
     """Get the user roles ID."""
     result = [get_role_id(request.get_organization_role("anonymous"))]
     if is_intranet(request):
         result.append(get_role_id(request.get_organization_role("intranet")))
     if request.user is not None:
         result.append(get_role_id(request.get_organization_role("registered")))
         result.extend([r.id for r in request.user.roles])
```

## c2cgeoportal_geoportal/lib/authentication.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2014-2021, Camptocamp SA
+# Copyright (c) 2014-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -27,15 +27,15 @@
 
 
 import binascii
 import json
 import logging
 import os
 import time
-from typing import Any, Callable, Dict, List, Optional, cast
+from typing import Any, Callable, Optional, cast
 
 import pyramid.request
 from Crypto.Cipher import AES  # nosec
 from pyramid.authentication import (
     AuthTktAuthenticationPolicy,
     BasicAuthAuthenticationPolicy,
     CallbackAuthenticationPolicy,
@@ -52,58 +52,56 @@
 
 
 @implementer(IAuthenticationPolicy)
 class UrlAuthenticationPolicy(CallbackAuthenticationPolicy):  # type: ignore
     """An authentication policy based on information given in the URL."""
 
     def __init__(
-        self, aes_key: str, callback: Optional[Callable[[str, Any], List[str]]] = None, debug: bool = False
+        self, aes_key: str, callback: Optional[Callable[[str, Any], list[str]]] = None, debug: bool = False
     ):
         self.aeskey = aes_key
         self.callback = callback
         self.debug = debug
 
     def unauthenticated_userid(self, request: pyramid.request.Request) -> Optional[str]:
         if not request.method == "GET" or "auth" not in request.params:
             return None
         auth_enc = request.params.get("auth")
         if auth_enc is None:
             return None
         try:
             if self.aeskey is None:  # pragma: nocover
-                raise Exception("urllogin is not configured")
+                raise Exception("urllogin is not configured")  # pylint: disable=broad-exception-raised
             now = int(time.time())
             data = binascii.unhexlify(auth_enc.encode("ascii"))
             nonce = data[0:16]
             tag = data[16:32]
             ciphertext = data[32:]
             cipher = AES.new(self.aeskey.encode("ascii"), AES.MODE_EAX, nonce)
-            auth = json.loads(cipher.decrypt_and_verify(ciphertext, tag).decode("utf-8"))  # type: ignore
+            auth = json.loads(cipher.decrypt_and_verify(ciphertext, tag).decode("utf-8"))
 
             if "t" in auth and "u" in auth and "p" in auth:
                 timestamp = int(auth["t"])
 
                 if now < timestamp and request.registry.validate_user(request, auth["u"], auth["p"]):
                     headers = remember(request, auth["u"])
                     request.response.headerlist.extend(headers)
                     return cast(str, auth["u"])
 
         except Exception as e:
             LOG.error("URL login error: %s.", e, exc_info=True)
 
         return None
 
-    def remember(  # pylint: disable=no-self-use
-        self, request: pyramid.request.Request, userid: str, **kw: Any
-    ) -> List[Dict[str, str]]:
+    def remember(self, request: pyramid.request.Request, userid: str, **kw: Any) -> list[dict[str, str]]:
         """Do no-op."""
         del request, userid, kw
         return []
 
-    def forget(self, request: pyramid.request.Request) -> List[Dict[str, str]]:  # pylint: disable=no-self-use
+    def forget(self, request: pyramid.request.Request) -> list[dict[str, str]]:
         """Do no-op."""
         del request
         return []
 
 
 @implementer(IAuthenticationPolicy)
 class OAuth2AuthenticationPolicy(CallbackAuthenticationPolicy):  # type: ignore
@@ -130,25 +128,23 @@
             request.headers,
             [],
         )
         LOG.debug("OAuth verify_request: %s", valid)
         if valid:
             request.user_ = oauth2_request.user
 
-            return cast(str, request.user_.username)
+            return cast(str, request.user.username)
         return None
 
-    def remember(  # pylint: disable=no-self-use
-        self, request: pyramid.request.Request, userid: str, **kw: Any
-    ) -> List[Dict[str, str]]:
+    def remember(self, request: pyramid.request.Request, userid: str, **kw: Any) -> list[dict[str, str]]:
         """Do no-op."""
         del request, userid, kw
         return []
 
-    def forget(self, request: pyramid.request.Request) -> List[Dict[str, str]]:  # pylint: disable=no-self-use
+    def forget(self, request: pyramid.request.Request) -> list[dict[str, str]]:
         """Do no-op."""
         del request
         return []
 
 
 @implementer(IAuthenticationPolicy)
 class DevAuthenticationPolicy(CallbackAuthenticationPolicy):  # type: ignore
@@ -157,15 +153,15 @@
     @staticmethod
     def unauthenticated_userid(request: pyramid.request.Request) -> Optional[str]:
         """Get the user name from the environment variable."""
         del request
         return os.environ["DEV_LOGINNAME"]
 
 
-def create_authentication(settings: Dict[str, Any]) -> MultiAuthenticationPolicy:
+def create_authentication(settings: dict[str, Any]) -> MultiAuthenticationPolicy:
     """Create all the authentication policies."""
     timeout = settings.get("authtkt_timeout")
     timeout = None if timeout is None or timeout.lower() == "none" else int(timeout)
     reissue_time = settings.get("authtkt_reissue_time")
     reissue_time = None if reissue_time is None or reissue_time.lower() == "none" else int(reissue_time)
     max_age = settings.get("authtkt_max_age")
     max_age = None if max_age is None or max_age.lower() == "none" else int(max_age)
@@ -173,15 +169,15 @@
     http_only = http_only.lower() in ("true", "yes", "1")
     secure = settings.get("authtkt_secure", "True")
     secure = secure.lower() in ("true", "yes", "1")
     samesite = settings.get("authtkt_samesite", "Lax")
     secret = settings["authtkt_secret"]
     basicauth = settings.get("basicauth", "False").lower() in ("true", "yes", "1")
     if len(secret) < 64:
-        raise Exception(
+        raise Exception(  # pylint: disable=broad-exception-raised
             '"authtkt_secret should be at least 64 characters.'
             "See https://docs.pylonsproject.org/projects/pyramid/en/latest/api/session.html"
         )
 
     policies = []
 
     policies.append(
@@ -207,26 +203,26 @@
     )
 
     policies.append(OAuth2AuthenticationPolicy())
 
     if basicauth:
         if settings["authentication"].get("two_factor", False):
             LOG.warning(
-                "Basic auth and tow factor auth should not be enable toogether, "
+                "Basic auth and two factor auth should not be enable together, "
                 "you should use OAuth2 instead of Basic auth"
             )
 
         basic_authentication_policy = BasicAuthAuthenticationPolicy(c2cgeoportal_check)
         policies.append(basic_authentication_policy)
 
     # Consider empty string as not configured
     if "DEV_LOGINNAME" in os.environ and os.environ["DEV_LOGINNAME"]:
         policies.append(DevAuthenticationPolicy())
 
     return MultiAuthenticationPolicy(policies)
 
 
-def c2cgeoportal_check(username: str, password: str, request: pyramid.request.Request) -> Optional[List[str]]:
+def c2cgeoportal_check(username: str, password: str, request: pyramid.request.Request) -> Optional[list[str]]:
     """Check the user authentication."""
     if request.registry.validate_user(request, username, password):
         return defaultgroupsfinder(username, request)
     return None
```

## c2cgeoportal_geoportal/lib/cacheversion.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,35 +23,35 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import uuid
-from typing import Any, Callable, Dict, Tuple
+from typing import Any, Callable
 from urllib.parse import urljoin
 
 import pyramid.registry
 import pyramid.request
 import pyramid.response
 
 from c2cgeoportal_geoportal.lib.caching import get_region
 
 CACHE_REGION = get_region("std")
 
 
-@CACHE_REGION.cache_on_arguments()  # type: ignore
+@CACHE_REGION.cache_on_arguments()
 def get_cache_version() -> str:
     """Return a cache version that is regenerate after each cache invalidation."""
     return uuid.uuid4().hex
 
 
 def version_cache_buster(
-    request: pyramid.request.Request, subpath: str, kw: Dict[str, Any]
-) -> Tuple[str, Dict[str, Any]]:
+    request: pyramid.request.Request, subpath: str, kw: dict[str, Any]
+) -> tuple[str, dict[str, Any]]:
     """Join the cash buster version with the sub path."""
     del request  # unused
     return urljoin(get_cache_version() + "/", subpath), kw
 
 
 class CachebusterTween:
     """Get back the cachebuster URL."""
```

## c2cgeoportal_geoportal/lib/caching.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2021, Camptocamp SA
+# Copyright (c) 2012-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,40 +24,39 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import inspect
 import logging
-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional
+from collections.abc import Mapping, Sequence
+from typing import TYPE_CHECKING, Any, Callable, Optional, Union
 
-import sqlalchemy.ext.declarative
-from dogpile.cache.api import NO_VALUE, CacheBackend
+import pyramid.interfaces
+import zope.interface
+from dogpile.cache.api import NO_VALUE, CacheBackend, CachedValue, NoValue
 from dogpile.cache.backends.memory import MemoryBackend
 from dogpile.cache.backends.redis import RedisBackend, RedisSentinelBackend
 from dogpile.cache.region import CacheRegion, make_region
 from dogpile.cache.util import sha1_mangle_key
-from pyramid.request import Request
 from sqlalchemy.orm.util import identity_key
 
 from c2cgeoportal_commons.models import Base
 
 if TYPE_CHECKING:
     from dogpile.cache.api import SerializedReturnType
 else:
     SerializedReturnType = Any
 
 LOG = logging.getLogger(__name__)
-_REGION: Dict[str, Any] = {}
-MEMORY_CACHE_DICT: Dict[str, Any] = {}
+_REGION: dict[str, CacheRegion] = {}
+MEMORY_CACHE_DICT: dict[str, Any] = {}
 
 
-def map_dbobject(
-    item: sqlalchemy.ext.declarative.ConcreteBase,
-) -> sqlalchemy.ext.declarative.ConcreteBase:
+def map_dbobject(item: type[Any]) -> Any:
     """Get an cache identity key for the cache."""
     return identity_key(item) if isinstance(item, Base) else item
 
 
 def keygen_function(namespace: Any, function: Callable[..., Any]) -> Callable[..., str]:
     """
     Return a function that generates a string key.
@@ -74,96 +73,104 @@
 
     args = inspect.getfullargspec(function)
     ignore_first_argument = args[0] and args[0][0] in ("self", "cls")
 
     def generate_key(*args: Any, **kw: Any) -> str:
         if kw:
             raise ValueError("key creation function does not accept keyword arguments.")
-        parts: List[str] = []
+        parts: list[str] = []
         parts.extend(namespace)
         if ignore_first_argument:
             args = args[1:]
-        new_args: List[str] = [arg for arg in args if not isinstance(arg, Request)]
+        new_args = [
+            arg for arg in args if pyramid.interfaces.IRequest not in zope.interface.implementedBy(type(arg))
+        ]
         parts.extend(map(str, map(map_dbobject, new_args)))
         return "|".join(parts)
 
     return generate_key
 
 
-def init_region(conf: Dict[str, Any], region: str) -> CacheRegion:
+def init_region(conf: dict[str, Any], region: str) -> CacheRegion:
     """Initialize the caching module."""
     cache_region = get_region(region)
     _configure_region(conf, cache_region)
     return cache_region
 
 
-def _configure_region(conf: Dict[str, Any], cache_region: CacheRegion) -> None:
-    kwargs: Dict[str, Any] = {"replace_existing_backend": True}
+def _configure_region(conf: dict[str, Any], cache_region: CacheRegion) -> None:
+    kwargs: dict[str, Any] = {"replace_existing_backend": True}
     backend = conf["backend"]
     kwargs.update({k: conf[k] for k in conf if k != "backend"})
-    kwargs.setdefault("arguments", {})
-    kwargs["arguments"]["cache_dict"] = MEMORY_CACHE_DICT
+    kwargs.setdefault("arguments", {}).setdefault("cache_dict", MEMORY_CACHE_DICT)
     cache_region.configure(backend, **kwargs)
 
 
 def get_region(region: str) -> CacheRegion:
     """Return a cache region."""
     if region not in _REGION:
         _REGION[region] = make_region(function_key_generator=keygen_function)
     return _REGION[region]
 
 
 def invalidate_region(region: Optional[str] = None) -> None:
     """Invalidate a cache region."""
     if region is None:
         for cache_region in _REGION.values():
-            cache_region.invalidate()
+            cache_region.invalidate()  # type: ignore[no-untyped-call]
     else:
-        get_region(region).invalidate()
+        get_region(region).invalidate()  # type: ignore[no-untyped-call]
 
 
-class HybridRedisBackend(CacheBackend):  # type: ignore
+class HybridRedisBackend(CacheBackend):
     """A Dogpile cache backend with a memory cache backend in front of a Redis backend for performance."""
 
-    def __init__(self, arguments: Dict[str, Any]):  # pylint: disable=super-init-not-called
+    def __init__(self, arguments: dict[str, Any]):
         self._use_memory_cache = not arguments.pop("disable_memory_cache", False)
-        self._memory = MemoryBackend({"cache_dict": arguments.pop("cache_dict", {})})
-        self._redis = RedisBackend(arguments)
+        self._memory: CacheBackend = MemoryBackend(  # type: ignore[no-untyped-call]
+            {"cache_dict": arguments.pop("cache_dict", {})},
+        )
+        self._redis: CacheBackend = RedisBackend(arguments)  # type: ignore[no-untyped-call]
 
-    def get(self, key: str) -> SerializedReturnType:
+    def get(self, key: str) -> Union[CachedValue, bytes, NoValue]:
         value = self._memory.get(key)
         if value == NO_VALUE:
-            val = self._redis.get_serialized(sha1_mangle_key(key.encode()))
+            val = self._redis.get_serialized(sha1_mangle_key(key.encode()))  # type: ignore[no-untyped-call]
             if val in (None, NO_VALUE):
                 return NO_VALUE
-            value = self._redis.deserializer(val)
+            assert isinstance(val, bytes)
+            value = self._redis.deserializer(val)  # type: ignore[misc]
             if value != NO_VALUE and self._use_memory_cache:
+                assert isinstance(value, (CachedValue, bytes))
                 self._memory.set(key, value)
         return value
 
-    def get_multi(self, keys: List[str]) -> List[SerializedReturnType]:
+    def get_multi(self, keys: Sequence[str]) -> list[Union[CachedValue, bytes, NoValue]]:
         return [self.get(key) for key in keys]
 
-    def set(self, key: str, value: SerializedReturnType) -> None:
+    def set(self, key: str, value: Union[CachedValue, bytes]) -> None:
         if self._use_memory_cache:
             self._memory.set(key, value)
-        self._redis.set_serialized(sha1_mangle_key(key.encode()), self._redis.serializer(value))
+        self._redis.set_serialized(
+            sha1_mangle_key(key.encode()),  # type: ignore[no-untyped-call]
+            self._redis.serializer(value),  # type: ignore[misc]
+        )
 
-    def set_multi(self, mapping: Dict[str, SerializedReturnType]) -> None:
+    def set_multi(self, mapping: Mapping[str, Union[CachedValue, bytes]]) -> None:
         for key, value in mapping.items():
             self.set(key, value)
 
     def delete(self, key: str) -> None:
         self._memory.delete(key)
         self._redis.delete(key)
 
-    def delete_multi(self, keys: List[str]) -> None:
+    def delete_multi(self, keys: Sequence[str]) -> None:
         self._memory.delete_multi(keys)
         self._redis.delete_multi(keys)
 
 
 class HybridRedisSentinelBackend(HybridRedisBackend):
     """Same as HybridRedisBackend but using the Redis Sentinel."""
 
-    def __init__(self, arguments: Dict[str, Any]):
+    def __init__(self, arguments: dict[str, Any]):
         super().__init__(arguments)
-        self._redis = RedisSentinelBackend(arguments)
+        self._redis = RedisSentinelBackend(arguments)  # type: ignore[no-untyped-call]
```

## c2cgeoportal_geoportal/lib/check_collector.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -21,15 +21,15 @@
 # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 import logging
-from typing import Any, Dict, Optional, cast
+from typing import Any, Optional, cast
 
 import c2cwsgiutils.health_check
 import pyramid.config
 import pyramid.request
 import requests
 
 from c2cgeoportal_geoportal.lib.checker import build_url
@@ -50,31 +50,31 @@
     c2c_base = global_settings.get("c2c.base_path", "")
 
     max_level = settings["max_level"]
 
     for host in settings["hosts"]:
 
         class Check:
-            def __init__(self, host: Dict[str, Any]):
+            def __init__(self, host: dict[str, Any]):
                 self.host = host
 
-            def __call__(self, request: pyramid.request.Request) -> Optional[Dict[str, Any]]:
+            def __call__(self, request: pyramid.request.Request) -> Optional[dict[str, Any]]:
                 params = request.params
                 display = self.host["display"]
                 if "host" not in params or display == params["host"]:
                     url_headers = build_url(
                         "check_collector",
                         f"{self.host['url'].rstrip('/')}/{c2c_base.strip('/')}/health_check",
                         request,
                     )
                     r = requests.get(
                         params={"max_level": str(self.host.get("max_level", max_level))},
                         timeout=120,
                         **url_headers,  # type: ignore
                     )
                     r.raise_for_status()
-                    return cast(Dict[str, Any], r.json())
+                    return cast(dict[str, Any], r.json())
                 return None
 
         health_check.add_custom_check(
             name="check_collector_" + host["display"], check_cb=Check(host), level=settings["level"]
         )
```

## c2cgeoportal_geoportal/lib/checker.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -25,83 +25,84 @@
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import json
 import logging
 import os
 import subprocess
+from collections.abc import Mapping
 from time import sleep
-from typing import Any, Dict, List, Mapping, Optional, Union, cast
+from typing import Any, Optional, Union, cast
 from urllib.parse import urljoin
 
 import c2cwsgiutils.health_check
 import pyramid.config
 import pyramid.request
 import requests
 
 LOG = logging.getLogger(__name__)
 
 
 def build_url(
-    name: str, path: str, request: pyramid.request.Request, headers: Optional[Dict[str, str]] = None
-) -> Dict[str, Union[str, Dict[str, str]]]:
+    name: str, path: str, request: pyramid.request.Request, headers: Optional[dict[str, str]] = None
+) -> dict[str, Union[str, dict[str, str]]]:
     """Build an URL and headers for the checkers."""
     base_internal_url = request.registry.settings["checker"]["base_internal_url"]
     url = urljoin(base_internal_url, path)
 
     forward_host = request.registry.settings["checker"].get("forward_host", False)
     headers = _build_headers(request, headers)
     if forward_host:
         headers["Host"] = request.host
 
     LOG.debug("%s, URL: %s", name, url)
     return {"url": url, "headers": headers}
 
 
 def _build_headers(
-    request: pyramid.request.Request, headers: Optional[Dict[str, str]] = None
-) -> Dict[str, str]:
+    request: pyramid.request.Request, headers: Optional[dict[str, str]] = None
+) -> dict[str, str]:
     if headers is None:
         headers = {}
     headers["Cache-Control"] = "no-cache"
     settings = request.registry.settings.get("checker", {})
     for header in settings.get("forward_headers", []):
         value = request.headers.get(header)
         if value is not None:
             headers[header] = value
     return headers
 
 
-def _routes(settings: Dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
+def _routes(settings: dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
     routes_settings = settings["routes"]
     for route in routes_settings["routes"]:
         if route.get("checker_name", route["name"]) not in routes_settings["disable"]:
             name = "checker_routes_" + route.get("checker_name", route["name"])
 
             class GetRequest:
                 """Get the request information about the current route name."""
 
                 def __init__(self, route_name: str, type_: str) -> None:
                     self.route_name = route_name
                     self.type = type_
 
-                def __call__(self, request: pyramid.request.Request) -> Union[str, Dict[str, str]]:
+                def __call__(self, request: pyramid.request.Request) -> Union[str, dict[str, str]]:
                     return build_url("route", request.route_path(self.route_name), request)[self.type]
 
             health_check.add_url_check(
                 url=GetRequest(route["name"], "url"),  # type: ignore
                 name=name,
                 params=route.get("params", None),
                 headers=GetRequest(route["name"], "headers"),  # type: ignore
                 level=route["level"],
                 timeout=30,
             )
 
 
-def _pdf3(settings: Dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
+def _pdf3(settings: dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
     print_settings = settings["print"]
     if "spec" not in print_settings:
         return
 
     def check(request: pyramid.request.Request) -> None:
         path = request.route_path("printproxy_report_create", format="pdf")
         url_headers = build_url("Check the printproxy request (create)", path, request)
@@ -118,31 +119,33 @@
         while not done:
             sleep(1)
             resp = session.get(timeout=30, **url_headers)  # type: ignore
             resp.raise_for_status()
 
             status = resp.json()
             if "error" in status:
-                raise Exception(f"Failed to do the printing: {status['error']}")
+                raise Exception(  # pylint: disable=broad-exception-raised
+                    f"Failed to do the printing: {status['error']}",
+                )
             done = status["done"]
 
         path = request.route_path("printproxy_report_get", ref=job["ref"])
         url_headers = build_url("Check the printproxy pdf retrieve", path, request)
         resp = session.get(timeout=30, **url_headers)  # type: ignore
         resp.raise_for_status()
 
     health_check.add_custom_check(name="checker_print", check_cb=check, level=print_settings["level"])
 
 
-def _fts(settings: Dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
+def _fts(settings: dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
     fts_settings = settings["fulltextsearch"]
     if fts_settings.get("disable", False):
         return
 
-    def get_both(request: pyramid.request.Request) -> Dict[str, Union[str, Dict[str, str]]]:
+    def get_both(request: pyramid.request.Request) -> dict[str, Union[str, dict[str, str]]]:
         return build_url("Check the fulltextsearch", request.route_path("fulltextsearch"), request)
 
     def check(_request: pyramid.request.Request, response: pyramid.response.Response) -> None:
         assert response.json()["features"], "No result"
 
     health_check.add_url_check(
         name="checker_fulltextsearch",
@@ -150,27 +153,29 @@
         headers=lambda r: get_both(r)["headers"],  # type: ignore
         params={"query": fts_settings["search"], "limit": "1"},
         check_cb=check,
         level=fts_settings["level"],
     )
 
 
-def _themes_errors(settings: Dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
+def _themes_errors(settings: dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
     from c2cgeoportal_commons.models.main import Interface  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     themes_settings = settings["themes"]
     default_params = themes_settings.get("params", {})
     interfaces_settings = themes_settings["interfaces"]
 
     def check(request: pyramid.request.Request) -> None:
         path = request.route_path("themes")
         session = requests.session()
         for (interface,) in DBSession.query(Interface.name).all():
-            params: Dict[str, str] = {}
+            params: dict[str, str] = {}
             params.update(default_params)
             params.update(interfaces_settings.get(interface, {}).get("params", {}))
             params["interface"] = interface
 
             interface_url_headers = build_url("checker_themes " + interface, path, request)
 
             response = session.get(params=params, timeout=120, **interface_url_headers)  # type: ignore
@@ -182,16 +187,16 @@
                     f"Interface '{interface}' has error in Theme.", result["errors"]
                 )
 
     health_check.add_custom_check(name="checker_themes", check_cb=check, level=themes_settings["level"])
 
 
 def _lang_files(
-    global_settings: Dict[str, Any],
-    settings: Dict[str, Any],
+    global_settings: dict[str, Any],
+    settings: dict[str, Any],
     health_check: c2cwsgiutils.health_check.HealthCheck,
 ) -> None:
     lang_settings = settings["lang"]
     available_locale_names = global_settings["available_locale_names"]
 
     default_name = global_settings["default_locale_name"]
     assert default_name in available_locale_names, (
@@ -200,15 +205,17 @@
     )
 
     for type_ in lang_settings.get("files", []):
         for lang in available_locale_names:
             if type_ == "ngeo":
                 url = f"/etc/geomapfish/static/{lang}.json"
             else:
-                raise Exception(f"Your language type value '{type_}' is not valid, available values [ngeo]")
+                raise Exception(  # pylint: disable=broad-exception-raised
+                    f"Your language type value '{type_}' is not valid, available values [ngeo]",
+                )
 
             name = f"checker_lang_{type_}_{lang}"
 
             class GetRequest:
                 """Get the request information about the current route name."""
 
                 def __init__(self, name: str, url: str, lang: str, type_: str) -> None:
@@ -230,46 +237,46 @@
                 name=name,
                 url=GetRequest(name, url, lang, "url"),  # type: ignore
                 headers=GetRequest(name, url, lang, "headers"),  # type: ignore
                 level=lang_settings["level"],
             )
 
 
-def _phantomjs(settings: Dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
+def _phantomjs(settings: dict[str, Any], health_check: c2cwsgiutils.health_check.HealthCheck) -> None:
     phantomjs_settings = settings["phantomjs"]
     for route in phantomjs_settings["routes"]:
         if route.get("checker_name", route["name"]) in phantomjs_settings["disable"]:
             continue
 
         class _Check:
-            def __init__(self, route: Dict[str, Any]) -> None:
+            def __init__(self, route: dict[str, Any]) -> None:
                 self.route = route
 
             def __call__(self, request: pyramid.request.Request) -> None:
                 path = request.route_path(self.route["name"], _query=self.route.get("params", {}))
                 url: str = cast(str, build_url("Check", path, request)["url"])
 
-                cmd: List[str] = ["node", "/usr/bin/check-example.js", url]
+                cmd: list[str] = ["check-example", url]
                 env = dict(os.environ)
                 for name, value in self.route.get("environment", {}).items():
                     if isinstance(value, (list, dict)):
                         value = json.dumps(value)
                     elif not isinstance(value, str):
                         value = str(value)
                     env[name] = value
 
                 try:
                     subprocess.check_output(cmd, env=env, timeout=70)
                 except subprocess.CalledProcessError as exception:
-                    raise Exception(
+                    raise Exception(  # pylint: disable=broad-exception-raised
                         f"{' '.join(exception.cmd)} exit with code: {exception.returncode}\n"
                         f"{exception.output.decode('utf-8')[:10000]}"
                     ) from exception
                 except subprocess.TimeoutExpired as exception:
-                    raise Exception(
+                    raise Exception(  # pylint: disable=broad-exception-raised
                         f"""Timeout:
 command: {' '.join(exception.cmd)}
 output:
 {exception.output.decode('utf-8')}"""
                     ) from exception
 
         name = "checker_phantomjs_" + route.get("checker_name", route["name"])
```

## c2cgeoportal_geoportal/lib/common_headers.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2021, Camptocamp SA
+# Copyright (c) 2012-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,15 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
 from enum import Enum
-from typing import Any, Dict, List, Optional, cast
+from typing import Any, Optional, cast
 
 import pyramid.request
 import pyramid.response
 
 from c2cgeoportal_geoportal.lib import is_intranet
 
 _LOG = logging.getLogger(__name__)
@@ -55,29 +55,29 @@
 CORS_METHODS = "HEAD, GET, POST, PUT, DELETE"
 
 
 def _set_cors_headers(
     request: pyramid.request.Request,
     response: pyramid.response.Response,
     service_name: str,
-    service_headers_settings: Dict[str, Any],
+    service_headers_settings: dict[str, Any],
     credentials: bool,
 ) -> None:
     """Handle CORS requests, as specified in https://www.w3.org/TR/cors/."""
     response.vary = (response.vary or ()) + ("Origin",)
 
     if "Origin" not in request.headers:
         return  # Not a CORS request if this header is missing
     origin = request.headers["Origin"]
 
     if request.method == "OPTIONS" and "Access-Control-Request-Method" not in request.headers:
         _LOG.warning("CORS preflight query missing the Access-Control-Request-Method header")
         return
 
-    allowed_origins = cast(List[str], service_headers_settings.get("access_control_allow_origin", []))
+    allowed_origins = cast(list[str], service_headers_settings.get("access_control_allow_origin", []))
     if origin not in allowed_origins:
         if "*" in allowed_origins:
             origin = "*"
             credentials = False  # Force no credentials
         else:
             _LOG.warning("CORS query not allowed for origin=%s, service=%s", origin, service_name)
             return
@@ -109,15 +109,15 @@
     # If we start using headers in responses, we'll have to add
     # Access-Control-Expose-Headers
 
 
 def _set_common_headers(
     request: pyramid.request.Request,
     response: pyramid.response.Response,
-    service_headers_settings: Dict[str, Dict[str, str]],
+    service_headers_settings: dict[str, dict[str, str]],
     cache: Cache,
     content_type: Optional[str],
 ) -> pyramid.response.Response:
     """Set the common headers."""
 
     response.headers.update(service_headers_settings.get("headers", {}))
 
@@ -137,15 +137,15 @@
         response.cache_control.public = True
     elif cache in (Cache.PRIVATE, Cache.PRIVATE_NO):
         if hasattr(request, "user") and request.user is not None or is_intranet(request):
             response.cache_control.private = True
         else:
             response.cache_control.public = True
     else:
-        raise Exception("Invalid cache type")
+        raise Exception("Invalid cache type")  # pylint: disable=broad-exception-raised
 
     if content_type is not None:
         response.content_type = content_type
 
     return response
```

## c2cgeoportal_geoportal/lib/dbreflection.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,15 +24,16 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import random
 import threading
 import warnings
-from typing import Dict, Iterable, List, Optional, Tuple, Union
+from collections.abc import Iterable
+from typing import Any, Optional, Union
 
 import sqlalchemy.ext.declarative
 from papyrus.geo_interface import GeoInterface
 from sqlalchemy import Column, Integer, MetaData, Table
 from sqlalchemy.exc import SAWarning
 from sqlalchemy.orm import relationship
 from sqlalchemy.orm.session import Session
@@ -59,40 +60,42 @@
         self.value_attr = value_attr
         self.nullable = nullable
         self.order_by = order_by
 
     def __get__(
         self,
         obj: sqlalchemy.ext.declarative.ConcreteBase,
-        type_: sqlalchemy.ext.declarative.DeclarativeMeta = None,
+        type_: Optional[sqlalchemy.ext.declarative.DeclarativeMeta] = None,
     ) -> Optional[Union["_AssociationProxy", str]]:
         if obj is None:
             # For "hybrid" descriptors that work both at the instance
             # and class levels we could return an SQL expression here.
             # The code of hybrid_property in SQLAlchemy illustrates
             # how to do that.
             return self
         target = getattr(obj, self.target)
         return getattr(target, self.value_attr) if target else None
 
     def __set__(self, obj: str, val: str) -> None:
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         o = getattr(obj, self.target)
         # if the obj as no child object or if the child object
         # does not correspond to the new value then we need to
         # read a new child object from the database
         if not o or getattr(o, self.value_attr) != val:
             relationship_property = class_mapper(obj.__class__).get_property(self.target)
             child_cls = relationship_property.argument
             o = DBSession.query(child_cls).filter(getattr(child_cls, self.value_attr) == val).first()
             setattr(obj, self.target, o)
 
 
-def _get_schema(tablename: str) -> Tuple[str, str]:
+def _get_schema(tablename: str) -> tuple[str, str]:
     if "." in tablename:
         schema, tablename = tablename.split(".", 1)
     else:
         schema = "public"
 
     return tablename, schema
 
@@ -107,44 +110,50 @@
     primary_key: Optional[str] = None,
 ) -> Table:
     """Build an SQLAlchemy table."""
     if schema is None:
         tablename, schema = _get_schema(tablename)
 
     if session is not None:
+        assert session.bind is not None
         engine = session.bind.engine
-        metadata = MetaData(bind=engine)
+        metadata = MetaData()
     else:
         from c2cgeoportal_commons.models import Base  # pylint: disable=import-outside-toplevel
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+        assert DBSession.bind is not None
+
         engine = DBSession.bind.engine
         metadata = Base.metadata
 
     # create table and reflect it
     with warnings.catch_warnings():
         warnings.filterwarnings("ignore", "Did not recognize type 'geometry' of column", SAWarning)
         args = [tablename, metadata]
         if primary_key is not None:
             # Ensure we have a primary key to be able to edit views
             args.append(Column(primary_key, Integer, primary_key=True))
         with _get_table_lock:
-            table = Table(*args, schema=schema, autoload=True, autoload_with=engine)
+            table = Table(*args, schema=schema, autoload_with=engine)  # type: ignore[arg-type]
+        print(f"Table {tablename} loaded")
+        print([c.name for c in table.columns])
     return table
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
+@CACHE_REGION_OBJ.cache_on_arguments()
 def get_class(
     tablename: str,
-    exclude_properties: Optional[List[str]] = None,
+    exclude_properties: Optional[list[str]] = None,
     primary_key: Optional[str] = None,
-    attributes_order: Optional[List[str]] = None,
-    enumerations_config: Optional[Dict[str, str]] = None,
-    readonly_attributes: Optional[List[str]] = None,
-) -> sqlalchemy.ext.declarative.DeclarativeMeta:
+    attributes_order: Optional[list[str]] = None,
+    enumerations_config: Optional[dict[str, str]] = None,
+    readonly_attributes: Optional[list[str]] = None,
+) -> type:
     """
     Get the SQLAlchemy mapped class for "tablename".
 
     If no class exists for "tablename" one is created, and added to the cache. "tablename" must reference a
     valid string. If there is no table identified by tablename in the database a NoSuchTableError SQLAlchemy
     exception is raised.
     """
@@ -164,48 +173,48 @@
 
     return cls
 
 
 def _create_class(
     table: Table,
     exclude_properties: Optional[Iterable[str]] = None,
-    attributes_order: Optional[List[str]] = None,
-    enumerations_config: Optional[Dict[str, str]] = None,
-    readonly_attributes: Optional[List[str]] = None,
+    attributes_order: Optional[list[str]] = None,
+    enumerations_config: Optional[dict[str, str]] = None,
+    readonly_attributes: Optional[list[str]] = None,
     pk_name: Optional[str] = None,
-) -> sqlalchemy.ext.declarative.DeclarativeMeta:
+) -> type:
     from c2cgeoportal_commons.models import Base  # pylint: disable=import-outside-toplevel
 
     exclude_properties = exclude_properties or ()
-    attributes = dict(
-        __table__=table,
-        __mapper_args__={"exclude_properties": exclude_properties},
-        __attributes_order__=attributes_order,
-        __enumerations_config__=enumerations_config,
-    )
+    attributes = {
+        "__table__": table,
+        "__mapper_args__": {"exclude_properties": exclude_properties},
+        "__attributes_order__": attributes_order,
+        "__enumerations_config__": enumerations_config,
+    }
     if pk_name is not None:
         attributes[pk_name] = Column(Integer, primary_key=True)
     # The randint is to fix the SAWarning: This declarative base already contains a class with the same
-    # class name and module nam
+    # class name and module name
     cls = type(
-        f"{table.name.capitalize()}_{random.randint(0, 9999999)}", (GeoInterface, Base), attributes  # nosec
+        f"{table.name.capitalize()}_{random.randint(0, 9999999)}",  # nosec
+        (GeoInterface, Base),
+        attributes,
     )
 
     for col in table.columns:
         if col.name in (readonly_attributes or []):
             col.info["readonly"] = True
         if col.foreign_keys and col.name not in exclude_properties:
             _add_association_proxy(cls, col)
 
     return cls
 
 
-def _add_association_proxy(
-    cls: sqlalchemy.ext.declarative.DeclarativeMeta, col: sqlalchemy.sql.schema.Column
-) -> None:
+def _add_association_proxy(cls: type[Any], col: sqlalchemy.sql.schema.Column[Any]) -> None:
     if len(col.foreign_keys) != 1:
         raise NotImplementedError
 
     fk = next(iter(col.foreign_keys))
     child_tablename, child_pk = fk.target_fullname.rsplit(".", 1)
     child_cls = get_class(child_tablename)
```

## c2cgeoportal_geoportal/lib/filter_capabilities.py

```diff
@@ -25,19 +25,21 @@
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import copy
 import logging
 import xml.sax.handler  # nosec
+import xml.sax.xmlreader  # nosec
 from io import StringIO
-from typing import Any, Callable, Dict, List, Optional, Set, Union
+from typing import Any, Callable, Optional, Union
 from xml.sax.saxutils import XMLFilterBase, XMLGenerator  # nosec
 
 import defusedxml.expatreader
+import pyramid.httpexceptions
 import pyramid.request
 import requests
 from owslib.map.wms111 import ContentMetadata as ContentMetadata111
 from owslib.map.wms130 import ContentMetadata as ContentMetadata130
 from owslib.wms import WebMapService
 from pyramid.httpexceptions import HTTPBadGateway
 
@@ -46,16 +48,16 @@
 from c2cgeoportal_geoportal.lib.layers import get_private_layers, get_protected_layers, get_writable_layers
 
 CACHE_REGION = caching.get_region("std")
 LOG = logging.getLogger(__name__)
 ContentMetadata = Union[ContentMetadata111, ContentMetadata130]
 
 
-@CACHE_REGION.cache_on_arguments()  # type: ignore
-def wms_structure(wms_url: Url, host: str, request: pyramid.request.Request) -> Dict[str, List[str]]:
+@CACHE_REGION.cache_on_arguments()
+def wms_structure(wms_url: Url, host: str, request: pyramid.request.Request) -> dict[str, list[str]]:
     """Get a simple serializable structure of the WMS capabilities."""
     url = wms_url.clone().add_query({"SERVICE": "WMS", "VERSION": "1.1.1", "REQUEST": "GetCapabilities"})
 
     # Forward request to target (without Host Header)
     headers = {}
     if url.hostname == "localhost" and host is not None:
         headers["Host"] = host
@@ -73,15 +75,15 @@
         raise HTTPBadGateway(
             f"GetCapabilities from wms_url {url.url()} return the error: "
             f"{response.status_code:d} {response.reason}"
         )
 
     try:
         wms = WebMapService(None, xml=response.content)
-        result: Dict[str, List[str]] = {}
+        result: dict[str, list[str]] = {}
 
         def _fill(name: str, parent: ContentMetadata) -> None:
             if parent is None:
                 return
             if parent.name not in result:
                 result[parent.name] = []
             result[parent.name].append(name)
@@ -101,15 +103,15 @@
         error = "WARNING! an error occurred while trying to read the mapfile and recover the themes."
         error = f"{error}\nurl: {wms_url}\nxml:\n{response.text}"
         LOG.exception(error)
         raise HTTPBadGateway(error)  # pylint: disable=raise-missing-from
 
 
 def filter_capabilities(
-    content: str, wms: bool, url: Url, headers: Dict[str, str], request: pyramid.request.Request
+    content: str, wms: bool, url: Url, headers: dict[str, str], request: pyramid.request.Request
 ) -> str:
     """Filter the WMS/WFS capabilities."""
 
     wms_structure_ = wms_structure(url, headers.get("Host"), request)
 
     ogc_server_ids = (
         get_ogc_server_wms_url_ids(request) if wms else get_ogc_server_wfs_url_ids(request)
@@ -138,23 +140,26 @@
     parser.setFeature(xml.sax.handler.feature_external_pes, False)
 
     result = StringIO()
     downstream_handler = XMLGenerator(result, "utf-8")
     filter_handler = _CapabilitiesFilter(
         parser, downstream_handler, "Layer" if wms else "FeatureType", layers_blacklist=private_layers
     )
-    filter_handler.parse(StringIO(content))  # type: ignore
+    filter_handler.parse(StringIO(content))
     return result.getvalue()
 
 
 def filter_wfst_capabilities(content: str, wfs_url: Url, request: pyramid.request.Request) -> str:
     """Filter the WTS capabilities."""
 
-    writable_layers: Set[str] = set()
+    writable_layers: set[str] = set()
     ogc_server_ids = get_ogc_server_wfs_url_ids(request).get(wfs_url.url())
+    if ogc_server_ids is None:
+        LOG.error("No OGC server found for WFS URL %s", wfs_url)
+        raise pyramid.httpexceptions.HTTPInternalServerError("No OGC server found for WFS URL")
 
     for gmf_layer in list(get_writable_layers(request, ogc_server_ids).values()):
         writable_layers |= set(gmf_layer.layer.split(","))
 
     LOG.debug(
         "Filter WFS-T capabilities of OGC server %s\nlayers: %s",
         ", ".join([str(e) for e in ogc_server_ids]),
@@ -167,21 +172,21 @@
     parser.setFeature(xml.sax.handler.feature_external_pes, False)
 
     result = StringIO()
     downstream_handler = XMLGenerator(result, "utf-8")
     filter_handler = _CapabilitiesFilter(
         parser, downstream_handler, "FeatureType", layers_whitelist=writable_layers
     )
-    filter_handler.parse(StringIO(content))  # type: ignore
+    filter_handler.parse(StringIO(content))
     return result.getvalue()
 
 
 class _Layer:
     def __init__(self, self_hidden: bool = False):
-        self.accumulator: List[Callable[[], None]] = []
+        self.accumulator: list[Callable[[], None]] = []
         self.hidden = True
         self.self_hidden = self_hidden
         self.has_children = False
         self.children_nb = 0
 
 
 class _CapabilitiesFilter(XMLFilterBase):
@@ -194,20 +199,20 @@
     """
 
     def __init__(
         self,
         upstream: XMLFilterBase,
         downstream: XMLGenerator,
         tag_name: str,
-        layers_blacklist: Optional[Set[str]] = None,
-        layers_whitelist: Optional[Set[str]] = None,
+        layers_blacklist: Optional[set[str]] = None,
+        layers_whitelist: Optional[set[str]] = None,
     ):
         XMLFilterBase.__init__(self, upstream)
         self._downstream = downstream
-        self._accumulator: List[str] = []
+        self._accumulator: list[str] = []
 
         assert (
             layers_blacklist is not None or layers_whitelist is not None
         ), "either layers_blacklist OR layers_whitelist must be set"
         assert not (
             layers_blacklist is not None and layers_whitelist is not None
         ), "only either layers_blacklist OR layers_whitelist can be set"
@@ -215,22 +220,22 @@
         if layers_blacklist is not None:
             layers_blacklist = {layer.lower() for layer in layers_blacklist}
         if layers_whitelist is not None:
             layers_whitelist = {layer.lower() for layer in layers_whitelist}
         self.layers_blacklist = layers_blacklist
         self.layers_whitelist = layers_whitelist
 
-        self.layers_path: List[_Layer] = []
+        self.layers_path: list[_Layer] = []
         self.in_name = False
         self.tag_name = tag_name
         self.level = 0
 
     def _complete_text_node(self) -> None:
         if self._accumulator:
-            self._downstream.characters("".join(self._accumulator))  # type: ignore
+            self._downstream.characters("".join(self._accumulator))
             self._accumulator = []
 
     def _do(self, action: Callable[[], Any]) -> None:
         if self.layers_path:
             self.layers_path[-1].accumulator.append(action)
         else:
             self._complete_text_node()
@@ -239,28 +244,28 @@
     def _add_child(self, layer: _Layer) -> None:
         if not layer.hidden and not (layer.has_children and layer.children_nb == 0):
             for action in layer.accumulator:
                 self._complete_text_node()
                 action()
             layer.accumulator = []
 
-    def setDocumentLocator(self, locator: str) -> None:  # noqa: ignore=N802
-        self._downstream.setDocumentLocator(locator)  # type: ignore
+    def setDocumentLocator(self, locator: xml.sax.xmlreader.Locator) -> None:  # noqa: ignore=N802
+        self._downstream.setDocumentLocator(locator)
 
     def startDocument(self) -> None:  # noqa: ignore=N802
-        self._downstream.startDocument()  # type: ignore
+        self._downstream.startDocument()
 
     def endDocument(self) -> None:  # noqa: ignore=N802
-        self._downstream.endDocument()  # type: ignore
+        self._downstream.endDocument()
 
-    def startPrefixMapping(self, prefix: str, uri: str) -> None:  # noqa: ignore=N802
-        self._downstream.startPrefixMapping(prefix, uri)  # type: ignore
+    def startPrefixMapping(self, prefix: Optional[str], uri: str) -> None:  # noqa: ignore=N802
+        self._downstream.startPrefixMapping(prefix, uri)
 
-    def endPrefixMapping(self, prefix: str) -> None:  # noqa: ignore=N802
-        self._downstream.endPrefixMapping(prefix)  # type: ignore
+    def endPrefixMapping(self, prefix: Optional[str]) -> None:  # noqa: ignore=N802
+        self._downstream.endPrefixMapping(prefix)
 
     def startElement(self, name: str, attrs: xml.sax.xmlreader.AttributesImpl) -> None:  # noqa: ignore=N802
         if name == self.tag_name:
             self.level += 1
             if self.layers_path:
                 parent_layer = self.layers_path[-1]
                 parent_layer.has_children = True
@@ -271,34 +276,36 @@
                 parent_layer.accumulator.append(lambda: self._add_child(layer))
             else:
                 layer = _Layer()
                 self.layers_path.append(layer)
         elif name == "Name" and self.layers_path:
             self.in_name = True
 
-        self._do(lambda: self._downstream.startElement(name, attrs))  # type: ignore
+        self._do(lambda: self._downstream.startElement(name, attrs))
 
     def endElement(self, name: str) -> None:  # noqa: ignore=N802
-        self._do(lambda: self._downstream.endElement(name))  # type: ignore
+        self._do(lambda: self._downstream.endElement(name))
 
         if name == self.tag_name:
             self.level -= 1
             if self.level == 0 and not self.layers_path[0].hidden:
                 for action in self.layers_path[0].accumulator:
                     self._complete_text_node()
                     action()
             self.layers_path.pop()
         elif name == "Name":
             self.in_name = False
 
-    def startElementNS(self, name: str, qname: str, attrs: Dict[str, str]) -> None:  # noqa: ignore=N802
-        self._do(lambda: self._downstream.startElementNS(name, qname, attrs))  # type: ignore
+    def startElementNS(  # noqa: ignore=N802
+        self, name: tuple[str, str], qname: str, attrs: xml.sax.xmlreader.AttributesNSImpl
+    ) -> None:
+        self._do(lambda: self._downstream.startElementNS(name, qname, attrs))
 
-    def endElementNS(self, name: str, qname: str) -> None:  # noqa: ignore=N802
-        self._do(lambda: self._downstream.endElementNS(name, qname))  # type: ignore
+    def endElementNS(self, name: tuple[str, str], qname: str) -> None:  # noqa: ignore=N802
+        self._do(lambda: self._downstream.endElementNS(name, qname))
 
     def _keep_layer(self, layer_name: str) -> bool:
         return (self.layers_blacklist is not None and layer_name not in self.layers_blacklist) or (
             self.layers_whitelist is not None and layer_name in self.layers_whitelist
         )
 
     def characters(self, content: str) -> None:
@@ -315,18 +322,18 @@
 
         self._do(lambda: self._accumulator.append(content))
 
     def ignorableWhitespace(self, chars: str) -> None:  # noqa: ignore=N802
         self._do(lambda: self._accumulator.append(chars))
 
     def processingInstruction(self, target: str, data: str) -> None:  # noqa: ignore=N802
-        self._do(lambda: self._downstream.processingInstruction(target, data))  # type: ignore
+        self._do(lambda: self._downstream.processingInstruction(target, data))
 
     def skippedEntity(self, name: str) -> None:  # noqa: ignore=N802
-        self._downstream.skippedEntity(name)  # type: ignore
+        self._downstream.skippedEntity(name)
 
 
 def normalize_tag(tag: str) -> str:
     """
     Drop the namespace from a tag and converts to lower case.
 
     e.g. '{https://....}TypeName' -> 'TypeName'
```

## c2cgeoportal_geoportal/lib/fulltextsearch.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2020-2021, Camptocamp SA
+# Copyright (c) 2020-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -22,21 +22,21 @@
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import re
-from typing import Any, Dict
+from typing import Any
 
 
 class Normalize:
     """Normalize a text for the Full text search."""
 
-    def __init__(self, config: Dict[str, Any]) -> None:
+    def __init__(self, config: dict[str, Any]) -> None:
         split = config.get("split_regex")
         self.split_re = re.compile(split) if split is not None else None
 
         self.word_replace = []
         for search_regex, text in config.get("replace", {}).items():
             self.word_replace.append((re.compile(search_regex), text))
```

## c2cgeoportal_geoportal/lib/functionality.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,60 +23,62 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging.config
-from typing import Any, Dict, List, Set, Union, cast
+from typing import Any, Optional, Union, cast
 
 import pyramid.request
 from sqlalchemy.orm import joinedload
 
 from c2cgeoportal_commons.models import main, static
 from c2cgeoportal_geoportal.lib import get_typed, get_types_map, is_intranet
 from c2cgeoportal_geoportal.lib.caching import get_region
 
 LOG = logging.getLogger(__name__)
 CACHE_REGION_OBJ = get_region("obj")
 CACHE_REGION = get_region("std")
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
-def _get_role(name: str) -> Dict[str, Any]:
+@CACHE_REGION_OBJ.cache_on_arguments()
+def _get_role(name: str) -> dict[str, Any]:
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     role = (
         DBSession.query(main.Role)
         .filter(main.Role.name == name)
         .options(joinedload(main.Role.functionalities))
         .one_or_none()
     )
     struct = _role_to_struct(role)
     return {"settings_functionalities": struct, "roles_functionalities": {name: struct}}
 
 
-def _user_to_struct(user: static.User) -> Dict[str, Any]:
+def _user_to_struct(user: static.User) -> dict[str, Any]:
     return {
         "settings_functionalities": _role_to_struct(user.settings_role),
         "roles_functionalities": {role.name: _role_to_struct(role) for role in user.roles},
     }
 
 
-def _role_to_struct(role: main.Role) -> List[Dict[str, Any]]:
+def _role_to_struct(role: Optional[main.Role]) -> list[dict[str, Any]]:
     return [{"name": f.name, "value": f.value} for f in role.functionalities] if role else []
 
 
 def _get_db_functionality(
     name: str,
-    user: Dict[str, Any],
-    types: Dict[str, Dict[str, Any]],
+    user: dict[str, Any],
+    types: dict[str, dict[str, Any]],
     request: pyramid.request.Request,
-    errors: Set[str],
-) -> List[Union[str, int, float, bool, List[Any], Dict[str, Any]]]:
+    errors: set[str],
+) -> list[Union[str, int, float, bool, list[Any], dict[str, Any]]]:
     if types.get(name, {}).get("single", False):
         values = [
             get_typed(name, functionality["value"], types, request, errors)
             for functionality in user["settings_functionalities"]
             if functionality["name"] == name
         ]
         return [r for r in values if r is not None]
@@ -90,27 +92,27 @@
         get_typed(name, functionality_value, types, request, errors)
         for functionality_value in functionalities
     ]
 
     return [r for r in values if r is not None]
 
 
-@CACHE_REGION_OBJ.cache_on_arguments()  # type: ignore
-def _get_functionalities_type(request: pyramid.request.Request) -> Dict[str, Dict[str, Any]]:
+@CACHE_REGION_OBJ.cache_on_arguments()
+def _get_functionalities_type(request: pyramid.request.Request) -> dict[str, dict[str, Any]]:
     return get_types_map(
         request.registry.settings.get("admin_interface", {}).get("available_functionalities", [])
     )
 
 
 def get_functionality(
     name: str, request: pyramid.request.Request, is_intranet_: bool
-) -> List[Union[str, int, float, bool, List[Any], Dict[str, Any]]]:
+) -> list[Union[str, int, float, bool, list[Any], dict[str, Any]]]:
     """Get all the functionality for the current user."""
-    result: List[Union[str, int, float, bool, List[Any], Dict[str, Any]]] = []
-    errors: Set[str] = set()
+    result: list[Union[str, int, float, bool, list[Any], dict[str, Any]]] = []
+    errors: set[str] = set()
 
     if request.user is not None:
         result = _get_db_functionality(
             name, _user_to_struct(request.user), _get_functionalities_type(request), request, errors
         )
         if not result:
             result = _get_db_functionality(
@@ -140,17 +142,17 @@
         )
 
     if errors != set():
         LOG.error("\n".join(errors))
     return result
 
 
-def get_mapserver_substitution_params(request: pyramid.request.Request) -> Dict[str, str]:
+def get_mapserver_substitution_params(request: pyramid.request.Request) -> dict[str, str]:
     """Get the parameters used by the mapserver substitution."""
-    params: Dict[str, str] = {}
+    params: dict[str, str] = {}
     mss = get_functionality("mapserver_substitution", request, is_intranet(request))
     if mss:
         for s_ in mss:
             s = cast(str, s_)
             index = s.find("=")
             if index > 0:
                 attribute = "s_" + s[:index]
```

## c2cgeoportal_geoportal/lib/i18n.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2020-2021, Camptocamp SA
+# Copyright (c) 2020-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,17 +23,16 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import os
-from typing import List
 
 LOCALE_PATH = "/etc/geomapfish/locale/"
 
 
-def available_locale_names(path: str = LOCALE_PATH) -> List[str]:
+def available_locale_names(path: str = LOCALE_PATH) -> list[str]:
     """Get the available locales."""
     if not os.path.exists(path):
         return []
     return [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
```

## c2cgeoportal_geoportal/lib/layers.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2021, Camptocamp SA
+# Copyright (c) 2018-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -22,41 +22,47 @@
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
-from typing import Any, Dict, Iterable, Optional
+from collections.abc import Iterable
+from typing import TYPE_CHECKING, Any, Optional, Union
 
+import sqlalchemy.orm
 from pyramid.request import Request
-from sqlalchemy.ext.declarative import DeclarativeMeta
 from sqlalchemy.orm.query import Query
 
 from c2cgeoportal_geoportal.lib import caching, get_roles_id
 
+if TYPE_CHECKING:
+    from c2cgeoportal_commons.models import main
+
 CACHE_REGION = caching.get_region("std")
 
 
-def _get_layers_query(request: Request, what: DeclarativeMeta) -> Query:
+def _get_layers_query(request: Request, what: Union[sqlalchemy.orm.Mapper[Any], type[Any]]) -> Query[Any]:
     from c2cgeoportal_commons.models import DBSession, main  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     q = DBSession.query(what)
     q = q.join(main.Layer.restrictionareas)
     q = q.join(main.RestrictionArea.roles)
     q = q.filter(main.Role.id.in_(get_roles_id(request)))
 
     return q
 
 
 def get_protected_layers_query(
     request: Request,
     ogc_server_ids: Optional[Iterable[int]],
-    what: DeclarativeMeta = None,
-) -> Query:
+    what: Union[sqlalchemy.orm.Mapper[Any], type[Any]],
+) -> Query[Any]:
     """
     Get the protected layers query.
 
     Private layers but accessible to the user.
     """
     from c2cgeoportal_commons.models import main  # pylint: disable=import-outside-toplevel
 
@@ -64,55 +70,61 @@
     q = q.filter(main.Layer.public.is_(False))
     if ogc_server_ids is not None:
         q = q.join(main.LayerWMS.ogc_server)
         q = q.filter(main.OGCServer.id.in_(ogc_server_ids))
     return q
 
 
-def get_writable_layers_query(request: Request, ogc_server_ids: Iterable[int]) -> Query:
+def get_writable_layers_query(request: Request, ogc_server_ids: Iterable[int]) -> Query["main.LayerWMS"]:
     """Get the writable layers query."""
     from c2cgeoportal_commons.models import main  # pylint: disable=import-outside-toplevel
 
     q = _get_layers_query(request, main.LayerWMS)
     return (
         q.filter(main.RestrictionArea.readwrite.is_(True))
         .join(main.LayerWMS.ogc_server)
         .filter(main.OGCServer.id.in_(ogc_server_ids))
     )
 
 
-def get_protected_layers(request: Request, ogc_server_ids: Iterable[int]) -> Dict[int, DeclarativeMeta]:
+def get_protected_layers(request: Request, ogc_server_ids: Iterable[int]) -> dict[int, "main.LayerWMS"]:
     """
     Get the protected layers.
 
     Private layers but accessible to the user.
     """
     from c2cgeoportal_commons.models import DBSession, main  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     q = get_protected_layers_query(request, ogc_server_ids, what=main.LayerWMS)
     results = q.all()
     DBSession.expunge_all()
     return {r.id: r for r in results}
 
 
-def get_writable_layers(request: Request, ogc_server_ids: Iterable[int]) -> Dict[int, DeclarativeMeta]:
+def get_writable_layers(request: Request, ogc_server_ids: Iterable[int]) -> dict[int, "main.LayerWMS"]:
     """Get the writable layers."""
     from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     q = get_writable_layers_query(request, ogc_server_ids)
     results = q.all()
     DBSession.expunge_all()
     return {r.id: r for r in results}
 
 
-@CACHE_REGION.cache_on_arguments()  # type: ignore
-def get_private_layers(ogc_server_ids: Iterable[int]) -> Dict[int, Any]:
+@CACHE_REGION.cache_on_arguments()
+def get_private_layers(ogc_server_ids: Iterable[int]) -> dict[int, "main.LayerWMS"]:
     """Get the private layers."""
     from c2cgeoportal_commons.models import DBSession, main  # pylint: disable=import-outside-toplevel
 
+    assert DBSession is not None
+
     q = (
         DBSession.query(main.LayerWMS)
         .filter(main.LayerWMS.public.is_(False))
         .join(main.LayerWMS.ogc_server)
         .filter(main.OGCServer.id.in_(ogc_server_ids))
     )
     results = q.all()
```

## c2cgeoportal_geoportal/lib/lingua_extractor.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2023, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -27,45 +27,49 @@
 
 
 import json
 import os
 import re
 import subprocess
 import traceback
-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Set, Tuple, Type, cast
+from typing import TYPE_CHECKING, Any, Callable, Optional, cast
 from xml.dom import Node
 from xml.parsers.expat import ExpatError
 
 import pyramid.threadlocal
 import requests
+import sqlalchemy.orm
 import yaml
 from bottle import MakoTemplate, template
 from c2c.template.config import config
 from defusedxml.minidom import parseString
 from geoalchemy2.types import Geometry
 from lingua.extractors import Extractor, Message
 from mako.lookup import TemplateLookup
 from mako.template import Template
 from owslib.wms import WebMapService
 from sqlalchemy.exc import NoSuchTableError, OperationalError, ProgrammingError
-from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.orm.exc import NoResultFound  # type: ignore[attr-defined]
 from sqlalchemy.orm.properties import ColumnProperty
-from sqlalchemy.orm.session import Session
 from sqlalchemy.orm.util import class_mapper
 
 import c2cgeoportal_geoportal
 from c2cgeoportal_commons.lib.url import Url, get_url2
 from c2cgeoportal_geoportal.lib.bashcolor import Color, colorize
 from c2cgeoportal_geoportal.lib.caching import init_region
 from c2cgeoportal_geoportal.views.layers import Layers, get_layer_class
 
 if TYPE_CHECKING:
     from c2cgeoportal_commons.models import main  # pylint: disable=ungrouped-imports,useless-suppression
 
 
+class LinguaExtractorException(Exception):
+    """Exception raised when an error occurs during the extraction."""
+
+
 def _get_config(key: str, default: Optional[str] = None) -> Optional[str]:
     """
     Return the config value for passed key.
 
     Passed throw environment variable for the command line,
     or throw the query string on HTTP request.
     """
@@ -81,24 +85,24 @@
     assert result is not None
     return result
 
 
 class _Registry:
     settings = None
 
-    def __init__(self, settings: Optional[Dict[str, Any]]) -> None:
+    def __init__(self, settings: Optional[dict[str, Any]]) -> None:
         self.settings = settings
 
 
 class _Request:
-    params: Dict[str, str] = {}
-    matchdict: Dict[str, str] = {}
-    GET: Dict[str, str] = {}
+    params: dict[str, str] = {}
+    matchdict: dict[str, str] = {}
+    GET: dict[str, str] = {}
 
-    def __init__(self, settings: Optional[Dict[str, Any]] = None) -> None:
+    def __init__(self, settings: Optional[dict[str, Any]] = None) -> None:
         self.registry: _Registry = _Registry(settings)
 
     @staticmethod
     def static_url(*args: Any, **kwargs: Any) -> str:
         del args
         del kwargs
         return ""
@@ -127,17 +131,19 @@
 
     extensions = [".js", ".html"]
 
     def __init__(self) -> None:
         super().__init__()
         if os.path.exists("/etc/geomapfish/config.yaml"):
             config.init("/etc/geomapfish/config.yaml")
-            self.config = config.get_config()
+            conf = config.get_config()
+            assert conf is not None
+            self.config = conf
         else:
-            self.config = None
+            self.config = {}
         self.tpl = None
 
     @staticmethod
     def get_message_cleaner(filename: str) -> Callable[[str], str]:
         """Return a function for cleaning messages according to input file format."""
         ext = os.path.splitext(filename)[1]
 
@@ -147,18 +153,18 @@
             return lambda s: re.sub(pattern, " ", s)
 
         return lambda s: s
 
     def __call__(
         self,
         filename: str,
-        options: Dict[str, Any],
-        fileobj: Optional[Dict[str, Any]] = None,
+        options: dict[str, Any],
+        fileobj: Optional[dict[str, Any]] = None,
         lineno: int = 0,
-    ) -> List[Message]:
+    ) -> list[Message]:
         del fileobj, lineno
 
         print(f"Running {self.__class__.__name__} on {filename}")
 
         cleaner = self.get_message_cleaner(filename)
 
         init_region({"backend": "dogpile.cache.memory"}, "std")
@@ -166,16 +172,15 @@
 
         int_filename = filename
         if re.match("^" + re.escape(f"./{self.config['package']}/templates"), filename):
             try:
                 empty_template = Template("")  # nosec
 
                 class Lookup(TemplateLookup):  # type: ignore
-                    @staticmethod
-                    def get_template(uri: str) -> Template:
+                    def get_template(self, uri: str) -> Template:
                         del uri  # unused
                         return empty_template
 
                 class MyTemplate(MakoTemplate):  # type: ignore
                     tpl = None
 
                     def prepare(self, **kwargs: Any) -> None:
@@ -216,18 +221,15 @@
                         int_filename = filename
                     else:
                         raise
             except Exception:
                 print(traceback.format_exc())
 
         # Path in geomapfish-tools
-        script_path = "geoportal/tools/extract-messages.js"
-        if not os.path.isfile(script_path):
-            # Path in geomapfish runner
-            script_path = "/app/tools/extract-messages.js"
+        script_path = "/opt/c2cgeoportal/geoportal/extract-messages.js"
         message_str = subprocess.check_output(["node", script_path, int_filename]).decode("utf-8")
         if int_filename != filename:
             os.unlink(int_filename)
         try:
             messages = []
             for contexts, message in json.loads(message_str):
                 assert message is not None
@@ -238,39 +240,40 @@
         except Exception:
             print(colorize("An error occurred", Color.RED))
             print(colorize(message_str, Color.RED))
             print("------")
             raise
 
 
-def init_db(settings: Dict[str, Any]) -> None:
+def init_db(settings: dict[str, Any]) -> None:
     """
     Initialize the SQLAlchemy Session.
 
-    First test the connection, on wen environment it should be OK, with the command line we should get
-    an exception ind initialise the connection.
+    First test the connection, on when environment it should be OK, with the command line we should get
+    an exception ind initialize the connection.
     """
 
     try:
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
         from c2cgeoportal_commons.models.main import Theme  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         session = DBSession()
         session.query(Theme).count()
     except:  # pylint: disable=bare-except
-
         # Init db sessions
 
         class R:
-            settings: Dict[str, Any] = {}
+            settings: dict[str, Any] = {}
 
         class C:
             registry = R()
 
-            def get_settings(self) -> Dict[str, Any]:
+            def get_settings(self) -> dict[str, Any]:
                 return self.registry.settings
 
             def add_tween(self, *args: Any, **kwargs: Any) -> None:
                 pass
 
         config_ = C()
         config_.registry.settings = settings
@@ -282,18 +285,18 @@
     """GeoMapFish config extractor (raster layers, and print templates)."""
 
     extensions = [".yaml", ".tmpl"]
 
     def __call__(
         self,
         filename: str,
-        options: Dict[str, Any],
-        fileobj: Optional[Dict[str, Any]] = None,
+        options: dict[str, Any],
+        fileobj: Optional[dict[str, Any]] = None,
         lineno: int = 0,
-    ) -> List[Message]:
+    ) -> list[Message]:
         del options, fileobj, lineno
 
         print(f"Running {self.__class__.__name__} on {filename}")
 
         init_region({"backend": "dogpile.cache.memory"}, "std")
         init_region({"backend": "dogpile.cache.memory"}, "obj")
 
@@ -301,19 +304,20 @@
             gmf_config = yaml.load(config_file, Loader=yaml.BaseLoader)  # nosec
             # For application config (config.yaml)
             if "vars" in gmf_config:
                 return self._collect_app_config(filename)
             # For the print config
             if "templates" in gmf_config:
                 return self._collect_print_config(gmf_config, filename)
-            raise Exception("Not a known config file")
+            raise Exception("Not a known config file")  # pylint: disable=broad-exception-raised
 
-    def _collect_app_config(self, filename: str) -> List[Message]:
+    def _collect_app_config(self, filename: str) -> list[Message]:
         config.init(filename)
         settings = config.get_config()
+        assert settings is not None
         assert not [
             raster_layer for raster_layer in list(settings.get("raster", {}).keys()) if raster_layer is None
         ]
         # Collect raster layers names
         raster = [
             Message(None, raster_layer, None, [], "", "", (filename, f"raster/{raster_layer}"))
             for raster_layer in list(settings.get("raster", {}).keys())
@@ -325,14 +329,16 @@
 
         from c2cgeoportal_commons.models import (  # pylint: disable=import-outside-toplevel
             DBSession,
             DBSessions,
         )
         from c2cgeoportal_commons.models.main import Metadata  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         enums = []
         enum_layers = settings.get("layers", {}).get("enum", {})
         for layername in list(enum_layers.keys()):
             layerinfos = enum_layers.get(layername, {})
             attributes = layerinfos.get("attributes", {})
             for fieldname in list(attributes.keys()):
                 values = self._enumerate_attributes_values(DBSessions, layerinfos, fieldname)
@@ -387,40 +393,43 @@
                 assert merge_tab is not None
                 interfaces_messages.append(Message(None, merge_tab, None, [], "", "", (filename, location)))
 
         return raster + enums + metadata_list + interfaces_messages
 
     @staticmethod
     def _enumerate_attributes_values(
-        dbsessions: Dict[str, Session], layerinfos: Dict[str, Any], fieldname: str
-    ) -> Set[Tuple[str, ...]]:
+        dbsessions: dict[str, sqlalchemy.orm.scoped_session[sqlalchemy.orm.Session]],
+        layerinfos: dict[str, Any],
+        fieldname: str,
+    ) -> set[tuple[str, ...]]:
         dbname = layerinfos.get("dbsession", "dbsession")
-        translate = cast(Dict[str, Any], layerinfos["attributes"]).get(fieldname, {}).get("translate", True)
+        translate = cast(dict[str, Any], layerinfos["attributes"]).get(fieldname, {}).get("translate", True)
         if not translate:
             return set()
         try:
             dbsession = dbsessions.get(dbname)
+            assert dbsession is not None
             return Layers.query_enumerate_attribute_values(dbsession, layerinfos, fieldname)
         except Exception as e:
-            table = cast(Dict[str, Any], layerinfos["attributes"]).get(fieldname, {}).get("table")
+            table = cast(dict[str, Any], layerinfos["attributes"]).get(fieldname, {}).get("table")
             print(
                 colorize(
                     "ERROR! Unable to collect enumerate attributes for "
                     f"db: {dbname}, table: {table}, column: {fieldname} ({e!s})",
                     Color.RED,
                 )
             )
             if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") == "TRUE":
                 return set()
             raise
 
     @staticmethod
-    def _collect_print_config(print_config: Dict[str, Any], filename: str) -> List[Message]:
+    def _collect_print_config(print_config: dict[str, Any], filename: str) -> list[Message]:
         result = []
-        for template_ in list(cast(Dict[str, Any], print_config.get("templates")).keys()):
+        for template_ in list(cast(dict[str, Any], print_config.get("templates")).keys()):
             assert template_ is not None
             result.append(Message(None, template_, None, [], "", "", (filename, f"template/{template_}")))
             assert not [
                 attribute
                 for attribute in list(print_config["templates"][template_]["attributes"].keys())
                 if attribute is None
             ]
@@ -440,39 +449,43 @@
 
 
 class GeomapfishThemeExtractor(Extractor):  # type: ignore
     """GeoMapFish theme extractor."""
 
     # Run on the development.ini file
     extensions = [".ini"]
-    featuretype_cache: Dict[str, Optional[Dict[str, Any]]] = {}
-    wms_capabilities_cache: Dict[str, WebMapService] = {}
+    featuretype_cache: dict[str, Optional[dict[str, Any]]] = {}
+    wms_capabilities_cache: dict[str, WebMapService] = {}
 
     def __init__(self) -> None:
         super().__init__()
         if os.path.exists("/etc/geomapfish/config.yaml"):
             config.init("/etc/geomapfish/config.yaml")
-            self.config = config.get_config()
+            conf = config.get_config()
+            assert conf is not None
+            self.config = conf
         else:
-            self.config = None
+            self.config = {}
         self.env = None
 
     def __call__(
-        self, filename: str, options: Dict[str, Any], fileobj: Optional[str] = None, lineno: int = 0
-    ) -> List[Message]:
+        self, filename: str, options: dict[str, Any], fileobj: Optional[str] = None, lineno: int = 0
+    ) -> list[Message]:
         del fileobj, lineno
 
         print(f"Running {self.__class__.__name__} on {filename}")
 
-        messages: List[Message] = []
+        messages: list[Message] = []
 
         try:
             init_db(self.config)
             from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+            assert DBSession is not None
+
             db_session = DBSession()
 
             try:
                 from c2cgeoportal_commons.models.main import (  # pylint: disable=import-outside-toplevel
                     FullTextSearch,
                     LayerGroup,
                     LayerWMS,
@@ -534,60 +547,62 @@
                 print(
                     colorize(
                         "ERROR! The database is probably not up to date "
                         "(should be ignored when happen during the upgrade)",
                         Color.RED,
                     )
                 )
-                print(colorize(e, Color.RED))
+                print(colorize(str(e), Color.RED))
                 if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
                     raise
         except NoSuchTableError as e:
             print(
                 colorize(
                     "ERROR! The schema didn't seem to exists "
                     "(should be ignored when happen during the deploy)",
                     Color.RED,
                 )
             )
-            print(colorize(e, Color.RED))
+            print(colorize(str(e), Color.RED))
             if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
                 raise
         except OperationalError as e:
             print(
                 colorize(
                     "ERROR! The database didn't seem to exists "
                     "(should be ignored when happen during the deploy)",
                     Color.RED,
                 )
             )
-            print(colorize(e, Color.RED))
+            print(colorize(str(e), Color.RED))
             if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
                 raise
 
         return messages
 
     @staticmethod
     def _import(
-        object_type: Type[Any],
-        messages: List[str],
-        callback: Optional[Callable[["main.Layer", List[str]], None]] = None,
+        object_type: type[Any],
+        messages: list[str],
+        callback: Optional[Callable[["main.Layer", list[str]], None]] = None,
         has_interfaces: bool = True,
         name_regex: str = ".*",
     ) -> None:
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
         from c2cgeoportal_commons.models.main import Interface  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         filter_re = re.compile(name_regex)
 
         query = DBSession.query(object_type)
 
         interfaces = _get_config("INTERFACES")
         if has_interfaces and interfaces is not None:
-            query.join(object_type.interface).filter(Interface.name in interfaces.split("."))
+            query.join(object_type.interface).filter(Interface.name in interfaces.split("."))  # type: ignore[arg-type]
 
         for item in query.all():
             assert item.name is not None
             if filter_re.match(item.name):
                 messages.append(
                     Message(
                         None,
@@ -599,15 +614,15 @@
                         (item.item_type, item.name.encode("ascii", errors="replace")),
                     )
                 )
 
             if callback is not None:
                 callback(item, messages)
 
-    def _import_layer_wms(self, layer: "main.Layer", messages: List[str]) -> None:
+    def _import_layer_wms(self, layer: "main.Layer", messages: list[str]) -> None:
         server = layer.ogc_server
         url = server.url_wfs or server.url
         if url is None:
             return
         if layer.ogc_server.wfs_support:
             for wms_layer in layer.layer.split(","):
                 self._import_layer_attributes(url, wms_layer, layer.item_type, layer.name, messages)
@@ -646,18 +661,20 @@
                         Color.RED,
                     )
                 )
                 print(colorize(traceback.format_exc(), Color.RED))
                 if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
                     raise
 
-    def _import_layer_wmts(self, layer: "main.Layer", messages: List[str]) -> None:
+    def _import_layer_wmts(self, layer: "main.Layer", messages: list[str]) -> None:
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
         from c2cgeoportal_commons.models.main import OGCServer  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         layers = [d.value for d in layer.metadatas if d.name == "queryLayers"]
         if not layers:
             layers = [d.value for d in layer.metadatas if d.name == "wmsLayer"]
         server = [d.value for d in layer.metadatas if d.name == "ogcServer"]
         if server and layers:
             layers = [layer for ls in layers for layer in ls.split(",")]
             for wms_layer in layers:
@@ -679,15 +696,15 @@
                             Color.RED,
                         )
                     )
                     if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
                         raise
 
     def _import_layer_attributes(
-        self, url: str, layer: "main.Layer", item_type: str, name: str, messages: List[str]
+        self, url: str, layer: "main.Layer", item_type: str, name: str, messages: list[str]
     ) -> None:
         attributes, layers = self._layer_attributes(url, layer)
         for sub_layer in layers:
             assert sub_layer is not None
             messages.append(
                 Message(
                     None,
@@ -709,29 +726,29 @@
                     [],
                     "",
                     "",
                     (".".join([item_type, name]), layer.encode("ascii", "replace")),
                 )
             )
 
-    def _build_url(self, url: Url) -> Tuple[Url, Dict[str, str], Dict[str, Any]]:
+    def _build_url(self, url: Url) -> tuple[Url, dict[str, str], dict[str, Any]]:
         hostname = url.hostname
         host_map = self.config.get("lingua_extractor", {}).get("host_map", {})
         if hostname in host_map:
             map_ = host_map[hostname]
             if "netloc" in map_:
                 url.netloc = map_["netloc"]
             if "scheme" in map_:
                 url.scheme = map_["scheme"]
             kwargs = {"verify": map_["verify"]} if "verify" in map_ else {}
             return url, map_.get("headers", {}), kwargs
         return url, {}, {}
 
-    def _layer_attributes(self, url: str, layer: str) -> Tuple[List[str], List[str]]:
-        errors: Set[str] = set()
+    def _layer_attributes(self, url: str, layer: str) -> tuple[list[str], list[str]]:
+        errors: set[str] = set()
 
         request = pyramid.threadlocal.get_current_request()
         if request is None:
             request = _Request()
             request.registry.settings = self.config
 
         # Static schema will not be supported
@@ -766,15 +783,15 @@
                 rendered_headers = " ".join(
                     [
                         f"{h}={v if h not in ('Authorization', 'Cookies') else '***'}"
                         for h, v in headers.items()
                     ]
                 )
                 print(f"Get WMS GetCapabilities for URL {wms_getcap_url},\nwith headers: {rendered_headers}")
-                response = requests.get(wms_getcap_url, headers=headers, **kwargs)
+                response = requests.get(wms_getcap_url, headers=headers, timeout=60, **kwargs)
 
                 if response.ok:
                     try:
                         self.wms_capabilities_cache[url] = WebMapService(None, xml=response.content)
                     except Exception as e:
                         print(
                             colorize(
@@ -793,15 +810,15 @@
                             f"ERROR! Unable to GetCapabilities from URL: {wms_getcap_url},\n"
                             f"with headers: {rendered_headers}",
                             Color.RED,
                         )
                     )
                     print(f"Response: {response.status_code} {response.reason}\n{response.text}")
                     if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") != "TRUE":
-                        raise Exception(response.reason)
+                        raise LinguaExtractorException(response.reason)
             except Exception as e:
                 print(colorize(str(e), Color.RED))
                 rendered_headers = " ".join(
                     [
                         f"{h}={v if h not in ('Authorization', 'Cookies') else '***'}"
                         for h, v in headers.items()
                     ]
@@ -832,15 +849,15 @@
                         "ROLE_IDS": "0",
                         "USER_ID": "0",
                     }
                 )
                 .url()
             )
             try:
-                response = requests.get(wfs_describe_feature_url, headers=headers, **kwargs)
+                response = requests.get(wfs_describe_feature_url, headers=headers, timeout=60, **kwargs)
             except Exception as e:
                 print(colorize(str(e), Color.RED))
                 print(
                     colorize(
                         f"ERROR! Unable to DescribeFeatureType from URL: {wfs_describe_feature_url}",
                         Color.RED,
                     )
@@ -855,24 +872,24 @@
                         f"ERROR! DescribeFeatureType from URL {wfs_describe_feature_url} return the error: "
                         f"{response.status_code:d} {response.reason}",
                         Color.RED,
                     )
                 )
                 if _get_config_str("IGNORE_I18N_ERRORS", "FALSE") == "TRUE":
                     return [], []
-                raise Exception("Aborted")
+                raise Exception("Aborted")  # pylint: disable=broad-exception-raised
 
             try:
                 describe = parseString(response.text)
-                featurestype: Optional[Dict[str, Node]] = {}
+                featurestype: Optional[dict[str, Node]] = {}
                 self.featuretype_cache[url] = featurestype
                 for type_element in describe.getElementsByTagNameNS(
                     "http://www.w3.org/2001/XMLSchema", "complexType"
                 ):
-                    cast(Dict[str, Node], featurestype)[type_element.getAttribute("name")] = type_element
+                    cast(dict[str, Node], featurestype)[type_element.getAttribute("name")] = type_element
             except ExpatError as e:
                 print(
                     colorize(
                         "ERROR! an error occurred while trying to parse the DescribeFeatureType document.",
                         Color.RED,
                     )
                 )
@@ -895,21 +912,21 @@
                 raise
         else:
             featurestype = self.featuretype_cache[url]
 
         if featurestype is None:
             return [], []
 
-        layers: List[str] = [layer]
+        layers: list[str] = [layer]
         if wms_capabilities is not None and layer in list(wms_capabilities.contents):
             layer_obj = wms_capabilities[layer]
             if layer_obj.layers:
                 layers = [layer.name for layer in layer_obj.layers]
 
-        attributes: List[str] = []
+        attributes: list[str] = []
         for sub_layer in layers:
             # Should probably be adapted for other king of servers
             type_element = featurestype.get(f"{sub_layer}Type")
             if type_element is not None:
                 for element in type_element.getElementsByTagNameNS(
                     "http://www.w3.org/2001/XMLSchema", "element"
                 ):
```

## c2cgeoportal_geoportal/lib/loader.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2019-2021, Camptocamp SA
+# Copyright (c) 2019-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,33 +23,35 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
-from typing import Any, Dict, Optional, cast
+from typing import Any, Optional, cast
 
 from c2c.template.config import config as configuration
 from c2cwsgiutils.loader import Loader as BaseLoader
 
 from c2cgeoportal_geoportal.lib.i18n import available_locale_names
 
 LOG = logging.getLogger(__name__)
 
 
 class Loader(BaseLoader):
     """The Pyramid configuration loader."""
 
     def get_wsgi_app_settings(
-        self, name: Optional[str] = None, defaults: Optional[Dict[str, str]] = None
-    ) -> Dict[str, Any]:
-        settings = cast(Dict[str, Any], super().get_wsgi_app_settings(name, defaults))
-        configuration.init(settings.get("app.cfg"))
-        settings.update(configuration.get_config())
+        self, name: Optional[str] = None, defaults: Optional[dict[str, str]] = None
+    ) -> dict[str, Any]:
+        settings = cast(dict[str, Any], super().get_wsgi_app_settings(name, defaults))
+        app_cfg = settings.get("app.cfg")
+        if app_cfg is not None:
+            configuration.init(app_cfg)
+        settings.update(configuration.get_config())  # type: ignore[arg-type]
         if "available_locale_names" not in settings:
             settings["available_locale_names"] = available_locale_names()
         return settings
 
     def __repr__(self) -> str:
         """Get the object representation."""
         return f'c2cgeoportal_geoportal.lib.loader.Loader(uri="{self.uri}")'
```

## c2cgeoportal_geoportal/lib/metrics.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2021, Camptocamp SA
+# Copyright (c) 2018-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,90 +23,95 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import gc
 import sys
-from typing import Any, Dict, List, Tuple
+from collections.abc import Generator
 
+import prometheus_client.core
+import prometheus_client.registry
 from c2cwsgiutils import broadcast
 from c2cwsgiutils.debug import get_size
-from c2cwsgiutils.metrics import Provider
 
 from c2cgeoportal_geoportal.lib.caching import MEMORY_CACHE_DICT
 from c2cgeoportal_geoportal.views.raster import Raster
 
 
-class MemoryCacheSizeProvider(Provider):
+class MemoryCacheSizeCollector(prometheus_client.registry.Collector):
     """Get the memory used by the cache."""
 
     def __init__(self, all_: bool = False):
-        super().__init__("pod_process_memory_cache_kb", "Used memory cache")
+        super().__init__()
         self.all = all_
 
-    def get_data(self) -> List[Tuple[Dict[str, Any], float]]:
+    def collect(self) -> Generator[prometheus_client.core.GaugeMetricFamily, None, None]:
+        gauge = prometheus_client.core.GaugeMetricFamily(
+            "c2cgeoportal_memory_cache_bytes",
+            "Memory used by cache",
+            labels=["pid", "hostname", "key"],
+            unit="bytes",
+        )
+
         elements = _get_memory_cache(all_=self.all)
         assert elements is not None
-        result = []
         for elem in elements:
             if elem is not None:
-                for value in elem["values"]:
-                    value[0]["pid"] = str(elem["pid"])
-                    value[0]["hostname"] = elem["hostname"]
-                    result.append(value)
-        return result
+                for key, value in elem["values"]:
+                    gauge.add_metric([str(elem["pid"]), str(elem["hostname"]), key], value)
+        yield gauge
 
 
 @broadcast.decorator(expect_answers=True, timeout=15)
-def _get_memory_cache(all_: bool) -> Dict[str, List[Tuple[Dict[str, Any], float]]]:
-    values = (
-        [({"key": key}, get_size(value) / 1024) for key, value in list(MEMORY_CACHE_DICT.items())]
-        if all_
-        else []
-    )
-    values.append(({"key": "total"}, get_size(MEMORY_CACHE_DICT) / 1024))
+def _get_memory_cache(all_: bool) -> dict[str, list[tuple[str, int]]]:
+    values = [(key, get_size(value)) for key, value in list(MEMORY_CACHE_DICT.items())] if all_ else []
+    values.append(("total", get_size(MEMORY_CACHE_DICT)))
     return {"values": values}
 
 
-class RasterDataSizeProvider(Provider):
+class RasterDataSizeCollector(prometheus_client.registry.Collector):
     """Get the memory used by Raster data cache."""
 
-    def __init__(self) -> None:
-        super().__init__("pod_process_raster_data_kb", "Memory used by raster")
+    def collect(self) -> Generator[prometheus_client.core.GaugeMetricFamily, None, None]:
+        gauge = prometheus_client.core.GaugeMetricFamily(
+            "c2cgeoportal_raster_data_bytes",
+            "Memory used by raster",
+            labels=["pid", "hostname", "key"],
+            unit="bytes",
+        )
 
-    def get_data(self) -> List[Tuple[Dict[str, Any], float]]:
         elements = _get_raster_data()
         assert elements is not None
-        result = []
         for elem in elements:
-            for value in elem["values"]:
-                value[0]["pid"] = str(elem["pid"])
-                value[0]["hostname"] = str(elem["hostname"])
-                result.append(value)
-        return result
+            for key, value in elem["values"]:
+                gauge.add_metric([str(elem["pid"]), str(elem["hostname"]), key], value)
+        yield gauge
 
 
 @broadcast.decorator(expect_answers=True, timeout=15)
-def _get_raster_data() -> Dict[str, List[Tuple[Dict[str, str], float]]]:
-    return {"values": [({"key": key}, get_size(value) / 1024) for key, value in list(Raster.data.items())]}
+def _get_raster_data() -> dict[str, list[tuple[str, float]]]:
+    return {"values": [(key, get_size(value)) for key, value in list(Raster.data.items())]}
 
 
-class TotalPythonObjectMemoryProvider(Provider):
+class TotalPythonObjectMemoryCollector(prometheus_client.registry.Collector):
     """Get the memory used by Python objects."""
 
-    def __init__(self) -> None:
-        super().__init__("total_python_object_memory_kb", "Memory used by raster")
+    def collect(self) -> Generator[prometheus_client.core.GaugeMetricFamily, None, None]:
+        gauge = prometheus_client.core.GaugeMetricFamily(
+            "c2cgeoportal_total_python_object_memory_bytes",
+            "Memory used by Python objects",
+            labels=["pid", "hostname"],
+            unit="bytes",
+        )
 
-    def get_data(self) -> List[Tuple[Dict[str, str], float]]:
         object_size = _get_python_object_size()
         assert object_size is not None
-        return [
-            ({"pid": str(val["pid"]), "hostname": str(val["hostname"])}, val["value"])
-            for val in object_size
-            if val is not None
-        ]
+        for val in object_size:
+            if val is not None:
+                gauge.add_metric([str(val["pid"]), str(val["hostname"])], val["value"])
+        yield gauge
 
 
 @broadcast.decorator(expect_answers=True, timeout=15)
-def _get_python_object_size() -> Dict[str, float]:
-    return {"value": sum(sys.getsizeof(o) / 1024 for o in gc.get_objects())}
+def _get_python_object_size() -> dict[str, float]:
+    return {"value": sum(sys.getsizeof(o) for o in gc.get_objects())}
```

## c2cgeoportal_geoportal/lib/oauth2.py

```diff
@@ -23,36 +23,44 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import logging
 from datetime import datetime, timedelta
-from typing import Any, Dict, List, Union
+from typing import Any, Optional, TypedDict
 
 import basicauth
 import oauthlib.common
 import oauthlib.oauth2
 import pyramid.threadlocal
+from pyramid.httpexceptions import HTTPBadRequest
 
-import c2cgeoportal_commons  # pylint: disable=unused-import
+import c2cgeoportal_commons
 from c2cgeoportal_geoportal.lib.caching import get_region
 
 LOG = logging.getLogger(__name__)
 OBJECT_CACHE_REGION = get_region("obj")
 
 
+class _Token(TypedDict):
+    access_token: str
+    refresh_token: str
+    expires_in: int
+    state: Optional[str]
+
+
 class RequestValidator(oauthlib.oauth2.RequestValidator):  # type: ignore
     """The oauth2 request validator implementation."""
 
     def __init__(self, authorization_expires_in: int) -> None:
         # in minutes
         self.authorization_expires_in = authorization_expires_in
 
-    def authenticate_client(  # pylint: disable=no-self-use,useless-suppression
+    def authenticate_client(
         self,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Authenticate client through means outside the OAuth 2 spec.
@@ -61,15 +69,15 @@
         be `HTTP Basic Authentication Scheme`_ which utilizes the Authorization
         header.
 
         Headers may be accesses through request.headers and parameters found in
         both body and query can be obtained by direct attribute access, i.e.
         request.client_id for client_id in the URL query.
 
-        Arguments:
+        Keyword Arguments:
 
             request: oauthlib.common.Request
 
         Returns: True or False
 
         Method is used by:
             - Authorization Code Grant
@@ -81,15 +89,15 @@
         """
         del args, kwargs
 
         LOG.debug("authenticate_client => unimplemented")
 
         raise NotImplementedError("Not implemented, the method `authenticate_client_id` should be used.")
 
-    def authenticate_client_id(  # pylint: disable=no-self-use,useless-suppression
+    def authenticate_client_id(
         self,
         client_id: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
@@ -107,14 +115,16 @@
         """
         del args, kwargs
 
         LOG.debug("authenticate_client_id %s", client_id)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         params = dict(request.decoded_body)
 
         if "client_secret" in params:
             client_secret = params["client_secret"]
         elif "Authorization" in request.headers:
             username, password = basicauth.decode(request.headers["Authorization"])
             assert client_id == username
@@ -129,15 +139,15 @@
             .filter(static.OAuth2Client.secret == client_secret)
             .one_or_none()
         )
 
         LOG.debug("authenticate_client_id => %s", request.client is not None)
         return request.client is not None
 
-    def client_authentication_required(  # pylint: disable=no-self-use,useless-suppression
+    def client_authentication_required(
         self,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Determine if client authentication is required for current request.
@@ -149,15 +159,15 @@
             - Authorization Code Grant, when Client type is Confidential or when Client was issued
               client credentials or whenever Client provided client authentication,
               see `Section 4.1.3`_.
             - Refresh Token Grant, when Client type is Confidential or when Client was issued
               client credentials or whenever Client provided client authentication, see
               `Section 6`_
 
-        Arguments:
+        Keyword Arguments:
 
             request: oauthlib.common.Request
 
         Returns: True or False
 
         Method is used by:
             - Authorization Code Grant
@@ -170,15 +180,15 @@
         """
         del request, args, kwargs
 
         LOG.debug("client_authentication_required => False")
 
         return False
 
-    def confirm_redirect_uri(  # pylint: disable=no-self-use,useless-suppression
+    def confirm_redirect_uri(
         self,
         client_id: str,
         code: str,
         redirect_uri: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",  # noqa: F821
         *args: Any,
         **kwargs: Any,
@@ -191,15 +201,15 @@
 
         If the client specifies a redirect_uri when obtaining code then that
         redirect URI must be bound to the code and verified equal in this
         method, according to RFC 6749 section 4.1.3.  Do not compare against
         the client's allowed redirect URIs, but against the URI used when the
         code was saved.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             code: Unicode authorization_code.
             redirect_uri: Unicode absolute URI
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
@@ -210,63 +220,39 @@
         """
         del args, kwargs
 
         LOG.debug("confirm_redirect_uri %s %s", client_id, redirect_uri)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         authorization_code = (
             DBSession.query(static.OAuth2AuthorizationCode)
             .join(static.OAuth2AuthorizationCode.client)
             .filter(static.OAuth2AuthorizationCode.code == code)
             .filter(static.OAuth2Client.client_id == client_id)
             .filter(static.OAuth2AuthorizationCode.redirect_uri == redirect_uri)
             .filter(static.OAuth2AuthorizationCode.expire_at > datetime.now())
             .one_or_none()
         )
         LOG.debug("confirm_redirect_uri => %s", authorization_code is not None)
         return authorization_code is not None
 
-    def get_code_challenge_method(  # pylint: disable=no-self-use,useless-suppression
-        self, code: str, request: oauthlib.common.Request
-    ) -> None:
-        """
-        Is called during the "token" request processing.
-
-        When a ``code_verifier`` and a ``code_challenge`` has
-        been provided. See ``.get_code_challenge``. Must return ``plain`` or ``S256``. You can return a custom
-        value if you have implemented your own ``AuthorizationCodeGrant`` class.
-
-        Arguments:
-
-            code: Authorization code.
-            request: OAuthlib request.
-
-        Returns: code_challenge_method string
-
-        Method is used by:
-            - Authorization Code Grant - when PKCE is active
-        """
-        del code, request
-
-        LOG.debug("get_code_challenge_method")
-
-        raise NotImplementedError("Not implemented.")
-
-    def get_default_redirect_uri(  # pylint: disable=no-self-use,useless-suppression
+    def get_default_redirect_uri(
         self,
         client_id: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> str:
         """
         Get the default redirect URI for the client.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             request: The HTTP Request
 
         Returns: The default redirect URI for the client
 
         Method is used by:
@@ -275,25 +261,25 @@
         """
         del request, args, kwargs
 
         LOG.debug("get_default_redirect_uri %s", client_id)
 
         raise NotImplementedError("Not implemented.")
 
-    def get_default_scopes(  # pylint: disable=no-self-use,useless-suppression
+    def get_default_scopes(
         self,
         client_id: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
-    ) -> List[str]:
+    ) -> list[str]:
         """
         Get the default scopes for the client.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             request: The HTTP Request
 
         Returns: List of default scopes
 
         Method is used by all core grant types:
@@ -304,25 +290,25 @@
         """
         del request, args, kwargs
 
         LOG.debug("get_default_scopes %s", client_id)
 
         return ["geomapfish"]
 
-    def get_original_scopes(  # pylint: disable=no-self-use,useless-suppression
+    def get_original_scopes(
         self,
         refresh_token: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
-    ) -> List[str]:
+    ) -> list[str]:
         """
         Get the list of scopes associated with the refresh token.
 
-        Arguments:
+        Keyword Arguments:
 
             refresh_token: Unicode refresh token
             request: The HTTP Request
 
         Returns: List of scopes.
 
         Method is used by:
@@ -330,15 +316,15 @@
         """
         del refresh_token, request, args, kwargs
 
         LOG.debug("get_original_scopes")
 
         return []
 
-    def introspect_token(  # pylint: disable=no-self-use,useless-suppression
+    def introspect_token(
         self,
         token: str,
         token_type_hint: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> None:
@@ -362,15 +348,15 @@
         - jti : string identifier for the token
         Note that most of them are coming directly from JWT RFC. More details
         can be found in `Introspect Claims`_ or `_JWT Claims`_.
         The implementation can use *token_type_hint* to improve lookup
         efficiency, but must fallback to other types to be compliant with RFC.
         The dict of claims is added to request.token after this method.
 
-        Arguments:
+        Keyword Arguments:
 
             token: The token string.
             token_type_hint: access_token or refresh_token.
             request: OAuthlib request.
 
         Method is used by:
             - Introspect Endpoint (all grants are compatible)
@@ -380,52 +366,54 @@
         """
         del token, request, args, kwargs
 
         LOG.debug("introspect_token %s", token_type_hint)
 
         raise NotImplementedError("Not implemented.")
 
-    def invalidate_authorization_code(  # pylint: disable=no-self-use,useless-suppression
+    def invalidate_authorization_code(
         self,
         client_id: str,
         code: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> None:
         """
         Invalidate an authorization code after use.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             code: The authorization code grant (request.code).
             request: The HTTP Request
 
         Method is used by:
             - Authorization Code Grant
         """
         del args, kwargs
 
         LOG.debug("invalidate_authorization_code %s", client_id)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         DBSession.delete(
             DBSession.query(static.OAuth2AuthorizationCode)
             .join(static.OAuth2AuthorizationCode.client)
             .filter(static.OAuth2AuthorizationCode.code == code)
             .filter(static.OAuth2Client.client_id == client_id)
             .filter(static.OAuth2AuthorizationCode.user_id == request.user.id)
             .one()
         )
 
-    def is_within_original_scope(  # pylint: disable=no-self-use,useless-suppression
+    def is_within_original_scope(
         self,
-        request_scopes: List[str],
+        request_scopes: list[str],
         refresh_token: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Check if requested scopes are within a scope of the refresh token.
@@ -434,82 +422,80 @@
         needs to be within the scope of the original token. This is
         ensured by checking that all requested scopes strings are on
         the list returned by the get_original_scopes. If this check
         fails, is_within_original_scope is called. The method can be
         used in situations where returning all valid scopes from the
         get_original_scopes is not practical.
 
-        Arguments:
+        Keyword Arguments:
 
             request_scopes: A list of scopes that were requested by client
             refresh_token: Unicode refresh_token
             request: The HTTP Request
 
         Method is used by:
             - Refresh token grant
         """
         del request, args, kwargs
 
         LOG.debug("is_within_original_scope %s %s", request_scopes, refresh_token)
 
         return False
 
-    def revoke_token(  # pylint: disable=no-self-use,useless-suppression
+    def revoke_token(
         self,
         token: str,
         token_type_hint: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> None:
         """
         Revoke an access or refresh token.
 
-        Arguments:
+        Keyword Arguments:
 
             token: The token string.
             token_type_hint: access_token or refresh_token.
             request: The HTTP Request
 
         Method is used by:
             - Revocation Endpoint
         """
         del token, request, args, kwargs
 
         LOG.debug("revoke_token %s", token_type_hint)
 
         raise NotImplementedError("Not implemented.")
 
-    def rotate_refresh_token(  # pylint: disable=no-self-use,useless-suppression
-        self, request: oauthlib.common.Request
-    ) -> bool:
+    def rotate_refresh_token(self, request: oauthlib.common.Request) -> bool:
         """
         Determine whether to rotate the refresh token. Default, yes.
 
         When access tokens are refreshed the old refresh token can be kept
         or replaced with a new one (rotated). Return True to rotate and
         and False for keeping original.
 
-        Arguments:
+        Keyword Arguments:
 
             request: oauthlib.common.Request
 
         Method is used by:
             - Refresh Token Grant
         """
         del request
 
         LOG.debug("rotate_refresh_token")
 
         return True
 
-    def save_authorization_code(  # pylint: disable=no-self-use,useless-suppression
+    def save_authorization_code(
         self,
         client_id: str,
-        code: Dict[str, str],
+        code: dict[str, str],
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> None:
         """
         Persist the authorization_code.
 
@@ -519,62 +505,81 @@
             - a resource owner / user (request.user)
             - the authorized scopes (request.scopes)
             - the client state, if given (code.get('state'))
 
         The 'code' argument is actually a dictionary, containing at least a
         'code' key with the actual authorization code:
 
-            {'code': 'sdf345jsdf0934f'}
+            {'code': '<secret>'}
 
         It may also have a 'state' key containing a nonce for the client, if it
         chose to send one.  That value should be saved and used in
         'validate_code'.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             code: A dict of the authorization code grant and, optionally, state.
             request: The HTTP Request
 
         Method is used by:
             - Authorization Code Grant
+
+        To support PKCE, you MUST associate the code with:
+
+            Code Challenge (request.code_challenge) and
+            Code Challenge Method (request.code_challenge_method)
         """
         del args, kwargs
 
         LOG.debug("save_authorization_code %s", client_id)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
-        user = pyramid.threadlocal.get_current_request().user_
+        assert DBSession is not None
+
+        user = pyramid.threadlocal.get_current_request().user
 
         # Don't allows to have two authentications for the same user and the same client
         authorization_code = (
             DBSession.query(static.OAuth2AuthorizationCode)
             .filter(static.OAuth2AuthorizationCode.client_id == request.client.id)
             .filter(static.OAuth2AuthorizationCode.user_id == user.id)
             .one_or_none()
         )
 
         if authorization_code is not None:
-            authorization_code.code = code["code"]
             authorization_code.expire_at = datetime.now() + timedelta(minutes=self.authorization_expires_in)
-            authorization_code.redirect_uri = request.redirect_uri
         else:
             authorization_code = static.OAuth2AuthorizationCode()
             authorization_code.client_id = request.client.id
-            authorization_code.code = code["code"]
             authorization_code.user_id = user.id
             authorization_code.expire_at = datetime.now() + timedelta(minutes=self.authorization_expires_in)
-            authorization_code.redirect_uri = request.redirect_uri
+            authorization_code.state = code.get("state")
+
+        authorization_code.code = code["code"]
+        authorization_code.redirect_uri = request.redirect_uri
+
+        client = (
+            DBSession.query(static.OAuth2Client)
+            .filter(static.OAuth2Client.client_id == client_id)
+            .one_or_none()
+        )
+        if client and client.state_required and not code.get("state"):
+            raise HTTPBadRequest("Client is missing the state parameter.")
+
+        if client and client.pkce_required:
+            authorization_code.challenge = request.code_challenge
+            authorization_code.challenge_method = request.code_challenge_method
 
         DBSession.add(authorization_code)
 
-    def save_bearer_token(  # pylint: disable=no-self-use,useless-suppression
+    def save_bearer_token(
         self,
-        token: Dict[str, Union[str, int]],
+        token: _Token,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> None:
         """
         Persist the Bearer token.
 
@@ -585,25 +590,25 @@
             - an expiration time
             - a refresh token, if issued
 
         The Bearer token dict may hold a number of items::
 
             {
                 'token_type': 'Bearer',
-                'access_token': 'askfjh234as9sd8',
+                'access_token': '<secret>',
                 'expires_in': 3600,
                 'scope': 'string of space separated authorized scopes',
-                'refresh_token': '23sdf876234',  # if issued
+                'refresh_token': '<secret>',  # if issued
                 'state': 'given_by_client',  # if supplied by client
             }
 
         Note that while "scope" is a string-separated list of authorized scopes,
         the original list is still available in request.scopes
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             token: A Bearer token dict
             request: The HTTP Request
 
         Returns: The default redirect URI for the client
 
@@ -615,46 +620,45 @@
         """
         del args, kwargs
 
         LOG.debug("save_bearer_token")
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         # Don't allows to have tow token for one user end one client
         bearer_token = (
             DBSession.query(static.OAuth2BearerToken)
             .filter(static.OAuth2BearerToken.client_id == request.client.id)
             .filter(static.OAuth2BearerToken.user_id == request.user.id)
             .one_or_none()
         )
 
-        if bearer_token is not None:
-            bearer_token.access_token = token["access_token"]
-            bearer_token.refresh_token = token["refresh_token"]
-            bearer_token.expire_at = datetime.now() + timedelta(seconds=float(token["expires_in"]))
-        else:
+        if bearer_token is None:
             bearer_token = static.OAuth2BearerToken()
             bearer_token.client_id = request.client.id
             bearer_token.user_id = request.user.id
-            bearer_token.access_token = token["access_token"]
-            bearer_token.refresh_token = token["refresh_token"]
-            bearer_token.expire_at = datetime.now() + timedelta(seconds=float(token["expires_in"]))
-
             DBSession.add(bearer_token)
 
-    def validate_bearer_token(  # pylint: disable=no-self-use,useless-suppression
+        bearer_token.access_token = token["access_token"]
+        bearer_token.refresh_token = token["refresh_token"]
+        bearer_token.expire_at = datetime.now() + timedelta(seconds=float(token["expires_in"]))
+        bearer_token.state = token.get("state")
+
+    def validate_bearer_token(
         self,
         token: str,
-        scopes: List[str],
+        scopes: list[str],
         request: oauthlib.common.Request,
     ) -> bool:
         """
         Ensure the Bearer token is valid and authorized access to scopes.
 
-        Arguments:
+        Keyword Arguments:
 
             token: A string of random characters.
             scopes: A list of scopes associated with the protected resource.
             request: The HTTP Request
 
         A key to OAuth 2 security and restricting impact of leaked tokens is
         the short expiration time of tokens, *always ensure the token has not
@@ -682,15 +686,15 @@
         Note, the request.user attribute can be set to the resource owner
         associated with this token. Similarly the request.client and
         request.scopes attribute can be set to associated client object
         and authorized scopes. If you then use a decorator such as the
         one provided for django these attributes will be made available
         in all protected views as keyword arguments.
 
-        Arguments:
+        Keyword Arguments:
 
             token: Unicode Bearer token
             scopes: List of scopes (defined by you)
             request: The HTTP Request
 
         Method is indirectly used by all core Bearer token issuing grant types:
             - Authorization Code Grant
@@ -699,65 +703,70 @@
             - Client Credentials Grant
         """
 
         LOG.debug("validate_bearer_token %s", scopes)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         bearer_token = (
             DBSession.query(static.OAuth2BearerToken)
+            .join(static.User)
             .filter(static.OAuth2BearerToken.access_token == token)
             .filter(static.OAuth2BearerToken.expire_at > datetime.now())
         ).one_or_none()
 
         if bearer_token is not None:
             request.user = bearer_token.user
 
         LOG.debug("validate_bearer_token => %s", bearer_token is not None)
         return bearer_token is not None
 
-    def validate_client_id(  # pylint: disable=no-self-use,useless-suppression
+    def validate_client_id(
         self,
         client_id: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure client_id belong to a valid and active client.
 
         Note, while not strictly necessary it can often be very convenient
         to set request.client to the client object associated with the
         given client_id.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             request: oauthlib.common.Request
 
         Method is used by:
             - Authorization Code Grant
             - Implicit Grant
         """
         del args, kwargs
 
         LOG.debug("validate_client_id")
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         client = (
             DBSession.query(static.OAuth2Client)
             .filter(static.OAuth2Client.client_id == client_id)
             .one_or_none()
         )
         if client is not None:
             request.client = client
         return client is not None
 
-    def validate_code(  # pylint: disable=no-self-use,useless-suppression
+    def validate_code(
         self,
         client_id: str,
         code: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",  # noqa: F821
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
@@ -771,15 +780,15 @@
             - request.user
             - request.state (if given)
             - request.scopes
         OBS! The request.user attribute should be set to the resource owner
         associated with this authorization code. Similarly request.scopes
         must also be set.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             code: Unicode authorization code
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by:
@@ -787,40 +796,54 @@
         """
         del args, kwargs
 
         LOG.debug("validate_code %s", client_id)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
-        authorization_code = (
+        assert DBSession is not None
+
+        authorization_code_query = (
             DBSession.query(static.OAuth2AuthorizationCode)
             .join(static.OAuth2AuthorizationCode.client)
             .filter(static.OAuth2AuthorizationCode.code == code)
-            .filter(static.OAuth2Client.client_id == client_id)
+            .filter(static.OAuth2AuthorizationCode.client_id == client.id)
             .filter(static.OAuth2AuthorizationCode.expire_at > datetime.now())
-            .one_or_none()
         )
-        if authorization_code is not None:
-            request.user = authorization_code.user
-        LOG.debug("validate_code => %s", authorization_code is not None)
-        return authorization_code is not None
+        if client.state_required:
+            authorization_code_query = authorization_code_query.filter(
+                static.OAuth2AuthorizationCode.state == request.state
+            )
+
+        authorization_code = authorization_code_query.one_or_none()
+        if authorization_code is None:
+            LOG.debug("validate_code => KO, no authorization_code found")
+            return False
 
-    def validate_grant_type(  # pylint: disable=no-self-use,useless-suppression
+        if authorization_code.client.pkce_required:
+            request.code_challenge = authorization_code.challenge
+            request.code_challenge_method = authorization_code.challenge_method
+
+        request.user = authorization_code.user
+        LOG.debug("validate_code => OK")
+        return True
+
+    def validate_grant_type(
         self,
         client_id: str,
         grant_type: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure client is authorized to use the grant_type requested.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             grant_type: Unicode grant type, i.e. authorization_code, password.
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by:
@@ -836,29 +859,29 @@
             client_id,
             grant_type,
             grant_type in ("authorization_code", "refresh_token"),
         )
 
         return grant_type in ("authorization_code", "refresh_token")
 
-    def validate_redirect_uri(  # pylint: disable=no-self-use,useless-suppression
+    def validate_redirect_uri(
         self,
         client_id: str,
         redirect_uri: str,
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure client is authorized to redirect to the redirect_uri requested.
 
         All clients should register the absolute URIs of all URIs they intend
         to redirect to. The registration is outside of the scope of oauthlib.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             redirect_uri: Unicode absolute URI
             request: The HTTP Request
 
         Method is used by:
             - Authorization Code Grant
@@ -866,38 +889,40 @@
         """
         del request, args, kwargs
 
         LOG.debug("validate_redirect_uri %s %s", client_id, redirect_uri)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         client = (
             DBSession.query(static.OAuth2Client)
             .filter(static.OAuth2Client.client_id == client_id)
             .filter(static.OAuth2Client.redirect_uri == redirect_uri)
             .one_or_none()
         )
         LOG.debug("validate_redirect_uri %s", client is not None)
         return client is not None
 
-    def validate_refresh_token(  # pylint: disable=no-self-use,useless-suppression
+    def validate_refresh_token(
         self,
         refresh_token: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",  # noqa: F821
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure the Bearer token is valid and authorized access to scopes.
 
         OBS! The request.user attribute should be set to the resource owner
         associated with this refresh token.
 
-        Arguments:
+        Keyword Arguments:
 
             refresh_token: Unicode refresh token
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by:
             - Authorization Code Grant (indirectly by issuing refresh tokens)
@@ -906,39 +931,41 @@
         """
         del args, kwargs
 
         LOG.debug("validate_refresh_token %s", client.client_id if client else None)
 
         from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         bearer_token = (
             DBSession.query(static.OAuth2BearerToken)
             .filter(static.OAuth2BearerToken.refresh_token == refresh_token)
             .filter(static.OAuth2BearerToken.client_id == request.client.id)
             .one_or_none()
         )
 
         if bearer_token is not None:
             request.user = bearer_token.user
 
         return bearer_token is not None
 
-    def validate_response_type(  # pylint: disable=no-self-use,useless-suppression
+    def validate_response_type(
         self,
         client_id: str,
         response_type: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure client is authorized to use the response_type requested.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             response_type: Unicode response type, i.e. code, token.
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by:
@@ -947,27 +974,27 @@
         """
         del client, request, args, kwargs
 
         LOG.debug("validate_response_type %s %s", client_id, response_type)
 
         return response_type == "code"
 
-    def validate_scopes(  # pylint: disable=no-self-use,useless-suppression
+    def validate_scopes(
         self,
         client_id: str,
-        scopes: List[str],
+        scopes: list[str],
         client: "c2cgeoportal_commons.models.static.OAuth2Client",
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
     ) -> bool:
         """
         Ensure the client is authorized access to requested scopes.
 
-        Arguments:
+        Keyword Arguments:
 
             client_id: Unicode client identifier
             scopes: List of scopes (defined by you)
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by all core grant types:
@@ -978,15 +1005,15 @@
         """
         del client, request, args, kwargs
 
         LOG.debug("validate_scopes %s %s", client_id, scopes)
 
         return True
 
-    def validate_user(  # pylint: disable=no-self-use,useless-suppression
+    def validate_user(
         self,
         username: str,
         password: str,
         client: "c2cgeoportal_commons.models.static.OAuth2Client",  # noqa: F821
         request: oauthlib.common.Request,
         *args: Any,
         **kwargs: Any,
@@ -995,15 +1022,15 @@
         Ensure the username and password is valid.
 
         OBS! The validation should also set the user attribute of the request
         to a valid resource owner, i.e. request.user = username or similar. If
         not set you will be unable to associate a token with a user in the
         persistence method used (commonly, save_bearer_token).
 
-        Arguments:
+        Keyword Arguments:
 
             username: Unicode username
             password: Unicode password
             client: Client object set by you, see authenticate_client.
             request: The HTTP Request
 
         Method is used by:
@@ -1011,25 +1038,148 @@
         """
         del password, client, request, args, kwargs
 
         LOG.debug("validate_user %s", username)
 
         raise NotImplementedError("Not implemented.")
 
+    def is_pkce_required(self, client_id: int, request: oauthlib.common.Request) -> bool:
+        """
+        Determine if current request requires PKCE.
+
+        Default, False. This is called for both authorization and token requests.
+
+        Override this method by return True to enable PKCE for everyone. You might want to enable it only
+        for public clients. Note that PKCE can also be used in addition of a client authentication.
+
+        OAuth 2.0 public clients utilizing the Authorization Code Grant are susceptible to
+        the authorization code interception attack. This specification describes the attack as well as
+        a technique to mitigate against the threat through the use of Proof Key for Code Exchange
+        (PKCE, pronounced pixy). See RFC7636.
+
+        Keyword Arguments:
+
+            client_id: Client identifier.
+            request (oauthlib.common.Request): OAuthlib request.
+
+
+        Method is used by:
+
+                Authorization Code Grant
+
+
+        """
+        from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
+
+        assert DBSession is not None
+
+        client = (
+            DBSession.query(static.OAuth2Client)
+            .filter(static.OAuth2Client.client_id == client_id)
+            .one_or_none()
+        )
+
+        return client and client.pkce_required  # type: ignore
+
+    def get_code_challenge(self, code: str, request: oauthlib.common.Request) -> Optional[str]:
+        """
+        Is called for every token requests.
+
+        When the server issues the authorization code in the authorization response, it MUST associate the
+        code_challenge and code_challenge_method values with the authorization code so it can be
+        verified later.
+
+        Typically, the code_challenge and code_challenge_method values are stored in encrypted form in
+        the code itself but could alternatively be stored on the server associated with the code.
+        The server MUST NOT include the code_challenge value in client requests in a form that other
+        entities can extract.
+
+        Return the code_challenge associated to the code. If None is returned, code is considered to not
+        be associated to any challenges.
+
+        Keyword Arguments:
+
+            code: Authorization code.
+            request: OAuthlib request.
+
+        Return:
+
+            code_challenge string
+
+        Method is used by:
+
+                Authorization Code Grant - when PKCE is active
+        """
+        from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
+
+        assert DBSession is not None
+
+        LOG.debug("get_code_challenge")
+
+        authorization_code = (
+            DBSession.query(static.OAuth2AuthorizationCode)
+            .filter(static.OAuth2AuthorizationCode.code == code)
+            .one_or_none()
+        )
+        if authorization_code:
+            return authorization_code.challenge
+        LOG.debug("get_code_challenge authorization_code not found")
+        return None
+
+    def get_code_challenge_method(self, code: str, request: oauthlib.common.Request) -> Optional[str]:
+        """
+        Is called during the token request processing.
+
+        When a code_verifier and a code_challenge has been provided.
+
+        See .get_code_challenge.
+
+        Must return plain or S256. You can return a custom value if you have implemented your own
+        AuthorizationCodeGrant class.
+
+        Keyword Arguments:
+
+            code: Authorization code.
+            request: OAuthlib request.
+
+        Return type:
+
+            code_challenge_method string
+
+        Method is used by:
+
+                Authorization Code Grant - when PKCE is active
+        """
+        from c2cgeoportal_commons.models import DBSession, static  # pylint: disable=import-outside-toplevel
+
+        assert DBSession is not None
+
+        LOG.debug("get_code_challenge_method")
+
+        authorization_code = (
+            DBSession.query(static.OAuth2AuthorizationCode)
+            .filter(static.OAuth2AuthorizationCode.code == code)
+            .one_or_none()
+        )
+        if authorization_code:
+            return authorization_code.challenge_method
+        LOG.debug("get_code_challenge_method authorization_code not found")
+        return None
+
 
-def get_oauth_client(settings: Dict[str, Any]) -> oauthlib.oauth2.WebApplicationServer:
+def get_oauth_client(settings: dict[str, Any]) -> oauthlib.oauth2.WebApplicationServer:
     """Get the oauth2 client, with a cache."""
     authentication_settings = settings.get("authentication", {})
     return _get_oauth_client_cache(
         authentication_settings.get("oauth2_authorization_expire_minutes", 10),
         authentication_settings.get("oauth2_token_expire_minutes", 60),
     )
 
 
-@OBJECT_CACHE_REGION.cache_on_arguments()  # type: ignore
+@OBJECT_CACHE_REGION.cache_on_arguments()
 def _get_oauth_client_cache(
     authorization_expire_minutes: int, token_expire_minutes: int
 ) -> oauthlib.oauth2.WebApplicationServer:
     """Get the oauth2 client, with a cache."""
     return oauthlib.oauth2.WebApplicationServer(
         RequestValidator(authorization_expires_in=authorization_expire_minutes),
         token_expires_in=token_expire_minutes * 60,
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## c2cgeoportal_geoportal/lib/wmstparsing.py

```diff
@@ -23,15 +23,15 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import datetime
-from typing import Any, Dict, List, Optional, Set, Tuple, Union
+from typing import Any, Optional, Union
 
 import isodate
 
 TimeExtent = Union["TimeExtentValue", "TimeExtentInterval"]
 
 
 def min_none(a: Optional[datetime.datetime], b: Optional[datetime.datetime]) -> Optional[datetime.datetime]:
@@ -63,17 +63,17 @@
         widget: The layer mode ("slider" (default) or "datepicker")
     """
 
     def __init__(self) -> None:
         self.extent: Optional[TimeExtent] = None
         self.mode: Optional[str] = None
         self.widget: Optional[str] = None
-        self.layer: Optional[Dict[str, Any]] = None
+        self.layer: Optional[dict[str, Any]] = None
 
-    def merge(self, layer: Dict[str, Any], extent: TimeExtent, mode: str, widget: str) -> None:
+    def merge(self, layer: dict[str, Any], extent: TimeExtent, mode: str, widget: str) -> None:
         layer_apply = self.layer == layer or (not self.has_time() and extent is not None)
 
         self.merge_extent(extent)
         self.merge_mode(mode)
         self.merge_widget(widget)
 
         if layer_apply:
@@ -106,36 +106,36 @@
                 raise ValueError(f"Could not mix time widget '{widget!s}' and '{self.widget!s}'")
         else:
             self.widget = widget
 
     def has_time(self) -> bool:
         return self.extent is not None
 
-    def to_dict(self) -> Optional[Dict[str, Any]]:
+    def to_dict(self) -> Optional[dict[str, Any]]:
         if self.has_time():
             assert self.extent is not None
             time = self.extent.to_dict()
             time["mode"] = self.mode
             time["widget"] = self.widget
             return time
         return None
 
 
 class TimeExtentValue:
     """Represents time as a list of values."""
 
     def __init__(
         self,
-        values: Set[datetime.datetime],
+        values: set[datetime.datetime],
         resolution: str,
         min_def_value: Optional[datetime.datetime],
         max_def_value: Optional[datetime.datetime],
     ):
         """
-        Initialise.
+        Initialize.
 
         Arguments:
 
             values: A set() of datetime
             resolution: The resolution from the mapfile time definition
             min_def_value: the minimum default value as a datetime
             max_def_value: the maximum default value as a datetime
@@ -148,15 +148,15 @@
     def merge(self, extent: TimeExtent) -> None:
         if not isinstance(extent, TimeExtentValue):
             raise ValueError("Could not mix time defined as a list of values with other type of definition")
         self.values.update(extent.values)
         self.min_def_value = min_none(self.min_def_value, extent.min_def_value)
         self.max_def_value = max_none(self.max_def_value, extent.max_def_value)
 
-    def to_dict(self) -> Dict[str, Any]:
+    def to_dict(self) -> dict[str, Any]:
         values = sorted(self.values)
         min_def_value = _format_date(self.min_def_value) if self.min_def_value else None
         max_def_value = _format_date(self.max_def_value) if self.max_def_value else None
 
         return {
             "minValue": _format_date(values[0]),
             "maxValue": _format_date(values[-1]),
@@ -170,15 +170,15 @@
 class TimeExtentInterval:
     """Represents time with the help of a start, an end and an interval."""
 
     def __init__(
         self,
         start: datetime.datetime,
         end: datetime.datetime,
-        interval: Tuple[int, int, int, int],
+        interval: tuple[int, int, int, int],
         resolution: str,
         min_def_value: Optional[datetime.datetime],
         max_def_value: Optional[datetime.datetime],
     ):
         """
         Initialize.
 
@@ -224,29 +224,29 @@
             else (
                 extent.max_def_value
                 if self.max_def_value is None
                 else max_none(self.max_def_value, extent.max_def_value)
             )
         )
 
-    def to_dict(self) -> Dict[str, Any]:
+    def to_dict(self) -> dict[str, Any]:
         min_def_value = _format_date(self.min_def_value) if self.min_def_value is not None else None
         max_def_value = _format_date(self.max_def_value) if self.max_def_value is not None else None
 
         return {
             "minValue": _format_date(self.start),
             "maxValue": _format_date(self.end),
             "interval": self.interval,
             "resolution": self.resolution,
             "minDefValue": min_def_value,
             "maxDefValue": max_def_value,
         }
 
 
-def parse_extent(extent: List[str], default_values: str) -> TimeExtent:
+def parse_extent(extent: list[str], default_values: str) -> TimeExtent:
     """
     Parse a time extend from OWSLib to a ` TimeExtentValue`` or a ``TimeExtentInterval``.
 
     Two formats are supported:
     * ['start/end/interval']
     * ['date1', 'date2', ..., 'date N']
 
@@ -270,15 +270,15 @@
         resolution = dates[0][0]
         values = {d[1] for d in dates}
 
         return TimeExtentValue(values, resolution, min_def_value, max_def_value)
     raise ValueError(f"Invalid time extent format '{extent}'")
 
 
-def _parse_default_values(default_values: str) -> Tuple[datetime.datetime, Optional[datetime.datetime]]:
+def _parse_default_values(default_values: str) -> tuple[datetime.datetime, Optional[datetime.datetime]]:
     """
     Parse the 'default' value from OWSLib's defaulttimeposition and return a maximum of two dates.
 
     default value must be a slash separated String. return None on the seconde value if it does not exist.
     """
     if default_values is None:
         return None, None
@@ -290,15 +290,15 @@
 
     if len(def_value) > 1:
         _, max_def_value = _parse_date(def_value[1])
 
     return min_def_value, max_def_value
 
 
-def _parse_date(date: str) -> Tuple[str, datetime.datetime]:
+def _parse_date(date: str) -> tuple[str, datetime.datetime]:
     """
     Parse a date string.
 
     Return a tuple containing:
 
     * the resolution: "year", "month", "day" or "second"
     * the date as a datetime
@@ -327,15 +327,15 @@
     str_ = isodate.datetime_isoformat(date)
     assert isinstance(str_, str)
     if date.tzinfo is None:
         str_ += "Z"
     return str_
 
 
-def _parse_duration(duration: str) -> Tuple[int, int, int, int]:
+def _parse_duration(duration: str) -> tuple[int, int, int, int]:
     """
     Parse an ISO 8601 duration (i.e. "P2DT5S").
 
     Return a tuple containing:
 
     * years
     * months
```

## c2cgeoportal_geoportal/lib/xsd.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2021, Camptocamp SA
+# Copyright (c) 2018-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,37 +23,38 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 from io import BytesIO
-from typing import Any, Callable, Dict, Optional, Type, Union, cast
+from typing import Any, Callable, Optional, Union, cast
 
+import sqlalchemy.orm.mapper
+import sqlalchemy.sql.elements
 import sqlalchemy.sql.schema
 from papyrus.xsd import XSDGenerator as PapyrusXSDGenerator
 from papyrus.xsd import tag
-from sqlalchemy.ext.declarative import DeclarativeMeta
 from sqlalchemy.orm.properties import ColumnProperty
 from sqlalchemy.orm.util import class_mapper
 
 
 class XSDGenerator(PapyrusXSDGenerator):  # type: ignore
     """Extends the PapyrusXSDGenerator."""
 
-    def add_class_properties_xsd(self, tb: str, cls: DeclarativeMeta) -> None:
+    def add_class_properties_xsd(self, tb: str, cls: type) -> None:
         """
         Add the XSD for the class properties to the ``TreeBuilder``.
 
         And call the user ``sequence_callback``.
         """
-        mapper = class_mapper(cls)
+        mapper: sqlalchemy.orm.Mapper[Any] = class_mapper(cls)
         properties = []
-        if cls.__attributes_order__:
-            for attribute_name in cls.__attributes_order__:
+        if cls.__attributes_order__:  # type: ignore[attr-defined]
+            for attribute_name in cls.__attributes_order__:  # type: ignore[attr-defined]
                 attr = mapper.attrs.get(attribute_name)
                 if attr:
                     properties.append(attr)
 
             # Add other attributes
             for p in mapper.iterate_properties:
                 if p not in properties:
@@ -64,25 +65,27 @@
         for p in properties:
             if isinstance(p, ColumnProperty):
                 self.add_column_property_xsd(tb, p)
 
         if self.sequence_callback:
             self.sequence_callback(tb, cls)
 
-    def add_column_property_xsd(self, tb: str, column_property: ColumnProperty) -> None:
+    def add_column_property_xsd(self, tb: str, column_property: ColumnProperty[Any]) -> None:
         column = column_property.columns[0]
         if column.foreign_keys:
             self.add_association_proxy_xsd(tb, column_property)
             return
 
         super().add_column_property_xsd(tb, column_property)
 
-    def add_association_proxy_xsd(self, tb: str, column_property: ColumnProperty) -> None:
+    def add_association_proxy_xsd(self, tb: str, column_property: ColumnProperty[Any]) -> None:
         from c2cgeoportal_commons.models import DBSession  # pylint: disable=import-outside-toplevel
 
+        assert DBSession is not None
+
         column = column_property.columns[0]
         proxy = column.info["association_proxy"]
         attribute = column_property.class_attribute
         cls = attribute.parent.entity
         association_proxy = getattr(cls, proxy)
         relationship_property = class_mapper(cls).get_property(association_proxy.target)
         target_cls = relationship_property.argument
@@ -98,15 +101,15 @@
             with tag(tb2, "xsd:simpleType") as tb3:
                 with tag(tb3, "xsd:restriction", {"base": "xsd:string"}) as tb4:
                     for (value,) in query:
                         with tag(tb4, "xsd:enumeration", {"value": value}):
                             pass
             self.element_callback(tb4, column)
 
-    def element_callback(self, tb: str, column: sqlalchemy.sql.schema.Column) -> None:
+    def element_callback(self, tb: str, column: sqlalchemy.sql.elements.NamedColumn[Any]) -> None:
         if column.info.get("readonly"):
             with tag(tb, "xsd:annotation"):
                 with tag(tb, "xsd:appinfo"):
                     with tag(tb, "readonly", {"value": "true"}):
                         pass
 
 
@@ -125,16 +128,16 @@
             include_foreign_keys=include_foreign_keys,
             sequence_callback=sequence_callback,
             element_callback=element_callback,
         )
 
     def __call__(
         self, table: str
-    ) -> Callable[[Union[Type[str], Type[bytes]], Dict[str, Any]], Optional[bytes]]:
-        def _render(cls: Union[Type[str], Type[bytes]], system: Dict[str, Any]) -> Optional[bytes]:
+    ) -> Callable[[Union[type[str], type[bytes]], dict[str, Any]], Optional[bytes]]:
+        def _render(cls: Union[type[str], type[bytes]], system: dict[str, Any]) -> Optional[bytes]:
             request = system.get("request")
             if request is not None:
                 response = request.response
                 response.content_type = "application/xml"
                 io = self.generator.get_class_xsd(BytesIO(), cls)
                 return cast(bytes, io.getvalue())
             return None
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Dockerfile

```diff
@@ -1,54 +1,53 @@
 ARG {{cookiecutter.geomapfish_version_tag}}
 ARG {{cookiecutter.geomapfish_major_version_tag}}
 
 FROM camptocamp/geomapfish-tools:{{cookiecutter.geomapfish_version_tag_env}} as builder
 LABEL maintainer Camptocamp "info@camptocamp.com"
 
 COPY requirements.txt /tmp/requirements.txt
-RUN \
-  python3 -m pip install --disable-pip-version-check --no-cache-dir --requirement=/tmp/requirements.txt && \
-  rm --recursive --force /tmp/* /var/tmp/* /root/.cache/*
+RUN --mount=type=cache,target=/root/.cache \
+    python3 -m pip install --disable-pip-version-check --requirement=/tmp/requirements.txt
 
 WORKDIR /app
 COPY webpack.*.js Makefile CONST_Makefile /app/
 COPY {{cookiecutter.package}}_geoportal/static-ngeo /app/{{cookiecutter.package}}_geoportal/static-ngeo
 RUN make apps
 
 COPY . /app
 
-RUN make checks
 RUN make build
 RUN mv webpack.apps.js webpack.apps.js.tmpl
 
 ENTRYPOINT [ "/usr/bin/eval-templates" ]
 CMD [ "webpack-dev-server", "--mode=development", "--debug", "--watch", "--no-inline" ]
 
 ###############################################################################
 
 FROM camptocamp/geomapfish:{{cookiecutter.geomapfish_major_version_tag_env}} as runner
 
 COPY requirements.txt /tmp/requirements.txt
-RUN \
-  python3 -m pip install --disable-pip-version-check --no-cache-dir --requirement=/tmp/requirements.txt && \
-  rm --recursive --force /tmp/* /var/tmp/* /root/.cache/*
+RUN --mount=type=cache,target=/root/.cache \
+    python3 -m pip install --disable-pip-version-check --requirement=/tmp/requirements.txt
 
 WORKDIR /app
 COPY . /app
 # Workaround, see:https://github.com/moby/moby/issues/37965
 RUN true
 COPY --from=builder /usr/lib/node_modules/ngeo/dist/* /etc/static-ngeo/
 COPY --from=builder /etc/static-ngeo/* /etc/static-ngeo/
 COPY --from=builder /app/alembic.ini /app/alembic.yaml ./
 RUN chmod go+w /etc/static-ngeo/
 
-RUN python3 -m pip install --disable-pip-version-check --no-cache-dir --editable=/app/ && \
-    python3 -m compileall -q /usr/local/lib/python3.* \
-        -x '/(debugpy|pipenv|.*pydev.*|networkx)/' && \
-    python3 -m compileall -q /app/{{cookiecutter.package}}_geoportal -x /app/{{cookiecutter.package}}_geoportal/static.*
+RUN --mount=type=cache,target=/root/.cache \
+    python3 -m pip install --disable-pip-version-check --editable=/app/ \
+    && python3 -m compileall -q /usr/local/lib/python3.* \
+        -x '/(ptvsd|.*pydev.*|networkx|scaffolds|yaml_include)/' \
+    && python3 -m compileall -q /app/{{cookiecutter.package}}_geoportal -x /app/{{cookiecutter.package}}_geoportal/static.* \
+    && pip freeze > /requirements.txt
 
 ARG GIT_HASH
 RUN c2cwsgiutils-genversion ${GIT_HASH}
 
 ARG PGSCHEMA
 ENV PGSCHEMA=${PGSCHEMA}
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/development.ini

```diff
@@ -44,15 +44,15 @@
 listen = *:8080
 
 [filter:proxy-prefix]
 use = egg:PasteDeploy#prefix
 prefix = %(VISIBLE_ENTRY_POINT)s
 
 [pipeline:main]
-pipeline = egg:c2cwsgiutils#client_info egg:c2cwsgiutils#profiler egg:c2cwsgiutils#sentry app
+pipeline = egg:c2cwsgiutils#client_info egg:c2cwsgiutils#sentry app
 
 ###
 # logging configuration
 # https://docs.pylonsproject.org/projects/pyramid/en/1.5-branch/narr/logging.html
 ###
 
 [loggers]
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/gunicorn.conf.py

```diff
@@ -1,9 +1,7 @@
-# -*- coding: utf-8 -*-
-
 # Copyright (c) 2019-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
@@ -30,15 +28,18 @@
 ###
 # app configuration
 # https://docs.gunicorn.org/en/stable/settings.html
 ###
 
 import os
 
-from c2cwsgiutils import get_config_defaults
+import gunicorn.arbiter
+import gunicorn.workers.base
+from c2cwsgiutils import get_config_defaults, prometheus
+from prometheus_client import multiprocess
 
 bind = ":8080"
 
 worker_class = "gthread"
 workers = int(os.environ.get("GUNICORN_WORKERS", 2))
 threads = int(os.environ.get("GUNICORN_THREADS", 10))
 
@@ -98,7 +99,43 @@
             "datefmt": "[%Y-%m-%d %H:%M:%S %z]",
             "class": "logging.Formatter",
         }
     },
 }
 
 raw_paste_global_conf = ["=".join(e) for e in get_config_defaults().items()]
+
+
+def on_starting(server: gunicorn.arbiter.Arbiter) -> None:
+    """
+    Will start the prometheus server.
+
+    Called just before the master process is initialized.
+    """
+
+    del server
+
+    prometheus.start()
+
+
+def post_fork(server: gunicorn.arbiter.Arbiter, worker: gunicorn.workers.base.Worker) -> None:
+    """
+    Will cleanup the configuration we get from the main process.
+
+    Called just after a worker has been forked.
+    """
+
+    del server, worker
+
+    prometheus.cleanup()
+
+
+def child_exit(server: gunicorn.arbiter.Arbiter, worker: gunicorn.workers.base.Worker) -> None:
+    """
+    Remove the metrics for the exited worker.
+
+    Called just after a worker has been exited, in the master process.
+    """
+
+    del server
+
+    multiprocess.mark_process_dead(worker.pid)
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/requirements.txt

```diff
@@ -1,2 +1,2 @@
-#debugpy  # Remote debugging
+#ptvsd  # Remote debugging
 #wsgi-lineprof  # Profiling
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.api.js

### js-beautify {}

```diff
@@ -26,15 +26,19 @@
                 test: /\.js$/,
                 use: {
                     loader: 'babel-loader',
                     options: {
                         presets: babelPresets,
                         babelrc: false,
                         comments: false,
-                        plugins: [require.resolve('babel-plugin-angularjs-annotate')],
+                        plugins: [
+                            require.resolve('babel-plugin-angularjs-annotate'),
+                            require.resolve('@babel/plugin-proposal-nullish-coalescing-operator'),
+                            require.resolve('@babel/plugin-proposal-optional-chaining'),
+                        ],
                     },
                 },
             }, ],
         },
         output: {
             filename: 'api.js',
             path: destDir,
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.apps.js

### js-beautify {}

```diff
@@ -30,15 +30,15 @@
     );
 }
 
 const babelPresets = [
     [
         require.resolve('@babel/preset-env'), {
             targets: {
-                browsers: ['> 0.7% in CH', '> 0.7% in FR', 'Firefox ESR'],
+                browsers: ['defaults', '> 0.7% in CH', '> 0.9% in FR', 'Firefox ESR', 'supports es6-class'],
             },
             modules: false,
             loose: true,
         },
     ],
 ];
```

## c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py

```diff
@@ -1,15 +1,13 @@
-import distutils.core
-
 from pyramid.config import Configurator
 
 import {{cookiecutter.package}}_geoportal.authentication
 import {{cookiecutter.package}}_geoportal.dev
 import {{cookiecutter.package}}_geoportal.multi_organization
-from c2cgeoportal_geoportal import INTERFACE_TYPE_NGEO, add_interface_config, locale_negotiator
+from c2cgeoportal_geoportal import add_interface_config, locale_negotiator
 from c2cgeoportal_geoportal.lib.i18n import LOCALE_PATH
 from {{cookiecutter.package}}_geoportal.resources import Root
 
 
 def main(global_config, **settings):
     """
     This function returns a Pyramid WSGI application.
@@ -24,18 +22,15 @@
 
     config.include("c2cgeoportal_commons")
 
     config.include({{cookiecutter.package}}_geoportal.authentication.includeme)
 
     config.add_translation_dirs(LOCALE_PATH)
 
-    # Workaround to not have the error: distutils.errors.DistutilsArgError: no commands supplied
-    distutils.core._setup_stop_after = "config"  # pylint: disable=protected-access
     config.include("c2cgeoportal_geoportal")
-    distutils.core._setup_stop_after = None  # pylint: disable=protected-access
 
     config.include({{cookiecutter.package}}_geoportal.multi_organization.includeme)
 
     # Scan view decorator for adding routes
     config.scan()
 
     # Add the interfaces
```

## c2cgeoportal_geoportal/scaffolds/advance_update/{{cookiecutter.project}}/geoportal/CONST_Makefile

```diff
@@ -39,40 +39,20 @@
 WEBPACK_ARGS ?= --debug
 
 VALIDATE_PY_FOLDERS = admin/$(PACKAGE)_admin \
 	$(PACKAGE)_geoportal/*.py $(PACKAGE)_geoportal/lib \
 	$(PACKAGE)_geoportal/scripts $(PACKAGE)_geoportal/views
 VALIDATE_PY_TEST_FOLDERS = $(PACKAGE)_geoportal/tests
 
-PY_FILES = $(shell find $(PACKAGE) -type f -name '*.py' -print 2> /dev/null)
-
-# Templates
-
-
 # Disabling Make built-in rules to speed up execution time
 .SUFFIXES:
 
 .PHONY: build
 build: $(BUILD_RULES)
 
-.PHONY: checks
-checks: prospector eslint
-
-.PHONY: prospector
-prospector:
-	prospector
-
-.PHONY: eslint
-eslint: $(APP_JS_FILES)
-	eslint $?
-
-.PHONY: eslint-fix
-eslint-fix: $(APP_JS_FILES)
-	eslint --fix $?
-
 # Server localisation
 
 PO_FILES = $(addprefix $(PACKAGE)_geoportal/locale/, $(addsuffix /LC_MESSAGES/$(PACKAGE)_geoportal-server.po, $(LANGUAGES)))
 
 .INTERMEDIATE: $(PACKAGE)_geoportal/locale/$(PACKAGE)_geoportal-server.pot
 $(PACKAGE)_geoportal/locale/$(PACKAGE)_geoportal-server.pot: lingua-server.cfg $(SRC_FILES)
 	mkdir --parent $(dir $@)
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile

```diff
@@ -10,66 +10,65 @@
     default_locale_name servers layers cache admin_interface getitfixed functionalities \
     raster shortener hide_capabilities tinyowsproxy resourceproxy print_url print_get_redirect \
     checker check_collector default_max_age package srid \
     reset_password fulltextsearch global_headers headers authorized_referers hooks stats db_chooser \
     dbsessions urllogin host_forward_host headers_whitelist headers_blacklist \
     smtp c2c.base_path welcome_email \
     lingua_extractor interfaces_config interfaces devserver_url api authentication intranet metrics pdfreport \
-    vector_tiles i18next
+    vector_tiles i18next main_ogc_server
 
 COPY . /tmp/config/
 
 ARG SIMPLE
 ENV SIMPLE=$SIMPLE
 
 RUN build-l10n "{{cookiecutter.package}}"
 
 ARG PGSCHEMA
 ENV PGSCHEMA=$PGSCHEMA
 
 RUN \
-    cd /tmp/config/geoportal/ && \
-    c2c-template --vars ${VARS_FILE} \
+    cd /tmp/config/geoportal/ \
+    && c2c-template --vars ${VARS_FILE} \
         --get-config {{cookiecutter.package}}_geoportal/config.yaml \
-        ${CONFIG_VARS} && \
-    pykwalify --data-file {{cookiecutter.package}}_geoportal/config.yaml \
-        --schema-file CONST_config-schema.yaml && \
-    rm CONST_* vars.yaml && \
-    qgisserver-plugin-config {{cookiecutter.package}}_geoportal/config.yaml ../qgisserver/geomapfish.yaml.tmpl
+        ${CONFIG_VARS} \
+    && pykwalify --data-file {{cookiecutter.package}}_geoportal/config.yaml \
+        --schema-file CONST_config-schema.yaml \
+    && rm CONST_* vars.yaml \
+    && qgisserver-plugin-config {{cookiecutter.package}}_geoportal/config.yaml ../qgisserver/geomapfish.yaml.tmpl
 
 ###############################################################################
 
 FROM camptocamp/geomapfish-config:{{cookiecutter.geomapfish_major_version_tag_env}} AS gmf_config
 
 ARG PGSCHEMA
 ENV PGSCHEMA=$PGSCHEMA
 
 COPY --from=builder /tmp/config/ /tmp/config/
 
 RUN \
-    if [ -e /tmp/config/mapserver ]; then mv /tmp/config/mapserver /etc/; fi && \
-    if [ -e /tmp/config/tilegeneration ]; then mv /tmp/config/tilegeneration /etc/; fi && \
-    if [ -e /tmp/config/qgisserver ]; then mv /tmp/config/qgisserver /etc/qgisserver; fi && \
-    if [ -e /tmp/config/haproxy ]; then mv /tmp/config/haproxy/* /etc/haproxy/; fi && \
-    mkdir --parent /usr/local/tomcat/webapps/ROOT/ && \
-    if [ -e /tmp/config/print ]; then mv /tmp/config/print/print-apps /usr/local/tomcat/webapps/ROOT/; fi && \
-    mv /tmp/config/geoportal/{{cookiecutter.package}}_geoportal/ /etc/geomapfish/ && \
-    mv /tmp/config/geoportal/* /etc/geomapfish/ || true && \
-    chmod g+w -R \
+    mvif /tmp/config/mapserver /etc/ \
+    && mvif /tmp/config/tilegeneration /etc/ \
+    && mvif /tmp/config/qgisserver /etc/qgisserver \
+    && mvif /tmp/config/haproxy/* /etc/haproxy/ \
+    && mkdir --parent /usr/local/tomcat/webapps/ROOT/ \
+    && mvif /tmp/config/print /tmp/config/print/print-apps /usr/local/tomcat/webapps/ROOT/ \
+    && mv /tmp/config/geoportal/{{cookiecutter.package}}_geoportal/ /etc/geomapfish/ \
+    && mv /tmp/config/geoportal/* /etc/geomapfish/ || true \
+    && chmod g+w -R \
         /etc/geomapfish \
         /etc/mapserver \
         /etc/qgisserver \
         /etc/tilegeneration \
         /usr/local/tomcat/webapps/ROOT/print-apps \
         /etc/haproxy_dev \
-        /etc/haproxy && \
-    adduser www-data root && \
-    sed 's#bind :80#bind *:443 ssl crt /etc/haproxy_dev/localhost.pem#g' /etc/haproxy/haproxy.cfg.tmpl \
-        > /etc/haproxy_dev/haproxy.cfg.tmpl && \
-    echo '    http-request set-header X-Forwarded-Proto https' >> /etc/haproxy_dev/haproxy.cfg.tmpl
+        /etc/haproxy \
+    && sed 's#bind :80#bind *:443 ssl crt /etc/haproxy_dev/localhost.pem#g' /etc/haproxy/haproxy.cfg.tmpl \
+        > /etc/haproxy_dev/haproxy.cfg.tmpl \
+    && echo '    http-request set-header X-Forwarded-Proto https' >> /etc/haproxy_dev/haproxy.cfg.tmpl
 
 VOLUME /etc/geomapfish \
     /etc/mapserver \
     /etc/qgisserver \
     /etc/tilegeneration \
     /usr/local/tomcat/webapps/ROOT/print-apps \
     /etc/haproxy_dev \
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Makefile

```diff
@@ -1,14 +1,70 @@
 PROJECT_PUBLIC_URL=https://example.camptocamp.com/
+DUMP_FILE=dump.backup
 PACKAGE={{cookiecutter.package}}
 LANGUAGES=en fr de it
 
+.PHONY: help
+help: ## Display this help message
+	@echo "Usage: make <target>"
+	@echo
+	@echo "Available targets:"
+	@grep --extended-regexp --no-filename '^[a-zA-Z_-]+:.*## ' $(MAKEFILE_LIST) | sort | \
+		awk 'BEGIN {FS = ":.*?## "}; {printf "	%-20s%s\n", $$1, $$2}'
+
 .PHONY: update-po-from-url
 update-po-from-url: ## Update the po files from the URL provide by PROJECT_PUBLIC_URL
 	curl --fail --retry 5 --retry-delay 1 \
 		$(PROJECT_PUBLIC_URL)locale.pot > geoportal/${PACKAGE}_geoportal/locale/${PACKAGE}_geoportal-client${SUFFIX}.pot
 	sed -i '/^"POT-Creation-Date: /d' geoportal/${PACKAGE}_geoportal/locale/${PACKAGE}_geoportal-client${SUFFIX}.pot
-	docker-compose run --rm -T tools update-po-only `id --user` `id --group` $(LANGUAGES)
+	docker compose run --rm -T tools update-po-only `id --user` `id --group` $(LANGUAGES)
 
 .PHONY: update-po
-update-po:
-	docker-compose exec -T tools sh -c "USER_ID=`id --user` GROUP_ID=`id --group` make -C geoportal update-po"
+update-po: ## Update the po files from the running composition
+	docker compose exec -T tools sh -c "USER_ID=`id --user` GROUP_ID=`id --group` make --directory=geoportal update-po"
+
+.PHONY: checks
+checks: prospector eslint ## Runs the checks
+
+.PHONY: prospector
+prospector: ## Runs the Prospector checks
+	docker compose run --entrypoint= --no-deps --rm --volume=$(CURDIR)/geoportal:/app geoportal \
+		prospector --output-format=pylint --die-on-tool-error
+
+.PHONY: eslint
+eslint: ## Runs the eslint checks
+	docker compose run --entrypoint= --no-deps --rm --volume=$(CURDIR)/geoportal:/app geoportal \
+		eslint $(find {{cookiecutter.package}} -type f -name '*.js' -print 2> /dev/null)
+	docker compose run --entrypoint= --no-deps --rm --volume=$(CURDIR)/geoportal:/app geoportal \
+		eslint $(find {{cookiecutter.package}} -type f -name '*.ts' -print 2> /dev/null)
+
+.PHONY: qgis
+qgis: ## Run QGIS desktop
+	docker compose -f docker-compose.yaml -f docker-compose-qgis.yaml run --rm qgis
+
+secrets.tar.bz2.gpg: env.secrets ## Encrypt the secrets for committing changes
+	tar -jcf secrets.tar.bz2 $^
+	rm -f $@
+	gpg --symmetric --cipher-algo AES256 --batch \
+		--passphrase=$(shell gopass show gs/ci/large-secret-passphrase) secrets.tar.bz2
+	rm secrets.tar.bz2
+
+.PHONY: secrets
+secrets: ## Decrypt the secrets.tar.bz2.gpg file
+	gpg --quiet --batch --yes --decrypt --passphrase=$(shell gopass show gs/ci/large-secret-passphrase) \
+		--output secrets.tar.bz2 secrets.tar.bz2.gpg
+	tar --touch -jxf secrets.tar.bz2
+	rm secrets.tar.bz2
+
+.PHONY: acceptance-init
+acceptance-init: ## Initialize the acceptance tests
+	docker compose --file=docker-compose.yaml --file=docker-compose-db.yaml up -d db tools
+	docker compose exec -T tools wait-db
+	docker compose exec -T tools psql --command="DROP EXTENSION IF EXISTS postgis CASCADE"
+	scripts/db-restore --docker-compose-file=docker-compose.yaml --docker-compose-file=docker-compose-db.yaml \
+		--arg=--clean --arg=--if-exists --arg=--verbose $(DUMP_FILE)
+	docker compose --file=docker-compose.yaml --file=docker-compose-db.yaml up -d
+
+.PHONY: acceptance
+acceptance: ## Run the acceptance tests
+	docker compose exec -T tools pytest -vv tests/
+	ci/docker-compose-check
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst

```diff
@@ -20,10 +20,10 @@
   ./build
 
 Run
 ---
 
 .. code::
 
-   docker-compose up -d
+   docker compose up -d
 
 .. Feel free to add project-specific things.
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build

```diff
@@ -1,68 +1,83 @@
 #!/usr/bin/env python3
 
 import argparse
 import os
 import os.path
 import platform
 import re
+import shlex
 import shutil
 import stat
 import subprocess
 import sys
 import urllib.request
-from typing import Any, Dict, List, Optional
+from typing import TYPE_CHECKING, Any, List, Optional
 
 import yaml
 
+CompletedProcess = subprocess.CompletedProcess[str] if TYPE_CHECKING else subprocess.CompletedProcess
 
-def run(args: argparse.Namespace, command: List[str], **kwargs: Any) -> None:
+
+def run(
+    args: argparse.Namespace, command: List[str], exit_on_error: bool = True, **kwargs: Any
+) -> Optional[CompletedProcess]:
     if args.verbose or args.dry_run:
-        print(" ".join(command))
-    if not args.dry_run:
-        subprocess.run(command, **kwargs)  # nosec
+        print(shlex.join(command))
+    if not args.dry_run or "stdout" in kwargs:
+        if args.stack_trace and exit_on_error and not "checks" in kwargs:
+            kwargs["check"] = True
+        process = subprocess.run(command, **kwargs)  # nosec
+        if exit_on_error and process.returncode != 0:
+            print(f"An error occurred during execution of `{shlex.join(command)}`")
+            sys.exit(process.returncode)
+        return process
+    return None
 
 
 def main() -> None:
     parser = argparse.ArgumentParser(description="Build the project")
-    parser.add_argument("--verbose", action="store_true", help="Display the docker build commands")
+    parser.add_argument("--verbose", action="store_true", help="Display the Docker build commands")
     parser.add_argument(
         "--dry-run", action="store_true", help="Display the docker build commands without executing them"
     )
     parser.add_argument("--service", help="Build only the specified service")
     parser.add_argument("--env", action="store_true", help="Build only the .env file")
     parser.add_argument("--simple", action="store_true", help="Force simple application mode")
     parser.add_argument("--not-simple", action="store_true", help="Force not simple application mode")
     parser.add_argument("--upgrade", help="Start upgrading the project to version")
     parser.add_argument(
-        "--fast-reload",
-        action="store_true",
-        help="Restart the composition without Redis to don't lost the cache",
+        "--reload",
+        nargs="?",
+        action="store",
+        const="",
+        help="Comma separate list of services that will be reloaded after the build",
     )
     parser.add_argument(
         "--no-pull",
         action="store_true",
         default=os.environ.get("CI", "FALSE").upper() == "TRUE",
         help="Do not pull external or base images for faster rebuild during development.",
     )
     parser.add_argument(
         "--debug", help="Path to c2cgeoportal source folder to be able to debug the upgrade procedure"
     )
+    parser.add_argument("--stack-trace", action="store_true", help="Display the stack trace on error")
     parser.add_argument("env_files", nargs="*", help="The environment config")
     args = parser.parse_args()
 
     if args.upgrade:
         major_version = args.upgrade
         match = re.match(r"^([0-9]+\.[0-9]+)\.[0-9]+$", args.upgrade)
         if match is not None:
             major_version = match.group(1)
         match = re.match(r"^([0-9]+\.[0-9]+)\.[0-9a-z]+\.[0-9]+$", args.upgrade)
         if match is not None:
             major_version = match.group(1)
-        full_version = args.upgrade if args.upgrade != "master" else "latest"
+        full_version = args.upgrade
         with open("upgrade", "w", encoding="utf-8") as f:
             with urllib.request.urlopen(  # nosec
                 "https://raw.githubusercontent.com/camptocamp/c2cgeoportal/{major_version}/scripts/upgrade".format(
                     major_version=major_version
                 )
             ) as result:
                 if result.code != 200:
@@ -73,86 +88,92 @@
         debug_args = []
         if args.debug:
             shutil.copyfile(os.path.join(args.debug, "scripts", "upgrade"), "upgrade")
             debug_args = ["--debug", args.debug]
         os.chmod("upgrade", os.stat("upgrade").st_mode | stat.S_IXUSR)
         try:
             if platform.system() == "Windows":
-                run(args, ["python", "upgrade", full_version] + debug_args, check=True)
+                run(args, ["python", "upgrade", full_version] + debug_args)
             else:
-                run(args, ["./upgrade", full_version] + debug_args, check=True)
+                run(args, ["./upgrade", full_version] + debug_args)
         except subprocess.CalledProcessError:
             sys.exit(1)
         sys.exit(0)
 
+    docker_compose_command = ["docker", "compose"]
     with open("project.yaml", encoding="utf-8") as project_file:
         project_env = yaml.load(project_file, Loader=yaml.SafeLoader)["env"]
     if len(args.env_files) != project_env["required_args"]:
         print(project_env["help"])
         sys.exit(1)
     env_files = [e.format(*args.env_files) for e in project_env["files"]]
     print("Use env files: {}".format(", ".join(env_files)))
     for env_file in env_files:
         if not os.path.exists(env_file):
-            print("Error: the env file '{env_file}' does not exist.".format(env_file=env_file))
+            print(f"Error: the env file '{env_file}' does not exist.")
             sys.exit(1)
 
     with open(".env", "w", encoding="utf-8") as dest:
         for file_ in env_files:
             with open(file_, encoding="utf-8") as src:
                 dest.write(src.read() + "\n")
 
             simple = not os.path.exists("geoportal/Dockerfile")
             if args.simple:
                 simple = True
             if args.not_simple:
                 simple = False
 
-            git_hash = (
-                subprocess.run(["git", "rev-parse", "HEAD"], check=True, stdout=subprocess.PIPE)
-                .stdout.strip()
-                .decode()
-            )
+            git_hash = run(args, ["git", "rev-parse", "HEAD"], stdout=subprocess.PIPE).stdout.decode().strip()
 
-            dest.write("SIMPLE={}\n".format(str(simple).upper()))
-            dest.write("GIT_HASH={git_hash}\n".format(git_hash=git_hash))
+            dest.write(f"SIMPLE={str(simple).upper()}\n")
+            dest.write(f"GIT_HASH={git_hash}\n")
 
         dest.write("# Used env files: {}\n".format(", ".join(env_files)))
 
     if not args.env:
-        docker_compose_build_cmd = ["docker-compose", "build"]
+        docker_compose_build_cmd = [*docker_compose_command, "build"]
 
         if not args.no_pull:
             # Pull all the images
             if not args.service:
-                run(args, ["docker-compose", "pull", "--ignore-pull-failures"], check=True)  # nosec
+                run(args, [*docker_compose_command, "pull", "--ignore-buildable"])  # nosec
             docker_compose_build_cmd.append("--pull")
 
         if args.service:
             docker_compose_build_cmd.append(args.service)
 
         print_args = [a.replace(" ", "\\ ") for a in docker_compose_build_cmd]
         print_args = [a.replace('"', '\\"') for a in print_args]
         print_args = [a.replace("'", "\\'") for a in print_args]
         try:
-            run(args, docker_compose_build_cmd, check=True)  # nosec
+            env = {"DOCKER_BUILDKIT": "1", "COMPOSE_DOCKER_CLI_BUILD": "1"}
+            env.update(os.environ)
+            run(args, docker_compose_build_cmd, env=env)  # nosec
         except subprocess.CalledProcessError as e:
             print("Error with command: " + " ".join(print_args))
             sys.exit(e.returncode)
 
-    if args.fast_reload:
+    if args.reload:
+        services = args.reload.split(",")
+    elif args.reload == "":
         services = [
             service
-            for service in subprocess.run(
-                ["docker-compose", "ps", "--services", "--all"], stdout=subprocess.PIPE, check=True
+            for service in run(
+                args,
+                [*docker_compose_command, "ps", "--services", "--all"],
+                stdout=subprocess.PIPE,
+                exit_on_error=True,
             )
             .stdout.decode()
             .splitlines()
             if not service.startswith("redis")
         ]
 
-        run(args, ["docker-compose", "rm", "--stop", "--force"] + services, check=True)
-        run(args, ["docker-compose", "up", "-d"], check=True)
+    if args.reload is not None:
+        run(args, [*docker_compose_command, "rm", "--force", "-v", "config"])
+        for service in services:
+            run(args, [*docker_compose_command, "up", "--detach", "--force-recreate", service])
 
 
 if __name__ == "__main__":
     main()
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml

```diff
@@ -1,8 +1,9 @@
----
+# This file is managed by c2cgeoportal, it contains the default services configuration
+
 version: '2.3'
 
 services:
   config:
     image: ${DOCKER_BASE}-config:${DOCKER_TAG}
     build:
       context: .
@@ -60,30 +61,33 @@
       - AZURE_STORAGE_CONNECTION_STRING
       - AZURE_STORAGE_ACCOUNT
       - AZURE_STORAGE_ACCESS_TOKEN
       - AZURE_STORAGE_ACCESS_KEY
       - AZURE_STORAGE_SAS_TOKEN
       - TILEGENERATION_AZURE_CONTAINER
       - RASTER_BASE_PATH
+      - DISABLE_HAPROXY_LOGGING
+      - HAPROXY_LOGGING_OPTIONS
 
   print:
-    image: camptocamp/mapfish_print:3.28
+    image: camptocamp/mapfish_print:3.30
     user: www-data
     restart: unless-stopped
     environment:
       - CATALINA_OPTS
       - PGOPTIONS
 
   mapserver:
-    image: camptocamp/mapserver:7.6-gdal3.7
+    image: camptocamp/mapserver:8.0-gdal3.6
     user: www-data
     restart: unless-stopped
     entrypoint: []
     environment:
       - PGOPTIONS
+      - MAPSERVER_CONFIG_FILE=/etc/mapserver/mapserver.conf
 
   qgisserver:
     image: camptocamp/geomapfish-qgisserver:gmf${GEOMAPFISH_MAIN_VERSION}-qgis${QGIS_VERSION}
     user: www-data
     restart: unless-stopped
     environment:
       - C2C_REDIS_URL
@@ -102,46 +106,42 @@
       - AZURE_STORAGE_ACCESS_TOKEN
       - AZURE_STORAGE_ACCESS_KEY
       - AZURE_STORAGE_SAS_TOKEN
       - CPL_VSIL_CURL_USE_CACHE
       - CPL_VSIL_CURL_CACHE_SIZE
       - CPL_VSIL_CURL_USE_HEAD
       - GDAL_DISABLE_READDIR_ON_OPEN
-      - QGIS_SERVER_LOG_LEVEL=2
+      - QGIS_SERVER_LOG_LEVEL
       - QGIS_AUTH_DB_DIR_PATH
       - QGIS_SERVER_IGNORE_BAD_LAYERS
       - QGIS_SERVER_DISABLE_GETPRINT
       - PGSERVICEFILE
-      - LOG_LEVEL=INFO
+      - LOG_LEVEL=${QGIS_LOG_LEVEL}
       - LOG_TYPE
       - C2CGEOPORTAL_LOG_LEVEL
       - SQL_LOG_LEVEL
       - OTHER_LOG_LEVEL
       - GEOMAPFISH_ACCESSCONTROL_BASE_URL=${QGISSERVER_URL}
-      - QGIS_SERVER_TRUST_LAYER_METADATA=TRUE
-      - QGIS_SERVER_PARALLEL_RENDERING=FALSE
-      - MAX_CACHE_LAYERS=100
-      - QGIS_SERVER_IGNORE_BAD_LAYERS=TRUE
-      - QGIS_SERVER_CACHE_SIZE=60 # MB
-      - QGIS_SERVER_WMS_MAX_HEIGHT=5000
-      - QGIS_SERVER_WMS_MAX_WIDTH=5000
-      - QGIS_SERVER_API_WFS3_MAX_LIMIT=10000
-      - QGIS_SERVER_DISABLE_GETPRINT=TRUE
-      - QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES=/etc/qgisserver/
-      - QGIS_SERVER_OVERRIDE_SYSTEM_LOCALE=fr
-      - QGIS_AUTH_DB_DIR_PATH=/etc/qgisserver/
-      - PGSERVICEFILE=/etc/qgisserver/pg_service.conf
+      - QGIS_SERVER_TRUST_LAYER_METADATA
+      - QGIS_SERVER_PARALLEL_RENDERING
+      - MAX_CACHE_LAYERS
+      - QGIS_SERVER_CACHE_SIZE
+      - QGIS_SERVER_WMS_MAX_HEIGHT
+      - QGIS_SERVER_WMS_MAX_WIDTH
+      - QGIS_SERVER_API_WFS3_MAX_LIMIT
+      - QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES
+      - QGIS_SERVER_OVERRIDE_SYSTEM_LOCALE
 
   tinyows:
     image: camptocamp/tinyows:master
     user: www-data
     restart: unless-stopped
 
   redis:
-    image: &redis-image redis:6
+    image: redis:7.2
     user: www-data
     restart: unless-stopped
     command:
       - redis-server
       - --save
       - ''
       - --appendonly
@@ -150,29 +150,40 @@
       - 512mb
       - --maxmemory-policy
       - volatile-lru
       - --tcp-keepalive
       - '30'
 
   redis_master:
-    image: *redis-image
+    image: bitnami/redis:7.2.4
+    environment:
+      - REDIS_REPLICATION_MODE=master
+      - ALLOW_EMPTY_PASSWORD=yes
 
   redis_slave:
-    image: *redis-image
-    command: redis-server --slaveof redis_master 6379
+    image: bitnami/redis:7.2.4
+    environment:
+      - REDIS_REPLICATION_MODE=slave
+      - REDIS_MASTER_HOST=redis_master
+      - ALLOW_EMPTY_PASSWORD=yes
+    depends_on:
+      - redis_master
 
   redis_sentinel:
-    image: camptocamp/c2cwsgiutils-redis-sentinel:6
+    image: bitnami/redis-sentinel:7.2.4
     environment:
-      - MASTER_NAME=mymaster
-      - QUORUM=1
-      - MASTER=redis_master
+      - REDIS_MASTER_HOST=redis_master
+      - REDIS_MASTER_SET=mymaster
+      - ALLOW_EMPTY_PASSWORD=yes
+    depends_on:
+      - redis_master
+      - redis_slave
 
   tilecloudchain:
-    image: &tilecloudchain-image camptocamp/tilecloud-chain:1.17
+    image: &tilecloudchain-image camptocamp/tilecloud-chain:1.20
     user: www-data
     restart: unless-stopped
     environment:
       - DEVELOPMENT
       - VISIBLE_ENTRY_POINT
       - TILEGENERATION_CONFIGFILE=/etc/tilegeneration/config.yaml
       - AWS_ACCESS_KEY_ID
@@ -194,26 +205,34 @@
       - C2C_REQUESTS_DEFAULT_TIMEOUT
       - C2C_LOG_VIEW_ENABLED=TRUE
       - C2C_DEBUG_VIEW_ENABLED=TRUE
       - C2C_SQL_PROFILER_ENABLED=TRUE
       - C2C_PROFILER_PATH
       - C2C_PROFILER_MODULES
       - C2C_SECRET
+      - C2C_AUTH_GITHUB_REPOSITORY
+      - C2C_AUTH_GITHUB_ACCESS_TYPE
+      - C2C_AUTH_GITHUB_CLIENT_ID
+      - C2C_AUTH_GITHUB_CLIENT_SECRET
+      - C2C_AUTH_GITHUB_SCOPE
+      - C2C_AUTH_GITHUB_SECRET
+      - C2C_AUTH_GITHUB_PROXY_URL
+      - C2C_USE_SESSION=true
       - TILECLOUD_LOG_LEVEL
       - TILECLOUD_CHAIN_LOG_LEVEL
       - C2CWSGI_LOG_LEVEL
       - OTHER_LOG_LEVEL
       - LOG_TYPE
 
   tilegeneration_slave:
     image: *tilecloudchain-image
     user: www-data
     restart: unless-stopped
     entrypoint:
-      - generate_tiles
+      - generate-tiles
       - --role=slave
       - --daemon
     environment:
       - AWS_ACCESS_KEY_ID
       - AWS_SECRET_ACCESS_KEY
       - AZURE_STORAGE_CONNECTION_STRING
       - AZURE_STORAGE_ACCOUNT
@@ -234,15 +253,14 @@
       - PGHOST_SLAVE
       - PGPORT
       - PGPORT_SLAVE
       - PGUSER
       - PGPASSWORD
       - PGDATABASE
       - PGSSLMODE
-      - PGSCHEMA
       - PGSCHEMA_STATIC
       - PGOPTIONS
       - SQLALCHEMY_POOL_RECYCLE
       - SQLALCHEMY_POOL_SIZE
       - SQLALCHEMY_MAX_OVERFLOW
       - SQLALCHEMY_SLAVE_POOL_RECYCLE
       - SQLALCHEMY_SLAVE_POOL_SIZE
@@ -287,14 +305,21 @@
       - C2C_REQUESTS_DEFAULT_TIMEOUT
       - C2C_LOG_VIEW_ENABLED=TRUE
       - C2C_SQL_PROFILER_ENABLED=TRUE
       - C2C_PROFILER_PATH
       - C2C_PROFILER_MODULES
       - C2C_DEBUG_VIEW_ENABLED=TRUE
       - C2C_SECRET
+      - C2C_AUTH_GITHUB_REPOSITORY
+      - C2C_AUTH_GITHUB_ACCESS_TYPE
+      - C2C_AUTH_GITHUB_CLIENT_ID
+      - C2C_AUTH_GITHUB_CLIENT_SECRET
+      - C2C_AUTH_GITHUB_SCOPE
+      - C2C_AUTH_GITHUB_SECRET
+      - C2C_AUTH_GITHUB_PROXY_URL
       - LOG_LEVEL
       - C2CGEOPORTAL_LOG_LEVEL
       - SQL_LOG_LEVEL
       - GUNICORN_LOG_LEVEL
       - OTHER_LOG_LEVEL
       - DOGPILECACHE_LOG_LEVEL
       - C2CWSGIUTILS_LOG_LEVEL
@@ -375,15 +400,14 @@
       - C2C_BROADCAST_PREFIX
       - C2C_REQUESTS_DEFAULT_TIMEOUT
       - C2C_LOG_VIEW_ENABLED=TRUE
       - C2C_SQL_PROFILER_ENABLED=TRUE
       - C2C_PROFILER_PATH
       - C2C_PROFILER_MODULES
       - C2C_DEBUG_VIEW_ENABLED=TRUE
-      - C2C_SECRET
       - LOG_LEVEL
       - C2CGEOPORTAL_LOG_LEVEL
       - SQL_LOG_LEVEL
       - GUNICORN_LOG_LEVEL
       - OTHER_LOG_LEVEL
       - DOGPILECACHE_LOG_LEVEL
       - C2CWSGIUTILS_LOG_LEVEL
@@ -404,25 +428,24 @@
       - PGHOST_SLAVE
       - PGPORT
       - PGPORT_SLAVE
       - PGUSER
       - PGPASSWORD
       - PGDATABASE
       - PGSSLMODE
-      - PGSCHEMA
       - PGSCHEMA_STATIC
       - LOG_TYPE
 
   alembic-advance:
     <<: *alembic
     image: ${DOCKER_BASE}-geoportal:${DOCKER_TAG}
     build: *geoportal-build
 
   front:
-    image: haproxy:2.3
+    image: haproxy:2.6.7
     restart: unless-stopped
     volumes:
       - ${FRONT_LOG_DIRECTORY}:/dev/log:rw
     command:
       - haproxy
       - -f
       - /etc/${FRONT_CONFIG}
@@ -462,13 +485,10 @@
       - AZURE_STORAGE_ACCESS_TOKEN
       - AZURE_STORAGE_ACCESS_KEY
       - AZURE_STORAGE_SAS_TOKEN
 
   db:
     image: camptocamp/postgres:${POSTGRES_TAG}
     environment:
-      - PGUSER
-      - PGPASSWORD
-      - PGDATABASE
       - POSTGRES_PASSWORD=${PGPASSWORD}
       - POSTGRES_DB=${PGDATABASE}
       - POSTGRES_USER=${PGUSER}
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml

```diff
@@ -1,8 +1,7 @@
----
 # This file can be renamed as `docker-compose.override.yaml` and uncomment the desired lines for
 # development. The file `docker-compose.override.yaml` is ignored by Git by default.
 
 version: '2.3'
 
 services:
   geoportal:
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml

```diff
@@ -1,9 +1,8 @@
----
-# The project Docker compose file for development.
+# The project Docker compose file.
 
 version: '2.3'
 
 volumes:
   postgresql_data:
 
 services:
@@ -19,14 +18,15 @@
     volumes_from:
       - config:ro
 
   mapserver:
     extends:
       file: docker-compose-lib.yaml
       service: mapserver
+
     volumes_from:
       - config:ro
     volumes:
       - /var/sig:/var/sig:ro
 
   ## qgisserver:
   ##   extends:
@@ -103,15 +103,15 @@
   front:
     extends:
       file: docker-compose-lib.yaml
       service: front
     volumes_from:
       - config:ro
 
-  # Rich image for project development with e.-g. vim, tree, awscli, psql, ...
+  # Rich image for project development with e.-g. vim, psql, ...
   tools:
     extends:
       file: docker-compose-lib.yaml
       service: tools
     volumes_from:
       - config:ro
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default

```diff
@@ -26,14 +26,19 @@
 # DISABLE_LOCAL will be set to # on mutualize services to comment local configuration
 # DISABLE_MUTUALIZE is set to # locally to comment mutualize services
 DISABLE_MUTUALIZE=#
 DISABLE_LOCAL=
 # For backward compatibility
 DISABLE_MUTUALIZED_PRINT=#
 DISABLE_LOCAL_PRINT=
+# Set DISABLE_HAPROXY_LOGGING to # to disable logging
+DISABLE_HAPROXY_LOGGING=
+HAPROXY_LOGGING_OPTIONS="log global
+    option httplog
+    option dontlognull"
 
 GEOPORTAL_INTERNAL_URL=http://geoportal:8080
 GEOPORTAL_INTERNAL_HOST=geoportal
 GEOPORTAL_INTERNAL_PORT=8080
 TILECLOUDCHAIN_INTERNAL_URL=http://tilecloudchain:8080
 TILECLOUDCHAIN_INTERNAL_HOST=tilecloudchain
 TILECLOUDCHAIN_INTERNAL_PORT=8080
@@ -67,16 +72,30 @@
 OTHER_LOG_LEVEL=WARN
 DOGPILECACHE_LOG_LEVEL=WARN
 C2CWSGI_LOG_LEVEL=WARN
 TILECLOUD_LOG_LEVEL=INFO
 TILECLOUD_CHAIN_LOG_LEVEL=INFO
 C2CWSGIUTILS_LOG_LEVEL=INFO
 LOG_TYPE=console
+
+# QGIS
+QGIS_LOG_LEVEL=INFO # For the plugin
+QGIS_SERVER_LOG_LEVEL=2
 CPL_VSIL_CURL_USE_CACHE=TRUE
 CPL_VSIL_CURL_CACHE_SIZE=128000000
 CPL_VSIL_CURL_USE_HEAD=FALSE
 GDAL_DISABLE_READDIR_ON_OPEN=TRUE
 QGIS_AUTH_DB_DIR_PATH=/etc/qgisserver/
-QGIS_SERVER_IGNORE_BAD_LAYERS=true
-QGIS_SERVER_DISABLE_GETPRINT=true
+QGIS_SERVER_IGNORE_BAD_LAYERS=TRUE
+QGIS_SERVER_DISABLE_GETPRINT=TRUE
 PGSERVICEFILE=/etc/qgisserver/pg_service.conf
+QGIS_SERVER_TRUST_LAYER_METADATA=TRUE
+QGIS_SERVER_PARALLEL_RENDERING=FALSE
+MAX_CACHE_LAYERS=100
+QGIS_SERVER_CACHE_SIZE=60 # MB
+QGIS_SERVER_WMS_MAX_HEIGHT=5000
+QGIS_SERVER_WMS_MAX_WIDTH=5000
+QGIS_SERVER_API_WFS3_MAX_LIMIT=10000
+QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES=/etc/qgisserver/
+QGIS_SERVER_OVERRIDE_SYSTEM_LOCALE=fr
+
 FRONT_LOG_DIRECTORY=/dev/log
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.project

```diff
@@ -54,7 +54,16 @@
 # For internal Redis
 REDIS_HOST=redis
 REDIS_PORT=6379
 C2C_REDIS_URL=redis://redis:6379/0
 
 # Set a strong password here for authentication on technical interfaces behind path /c2c
 C2C_SECRET=
+# Or use connection via GitHub, see: https://camptocamp.github.io/c2cgeoportal/{{cookiecutter.geomapfish_main_version}}/integrator/c2cwsgiutils.html#authentication
+C2C_AUTH_GITHUB_REPOSITORY=camptocamp/{{cookiecutter.package}}
+C2C_AUTH_GITHUB_ACCESS_TYPE=admin
+C2C_AUTH_GITHUB_CLIENT_ID=210aefe26259de1e9532
+#C2C_AUTH_GITHUB_CLIENT_SECRET=<github OAuth application client secret>
+C2C_AUTH_GITHUB_SCOPE=repo
+#C2C_AUTH_GITHUB_SECRET=<secret>
+#C2C_AUTH_GITHUB_PROXY_URL=https://geoservicies.camptocamp.com/redirect
+C2C_USE_SESSION=true
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/pyproject.toml

```diff
@@ -1,3 +1,7 @@
 [tool.black]
 line-length = 110
-target-version = ['py38']
+target-version = ['py39']
+
+[tool.isort]
+profile = "black"
+line_length = 110
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/run_alembic.sh

```diff
@@ -1,13 +1,11 @@
 #!/bin/bash -eu
 # Upgrade the DB.
 #
 # Mostly useful in a Docker environment.
 
-for ini in *alembic*.ini
-do
-    if [[ -f $ini ]]
-    then
+for ini in *alembic*.ini; do
+    if [[ -f "$ini" ]]; then
         echo "$ini ==========================="
-        alembic -c $ini upgrade head
+        alembic -c "$ini" upgrade head
     fi
 done
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/spell-ignore-words.txt

```diff
@@ -1,3 +1,5 @@
 oder
 sie
 sur
+copyable
+referer
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/main.yaml

```diff
@@ -1,43 +1,57 @@
 ---
 name: Continuous integration
 
 on:
   push:
 
 # To publish the images to be used on Kubernetes
-#env:
-#  PROJECT: {{cookiecutter.package}}
-#  HAS_SECRETS: ${{'{{'}} secrets.HAS_SECRETS }}
-#  # Requires CI_GPG_PRIVATE_KEY and GOPASS_CI_GITHUB_TOKEN secrets.
-#  # The release branches
-#  HELM_RELEASE_NAMES: int-{{cookiecutter.geomapfish_main_version_dash}},prod-{{cookiecutter.geomapfish_main_version_dash}}
+# env:
+#   PROJECT: {{cookiecutter.package}}
+#   HAS_SECRETS: ${{'{{'}} secrets.HAS_SECRETS }}
 
 jobs:
   main:
     runs-on: ubuntu-22.04
     name: Continuous integration
     timeout-minutes: 10
 
     steps:
-      - uses: actions/checkout@v2
+      - uses: actions/checkout@v4
 
       # To publish the images to be used on Kubernetes
       # - uses: camptocamp/initialise-gopass-summon-action@v2
       #   with:
       #     ci-gpg-private-key: ${{'{{'}} secrets.CI_GPG_PRIVATE_KEY }}
       #     github-gopass-ci-token: ${{'{{'}} secrets.GOPASS_CI_GITHUB_TOKEN }}
       #     patterns: docker
       #   if: env.HAS_SECRETS == 'HAS_SECRETS'
 
       - run: echo "${HOME}/.local/bin" >> ${GITHUB_PATH}
       - run: python3 -m pip install --user --requirement=ci/requirements.txt
 
-      - name: Checks
-        run: c2cciutils-checks
+      # Can be used to have some secrets (with mask)
+      # - run: make secrets
+      # - run: cat env.secrets |grep '^[# A-Z0-9_]\+='|sed -e 's/^[# A-Z0-9_]\+=\(.*\)/::add-mask::\1/g'
+
+      - name: Environment information
+        run: c2cciutils-env
+
+      # - name: Initialize the acceptance tests
+      #   run: make acceptance-init
+      # - run: c2cciutils-docker-logs
+      #   if: always()
+
+      # - name: Run the acceptance tests
+      #   run: make acceptance
+      # - run: c2cciutils-docker-logs
+      #   if: always()
 
       - name: Build
         run: ./build
 
+      - name: Application checks
+        run: make checks
+
       # To publish the images to be used on Kubernetes
       # - name: Publish
       #   run: c2cciutils-publish
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/rebuild.yaml

```diff
@@ -22,15 +22,15 @@
       fail-fast: false
       matrix:
         branch:
           - int-{{cookiecutter.geomapfish_main_version_dash}}
           - prod-{{cookiecutter.geomapfish_main_version_dash}}
 
     steps:
-      - uses: actions/checkout@v2
+      - uses: actions/checkout@v4
         with:
           ref: ${{'{{'}} matrix.branch }}
 
       - uses: camptocamp/initialise-gopass-summon-action@v2
         with:
           ci-gpg-private-key: ${{'{{'}} secrets.CI_GPG_PRIVATE_KEY }}
           github-gopass-ci-token: ${{'{{'}} secrets.GOPASS_CI_GITHUB_TOKEN }}
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml

```diff
@@ -3,29 +3,29 @@
 
 on:
   schedule:
     - cron: '0 3 * * *'
 
 jobs:
   l10n:
-    runs-on: ubuntu-18.04
+    runs-on: ubuntu-22.04
     name: Update l10n cron job
     timeout-minutes: 10
 
     strategy:
       fail-fast: false
       matrix:
         include:
           - branch: int
             base_url: int.customer.ch
           - branch: prod
             base_url: prod.customer.ch
 
     steps:
-      - uses: actions/checkout@v2
+      - uses: actions/checkout@v4
         with:
           ref: ${{'{{'}} matrix.branch {{'}}'}}
           token: ${{'{{'}} secrets.GOPASS_CI_GITHUB_TOKEN {{'}}'}}
 
       - run: ./build --env
       - run: PROJECT_PUBLIC_URL=${{'{{'}} matrix.base_url {{'}}'}} make -e update-po-from-url
 
@@ -55,11 +55,12 @@
                 'maintainer_can_modify': True
               },
               headers={
                   'Accept': 'application/vnd.github.v3+json',
                   'Authorization': 'Bearer ${{'{{'}} secrets.GOPASS_CI_GITHUB_TOKEN {{'}}'}}',
                   'Content-Type': 'application/json',
               },
+              timeout=120,
           )
           # 422 is the return code when the pull request already exists
           assert response.status_code < 300 or response.status_code == 422, f'{response.status_code} - {response.text}'"
         if: steps.status.outputs.status != 'unchanged'
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml

```diff
@@ -1,15 +1,11 @@
 # yaml-language-server: $schema=https://raw.githubusercontent.com/camptocamp/c2cciutils/master/c2cciutils/schema.json
 
 checks:
-  black: False
-  isort: False
-  prettier: False
   codespell: False
-  eof: False
   required_workflows: False
   dependabot_config: False
   prospector_config: False
   setup: False
 
 version:
   branch_to_version_re:
@@ -17,9 +13,10 @@
       to: \1
     - from: (int-[0-9]+-[0-9]+)
       to: \1
 
 publish:
   pypi: false
   docker:
+    dispatch: {}
     images:
       - name: camptocamp/{{cookiecutter.package}}-config
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt

```diff
@@ -1 +1 @@
-c2cciutils==1.1.*
+c2cciutils[checks,publish]==1.6.18
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml

```diff
@@ -1,22 +1,36 @@
 ---
 extends: CONST_vars.yaml
 
 vars:
+  # To use an other SRID you should change:
+  #  - vars.srid
+  #  - vars.alternate_projections
+  #  - vars.resolutions
+  #  - vars.extent
+  #  - vars.tilesOrigin
+  #  - vars.interfaces_config.default.constants.gmfOptions.view.center
+  #  - vars.interfaces_config.default.constants.gmfOptions.wmtsTopLeft
+  #  - vars.interfaces_config.default.constants.gmfVectorTilesOptions.tileGrid.origin
   srid: &srid {{cookiecutter.srid}}
 
+  main_ogc_server: source for image/png
+
   alternate_projections: &alternate_projections
     - EPSG:4326
     - EPSG:{srid}
     - EPSG:21781
 
-  resolutions: &resolutions [250, 100, 50, 20, 10, 5, 2, 1, 0.5, 0.25, 0.1, 0.05]
+  resolutions: &resolutions [250, 100, 50, 20, 10, 5, 2.5, 1, 0.5, 0.25, 0.1, 0.05]
 
   extent: &extent [2420000, 1030000, 2900000, 1350000]
 
+  # Origin of the tiles [left, top]
+  tilesOrigin: &tilesOrigin [2420000, 1350000]
+
   # The application's default language. This is the language used by
   # the application if no specific language is specified in the URLs.
   # This also defines the language used for the text search.
   default_locale_name: fr
 
   # All the application interfaces used to create the apache rewrite rules
   interfaces:
@@ -26,50 +40,52 @@
     - name: iframe_api
 
   interfaces_config:
     default:
       constants:
         defaultTheme: Demo
         defaultLang: '{default_locale_name}'
-        gmfOptions:
+        gmfOptions: &gmfOptions
           map: {}
           view: &view
             projection: EPSG:{srid}
             center: [2600000, 1200000]
             zoom: 3
             resolutions: *resolutions
             extent: *extent
           geolocalisation: True
+          # Used to get pixel perfect render on WMTS layers [left, top]
+          wmtsTopLeft: *tilesOrigin
         gmfElevationOptions:
           layers: [aster, srtm]
         gmfSearchOptions:
           coordinatesProjections: *alternate_projections
         gmfPermalinkOptions:
           projectionCodes: *alternate_projections
         gmfVectorTilesOptions:
           projection: EPSG:{srid}
           tileGrid:
             extent: *extent
-            origin: [2420000, 1350000]
+            origin: *tilesOrigin
             resolutions: *resolutions
       routes:
         fulltextsearchUrl:
           params:
             limit: 30
             partitionlimit: 5
 
     desktop:
       constants:
         gmfOptions:
+          <<: *gmfOptions
           map:
             maxTilesLoading: 128
           view:
             <<: *view
             constrainResolution: True
-          geolocalisation: True
         gmfExternalOGCServers:
           - name: swisstopo WMS
             type: WMS
             url: https://wms.geo.admin.ch/?lang=fr
           - name: swisstopo WMTS
             type: WMTS
             url: https://wmts.geo.admin.ch/1.0.0/WMTSCapabilities.xml?lang=fr
@@ -99,26 +115,29 @@
         gmfContextualDataOptions:
           projections: *alternate_projections
           rasterParams: {}
 
     mobile:
       constants:
         gmfOptions:
-          map: {}
+          <<: *gmfOptions
           view:
             <<: *view
             autoRotate: True
-          geolocalisation: True
         gmfMobileMeasurePointOptions:
           rasterLayers:
             - name: aster
               unit: m
             - name: srtm
               unit: m
 
+    iframe_api:
+      constants:
+        gmfOptions: *gmfOptions
+
     api:
       constants:
         # The resolutions list.
         resolutions: *resolutions
 
         # The extent restriction, must be in the same projection as `config.projection`.
         # the format is `[minx, miny, maxx, maxy]`for example: `[2420000, 1030000, 2660000, 1350000]`
@@ -158,19 +177,16 @@
     available_in_templates:
       - default_basemap
 
   layers:
     geometry_validation: True
 
   api:
-    {}
-    # The OGC server used by the API.
-    # ogc_server: Main PNG
     # The name of the API in JavaScript
-    # name: <package>
+    name: '{{cookiecutter.package}}'
 
   # The "vector tiles web service" configuration. See the "vector tiles"
   # chapter in the integrator documentation.
   vector_tiles:
     srid: *srid
     extent: *extent
     resolutions: *resolutions
@@ -279,25 +295,33 @@
     #   url: {web_protocol}://{host}/child/wsgi
 
   # The dogpile.cache configuration.
   cache:
     std:
       # Standalone version
       backend: c2cgeoportal.hybrid
-      arguments:
+      arguments: &redis-cache-arguments
         host: '{REDIS_HOST}'
         port: '{REDIS_PORT}'
         db: '{REDIS_DB}'
+        password: '{REDIS_PASSWORD}'
+        connection_kwargs:
+          ssl: '{REDIS_SSL}'
       # Kubernetes version
-      # arguments:
+      # arguments: &redis-cache-arguments
       #   sentinels:
       #     - - '{REDIS_HOST}'
       #       - '{REDIS_PORT}'
       #   connection_kwargs:
       #     db: '{REDIS_DB}'
+    ogc-server:
+      # Standalone version
+      backend: c2cgeoportal.hybrid
+      # All versions
+      arguments: *redis-cache-arguments
 
   # This parameter set the list of hosts allowed to use the iframe api.
   # 'self' will block all external usage, you must add additional hosts separated by space.
   # see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/frame-ancestors
   content_security_policy_iframe_api_frame_ancestors: "'self'"
 
   # Control the HTTP headers
@@ -322,16 +346,16 @@
 
 update_paths:
   - admin_interface.available_functionalities
   - admin_interface.available_metadata
   - admin_interface.functionalities
   - admin_interface.available_in_templates
   - api
-  - authorized_referers
   - cache.std.arguments
+  - cache.ogc-server.arguments
   - cache.obj
   - check_collector.disabled
   - check_collector.hosts
   - checker.fulltextsearch
   - checker.lang
   - checker.phantomjs
   - checker.print
@@ -364,18 +388,20 @@
   - interfaces_config.default.constants.gmfOptions.view
   - interfaces_config.default.constants.gmfSearchOptions
   - interfaces_config.default.constants.gmfPermalinkOptions
   - interfaces_config.default.constants.gmfVectorTilesOptions
   - interfaces_config.default.dynamic_constants
   - interfaces_config.default.static
   - interfaces_config.default.routes.fulltextsearchUrl
-  - interfaces_config.desktop.constants
+  - interfaces_config.desktop.constants.gmfOptions.view
+  - interfaces_config.desktop.constants.gmfPrintOptions
   - interfaces_config.desktop.routes
+  - interfaces_config.mobile.constants.gmfOptions.view
   - interfaces_config.mobile.constants.gmfMobileMeasurePointOptions
-  - interfaces_config.iframe_api.constants
+  - interfaces_config.iframe_api.constants.gmfOptions.view
   - interfaces_config.api.constants
   - interfaces_config.api.routes.searchUrl
   - interfaces_theme
   - resourceproxy
   - servers
   - shortener.allowed_hosts
   - smtp
@@ -390,7 +416,11 @@
   - welcome_email.email_body
 
 # Only for Standalone version (should be commented for Kubernetes version)
 runtime_postprocess:
   - expression: int({})
     vars:
       - cache.std.arguments.port
+  - expression: str({}).lower() in ("true", "yes", "1")
+    vars:
+      - cache.std.arguments.connection_kwargs.ssl
+      - cache.ogc-server.arguments.connection_kwargs.ssl
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl

```diff
@@ -31,15 +31,15 @@
 
     # MAXSIZE should not be less than 5000 for MF print on A3
     MAXSIZE 5000
     IMAGECOLOR 255 255 255
     STATUS ON
 
     FONTSET "fonts.conf"
-    #SYMBOLSET "symbole.sym"
+    #SYMBOLSET "symbol.sym"
 
     CONFIG "CPL_VSIL_CURL_USE_CACHE" "TRUE"
     CONFIG "CPL_VSIL_CURL_CACHE_SIZE" "128000000"
     CONFIG "CPL_VSIL_CURL_USE_HEAD" "FALSE"
     CONFIG "GDAL_DISABLE_READDIR_ON_OPEN" "TRUE"
 
     OUTPUTFORMAT
@@ -66,18 +66,17 @@
     END
     WEB
         METADATA
             "wms_title" "changeme"
             "wms_abstract" "changeme"
             "ows_onlineresource" "${VISIBLE_WEB_PROTOCOL}://${VISIBLE_WEB_HOST}${VISIBLE_ENTRY_POINT}mapserv_proxy?ogcserver=source%20for%20image%2Fpng"
             "wms_srs" "EPSG:{{cookiecutter.srid}}"
-            "wms_encoding" "UTF-8"
             "wms_enable_request" "*"
             "wfs_enable_request" "!*"
-            "wfs_encoding" "UTF-8"
+            "wms_allow_getmap_without_styles" "true"
         END
     END
     LEGEND
         LABEL
             ENCODING "UTF-8"
             TYPE TRUETYPE
             FONT "Arial"
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt

```diff
@@ -16,15 +16,15 @@
 Shape		Polygon			Country/area border as polygon(s)
 FIPS		String(2)		FIPS 10-4 Country Code
 ISO2		String(2)		ISO 3166-1 Alpha-2 Country Code
 ISO3		String(3)		ISO 3166-1 Alpha-3 Country Code
 UN		Short Integer(3)	ISO 3166-1 Numeric-3 Country Code
 NAME		String(50)		Name of country/area
 AREA		Long Integer(7)		Land area, FAO Statistics (2002)
-POP2005		Double(10,0)	 	Population, World Polulation Prospects (2005)
+POP2005		Double(10,0)	 	Population, World Population Prospects (2005)
 REGION		Short Integer(3) 	Macro geographical (continental region), UN Statistics
 SUBREGION	Short Integer(3)	Geogrpahical sub-region, UN Statistics
 LON		FLOAT (7,3)		Longitude
 LAT		FLOAT (6,3)		Latitude
 
 
 CHANGELOG VERSION 0.3 - 30 July 2008
@@ -32,15 +32,15 @@
 - Corrected spelling mistake (United Arab Emirates)
 - Corrected population number for Japan
 - Adjusted long/lat values for India, Italy and United Kingdom
 
 
 CHANGELOG VERSION 0.2 - 1 April 2008
 
-- Made new ZIP archieves. No change in dataset.
+- Made new ZIP archives. No change in dataset.
 
 
 CHANGELOG VERSION 0.1 - 13 March 2008
 
 - Polygons representing each country were merged into one feature
 - land Islands was extracted from Finland
 - Hong Kong was extracted from China
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml

### c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml

```diff
@@ -1,11 +1,12 @@
 <?xml version="1.0" encoding="utf-8"?>
 <!-- Created with Jaspersoft Studio version 6.6.0.final using JasperReports Library version 6.6.0  -->
 <jasperReport xmlns="http://jasperreports.sourceforge.net/jasperreports" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://jasperreports.sourceforge.net/jasperreports http://jasperreports.sourceforge.net/xsd/jasperreport.xsd" name="gmf16_A3_landscape" pageWidth="1191" pageHeight="842" orientation="Landscape" columnWidth="1151" leftMargin="20" rightMargin="20" topMargin="20" bottomMargin="20" uuid="2646b6ef-0cc4-4852-b6e9-8c4dc54c2e84">
   <parameter name="title" class="java.lang.String"/>
+  <parameter name="username" class="java.lang.String"/>
   <parameter name="comments" class="java.lang.String"/>
   <parameter name="debug" class="java.lang.Boolean"/>
   <parameter name="mapSubReport" class="java.lang.String"/>
   <parameter name="legendDataSource" class="net.sf.jasperreports.engine.data.JRTableModelDataSource"/>
   <parameter name="legendSubReport" class="java.lang.String"/>
   <parameter name="numberOfLegendRows" class="java.lang.Integer"/>
   <parameter name="scalebarSubReport" class="java.lang.String"/>
@@ -193,10 +194,14 @@
         <textFieldExpression><![CDATA[$R{page} + " " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
       <textField evaluationTime="Report">
         <reportElement x="1125" y="21" width="22" height="30" uuid="c3450c45-a812-40a4-9a5e-c62dd7cef852"/>
         <textElement verticalAlignment="Bottom"/>
         <textFieldExpression><![CDATA[" / " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
+      <textField>
+        <reportElement x="0" y="15" width="300" height="15" uuid="f2fb034e-297f-4107-a5f5-da84722deb70"/>
+        <textFieldExpression><![CDATA[$P{username}]]></textFieldExpression>
+      </textField>
     </band>
   </pageFooter>
 </jasperReport>
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml

### c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml

```diff
@@ -1,11 +1,12 @@
 <?xml version="1.0" encoding="utf-8"?>
 <!-- Created with Jaspersoft Studio version 6.6.0.final using JasperReports Library version 6.6.0  -->
 <jasperReport xmlns="http://jasperreports.sourceforge.net/jasperreports" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://jasperreports.sourceforge.net/jasperreports http://jasperreports.sourceforge.net/xsd/jasperreport.xsd" name="gmf16_A3_portrait" pageWidth="842" pageHeight="1191" columnWidth="802" leftMargin="20" rightMargin="20" topMargin="20" bottomMargin="20" uuid="041e6c80-82d5-4055-a560-dd402f39361f">
   <parameter name="title" class="java.lang.String"/>
+  <parameter name="username" class="java.lang.String"/>
   <parameter name="comments" class="java.lang.String"/>
   <parameter name="debug" class="java.lang.Boolean"/>
   <parameter name="mapSubReport" class="java.lang.String"/>
   <parameter name="legendDataSource" class="net.sf.jasperreports.engine.data.JRTableModelDataSource"/>
   <parameter name="legendSubReport" class="java.lang.String"/>
   <parameter name="numberOfLegendRows" class="java.lang.Integer"/>
   <parameter name="scalebarSubReport" class="java.lang.String"/>
@@ -171,10 +172,14 @@
         <textFieldExpression><![CDATA[$R{page} + " " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
       <textField evaluationTime="Report">
         <reportElement x="776" y="21" width="22" height="30" uuid="4574386a-cbc9-4529-896b-c402fb4236c1"/>
         <textElement verticalAlignment="Bottom"/>
         <textFieldExpression><![CDATA[" / " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
+      <textField>
+        <reportElement x="0" y="15" width="300" height="15" uuid="f2fb034e-297f-4107-a5f5-da84722deb70"/>
+        <textFieldExpression><![CDATA[$P{username}]]></textFieldExpression>
+      </textField>
     </band>
   </pageFooter>
 </jasperReport>
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml

### c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml

```diff
@@ -1,13 +1,14 @@
 <?xml version="1.0" encoding="utf-8"?>
 <!-- Created with Jaspersoft Studio version 6.6.0.final using JasperReports Library version 6.6.0  -->
 <jasperReport xmlns="http://jasperreports.sourceforge.net/jasperreports" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://jasperreports.sourceforge.net/jasperreports http://jasperreports.sourceforge.net/xsd/jasperreport.xsd" name="gmf16_A4_landscape" pageWidth="842" pageHeight="595" orientation="Landscape" columnWidth="802" leftMargin="20" rightMargin="20" topMargin="20" bottomMargin="20" uuid="2646b6ef-0cc4-4852-b6e9-8c4dc54c2e84">
   <property name="com.jaspersoft.studio.unit." value="pixel"/>
   <property name="com.jaspersoft.studio.data.defaultdataadapter" value="One Empty Record"/>
   <parameter name="title" class="java.lang.String"/>
+  <parameter name="username" class="java.lang.String"/>
   <parameter name="comments" class="java.lang.String"/>
   <parameter name="debug" class="java.lang.Boolean"/>
   <parameter name="mapSubReport" class="java.lang.String"/>
   <parameter name="legendDataSource" class="net.sf.jasperreports.engine.data.JRTableModelDataSource"/>
   <parameter name="legendSubReport" class="java.lang.String"/>
   <parameter name="numberOfLegendRows" class="java.lang.Integer"/>
   <parameter name="scalebarSubReport" class="java.lang.String"/>
@@ -186,10 +187,14 @@
         <textElement verticalAlignment="Bottom"/>
         <textFieldExpression><![CDATA[" / " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
       <textField>
         <reportElement x="0" y="1" width="300" height="14" uuid="dc102ea9-973f-4717-a872-0d24d4de1e17"/>
         <textFieldExpression><![CDATA[$R{info}]]></textFieldExpression>
       </textField>
+      <textField>
+        <reportElement x="0" y="15" width="300" height="15" uuid="f2fb034e-297f-4107-a5f5-da84722deb70"/>
+        <textFieldExpression><![CDATA[$P{username}]]></textFieldExpression>
+      </textField>
     </band>
   </pageFooter>
 </jasperReport>
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml

### c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml

```diff
@@ -1,10 +1,11 @@
 <?xml version="1.0" encoding="utf-8"?>
 <jasperReport xmlns="http://jasperreports.sourceforge.net/jasperreports" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://jasperreports.sourceforge.net/jasperreports http://jasperreports.sourceforge.net/xsd/jasperreport.xsd" name="gmf16_A4_portrait" pageWidth="595" pageHeight="842" columnWidth="555" leftMargin="20" rightMargin="20" topMargin="20" bottomMargin="20">
   <parameter name="title" class="java.lang.String"/>
+  <parameter name="username" class="java.lang.String"/>
   <parameter name="comments" class="java.lang.String"/>
   <parameter name="debug" class="java.lang.Boolean"/>
   <parameter name="mapSubReport" class="java.lang.String"/>
   <parameter name="legendDataSource" class="net.sf.jasperreports.engine.data.JRTableModelDataSource"/>
   <parameter name="legendSubReport" class="java.lang.String"/>
   <parameter name="numberOfLegendRows" class="java.lang.Integer"/>
   <parameter name="scalebarSubReport" class="java.lang.String"/>
@@ -156,10 +157,14 @@
         <textFieldExpression><![CDATA[$R{page} + " " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
       <textField evaluationTime="Report">
         <reportElement x="534" y="21" width="22" height="30"/>
         <textElement verticalAlignment="Bottom"/>
         <textFieldExpression><![CDATA[" / " + $V{PAGE_NUMBER}]]></textFieldExpression>
       </textField>
+      <textField>
+        <reportElement x="0" y="15" width="300" height="15"/>
+        <textFieldExpression><![CDATA[$P{username}]]></textFieldExpression>
+      </textField>
     </band>
   </pageFooter>
 </jasperReport>
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/config.yaml.tmpl

```diff
@@ -14,14 +14,17 @@
 templates:
   1 A4 portrait: !template
     reportTemplate: A4_Portrait.jrxml
     attributes:
       title:
         !string &title
         default: ""
+      username:
+        !string &username
+        default: ""
       comments:
         !string &comments
         default: ""
       debug:
         !boolean &debug
         default: false
       legend: !legend &legend {}
@@ -117,14 +120,15 @@
                 urlExtractor: (.*)
                 urlGroup: 1
 
   2 A4 landscape: !template
     reportTemplate: A4_Landscape.jrxml
     attributes:
       title: *title
+      username: *username
       comments: *comments
       debug: *debug
       legend: *legend
       map: !map
         <<: *map
         width: 800
         height: 441
@@ -134,14 +138,15 @@
       datasource: *datasource
     processors: *processors
 
   3 A3 portrait: !template
     reportTemplate: A3_Portrait.jrxml
     attributes:
       title: *title
+      username: *username
       comments: *comments
       debug: *debug
       legend: *legend
       map: !map
         <<: *map
         width: 800
         height: 1000
@@ -151,14 +156,15 @@
       datasource: *datasource
     processors: *processors
 
   4 A3 landscape: !template
     reportTemplate: A3_Landscape.jrxml
     attributes:
       title: *title
+      username: *username
       comments: *comments
       debug: *debug
       legend: *legend
       map: !map
         <<: *map
         width: 1150
         height: 673
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup

```diff
@@ -1,10 +1,10 @@
 #!/usr/bin/env python3
 
-# Copyright (c) 2021, Camptocamp SA
+# Copyright (c) 2021-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -85,18 +85,19 @@
                 + args.arg,
                 stdout=file_out,
                 check=True,
             )
         else:
             subprocess.run(
                 [
-                    "docker-compose",
+                    "docker",
+                    "compose",
                     "exec",
                     "-T",
-                    "db",
+                    "tools",
                     "bash",
                     "-c",
                     'pg_dump --format=c --dbname="$PGDATABASE"',
                 ]
                 + args.arg,
                 stdout=file_out,
                 check=True,
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore

```diff
@@ -1,10 +1,10 @@
 #!/usr/bin/env python3
 
-# Copyright (c) 2021, Camptocamp SA
+# Copyright (c) 2021-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -39,15 +39,15 @@
         help="The env file to use to get the connection settings, by default we log in the composition to "
         "do the restore.",
     )
     parser.add_argument(
         "--docker-compose-file",
         action="append",
         default=[],
-        help="The docker-compose file to used.",
+        help="The docker compose file to used.",
     )
     parser.add_argument(
         "--arg",
         action="append",
         default=[],
         help="Additional pg_restore argument, example: '--arg=--schema=main', may be used multiple times.",
     )
@@ -88,20 +88,20 @@
                 ]
                 + args.arg,
                 stdin=file_in,
                 check=True,
             )
         else:
             subprocess.run(
-                ["docker-compose"]
-                + ["--file={}".format(f) for f in args.docker_compose_file]
+                ["docker", "compose"]
+                + [f"--file={f}" for f in args.docker_compose_file]
                 + [
                     "exec",
                     "-T",
-                    "db",
+                    "tools",
                     "bash",
                     "-c",
                     'pg_restore --dbname="$PGDATABASE" ' + " ".join(args.arg),
                 ],
                 stdin=file_in,
                 check=True,
             )
```

## c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl

```diff
@@ -123,19 +123,19 @@
 server:
 ${DISABLE_LOCAL}  wmts_path: tiles
 ${DISABLE_LOCAL}  static_path: tiles/static
 ${DISABLE_LOCAL}  admin_path: tiles/admin
   expires: 8 # 8 hours
   predefined_commands:
     - name: Generation all layers
-      command: generate_tiles
+      command: generate-tiles
     - name: Generation layer plan
-      command: generate_tiles --layer=plan
+      command: generate-tiles --layer=plan
     - name: Generation layer ortho
-      command: generate_tiles --layer=ortho
+      command: generate-tiles --layer=ortho
     - name: Generate the legend images
       command: generate_controller --generate-legend-images
 
 process:
   optipng_test:
     - cmd: optipng -o7 -simulate %(in)s
   optipng:
```

## c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml

```diff
@@ -40,152 +40,22 @@
   - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/Controlleroeedit\.js
   - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/sass/mobile_alt\.scss
   - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/sass/vars_mobile_alt\.scss
   - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/sass/oeedit\.scss
   - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/sass/vars_oeedit\.scss
   - geoportal/interfaces/desktop_alt\.html\.mako
   - geoportal/{{cookiecutter.package}}_geoportal/static/images/background-layer-button\.png
+  - tests/test_testapp.py
 
 # Automated file system operations:
 # Remove some files or directories:
 #  - action: remove
 #    paths:
 #      - <one file or directory>
 # Move a file:
 #  - action: move
 #    from: <src file>
 #    to: <dst file>
 upgrade_files:
   - action: remove
     paths:
-      - docker-run
-      - .config
-      - docker-compose-run
-      - docker-compose-build.yaml
-      - geoportal/jsbuild/
-      - geoportal/{package}_geoportal/templates/api/
-      - geoportal/{package}_geoportal/static/lib/.gitignore
-      - testdb/
-      - vars_convert2tmpl.yaml
-      - CONST_convert2tmpl.mk
-      - CONST_config-schema.yaml
-      - CONST_Makefile
-      - CONST_vars.yaml
-      - project.yaml.mako
-      - geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/images
-  - action: move
-    from: .eslintrc
-    to: geoportal/.eslintrc
-  - action: move
-    from: language_mapping
-    to: geoportal/language_mapping
-  - action: move
-    from: lingua-client.cfg
-    to: geoportal/lingua-client.cfg
-  - action: move
-    from: lingua-server.cfg
-    to: geoportal/lingua-server.cfg
-  - action: move
-    from: vars.yaml
-    to: geoportal/vars.yaml
-  - action: move
-    from: geoportal/webpack.apps.js.mako
-    to: geoportal/webpack.apps.js
-  - action: move
-    from: geoportal/Dockerfile.mako
-    to: geoportal/Dockerfile
-  - action: move
-    from: geoportal/development.ini.mako
-    to: geoportal/development.ini
-  - action: move
-    from: geoportal/production.ini.mako
-    to: geoportal/production.ini
-  - action: move
-    from: .env.mako
-    to: .env.sample
-  - action: move
-    from: Dockerfile.mako
-    to: Dockerfile
-  - action: move
-    from: tools/extract-messages.js
-    to: geoportal/tools/extract-messages.js
-  - action: move
-    from: scripts/deploy-docker
-    to: scripts/publish-docker
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/index.html
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/index.html
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/rainbow-custom.min.js
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/rainbow-custom.min.js
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/github.css
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/github.css
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/data.txt
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/data.txt
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/img
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/img
-  - action: remove
-    paths:
-      - geoportal/{{cookiecutter.package}}_geoportal/static/apihelp/track0.gpx
-      - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/apihelp/
-  - action: remove
-    paths:
-      - geoportal/{{cookiecutter.package}}_geoportal/static/css/proj.css
-      - geoportal/{{cookiecutter.package}}_geoportal/static/css/proj-map.css
-      - geoportal/{{cookiecutter.package}}_geoportal/static/css/proj-widgets.css
-      - geoportal/{{cookiecutter.package}}_geoportal/static/js/
-  - action: remove
-    paths:
-      - scripts/CONST_clone_schema.sql
-  - action: remove
-    paths:
-      - front
-      - front_dev
-      - bin/entrypoint
-      - bin/eval-templates
-  - action: move
-    from: .env.sample
-    to: env.sample
-  - action: remove
-    paths:
-      - cgxp_revision
-  - action: remove
-    paths:
-      - .circleci/config.yml
-      - .travis.yml
-  - action: move
-    from: env.sample
-    to: env.default
-  - action: remove
-    paths:
-      - mapserver/CONST_example_map
-  - action: remove
-    paths:
-      - geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/image/crosshair.svg
-  - action: move
-    from: geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/apps/image/favicon.ico
-    to: geoportal/{{cookiecutter.package}}_geoportal/static/images/favicon.ico
-    override: True
-  - action: move
-    from: .github/workflows/ci.yaml
-    to: .github/workflows/main.yaml
-  - action: remove
-    paths:
-      - scripts/publish-docker
-  - action: remove
-    paths:
-      - geoportal/{{cookiecutter.package}}_geoportal/locale/.emptyfolder
-  - action: move
-    from: geoportal/.eslintrc
-    to: geoportal/.eslintrc.yaml
-  - action: remove
-    paths:
-      - qgisserver/geomapfish.yaml.tmpl
-  - action: remove
-    paths:
-      - ci/trigger
-  - action: remove
-    paths:
-      - yamllint.yaml
+      - geoportal/tools/extract-messages.js
```

## c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt

```diff
@@ -1,1153 +1,269 @@
 This file includes migration steps for each release of c2cgeoportal.
 
-
-=============
-Version 2.7.1
-=============
-
-1. Update dependencies to use GDAL 3.7
-
-   Use MapServer 7.6 with GDAL 3.7 (instead of 3.3) with new Ubuntu version
-   Use QGIS server 3.28 (instead of 3.22) with GDAL 3.7
-   Update rasterio to 1.3.9 (instead of 1.2.10)
-   Use GDAL 3.7 as based image with new Ubuntu version (Python 3.8 => 3.10)
-   Downgrade PyYAML to version 5.3.1 (instead of 5.4.1)
-   Downgrade transifex-client to version 0.12.5 (instead of 0.14.4)
-
-
 =============
-Version 2.7.0
+Version 2.9.0
 =============
 
 Information to know before starting the upgrade
 ===============================================
 
-1. Now the simple application is the default mode for new project, to continue with the advance application
-   mode you also should add an attribute ``advance: true`` in your ``project.yaml`` file before starting
-   the upgrade.
-
-2. All the files will be formatted with isort, Black and Prettier to be similar to the initial scaffolds.
-   If you have mako files in ``.html`` files Prettier will break them, to avoid that you should create
-   ``.prettierignore`` file with:
-
-   ```
-   *.min.js
-   ```
-
-   And the files you want to ignore.
-
-3. The Upgrade to the Web Components started, the authentication and the LiDAR profile are migrated.
-   In the desktop_alt we introduce a canvas component who manage the application layout and plug the
-   components through slots.
-   In ngeo, the sources files from contribs/gmf/src are moved in ngeo src folder.
-
-4. When importing external WMS layers through dedicated right panel in desktop interface, now we use the URL
-   from Capabilities/Request/GetMap/.../OnlineResource tag instead of Service/OnlineResource tag which,
-   regarding WMS specification, should contain the website URL.
-
-Main versions updates
----------------------
-Node is updated from 14.19 to 16.14
-Npm is updated from 6.14 to 8.5
-GDAL is updated from 3.2 to 3.4
-Proj is updated from 7.2 to 8.2
-
-
-Python packages updates
------------------------
-New packages:
-* arrow at version 1.2
-* azure-core at version 1.23
-* azure-identity at version 1.8
-* azure-storage-blob at version 12.10
-* binaryornot at version 0.4
-* boto3 at version 1.21
-* botocore at version 1.24
-* cffi at version 1.15
-* cookiecutter at version 1.7
-* cryptography at version 36.0
-* Cython at version 0.29
-* Deprecated at version 1.2
-* greenlet at version 1.1
-* importlib-metadata at version 4.11
-* importlib-resources at version 5.4
-* jinja2-time at version 0.2
-* jmespath at version 0.10
-* msal at version 1.17
-* msal-extensions at version 0.3
-* msrest at version 0.6
-* packaging at version 21.3
-* portalocker at version 2.4
-* poyo at version 0.5
-* pycparser at version 2.21
-* PyJWT at version 2.3
-* python-slugify at version 6.1
-* requests-oauthlib at version 1.3
-* s3transfer at version 0.5
-* text-unidecode at version 1.3
-* tilecloud at version 1.8
-* typing-extensions at version 4.1
-* wrapt at version 1.14
-* zipp at version 3.7
-
-Removed packages:
-* python-editor
-* simplejson
-
-Major updates:
-* attrs from 20.3 to 21.4
-* boltons from 20.2 to 21.0
-* c2cwsgiutils from 4.1 to 5.0
-* certifi from 2020.12 to 2021.10
-* click from 7.1 to 8.0
-* cornice from 5.0 to 6.0
-* decorator from 4.4 to 5.1
-* idna from 2.10 to 3.3
-* iso8601 from 0.1 to 1.0
-* Jinja2 from 2.11 to 3.0
-* MarkupSafe from 1.1 to 2.1
-* pyparsing from 2.4 to 3.0
-* pyramid from 1.10 to 2.0
-* pyramid-multiauth from 0.9 to 1.0
-* redis from 3.5 to 4.1
-* ujson from 4.0 to 5.1
-* waitress from 1.4 to 2.1
-
-Minor updates:
-* alembic from 1.5 to 1.7
-* Chameleon from 3.8 to 3.9
-* defusedxml from 0.6 to 0.7
-* dogpile.cache from 1.0 to 1.1
-* GDAL from 3.2 to 3.4
-* GeoAlchemy2 from 0.8 to 0.11
-* graphviz from 0.16 to 0.19
-* gunicorn from 20.0 to 20.1
-* lingua from 4.14 to 4.15
-* lxml from 4.6 to 4.8
-* Mako from 1.1 to 1.2
-* netifaces from 0.10 to 0.11
-* oauthlib from 3.1 to 3.2
-* OWSLib from 0.22 to 0.25
-* passwordgenerator from 1.4 to 1.5
-* pbr from 5.5 to 5.8
-* psycopg2 from 2.8 to 2.9
-* psycopg2-binary from 2.8 to 2.9
-* pycryptodome from 3.11 to 3.14
-* Pygments from 2.7 to 2.11
-* pygraphviz from 1.7 to 1.9
-* pyotp from 2.5 to 2.6
-* pyproj from 3.0 to 3.3
-* pyramid-jinja2 from 2.8 to 2.9
-* pyramid-tm from 2.4 to 2.5
-* pytz from 2021.1 to 2021.3
-* sentry-sdk from 1.0 to 1.5
-* Shapely from 1.7 to 1.8
-* six from 1.15 to 1.16
-* SQLAlchemy from 1.3 to 1.4
-* SQLAlchemy-Utils from 0.36 to 0.38
-* stevedore from 3.3 to 3.5
-* zope.interface from 5.2 to 5.4
-* zope.sqlalchemy from 1.3 to 1.6
-
-Npm packages updates
---------------------
-New packages:
-* @babel/plugin-proposal-class-properties at version 7.16
-* @babel/plugin-proposal-decorators at version 7.17
-* @babel/plugin-syntax-object-rest-spread at version 7.8
-* @babel/plugin-transform-spread at version 7.16
-* @babel/plugin-transform-typescript at version 7.16
-* @babel/preset-typescript at version 7.16
-* @lit/reactive-element at version 1.3
-* @sentry/integrations at version 6.18
-* @sentry/types at version 6.18
-* angular at version 1.8
-* co at version 4.6
-* console-control-strings at version 1.1
-* core-js at version 3.21
-* doctrine at version 3.0
-* eslint-plugin-jsdoc at version 38.0
-* glob at version 7.2
-* i18next-browser-languagedetector at version 6.1
-* i18next-parser at version 6.0
-* i18next-xhr-backend at version 3.2
-* i18next at version 21.6
-* jquery-mousewheel at version 3.1
-* jquery at version 3.6
-* lit-element at version 3.2
-* lit-html at version 2.2
-* lit at version 2.2
-* loader-utils at version 2.0
-* loc-i18next at version 0.1
-* ol-mapbox-style at version 7.1
-* ol at version 6.12
-* raw-loader at version 4.0
-* regenerator-runtime at version 0.13
-* rxjs at version 7.5
-* sass-loader at version 10.2
-* style-loader at version 2.0
-* terser at version 5.12
-* tsconfig-paths at version 3.14
-
-Removed packages:
-* @geoblocks/proj
-* eslint-config-openlayers
-* eslint-plugin-googshift
-* ng-raven
-
-Major updates:
-* chokidar from 2.1 to 3.5
-* commander from 7.0 to 9.0
-* d3 from 5.16 to 7.3
-* editorconfig-checker from 3.3 to 4.0
-* eslint from 7.19 to 8.11
-* fast-sass-loader from 1.5 to 2.0
-* fs-extra from 9.1 to 10.0
-* node-sass from 4.14 to 6.0
-* npm from 6.14 to 8.5
-* puppeteer from 5.5 to 13.5
-* sinon from 9.2 to 13.0
-* svgo-loader from 2.2 to 3.0
-* svgo from 1.3 to 2.8
-* ts-node from 9.1 to 10.7
-
-Minor updates:
-* @babel/core from 7.12 to 7.17
-* @babel/preset-env from 7.12 to 7.16
-* @sentry/browser from 6.2 to 6.18
-* @sentry/tracing from 6.2 to 6.18
-* css-loader from 5.0 to 5.2
-* jsts from 2.6 to 2.8
-* localforage from 1.9 to 1.10
-* mapillary-js from 4.0 to 4.1
-* proj4 from 2.7 to 2.8
-* webpack-merge from 5.7 to 5.8
+1. The build command will use Docker Compose version 2 (with the `docker compose` command).
 
 Information
 ===========
 
-1. The configuration of the QGIS authentication module is simplified,
-   now a new environment variable `GEOMAPFISH_ACCESSCONTROL_BASE_URL` is set to the base URL of
-   qgisserver, and we search for all the OGC servers that correspond to this URL.
-   Then the configuration file  (`qgisserver/accesscontrol_config.yaml`) and the specified configuration
-   in the `docker-compose.yaml` file can be removed.
-   It also requires that the OGC servers are configured with an URL like that
-   ``config://qgisserver?map=<project_file>``.
-
-2. Some little changes in the application build:
-
-   - In the ``./build`` script, we no longer call the ``docker build`` command with custom parameters,
-     but call the ``docker-compose build`` command with two additional environment variables:
-
-     * ``SIMPLE``: ``TRUE`` or ``FALSE`` if we compile a simple or advance application.
-     * ``GIT_HASH``: the git hash of the current version.
-
-     The build specification has been moved to the ``docker-compose`` files.
-   - The ``--geoportal`` and ``--config`` arguments have been replaced by ``--service=geoportal`` and
-     ``--service=config`` respectively.
-   - The external images used in the composition are pulled from the Docker hub on each build, but the
-     ``./build`` script supports a new argument ``--no-pull`` for faster rebuild during development.
-   - ``./build`` script supports a new argument ``--fast-reload`` that will recreate all containers except
-     Redis containers to keep the cache.
-   - ``./build`` script supports a new argument ``--dry-run`` which only displays the ``docker`` and
-     ``docker-compose`` commands without running them.
-
-3. Upgrade c2cwsgiutils to version 5, see more information in the
-   c2cwsgiutils changelog https://github.com/camptocamp/c2cwsgiutils/blob/master/CHANGELOG.md.
-
-SQLAlchemy upgrade to version 1.4
----------------------------------
-
-SQLAlchemy has been upgraded to version 1.4 which serves as potential migration point for a more dramatic
-series of API changes currently planned for release 2.0 of SQLAlchemy.
-
-For more details about SQLAlchemy 1.4 see: https://docs.sqlalchemy.org/en/14/changelog/migration_14.html
-
-To show SQLAlchemy deprecation warnings in your geoportal container logs, add this to your
-`docker-compose.override.yaml` file:
-
-```
----
-version: '2.3'
-
-services:
-  geoportal:
-    environment:
-      - PYTHONWARNINGS=default::DeprecationWarning
-      - SQLALCHEMY_WARN_20=true
-```
-
-For more information about Python warnings configuration see: https://docs.python.org/3/library/warnings.html#describing-warning-filters
-
-
-Changes to apply
-================
-
-1. For advance application:
-
-   In the ``docker-compose.yaml`` file in the service ``geoportal`` you should replace
-   ``service: geoportal`` by ``service: geoportal-advance``, and in service ``alembic`` you should replace
-   ``service: alembic`` by ``service: alembic-advance``.
-
-2. If you use the LiDAR profile you didn't need anymore to include your module in the controller.
-
-3. In the tilegeneration configuration ``on``/``off`` is no more considered as boolean, it should be
-   converted to ``true``/``false``, and the properties ``mapcache_internal`` and ``mapcache`` should be
-   removed.
-
-4. For the LiDAR profile you should update your controller, in the interface JavaScript file:
-
-    ```javascript
-    + import panels from 'gmfapi/store/panels';
-
-    ...
-
-      constructor($scope, $injector) {
-        super($scope, $injector);
-    ...
-    +   const $timeout = $injector.get('$timeout');
-    +
-    +   // Open the 'web-component' lidar panel
-    +   $scope.$watch(
-    +     () => this.drawLidarprofilePanelActive,
-    +     (newVal) => {
-    +       if (newVal) {
-    +         panels.openToolPanel('lidar');
-    +       } else {
-    +         panels.closeToolPanel();
-    +       }
-    +     }
-    +   );
-    +
-    +   // Make visible the footer
-    +   panels.getActiveFooterPanel().subscribe({
-    +     next: (panel) => {
-    +       this.lidarProfileFooterActive = panel === 'lidar';
-    +       $timeout(() => {}); // this triggered on DOM click, we call $timeout to force Angular digest
-    +     },
-    +   });
-    ...
-    ```
-
-    You should disable map interrogations when LiDAR tool is active, if missing add the following code to the controller:
-    ```javascript
-    +   import ngeoMiscToolActivate from 'ngeo/misc/ToolActivate';
-
-    +   const drawLidarprofilePanelActive = new ngeoMiscToolActivate(this, 'drawLidarprofilePanelActive');
-    +   this.ngeoToolActivateMgr.registerTool('mapTools', drawLidarprofilePanelActive, false);
-    ```
-
-    The interface HTML file needs a few changes.
-    To activate the LiDAR panel, you should makes sure to have correct ng-model attributes:
-    {% raw %}
-    ```html
-    ...
-      <button ngeo-btn class="btn btn-default" ng-model="mainCtrl.drawLidarprofilePanelActive"
-              data-toggle="tooltip" data-placement="left" data-original-title="{{'LiDAR'|translate}}">
-        <span class="fa fa-chart-line"></span>
-      </button>
-    ...
-    ```
-    {% endraw %}
-
-    The LiDAR panel should looks like that, where other tools panels are:
-    ```html
-    ...
-    +  <div ng-show="mainCtrl.drawLidarprofilePanelActive" class="row">
-    +    <div class="col-sm-12">
-    +      <a class="btn close gmf-close" ng-click="mainCtrl.drawLidarprofilePanelActive = false">&times;</a>
-    +      <gmf-lidar-panel></gmf-lidar-panel>
-    +    </div>
-    +  </div>
-    ...
-    ```
-
-    Finally the LiDAR footer in the footer balise should looks like that:
-    ```html
-     <footer>
-    +  <gmf-lidar-footer id="lidar-footer"></gmf-lidar-footer>
-       <gmf-profile
-         gmf-profile-active="profileChartActive"
-         gmf-profile-line="mainCtrl.profileLine"
-      ...
-     </footer>
-    ```
-
-5. Here is a list of the low-level components migrated as a dependency (of other migrated components):
-  - download/Csv
-  - map/FeatureOverlay
-  - map/FeatureOverlayMgr
-  - message/Message
-  - message/Notification
-
-  All of them use the singleton pattern, which means that in general it may only need to be initialized once (when required).
-  The component need to be imported with an 'import', not from the AngularJS dependency injector.
-
-  You should take care of the custom code in that regard if one of these components is used, as it's may needs some changes to be working fully.
-  If it is already initialized, you may need to change the code using this component in the custom component of your project.
-  In any case, it will be different in each project and use case.
-
-6. To access to the config in you components, previously it was injected through Angular, now you should get
-   it with RXJS, with:
-
-   ```javascript
-   import {Configuration} from 'gmfapi/store/config';
-
-   window.gmfapi.store.config.getConfig().subscribe({
-     next: (configuration: Configuration) => {
-       if (configuration) {
-         ...
-       }
-     },
-   })
-   ```
-
-7. To solve looping dependency we moved the `Cache` and `set_common_headers` function, then you should do
-   in your custom Python views a modification like:
-
-   ```diff
-   - from c2cgeoportal_geoportal.lib.caching import Cache, set_common_headers
-   + from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
-   ```
+1. Hostname check:
+   We add a hostname check on the `came_from` parameter, in the oauth2 login, allowed by
+   `vars.authentication.allowed_hosts` and in the OGC server clear cache, allowed by `vars.allowed_hosts`.
+   The behavior change a little bit in the `shortener.allowed_hosts` and in the `authorized_referers`.
+   Now everywhere:
+   - If the hostname (with port) of the candidate URL equals to the request's header "Host", then it's OK.
+   - If the hostname (with port) of the candidate URL is in the allowed list, then it's OK.
+   And they should be netloc (hostname with port) without schema or path.
 
+2. We replace checks (formatting) done by `c2cciutils` by `pre-commit` hooks.
+   This will me more standard and transparent for the project.
 
 =============
-Version 2.6.0
+Version 2.8.0
 =============
 
 Information to know before starting the upgrade
 ===============================================
 
-Direct dependencies updates
----------------------------
-
-Now we are based on the image `osgeo/gdal` (`ubuntu-small-3.2.1`) which is based on Ubuntu 20.04.
-Previously we were based on image `camptocamp/c2cwsgiutils` (`release_3`) which is based on Ubuntu 18.04
-
-Main version update
--------------------
-Ubuntu is updated from 18.04.5 to 20.04.1
-Python is updated from 3.7.5 to 3.8.5
-Node is updated from 10.24.1 to 14.17.0
-Npm is updated from 6.14.12 to 6.14.13
-Postgres is updated from 13+226.pgdg18.04+1 to 13+226.pgdg20.04+1
-
-Python package update
----------------------
-New packages:
-* c2cwsgiutils at version 4.1.1
-* GDAL at version 3.2.1
-* linesman at version 0.3.2
-* networkx at version 1.7
-* oauthlib at version 3.1.0
-* Paste at version 3.5.0
-* pbr at version 5.5.1
-* Pillow at version 8.1.2
-* pipfile at version 0.0.2
-* pkgconfig at version 1.5.1
-* pygraphviz at version 1.7
-* pyyaml-include at version 1.2.post2
-* stevedore at version 3.3.0
-* toml at version 0.10.2
-
-Removed packages:
-* importlib-metadata
-* simplejson
-* typing-extensions
-* zipp
-
-Major updates:
-* attrs from 19.3.0 to 20.3.0
-* chardet from 3.0.4 to 4.0.0
-* cornice from 4.0.1 to 5.0.3
-* dogpile.cache from 0.9.0 to 1.0.2
-* Jinja2 from 3.0.0a1 to 2.11.3
-* MarkupSafe from 2.0.0a1 to 1.1.1
-* pyparsing from 3.0.0a1 to 2.4.7
-* pyproj from 2.6.0 to 3.0.0.post1
-* pytz from 2019.3 to 2021.1
-* sentry-sdk from 0.14.3 to 1.0.0
-* ujson from 2.0.3 to 4.0.2
-
-Minor updates:
-* alembic from 1.4.2 to 1.5.3
-* Babel from 2.8.0 to 2.9.0
-* boltons from 20.1.0 to 20.2.1
-* c2c.template from 2.1.0 to 2.3.0
-* cee-syslog-handler from 0.5.0 to 0.6.0
-* certifi from 2020.4.5.1 to 2020.12.5
-* cligj from 0.5.0 to 0.7.1
-* colander from 1.7.0 to 1.8.3
-* GeoAlchemy2 from 0.7.0 to 0.8.4
-* idna from 2.9 to 2.10
-* numpy from 1.18.3 to 1.20.0
-* objgraph from 3.4.1 to 3.5.0
-* OWSLib from 0.19.2 to 0.22.0
-* pipenv from 2020.5.28 to 2020.11.15
-* Pygments from 2.6.1 to 2.7.4
-* pyotp from 2.3.0 to 2.5.1
-* pyramid-debugtoolbar from 4.6.1 to 4.9
-* PyYAML from 5.3.1 to 5.4.1
-* rasterio from 1.1.3 to 1.2.0
-* redis from 3.4.1 to 3.5.3
-* requests from 2.23.0 to 2.25.1
-* six from 1.14.0 to 1.15.0
-* translationstring from 1.3 to 1.4
-* urllib3 from 1.25.9 to 1.26.4
-* zope.interface from 5.1.0 to 5.2.0
-
-Npm package update
-------------------
-New packages:
-* @sentry/tracing at version 6.2.3
-* babel-plugin-angularjs-annotate at version 0.10.0
-* eslint at version 7.19.0
-* event-hooks-webpack-plugin at version 2.2.0
-* mapillary-js at version 2.21.0
-* tinycolor2 at version 1.4.2
-
-Removed packages:
-* @camptocamp/babel-plugin-angularjs-annotate
-* jsdoc
-* jsdoc-plugin-typescript
-* tsconfig-paths
-* typescript
-
-Major updates:
-* @sentry/browser from 5.15.4 to 6.2.3
-* commander from 5.0.0 to 7.0.0
-* copy-webpack-plugin from 5.1.1 to 6.4.1
-* css-loader from 3.5.2 to 5.0.1
-* expose-loader from 0.7.5 to 1.0.3
-* html-webpack-plugin from 3.2.0 to 4.5.1
-* node-sass-importer from 1.0.0 to 2.0.2
-* puppeteer from 2.1.1 to 5.5.0
-* ts-node from 8.8.2 to 9.1.1
-* webpack-merge from 4.2.2 to 5.7.3
-
-Minor updates:
-* @babel/core from 7.9.0 to 7.12.10
-* @babel/preset-env from 7.9.5 to 7.12.11
-* @fortawesome/fontawesome-free from 5.13.0 to 5.15.2
-* @trevoreyre/autocomplete-js from 2.1.1 to 2.2.0
-* angular-animate from 1.7.9 to 1.8.2
-* angular-mocks from 1.7.9 to 1.8.2
-* angular-sanitize from 1.7.9 to 1.8.2
-* angular-touch from 1.7.9 to 1.8.2
-* babel-loader from 8.1.0 to 8.2.2
-* bootstrap from 4.4.1 to 4.6.0
-* d3 from 5.15.1 to 5.16.0
-* ejs-loader from 0.3.6 to 0.5.0
-* extract-loader from 5.0.1 to 5.1.0
-* file-loader from 6.0.0 to 6.2.0
-* floatthead from 2.1.4 to 2.2.1
-* fs-extra from 9.0.0 to 9.1.0
-* jsts from 2.1.2 to 2.6.1
-* localforage from 1.7.3 to 1.9.0
-* moment from 2.24.0 to 2.29.1
-* node-sass from 4.13.1 to 4.14.1
-* ol-layerswitcher from 3.6.0 to 3.8.3
-* proj4 from 2.6.1 to 2.7.0
-* sinon from 9.0.2 to 9.2.4
-* terser-webpack-plugin from 4.1.0 to 4.2.3
-* webpack from 4.42.1 to 4.46.0
-
-Other Docker images
-~~~~~~~~~~~~~~~~~~~
-
-* `camptocamp/mapfish_print` from 3.22 to 3.27.
-* `camptocamp/mapserver` from 7.4 to 7.6.
-* `camptocamp/geomapfish-qgisserver` from 3.10 to 3.16.
-* `camptocamp/redis` from 5 to 6.
-* `camptocamp/tilecloud-chain` from 1.13 to 1.15.
-* `camptocamp/haproxy` from 1.9 to 2.2.
-
-Main Changes
-------------
-
-The migration process impacts the following:
-1. Openlayers view has a default value set to `false` for the `constrainOnlyCenter` parameter.
-Add to the vars.yaml the following config: `constrainOnlyCenter: True` to `gmfOptions/view` if required to keep 2.5 view behavior.
-
-The migration process will also require the following UI-related changes (visible in the html diffs):
-1. Right panel is movable, so the handle has to be added
-2. Draw and measure panel has extra fields for arrows drawing
-
-Note: The list presented in this chapter is not exhaustive.
-
-
-Client application configuration
---------------------------------
-
-Previous versions had configuration in the `*.html.ejs`, in the `Controler*.js`, and in the `vars.yaml` file.
-The goal of this change is to move this configuration to the `vars.yaml` file (with default values in
-the `CONST_vars.yaml`). This will make future upgrades easier and increase configuration possibilities
-in the simple application mode, see the documentation
-<https://camptocamp.github.io/c2cgeoportal/${MAIN_BRANCH}/integrator/create_application.html#simple-application>.
-
-
-When you apply the `ngeo.diff` you should first apply the changes in the `geoportal/vars.yaml` file.
-
-For the next step, you should consult the documentation about:
-- The interfaces_config documentation
-<https://camptocamp.github.io/c2cgeoportal/${MAIN_BRANCH}/integrator/ngeo.html?highlight=ngeo#dynamic-json-view>
-- GMF constants definitions <https://camptocamp.github.io/ngeo/master/jsdoc/module-contribs_gmf_src_options.html>
-- ngeo constants definitions <https://camptocamp.github.io/ngeo/master/jsdoc/module-src_options.html>
-
-
-Then configure the `vars/srid`, `vars/alternate_projections`, `vars/resolutions` and `vars/extent` they will
-be dispatched using `c2ctemplate` or YAML link.
-
-In the following, we show typical examples of necessary changes:
-
-Example in API
-..............
-
-In the ngeo.diff:
-```
---- a/geoportal/cartoriviera_geoportal/static-ngeo/api/index.js
-+++ b/geoportal/cartoriviera_geoportal/static-ngeo/api/index.js
-...
--// The URL to the search service.
--config.searchUrl = '{FULL_ENTRY_POINT}search?interface=api&limit=15';
-```
-
-And in your `geoportal/cartoriviera_geoportal/static-ngeo/api/index.js` file:
-```
-// The URL to the search service.
-onfig.searchUrl = '{FULL_ENTRY_POINT}search?interface=api&limit=15';
-```
-
-We see that the project settings didn't correspond to the previous default settings, therefore you should
-have in your vars file something like:
-```
-vars:
-  interfaces_config:
-    api:
-      routes:
-        searchUrl:
-          params:
-            limit: 15
-
-update_paths:
-  - interfaces_config.api.routes.searchUrl  # This one should already be present
-```
-
-In this case, you need to change this line of the `update_paths` as follows:
-```
-update_paths:
-  - interfaces_config.api.routes.searchUrl.params
-```
-
-This is because the default value in the
-`geoportal/CONST_vars.yaml` defines the searchUrl like this:
-
-```
-searchUrl:
-  name: fulltextsearch
-  params:
-    limit: 15
-    partitionlimit: 5
-  dynamic_params:
-    interface: interface
-```
-
-You won't redefine the whole `searchUrl` configuration you only want to set the params. The `update_paths`
-Allows you to update the one part of the configuration. Without this entry in the `update_paths`, the
-whole `searchUrl` configuration would have been replaced.
-
-Example in controller constructor
-.................................
-
-In the ngeo.diff:
-```
--  constructor($scope, $injector) {
--    super({
--      srid: 2056,
--      mapViewConfig: {
--        center: [2632464, 1185457],
--        zoom: 3,
--        resolutions: [250, 100, 50, 20, 10, 5, 2, 1, 0.5, 0.25, 0.1, 0.05],
--        constrainResolution: true,
--        extent: [2485071.54, 175346.36, 2828515.78, 1299941.84],
--      }
--    }, $scope, $injector);
-```
-
-And in your `geoportal/cartoriviera_geoportal/static-ngeo/api/index.js` file:
-```
-  constructor($scope, $injector) {
-    super({
-      maxTilesLoading: Infinity,
-      srid: 2056,
-      mapViewConfig: {
-        center: [2559045, 1144195],
-        zoom: 1,
-        constrainResolution: true,
-        resolutions: [50, 20, 10, 5, 2.5, 2, 1.5, 1, 0.5, 0.25, 0.1, 0.05, 0.025]
-      }
-    }, $scope, $injector);
-```
-
-We see that the project settings didn't correspond to the previous default settings, therefore you should
-have in your vars file something like:
-```
-vars:
-  interfaces_config:
-    default:  # or interface name
-      constants:
-        gmfOptions:
-          map:
-            maxTilesLoading: .Inf
-          view: &view
-            projection: EPSG:{srid}
-            center: [2559045, 1144195]
-            zoom: 1
-            resolutions: &resolutions [50, 20, 10, 5, 2.5, 2, 1.5, 1, 0.5, 0.25, 0.1, 0.05, 0.025]
-            extent: &extent [2420000, 1030000, 2900000, 1350000]
-          geolocalisation: True
-```
-
-Standard example in controller
-..............................
-
-In the ngeo.diff:
-```
--    this.elevationLayers = ['aster', 'srtm'];
-```
-
-And in your `geoportal/cartoriviera_geoportal/static-ngeo/api/index.js` file:
-```
-   this.elevationLayers = ['mns', 'mnt', 'rayglobal'];
-```
-
-We see that the project settings didn't correspond to the previous default settings, therefore you should
-have in your vars file something like:
-```
-vars:
-  interfaces_config:
-    default:  # or interface name
-      constants:
-        gmfElevationOptions:
-          layers: [mns, mnt, rayglobal]
-```
-
-Now we can easily switch between the display of query results in a window or in a grid by using
-`gmfQueryGrid` configuration variable.
-
-Now you can easily switch between flush theme mode and non-flush theme mode  by using
-`gmfTreeManagerModeFlush` configuration variable.
-
-Optional point
-..............
-
-The header can be in a separate file, diff in the `*.html.ejs` file:
-
-    - <header>
-    -   <div class="logo">
-    -     <span></span>
-    -   </div>
-    -   <div class="logo-right">
-    -     <span></span>
-    -   </div>
-    - </header>
-    + <ng-include src="'desktop_alt/header.html'"></ng-include>
-
-  The content will be in the `geoportal/geomapfish_geoportal/static/header.html` file.
-
-Print
------
-
-- You can now switch easily between local print and mutualised print by setting one
-  of `DISABLE_MUTUALIZED_PRINT` and `DISABLE_LOCAL_PRINT` environment variavle to '#' ant the other to ''.
-- The client timezone is added as a new attribute named `timezone`, you can use it with e.-g.:
-  `java.time.ZonedDateTime.now().format(java.time.format.DateTimeFormatter
-    .ofPattern("EEEE dd MMMM yyyy HH:mm")
-    .withLocale($P{REPORT_LOCALE})
-    .withZone(java.time.ZoneId.of($P{timezone}))`
-- If you use the most recent version of the `legend.jrxml` print template, you will obtain a legend with
-  elements indented hierarchically per groups level. If you want to keep the previous legend style, keep
-  your previous `legend.jrxml` template and add a new variable `gmfPrintOptions.legend.showGroupsTitle` in
-  the `interfaces_config` constants of the vars file and set it to false.
-
-Editing
--------
-
-- The default order column for edition enumeration lists is now the value column ("name" per
-  default). You can set it through the new `editingEnumerations` layer metadata.
-
-QGIS server
------------
-
-- The runtime variables of the GeoMapFish configuration (geomapfish.yaml.tmpl) are now filled in the config
-  container, previously it was in the QGIS server container.
-
-Tile generation
----------------
-
-- Some commands are added to generate the OpenLayers example,
-  and the legend images used in the WMTS capabilities (but not used in the web application).
-
-Redis
------
-
-- Redis can be used in a scalable architecture (with sentinel), this is disabled by default.
-
-Environment
------------
 
-C2C_SECRET: Default value "c2crulez" has been removed for evident security reason.
-
-Changes to apply
-================
-
-1. All ngeo components are now configured via variables in your project variables file, in the section
-   interfaces_config. To ease future migration, you should remove any existing custom JavaScript code which is
-   setting such variables.
-   There is some new documentation about the constants in ngeo
-   https://camptocamp.github.io/ngeo/{{cookiecutter.geomapfish_main_version}}/apidoc/index.html.
+Information
+===========
 
+1. We upgraded MapServer to version 8, then the Mapfiles should probably be updated, and we have a new
+   configurations file named `mapserver/mapserver.conf`.
+   Migration guide: https://mapserver.org/MIGRATION_GUIDE.html#mapserver-7-6-to-8-0-migration.
+   Deprecated element from `CLASS` removed (moved to `STYLE`)
+   https://mapserver.org/development/rfc/ms-rfc-133.html#rfc133.
+
+2. We added the support of 'main_ogc_server' to WMS mapserver proxy URL.
+   This means that if the value 'vars/main_ogc_server' is present in the vars.yaml of the project,
+   that will be used as default value when no 'ogcserver' parameter is present in the request.
+
+3. We switched the OpenLayers renderer to now use WegGL for WMTS. In the case of background tiles with
+   transparency, you should add the parameter 'ngeoTilesPreloadingLimit: 0' to the vars.yaml in 'constants'
+   so that background tiles are rendered correctly.
 
-=============
-Version 2.5.0
-=============
+4. In the `user` table, the column `deactivated` is now interpreted more strictly, `null` is now considered as `true`.
 
-Information to know before starting the upgrade
------------------------------------------------
+5. We add the `gmfPrintOptions` in the update path then the default print options are maintained in the
+   `CONST_vars.yaml`, especially the `hiddenAttributes`, then if you used the default value it can be
+   removed.
 
 Main versions updates
-.....................
-
-Ubuntu is updated from 18.04.2 to 18.04.5
-Python is updated from 3.6.7 to 3.7.5
-Node is updated from 10.15.3 to 10.24.1
-Npm is updated from 6.4.1 to 6.14.12
+-------------------
+Ubuntu is updated from 20.04.6 to 22.04.2
+Python is updated from 3.8.10 to 3.10.6
+Node is updated from 16.20.0 to 16.20.0
+Npm is updated from 8.19.4 to 8.19.4
+Postgres is updated from 15+250.pgdg20.04+1 to 15+250.pgdg22.04+1
+GDAL is updated from 3.4.3, to 3.6.4,
+Proj is updated from 9.0.0 to 9.1.1
 
 Python packages updates
-.......................
+---------------------
 New packages:
-* appdirs at version 1.4.4
-* beaker-redis at version 1.1.0
-* click at version 7.1.1
-* distlib at version 0.3.2
-* filelock at version 3.0.12
-* getitfixed at version 1.0.20
-* importlib-metadata at version 4.6.0
-* pipenv at version 2020.5.28
-* psycopg2 at version 2.8.5
-* pyotp at version 2.3.0
-* sentry-sdk at version 0.14.3
-* SQLAlchemy-Utils at version 0.36.3
-* typing-extensions at version 3.10.0.0
-* virtualenv-clone at version 0.5.4
-* zipp at version 3.4.1
+* astroid at version 2.15.5
+* bandit at version 1.7.5
+* dill at version 0.3.6
+* dodgy at version 0.2.1
+* flake8 at version 2.3.0
+* flake8-polyfill at version 1.0.2
+* gitdb at version 4.0.10
+* GitPython at version 3.1.31
+* isort at version 5.12.0
+* lazy-object-proxy at version 1.9.0
+* markdown-it-py at version 2.2.0
+* mccabe at version 0.7.0
+* mdurl at version 0.1.2
+* mypy at version 1.3.0
+* mypy-extensions at version 1.0.0
+* pep8 at version 1.7.1
+* pep8-naming at version 0.10.0
+* prospector at version 1.9.0
+* pycodestyle at version 2.10.0
+* pydocstyle at version 6.3.0
+* pyflakes at version 2.5.0
+* pylint at version 2.17.4
+* pylint-celery at version 0.3
+* pylint-django at version 2.5.3
+* pylint-flask at version 0.6
+* pylint-plugin-utils at version 0.7
+* requirements-detector at version 1.2.2
+* rich at version 13.4.1
+* semver at version 3.0.0
+* setoptconf-tmp at version 0.3.1
+* shapely at version 2.0.1
+* smmap at version 5.0.0
+* snowballstemmer at version 2.2.0
+* tomli at version 2.0.1
+* tomlkit at version 0.11.8
+* typing_extensions at version 4.6.2
 
 Removed packages:
-* alabaster
-* astroid
-* atomicwrites
-* awscli
-* beautifulsoup4
+* azure-identity
 * boto3
 * botocore
-* c2c.cssmin
-* c2cgeoportal-admin
-* c2cgeoportal-commons
-* c2cgeoportal-geoportal
-* c2cwsgiutils
-* Click
-* codacy-coverage
-* codespell
-* colorama
-* coverage
-* cssmin
-* dateutils
-* docopt
-* docutils
-* entrypoints
-* flake8
-* flake8-copyright
-* flake8-mypy
-* flake8-polyfill
-* GDAL
-* glob2
-* htmlmin
-* imagesize
-* ipcalc
-* isort
+* Cython
+* Deprecated
+* distlib
+* filelock
+* importlib-metadata
+* importlib-resources
 * jmespath
-* JSTools
-* junit2html
-* lazy-object-proxy
 * linesman
-* mccabe
-* more-itertools
-* mypy
-* mypy-extensions
+* msal
+* msal-extensions
+* msrest
 * networkx
-* packaging
 * Paste
-* PasteScript
-* pathspec
-* pep8
-* pep8-naming
-* Pillow
+* pipenv
+* pipfile
 * pkgconfig
-* pluggy
-* py
-* pyasn1
-* pycodestyle
-* pyflakes
+* portalocker
+* poyo
 * pygraphviz
-* pykwalify
-* pylint
-* Pympler
-* pytest
-* pytest-base-url
-* pytest-cov
-* pytest-html
-* pytest-metadata
-* pytest-selenium
-* pytest-variables
-* python-slugify
-* raven
-* rsa
+* repoze.lru
 * s3transfer
-* selenium
-* snowballstemmer
-* Sphinx
-* sphinx-prompt
-* sphinxcontrib-websupport
-* tilecloud
-* tilecloud-chain
-* transifex-client
-* typed-ast
-* Unidecode
-* WebTest
-* wrapt
-* wsgi-lineprof
-* yamllint
-* zgitignore
+* Shapely
+* typing-extensions
+* virtualenv
+* virtualenv-clone
+* zipp
 
 Major updates:
-* boltons from 19.0.0 to 20.1.0
-* certifi from 2019.3.9 to 2020.4.5.1
-* cornice from 3.5.1 to 4.0.1
-* gunicorn from 19.9.0 to 20.0.4
-* pyproj from 1.9.6 to 2.6.0
-* transaction from 2.4.0 to 3.0.0
-* ujson from 1.35 to 2.0.3
-* venusian from 1.2.0 to 3.0.0
-* virtualenv from 16.4.3 to 20.4.7
-* zope.interface from 4.6.0 to 5.1.0
+* attrs from 21.4.0 to 23.1.0
+* basicauth from 0.4.1 to 1.0.0
+* boltons from 21.0.0 to 23.0.0
+* Chameleon from 3.9.1 to 4.0.0
+* chardet from 4.0.0 to 5.1.0
+* charset-normalizer from 2.0.12 to 3.1.0
+* colander from 1.8.3 to 2.0
+* cryptography from 41.0.1 to 39.0.2
+* geojson from 2.5.0 to 3.0.1
+* greenlet from 1.1.3.post0 to 2.0.2
+* munch from 2.5.0 to 3.0.0
+* packaging from 21.3 to 23.1
+* PasteDeploy from 2.1.1 to 3.0.1
+* plaster-pastedeploy from 0.7 to 1.0.1
+* python-slugify from 4.0.1 to 8.0.1
+* pytz from 2021.3 to 2023.3
+* PyYAML from 5.4.1 to 6.0
+* stevedore from 3.5.2 to 5.1.0
+* urllib3 from 1.26.16 to 2.0.2
+* zope.deprecation from 4.4.0 to 5.0
+* zope.interface from 5.4.0 to 6.0
+* zope.sqlalchemy from 1.6 to 3.0
 
 Minor updates:
-* affine from 2.2.2 to 2.3.0
-* alembic from 1.0.9 to 1.4.2
-* attrs from 19.1.0 to 19.3.0
-* Babel from 2.6.0 to 2.8.0
-* Beaker from 1.10.1 to 1.11.0
-* c2cgeoform from 2.0.dev20190413 to 2.1.18
-* Chameleon from 3.6.1 to 3.8.1
-* defusedxml from 0.5.0 to 0.6.0
-* dogpile.cache from 0.7.1 to 0.9.0
-* GeoAlchemy2 from 0.6.1 to 0.7.0
-* geojson from 2.4.1 to 2.5.0
-* graphviz from 0.10.1 to 0.16
-* hupper from 1.6.1 to 1.10.2
-* idna from 2.8 to 2.9
-* Jinja2 from 2.10.1 to 2.11.3
-* lingua from 4.13 to 4.14
-* lxml from 4.3.1 to 4.6.3
-* Mako from 1.0.9 to 1.1.2
-* munch from 2.3.2 to 2.5.0
-* numpy from 1.16.3 to 1.18.3
-* OWSLib from 0.17.1 to 0.19.2
-* PasteDeploy from 2.0.1 to 2.1.0
-* pycryptodome from 3.8.1 to 3.9.7
-* Pygments from 2.3.1 to 2.6.1
-* pyramid from 1.9.4 to 1.10.4
-* pyramid-debugtoolbar from 4.5 to 4.6.1
-* pyramid-mako from 1.0.2 to 1.1.0
-* pyramid-tm from 2.2.1 to 2.4
-* python-dateutil from 2.6.1 to 2.8.1
-* pytz from 2019.1 to 2019.3
-* PyYAML from 5.1 to 5.4.1
-* rasterio from 1.0.2 to 1.1.3
-* redis from 3.2.1 to 3.4.1
-* requests from 2.21.0 to 2.23.0
-* Shapely from 1.6.4.post2 to 1.7.0
-* simplejson from 3.16.0 to 3.17.2
-* six from 1.11.0 to 1.14.0
-* urllib3 from 1.23 to 1.25.9
-* waitress from 1.2.1 to 1.4.3
-* zope.sqlalchemy from 1.1 to 1.3
+* affine from 2.3.1 to 2.4.0
+* alembic from 1.7.7 to 1.10.4
+* azure-core from 1.26.3 to 1.27.0
+* azure-storage-blob from 12.14.1 to 12.16.0
+* Babel from 2.9.1 to 2.12.1
+* Beaker from 1.11.0 to 1.12.1
+* c2cwsgiutils from 5.0.1 to 5.2.2
+* click from 8.0.4 to 8.1.3
+* dogpile.cache from 1.1.8 to 1.2.0
+* Fiona from 1.8.22 to 1.9.3
+* GDAL from 3.4.3 to 3.6.4
+* GeoAlchemy2 from 0.11.1 to 0.13.2
+* graphviz from 0.19.2 to 0.20.1
+* hupper from 1.10.3 to 1.12
+* idna from 3.3 to 3.4
+* iso8601 from 1.0.2 to 1.1.0
+* Jinja2 from 3.0.3 to 3.1.2
+* numpy from 1.22.4 to 1.24.3
+* OWSLib from 0.28.1 to 0.29.2
+* papyrus from 2.4 to 2.5
+* pbr from 5.8.1 to 5.11.1
+* Pillow from 9.4.0 to 9.5.0
+* plaster from 1.0 to 1.1.2
+* polib from 1.1.1 to 1.2.0
+* pycryptodome from 3.14.1 to 3.17
+* PyJWT from 2.4.0 to 2.7.0
+* pyotp from 2.6.0 to 2.8.0
+* pyproj from 3.3.1 to 3.5.0
+* pyramid-debugtoolbar from 4.9 to 4.10
+* pyramid-jinja2 from 2.9.2 to 2.10
+* pyyaml-include from 1.2.post2 to 1.3
+* rasterio from 1.2.10 to 1.3.6
+* redis from 4.3.6 to 4.5.4
+* sentry-sdk from 1.14.0 to 1.21.1
+* SQLAlchemy-Utils from 0.38.3 to 0.41.1
+* tilecloud from 1.8.2 to 1.9.3
+* transaction from 3.0.1 to 3.1.0
+* ujson from 5.4.0 to 5.7.0
+* wrapt from 1.13.3 to 1.15.0
+* zope.event from 4.4 to 4.6
 
 Npm packages updates
-....................
+------------------
 New packages:
-* @sentry/browser at version 5.15.4
-* @trevoreyre/autocomplete-js at version 2.1.1
-* commander at version 5.0.0
-* editorconfig-checker at version 3.3.0
-* jsdoc at version 3.6.4
-* jsdoc-plugin-typescript at version 2.0.5
-* localforage at version 1.7.3
-* ng-raven at version 1.0.1
-* parse-absolute-css-unit at version 1.0.2
-* popper.js at version 1.16.1
-* puppeteer at version 2.1.1
-* qruri at version 0.0.4
-* resize-observer-polyfill at version 1.5.1
-* simple-html-tokenizer at version 0.5.9
-* sinon at version 9.0.2
-* terser-webpack-plugin at version 4.1.0
-* typescript at version 3.8.3
+* @snyk/protect at version 1.1094.0
+* cy-mobile-commands at version 0.3.0
+* cypress-browser-permissions at version 1.1.0
+* cypress-real-events at version 1.7.6
+* eslint-plugin-lit at version 1.8.2
+* eslint-plugin-wc at version 1.4.0
+* i18next-http-backend at version 2.1.1
+* neat-csv at version 5.2.0
+* strip-bom at version 5.0.0
 
 Removed packages:
-* @openlayers/eslint-plugin
-* @types/angular-animate
-* @types/angular-dynamic-locale
-* @types/angular-gettext
-* @types/angular-mocks
-* @types/bootstrap
-* @types/cesium
-* @types/d3
-* @types/file-saver
-* @types/googlemaps
-* @types/jasmine
-* @types/jquery.ui.datetimepicker
-* @types/jsts
-* @types/proj4
-* @types/typeahead
-* angular
-* googshift
-* html-webpack-include-assets-plugin
-* ls
-* ol
-* ol-cesium
-* phantomjs-polyfill-string-includes
-* phantomjs-prebuilt
-* raven-js
+* @sentry/integrations
+* angular-gettext-tools
+* commander
+* eslint
+* i18next-xhr-backend
+* puppeteer
 
 Major updates:
-* css-loader from 2.1.1 to 3.5.2
-* eslint-config-openlayers from 11.0.0 to 14.0.0
-* extract-loader from 3.1.0 to 5.0.1
-* file-loader from 3.0.1 to 6.0.0
-* fs-extra from 7.0.1 to 9.0.0
+* @sentry/browser from 6.18.2 to 7.35.0
+* @sentry/tracing from 6.18.2 to 7.35.0
+* @sentry/types from 6.18.2 to 7.35.0
+* editorconfig-checker from 4.0.2 to 5.0.1
+* eslint-plugin-jsdoc from 38.0.8 to 39.7.5
+* fs-extra from 10.0.1 to 11.1.0
+* glob from 7.2.3 to 8.1.0
+* i18next-browser-languagedetector from 6.1.8 to 7.0.1
+* i18next-parser from 6.0.1 to 7.6.0
+* i18next from 21.6.16 to 22.4.9
+* node-sass from 6.0.1 to 7.0.3
+* ol-layerswitcher from 3.8.3 to 4.1.0
+* ol-mapbox-style from 7.1.1 to 9.5.0
+* ol from 6.12.0 to 7.2.2
+* sinon from 13.0.2 to 15.0.1
+* svgo from 2.8.0 to 3.0.2
+* tsconfig-paths from 3.14.2 to 4.1.2
 
 Minor updates:
-* @babel/core from 7.4.4 to 7.9.0
-* @babel/preset-env from 7.4.4 to 7.9.5
-* @fortawesome/fontawesome-free from 5.8.1 to 5.13.0
-* angular-gettext-tools from 2.4.1 to 2.5.3
-* babel-loader from 8.0.5 to 8.1.0
-* bootstrap from 4.3.1 to 4.4.1
-* copy-webpack-plugin from 5.0.3 to 5.1.1
-* corejs-typeahead from 1.2.1 to 1.3.1
-* d3 from 5.9.2 to 5.15.1
-* fast-sass-loader from 1.4.7 to 1.5.0
-* jsts from 2.0.4 to 2.1.2
-* moment from 2.22.2 to 2.24.0
-* node-sass from 4.12.0 to 4.13.1
-* npm from 6.4.1 to 6.14.12
-* ol-layerswitcher from 3.2.0 to 3.6.0
-* proj4 from 2.5.0 to 2.6.1
-* svgo from 1.2.2 to 1.3.2
-* ts-node from 8.1.0 to 8.8.2
-* tsconfig-paths from 3.8.0 to 3.9.0
-* webpack from 4.30.0 to 4.42.1
-* webpack-dev-server from 3.3.1 to 3.11.0
-
-Application build
-.................
-
-In the new version the build of the application becomes more Docker friendly.
-We didn't anymore have a build container that builds files in the local filesystem, now everything is done
-in Docker. The only thing that runs out of docker is the `build` script (that needs Python 3.x) which runs
-some `docker build`, and `docker-compose` commands.
-
-Main Changes
-------------
-
-The migration process impacts the following:
-1. Environment variables are now stored in the env.default and env.project files.
-2. .mako files are replaced by .tmpl, this means Python templating isn't possible anymore, (in .tmpl we just have template replacement).
-If dynamic variables are needed, you have to write a custom script in `script/config-eval-templates` and add it to the entrypoint into the config image
-3. Functionalities in the vars file (2.4) are now stored in the database (2.5) and manageable via the administration interface.
-4. In the geoportal folder, there are `static` and `static_ngeo` sub-folders. Since version 2.5 the usage is stricter.
-`static` can be used everywhere and is visible by all images, while `static_ngeo` can now only be used in the webpack build.
-5. Import of AngularJS library is required in JavaScript files using it, i.e for controllers or components: `import angular from 'angular';`.
-
-The migration process will also require the following UI-related changes (visible in the html diffs):
-1. Predefined values in editing form
-2. Query selection panel
-3. Loading spinners on various elements of the interfaces
-4. Geolocation on desktop (add the button)
-5. Map swipper
-
-Note: The list presented in this chapter is not exhaustive.
-
-
-Information
------------
+* @babel/core from 7.17.12 to 7.20.12
+* @babel/plugin-proposal-class-properties from 7.16.7 to 7.18.6
+* @babel/plugin-proposal-decorators from 7.17.12 to 7.20.13
+* @babel/plugin-transform-spread from 7.16.7 to 7.20.7
+* @babel/plugin-transform-typescript from 7.16.8 to 7.20.13
+* @babel/preset-env from 7.16.11 to 7.20.2
+* @babel/preset-typescript from 7.16.7 to 7.18.6
+* @lit/reactive-element from 1.3.4 to 1.6.1
+* @trevoreyre/autocomplete-js from 2.2.0 to 2.4.1
+* babel-loader from 8.2.5 to 8.3.0
+* core-js from 3.21.1 to 3.27.2
+* d3 from 7.3.0 to 7.8.2
+* jsts from 2.8.1 to 2.9.3
+* lit-html from 2.2.7 to 2.6.1
+* lit from 2.2.8 to 2.6.1
+* rxjs from 7.5.7 to 7.8.0
+* sass-loader from 10.2.1 to 10.4.1
+* terser from 5.12.1 to 5.16.2
+* tinycolor2 from 1.4.2 to 1.5.2
+* ts-node from 10.7.0 to 10.9.1
 
-1. Basic authentication is disabled by default from this version onward.
-   To enable basic auth see:
-   https://camptocamp.github.io/c2cgeoportal/{{cookiecutter.geomapfish_main_version}}/integrator/security.html#basic-auth
-
-2. We change the secret name from `GITHUB_GOPASS_CI_TOKEN` to `GOPASS_CI_GITHUB_TOKEN` because we can't
-   anymore create create secret started with `GITHUB_`.
-
-3. Layers which have any errors are not added to the theme anymore.
-
-4. If a WMS version is given in an OGC server URL, it will be used for the GetCapabilities request
-   Supported versions: 1.1.1 and 1.3.0
 
 Changes to apply
-----------------
-
-1. Now we need to have PyYAML python package installed in the home,
-   see the documentation for more information:
-   https://camptocamp.github.io/c2cgeoportal/{{cookiecutter.geomapfish_main_version}}/integrator/requirements.html
-
-2. The configuration vars `vars/functionalities/anonymous` and `vars/functionalities/registered` should
-   be moved to the new roles `anonymous` and `registered` that will be created once the database has been upgraded.
-
-3. The 'INSTANCE' configuration variable is removed, it should be in the '.env' files, and also the
-   environment makefiles, these contents should also be moved to the '.env' files. In a multi-organization
-   project you can have a chain of multiple '.env' files see the build configuration documentation.
-
-4. A new PostgreSQL extension is required, install it by running in psql:
-   `CREATE EXTENSION IF NOT EXISTS hstore;`
-
-5. The static files will be moved, therefore you should replace:
-   `request.static_url('{{cookiecutter.package}}_geoportal:static/` by:
-   `request.static_url('/etc/geomapfish/static/`.
-
-6. Optional, change your mapfiles according the documentation:
-   https://camptocamp.github.io/c2cgeoportal/{{cookiecutter.geomapfish_main_version}}/administrator/mapfile.html
-
-
-Version 2.4.2
-=============
-
-Information
------------
-
-1. The SVG inclusion through Webpack has changed, See ngeo SVG example for more information:
-   https://camptocamp.github.io/ngeo/master/examples/svg.html
-
-2. The WMTS capabilities is now generated on runtime.
-
-3. If not already done the 'edit' and 'routing' interfaces and their relations will be removed from the
-   database, If you don't want that, you should rename the interfaces before applying the alembic scripts.
-
-4. If not already done the 'api' and 'iframe_api' will be created. After the database upgrade you can run
-   the following request to fill e.-g. the api's interfaces with the desktop interface:
-
-    INSERT INTO main.interface_layer (interface_id, layer_id)
-    SELECT <api_interface_id>, layer_id FROM main.interface_layer WHERE interface_id = <other_interface_id>;
-    INSERT INTO main.interface_theme (interface_id, theme_id)
-    SELECT <api_interface_id>, theme_id FROM main.interface_theme WHERE interface_id = <other_interface_id>;
+================
```

## c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml

```diff
@@ -40,14 +40,16 @@
   vars:
     type: map
     required: True
     mapping:
       package:
         type: str
         required: True
+      main_ogc_server:
+        type: str
       enable_admin_interface:
         type: scalar
         required: True
       c2c.base_path:
         type: str
         required: True
       sqlalchemy.url:
@@ -119,62 +121,62 @@
               layout:
                 type: str
                 default: ngeo
       interfaces_config:
         required: True
         type: map
         mapping:
-          regex;.+:
+          regex;(.+):
             type: map
             mapping:
               extends:
                 type: str
               constants:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: any
               dynamic_constants:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: str
               routes:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: map
                     mapping:
                       name:
                         type: str
                       currentInterface:
                         type: bool
                       elements:
                         type: seq
                         sequence:
                           - type: str
                       kw:
                         type: map
                         mapping:
-                          regex;.+:
+                          regex;(.+):
                             type: str
                       params:
                         type: map
                         mapping:
-                          regex;.+:
+                          regex;(.+):
                             type: text
                       dynamic_params:
                         type: map
                         mapping:
-                          regex;.+:
+                          regex;(.+):
                             type: str
               static:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: map
                     mapping:
                       name:
                         type: str
                         required: True
                       append:
                         type: str
@@ -223,15 +225,15 @@
               pattern:
                 type: str
                 required: True
               headers:
                 type: map
                 required: True
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: str
       headers:
         type: map
         required: True
         mapping:
           login: &header
             type: map
@@ -249,15 +251,15 @@
                 type: scalar
               cache_control_max_age_nocache:
                 required: True
                 type: scalar
               headers:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: str
           index: *header
           dynamic: *header
           config: *header
           api: *header
           apihelp: *header
           themes: *header
@@ -279,24 +281,24 @@
           aes_key:
             type: str
 
       cache:
         type: map
         required: True
         mapping:
-          regex;.+:
+          regex;(.+):
             type: map
             mapping:
               backend:
                 required: True
                 type: str
               arguments:
                 type: map
                 mapping:
-                  regex;.+:
+                  regex;(.+):
                     type: any
       admin_interface:
         type: map
         required: True
         mapping:
           layer_tree_max_nodes:
             type: int
@@ -304,15 +306,15 @@
             type: map
             mapping:
               baseLayers:
                 type: seq
                 sequence:
                   - type: map
                     mapping:
-                      regex;.+:
+                      regex;(.+):
                         type: any
               fitSource:
                 type: bool
               fitMaxZoom:
                 type: int
               focusOnly:
                 type: bool
@@ -340,15 +342,15 @@
                     type: seq
                     sequence:
                       - type: int
                   projection:
                     type: str
                   zoom:
                     type: int
-                  regex;.+:
+                  regex;(.+):
                     type: any
           available_metadata:
             type: seq
             required: True
             sequence:
               - type: map
                 mapping:
@@ -403,25 +405,30 @@
                 mapping:
                   url_path:
                     type: str
                     required: True
                   model:
                     type: str
                     required: True
+          # Host allowed in the OGC server clear cache
+          allowed_hosts:
+            type: seq
+            sequence:
+              - type: str
 
       getitfixed:
         type: map
         required: True
         mapping:
           enabled:
             type: scalar
             required: True
           map:
             <<: *map_config
-          regex;.+:
+          regex;(.+):
             type: any
 
       layers:
         type: map
         required: True
         mapping:
           geometry_validation:
```

## c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml

```diff
@@ -17,21 +17,21 @@
 
   # Database information
   sqlalchemy:
     url: postgresql://{PGUSER}:{PGPASSWORD}@{PGHOST}:{PGPORT}/{PGDATABASE}?sslmode={PGSSLMODE}
     pool_recycle: '{SQLALCHEMY_POOL_RECYCLE}'
     pool_size: '{SQLALCHEMY_POOL_SIZE}'
     max_overflow: '{SQLALCHEMY_MAX_OVERFLOW}'
-    executemany_mode: batch
+    executemany_mode: values_plus_batch
   sqlalchemy_slave:
     url: postgresql://{PGUSER}:{PGPASSWORD}@{PGHOST_SLAVE}:{PGPORT_SLAVE}/{PGDATABASE}?sslmode={PGSSLMODE}
     pool_recycle: '{SQLALCHEMY_SLAVE_POOL_RECYCLE}'
     pool_size: '{SQLALCHEMY_SLAVE_POOL_SIZE}'
     max_overflow: '{SQLALCHEMY_SLAVE_MAX_OVERFLOW}'
-    executemany_mode: batch
+    executemany_mode: values_plus_batch
 
   # Session backend
   session:
     type: 'ext:redis'
     url: 'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'
 
   # 10 days of default cache
@@ -206,23 +206,24 @@
           layerIcon:
             width: 20
             height: 20
         gmfDisclaimerOptions: {}
         gmfBackgroundLayerSelectorOptions: {}
         defaultTheme: Demo
         defaultLang: en
-        gmfOptions:
+        gmfOptions: &gmfOptions
           map: {}
           view:
             srid: '{srid}'
             center: [2600000, 1200000]
             zoom: 3
             resolutions: [250, 100, 50, 20, 10, 5, 2, 1, 0.5, 0.25, 0.1, 0.05]
             extent: [2420000, 1030000, 2900000, 1350000]
             constrainRotation: false
+            constrainResolution: true
         gmfSearchOptions:
           styles:
             default:
               fill:
                 color: [65, 134, 240, 0.5]
               stroke:
                 color: [65, 134, 240, 1]
@@ -293,14 +294,19 @@
             fill:
               color: rgba(100, 100, 230, 0.3)
             stroke:
               color: rgba(40, 40, 230, 1)
               width: 2
           zoom:
           autoRotate: False
+        gmfWMSSourceOptions:
+          # The default value is 1.5 but it add a slight blur on the layer,
+          # 1 is also possible but the application will do a getMap on all the pan.
+          ratio: 2
+
       dynamic_constants:
         interface: interface
         cacheVersion: cache_version
         langUrls: lang_urls
         gmfI18nextConfiguration: i18next_configuration
         gmfTwoFactorAuth: two_factor
         gmfSearchGroups: fulltextsearch_groups
@@ -339,14 +345,15 @@
         gmfVectorTilesUrl:
           name: vector_tiles_root
     desktop:
       extends: default
       redirect_interface: mobile
       do_redirect: True
       constants:
+        gmfOptions: *gmfOptions
         ngeoProfileOptions: {}
         ngeoStreetviewOptions:
           viewer: 'mapillary'
         gmfPrintOptions:
           legend:
             # See:
             # https://www.mapserver.org/development/rfc/ms-rfc-101.html
@@ -359,15 +366,17 @@
               # https://docs.qgis.org/testing/en/docs/user_manual/working_with_ogc/server/services.html#getlegendgraphics
               qgis:
                 LAYERFONTFAMILY: DejaVu Sans
                 ITEMFONTFAMILY: DejaVu Sans
                 LAYERFONTSIZE: '10'
                 ITEMFONTSIZE: '8'
           hiddenAttributes:
+            - debug
             - timezone
+            - username
         gmfDisplayQueryGridOptions:
           featuresStyle: *featureStyle
           selectedFeatureStyle: *selectedFeatureStyle
         gmfEditFeatureOptions:
           tolerance: 10
           closeAfterSave: false
           highlightStyle:
@@ -388,23 +397,28 @@
           hoverPointStyle:
             circle:
               fill:
                 color: '#ffffff'
                 radius: 3
         gmfShareOptions:
           enableEmail: True
+        gmfFitOptions:
+          # Padding (in pixels) to be correctly fitted inside the view. Values in the array are top, right, bottom and left padding.
+          padding: [50, 10, 50, 50]
       routes:
         gmfProfileJsonUrl:
           name: profile.json
         gmfPrintUrl:
           name: printproxy
+
     mobile:
       extends: default
       redirect_interface: desktop
       constants:
+        gmfOptions: *gmfOptions
         gmfMobileMeasureAreaOptions:
           precision: 2
           sketchStyle: &mobileMeasureStyle
             fill:
               color: rgba(255, 128, 128, 0.2)
             stroke:
               color: rgba(255, 0, 0, 0.5)
@@ -436,18 +450,27 @@
               stroke:
                 color: rgba(0, 0, 0, 0.7)
                 width: 2
               points: 4
               radius: 8
               radius2: 0
               angle: 0
+        gmfFitOptions:
+          # Padding (in pixels) to be correctly fitted inside the view. Values in the array are top, right, bottom and left padding.
+          padding: [60, 60, 42, 10]
+
     iframe_api:
       extends: default
       constants:
+        gmfOptions: *gmfOptions
         gmfSearchGroups: []
+        gmfFitOptions:
+          # Padding (in pixels) to be correctly fitted inside the view. Values in the array are top, right, bottom and left padding.
+          padding: [20, 20, 20, 20]
+
     api:
       constants:
         projections: *projections
         # The projection of the map
         projection: EPSG:{srid}
       routes:
         themesUrl:
@@ -465,23 +488,27 @@
             partitionlimit: 5
           dynamic_params:
             interface: interface
 
   cache:
     std:
       backend: c2cgeoportal.hybridsentinel
-      arguments:
+      arguments: &redis-cache-arguments
         lock_timeout: '{REDIS_LOCK_TIMEOUT}' # seconds
         redis_expiration_time: '{REDIS_EXPIRATION_TIME}' # seconds
         distributed_lock: True
+        thread_local_lock: False
         service_name: '{REDIS_SERVICENAME}'
         socket_timeout: '{REDIS_TIMEOUT}' # seconds
         db: 0
     obj:
       backend: dogpile.cache.memory
+    ogc-server:
+      backend: c2cgeoportal.hybridsentinel
+      arguments: *redis-cache-arguments
 
   admin_interface:
     layer_tree_max_nodes: 1000
 
     # The list of available variable names for the `Metadatas` form.
     available_metadata:
       # TreeItem
@@ -489,14 +516,26 @@
         type: list
         description: >
           Comma separated list of search aliases (keywords) to be added to the tsearch.ts field for
           the considered tree item (theme, layer group or layer), that is to say that considered
           tree item will match when searching for the search aliases.
         relevant_for:
           - treeitem
+      - name: searchLabelPattern
+        description: >
+          Template string for the label of tree items in the search results, for example: "{name} ({theme})"
+          Supported parameters:
+          <ul>
+              <li>name (name of the tree item)</li>
+              <li>parent (parent of the item, may be a group, a block or a theme)</li>
+              <li>block (name of the block to which the item belongs)</li>
+              <li>theme (name of the theme to which the item belongs)</li>
+          </ul>
+        relevant_for:
+          - treeitem
       # Layers group
       - name: exclusiveGroup
         type: boolean
         description: >
           Whether the group contains children that have to be mutually exclusive, meaning that only
           one child may be ON at any time.
         relevant_for:
@@ -891,16 +930,14 @@
   # Used to send an email on password reset
   reset_password: {}
 
   # The shortener base configuration
   shortener:
     # The base of created URL
     base_url: '{VISIBLE_WEB_PROTOCOL}://{VISIBLE_WEB_HOST}{VISIBLE_ENTRY_POINT}s/'
-    allowed_hosts:
-      - '{VISIBLE_WEB_HOST}'
     length: 4
 
   # Define whether the MapServer proxy should hide the OGC capabilities.
   hide_capabilities: false
 
   # For print proxy
   print_url: '{PRINT_URL}'
@@ -910,18 +947,21 @@
 
   pdfreport:
     print_url: '{PRINT_URL}'
 
   lingua_extractor: {}
 
   content_security_policy_main_default_src_extra: ''
+  # Google Maps uses map.google.com and map.googleapis.com
+  # More info: https://developers.google.com/maps/documentation/javascript/content-security-policy?hl=fr#allowlist_csp
+  # Google Analytics 4 uses googletagmanager.com
+  # More info: https://developers.google.com/tag-platform/tag-manager/csp?hl=fr#google_analytics_4_google_analytics
   content_security_policy_main_script_src_extra: '
-    https://maps.google.com/
-    https://maps.googleapis.com/
-    https://www.google-analytics.com/
+    https://*.google.com/
+    https://*.googleapis.com/
     https://*.googletagmanager.com/'
   content_security_policy_main_style_src_extra: '
     https://fonts.googleapis.com/'
   content_security_policy_main_img_src_extra: '
     https://*.google-analytics.com/
     https://*.googletagmanager.com/'
   content_security_policy_main_connect_src_extra: '
@@ -1197,16 +1237,15 @@
     hosts:
       - display: Main
         url: 'http://localhost:8080{VISIBLE_ENTRY_POINT}'
     max_level: 3
     level: 10
 
   # What web page is authorized to use the API
-  authorized_referers:
-    - '{VISIBLE_WEB_PROTOCOL}://{VISIBLE_WEB_HOST}/'
+  authorized_referers: []
 
   metrics:
     memory_maps_rss: False
     memory_maps_size: False
     memory_cache: True
     memory_cache_all: False
     raster_data: False
@@ -1291,14 +1330,18 @@
     default: '0'
   - name: REDIS_SERVICENAME
     default: 'mymaster'
   - name: REDIS_TIMEOUT
     default: '30'
   - name: REDIS_LOCK_TIMEOUT
     default: '120' # Two minutes
+  - name: REDIS_PASSWORD
+    default: ''
+  - name: REDIS_SSL
+    default: 'false'
   - name: REDIS_EXPIRATION_TIME
     default: '86400' # One day
   - name: TILEGENERATION_SQS_QUEUE
     default: queue_name
   - name: TILEGENERATION_S3_BUCKET
     default: bucket_name
   - name: SENTRY_URL
@@ -1311,14 +1354,18 @@
 runtime_postprocess:
   - expression: int({})
     vars:
       - cache.std.arguments.lock_timeout
       - cache.std.arguments.redis_expiration_time
       - cache.std.arguments.socket_timeout
       - cache.std.arguments.db
+      - cache.ogc-server.arguments.lock_timeout
+      - cache.ogc-server.arguments.redis_expiration_time
+      - cache.ogc-server.arguments.socket_timeout
+      - cache.ogc-server.arguments.db
       - sqlalchemy\.pool_recycle
       - sqlalchemy\.pool_size
       - sqlalchemy\.max_overflow
       - sqlalchemy_slave\.pool_recycle
       - sqlalchemy_slave\.pool_size
       - sqlalchemy_slave\.max_overflow
       - authentication.max_consecutive_failures
```

## c2cgeoportal_geoportal/scripts/__init__.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,15 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import os
 from argparse import ArgumentParser, Namespace
-from typing import Any, Dict
+from typing import Any
 
 import c2cwsgiutils.setup_process
 import pyramid.config
 import transaction
 import zope.sqlalchemy
 from sqlalchemy import engine_from_config
 from sqlalchemy.orm import Session, configure_mappers, sessionmaker
@@ -47,15 +47,15 @@
 
 
 def get_appsettings(options: Namespace) -> pyramid.config.Configurator:
     """Get the application settings."""
     return c2cwsgiutils.setup_process.bootstrap_application_from_options(options)["registry"].settings
 
 
-def get_session(settings: Dict[str, Any], transaction_manager: transaction.TransactionManager) -> Session:
+def get_session(settings: dict[str, Any], transaction_manager: transaction.TransactionManager) -> Session:
     """Get the database session in script context."""
     configure_mappers()
     engine = engine_from_config(settings)
     session_factory = sessionmaker()
     session_factory.configure(bind=engine)
     dbsession = session_factory()
     zope.sqlalchemy.register(dbsession, transaction_manager=transaction_manager)
```

## c2cgeoportal_geoportal/scripts/c2cupgrade.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2014-2021, Camptocamp SA
+# Copyright (c) 2014-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -33,15 +33,15 @@
 import re
 import shutil
 import subprocess
 import sys
 from argparse import ArgumentParser, Namespace
 from json.decoder import JSONDecodeError
 from subprocess import call, check_call, check_output
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union, cast
+from typing import Any, Callable, Optional, Union, cast
 
 import pkg_resources
 import requests
 import yaml
 
 from c2cgeoportal_geoportal.lib.bashcolor import Color, colorize
 
@@ -60,15 +60,15 @@
 
 def fix_style() -> None:
     """Fix the style of all the project files using isort, Black and Prettier."""
 
     file_to_clean = []
     for filename, content in (
         (".prettierignore", "*.min.js\n"),
-        ("pyproject.toml", "[tool.black]\nline-length = 110\ntarget-version = ['py38']\n"),
+        ("pyproject.toml", "[tool.black]\nline-length = 110\ntarget-version = ['py39']\n"),
         (".prettierrc.yaml", "bracketSpacing: false\nquoteProps: preserve\n"),
         (
             ".editorconfig",
             """root = true
 [*]
 max_line_length = 110
 """,
@@ -80,17 +80,30 @@
                 shutil.copyfile(os.path.join("CONST_create_template", filename), filename)
             else:
                 with open(filename, "w", encoding="utf8") as file_:
                     file_.write(content)
 
     if os.path.exists("ci/config.yaml"):
         os.rename("ci/config.yaml", "ci/config.yaml_")
-    subprocess.run(["c2cciutils-checks", "--fix", "--check=isort"])  # pylint: disable=subprocess-run-check
-    subprocess.run(["c2cciutils-checks", "--fix", "--check=black"])  # pylint: disable=subprocess-run-check
-    subprocess.run(["c2cciutils-checks", "--fix", "--check=prettier"])  # pylint: disable=subprocess-run-check
+    if os.path.exists(".pre-commit-config.yaml"):
+        print("Run pre-commit to fix the style.")
+        sys.stdout.flush()
+        subprocess.run(["pre-commit", "run", "--all-files"])  # pylint: disable=subprocess-run-check
+    else:
+        print("Run c2cciutils-checks to fix the style.")
+        sys.stdout.flush()
+        subprocess.run(  # pylint: disable=subprocess-run-check
+            ["c2cciutils-checks", "--fix", "--check=isort"]
+        )
+        subprocess.run(  # pylint: disable=subprocess-run-check
+            ["c2cciutils-checks", "--fix", "--check=black"]
+        )
+        subprocess.run(  # pylint: disable=subprocess-run-check
+            ["c2cciutils-checks", "--fix", "--check=prettier"]
+        )
     if os.path.exists("ci/config.yaml_"):
         os.rename("ci/config.yaml_", "ci/config.yaml")
 
     for filename in file_to_clean:
         os.remove(filename)
 
 
@@ -184,30 +197,30 @@
     color_bar = colorize("================================================================", Color.GREEN)
 
     def __init__(self, options: Namespace):
         self.options = options
         self.project = self.get_project()
 
     @staticmethod
-    def get_project() -> Dict[str, Any]:
+    def get_project() -> dict[str, Any]:
         if not os.path.isfile("project.yaml"):
             print(colorize("Unable to find the required 'project.yaml' file.", Color.RED))
             sys.exit(1)
 
         with open("project.yaml", encoding="utf8") as project_file:
-            return cast(Dict[str, Any], yaml.safe_load(project_file))
+            return cast(dict[str, Any], yaml.safe_load(project_file))
 
     @staticmethod
-    def get_upgrade(section: str) -> Union[List[Any], Dict[str, Any]]:
+    def get_upgrade(section: str) -> Union[list[Any], dict[str, Any]]:
         if not os.path.isfile(".upgrade.yaml"):
             print(colorize("Unable to find the required '.upgrade.yaml' file.", Color.RED))
             sys.exit(1)
 
         with open(".upgrade.yaml", encoding="utf8") as project_file:
-            return cast(Union[List[Any], Dict[str, Any]], yaml.safe_load(project_file)[section])
+            return cast(Union[list[Any], dict[str, Any]], yaml.safe_load(project_file)[section])
 
     def print_step(
         self,
         step: int,
         error: bool = False,
         message: Optional[str] = None,
         prompt: str = "To continue, type:",
@@ -226,32 +239,32 @@
                     cmd.append(f"{step}")
                 print(colorize(" ".join(cmd), Color.GREEN))
                 instructions.write(f"{' '.join(cmd)}\n")
 
     def run_step(self, step: int) -> None:
         getattr(self, f"step{step}")()
 
-    def test_checkers(self) -> Tuple[bool, Optional[str]]:
+    def test_checkers(self) -> tuple[bool, Optional[str]]:
         headers = " ".join(
             [f"--header {i[0]}={i[1]}" for i in self.project.get("checker_headers", {}).items()]
         )
         run_curl = f"Run `curl --insecure {headers} '{self.project['checker_url']}'` for more information."
         try:
             requests.packages.urllib3.disable_warnings()  # type: ignore
             resp = requests.get(
                 self.project["checker_url"],
                 headers=self.project.get("checker_headers"),
                 verify=False,  # nosec
+                timeout=120,
             )
         except requests.exceptions.ConnectionError as exception:
             return False, "\n".join([f"Connection error: {exception}", run_curl])
         except ConnectionRefusedError as exception:
             return False, "\n".join([f"Connection refused: {exception}", run_curl])
         if resp.status_code < 200 or resp.status_code >= 300:
-
             print(colorize("=============", Color.RED))
             print(colorize("Checker error", Color.RED))
             try:
                 for name, value in resp.json()["failures"].items():
                     print(colorize(f"Test '{name}' failed with result:", Color.YELLOW))
                     del value["level"]
                     del value["timing"]
@@ -270,15 +283,15 @@
         return True, None
 
     def upgrade(self) -> None:
         self.run_step(self.options.step)
 
     @Step(0, file_marker=False)
     def step0(self, step: int) -> None:
-        project_template_keys = list(cast(Dict[str, Any], self.project.get("template_vars")).keys())
+        project_template_keys = list(cast(dict[str, Any], self.project.get("template_vars")).keys())
         messages = []
         for required in REQUIRED_TEMPLATE_KEYS:
             if required not in project_template_keys:
                 messages.append(
                     "The element '{required}' is missing in the `template_vars` of "
                     "the file 'project.yaml', you should have for example: {required}: {template}.".format(
                         required=required, template=TEMPLATE_EXAMPLE.get("required", "")
@@ -347,15 +360,15 @@
                     "--overwrite",
                     "--scaffold=advance_update",
                     project_path,
                 ]
             )
 
         shutil.copyfile(os.path.join(project_path, ".upgrade.yaml"), ".upgrade.yaml")
-        for upgrade_file in cast(List[Dict[str, Any]], self.get_upgrade("upgrade_files")):
+        for upgrade_file in cast(list[dict[str, Any]], self.get_upgrade("upgrade_files")):
             action = upgrade_file["action"]
             if action == "remove":
                 self.files_to_remove(upgrade_file, prefix="CONST_create_template", force=True)
             if action == "move":
                 self.files_to_move(upgrade_file, prefix="CONST_create_template", force=True)
 
         shutil.rmtree(project_path)
@@ -390,15 +403,15 @@
                     project_path,
                 ]
             )
         os.remove(project_path)
 
         check_call(["git", "add", "--all", "CONST_create_template/"])
 
-        def changed_files() -> List[str]:
+        def changed_files() -> list[str]:
             try:
                 status = [
                     [s for s in status.strip().split(" ", maxsplit=1) if s]
                     for status in check_git_status_output().strip().split("\n")
                     if status
                 ]
                 return [
@@ -444,15 +457,15 @@
             )
         else:
             self.run_step(step + 1)
 
     @Step(6)
     def step6(self, step: int) -> None:
         task_to_do = False
-        for upgrade_file in cast(List[Dict[str, Any]], self.get_upgrade("upgrade_files")):
+        for upgrade_file in cast(list[dict[str, Any]], self.get_upgrade("upgrade_files")):
             action = upgrade_file["action"]
             if action == "remove":
                 task_to_do |= self.files_to_remove(upgrade_file)
             elif action == "move":
                 task_to_do |= self.files_to_move(upgrade_file)
 
         if task_to_do:
@@ -466,15 +479,15 @@
                 - pattern: <pattern>
                   no_touch: True
                 """,
             )
         else:
             self.run_step(step + 1)
 
-    def files_to_remove(self, element: Dict[str, Any], prefix: str = "", force: bool = False) -> bool:
+    def files_to_remove(self, element: dict[str, Any], prefix: str = "", force: bool = False) -> bool:
         task_to_do = False
         for path in element["paths"]:
             file_ = os.path.join(prefix, path.format(package=self.project["project_package"]))
             if os.path.exists(file_):
                 managed = False
                 if not force:
                     for files in self.project["managed_files"]:
@@ -515,15 +528,15 @@
                         )
                     if os.path.isdir(file_):
                         shutil.rmtree(file_)
                     else:
                         os.remove(file_)
         return task_to_do
 
-    def files_to_move(self, element: Dict[str, Any], prefix: str = "", force: bool = False) -> bool:
+    def files_to_move(self, element: dict[str, Any], prefix: str = "", force: bool = False) -> bool:
         task_to_do = False
         src = os.path.join(prefix, element["from"].format(package=self.project["project_package"]))
         dst = os.path.join(prefix, element["to"].format(package=self.project["project_package"]))
         if os.path.exists(src):
             managed = False
             type_ = "directory" if os.path.isdir(src) else "file"
             if not force:
@@ -594,15 +607,15 @@
         self.files_to_get(step)
         self.run_step(step + 1)
 
     def is_managed(self, file_: str, files_to_get: bool = False) -> bool:
         # Dictionary with:
         # include: list of include regular expression
         # exclude: list of exclude regular expression
-        default_project_file = cast(Dict[str, List[str]], self.get_upgrade("default_project_file"))
+        default_project_file = cast(dict[str, list[str]], self.get_upgrade("default_project_file"))
 
         # Managed means managed by the application owner, not the c2cupgrade
         managed = False
         if (
             not files_to_get
             or os.path.exists(file_)
             or not check_git_status_output(["CONST_create_template/" + file_]).startswith("A  ")
@@ -703,15 +716,15 @@
         else:
             self.print_step(
                 step + 1,
                 message="Apply the manual migration steps based on what is in the CONST_CHANGELOG.txt "
                 "file (listed in the `changelog.diff` file).",
             )
 
-    def get_modified(self, status_path: str) -> List[str]:
+    def get_modified(self, status_path: str) -> list[str]:
         status = check_git_status_output([status_path]).split("\n")
         status = [s for s in status if len(s) > 3]
         status = [s[3:] for s in status if s[:3].strip() == "M"]
         for pattern in self.get_upgrade("no_diff"):
             matcher = re.compile(f"CONST_create_template/{pattern}$")
             status = [s for s in status if not matcher.match(s)]
         status = [s for s in status if os.path.exists(s[len("CONST_create_template/") :])]
@@ -782,14 +795,16 @@
             self.run_step(step + 1)
 
     @Step(11)
     def step11(self, step: int) -> None:
         if os.path.isfile("create.diff"):
             os.unlink("create.diff")
 
+        fix_style()
+
         message = [
             "The upgrade is nearly done, now you should:",
             "- Build your application with `./upgrade --finalize [build arguments]`",
             f"- Test your application on '{self.project.get('application_url', '... missing ...')}'.",
         ]
 
         if os.path.isfile(".upgrade.yaml"):
@@ -850,14 +865,14 @@
         print(colorize("Congratulations, your upgrade was successful.", Color.GREEN))
         print("")
         branch = check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"]).decode("utf-8").strip()
         print("Now all your files are committed; you should do a git push:")
         print(f"git push {self.options.git_remote} {branch}.")
 
 
-def check_git_status_output(args: Optional[List[str]] = None) -> str:
+def check_git_status_output(args: Optional[list[str]] = None) -> str:
     """Check if there is something that's not committed."""
     return check_output(["git", "status", "--short"] + (args if args is not None else [])).decode("utf-8")
 
 
 if __name__ == "__main__":
     main()
```

## c2cgeoportal_geoportal/scripts/manage_users.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2023, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -56,19 +56,19 @@
     return parser
 
 
 def main() -> None:
     """
     Emergency user create and password reset script example.
 
-    Reset toto password to foobar: docker-compose
+    Reset toto password to foobar: docker compose
     exec geoportal manage-users --password=foobar toto example, create user foo with password bar and role
-    admin: docker-compose exec geoportal manage-users --create --rolename=role_admin --password=bar foo.
+    admin: docker compose exec geoportal manage-users --create --rolename=role_admin --password=bar foo.
 
-    to get the options list, do: docker-compose exec geoportal manage-users --help
+    to get the options list, do: docker compose exec geoportal manage-users --help
     """
 
     parser = get_argparser()
     options = parser.parse_args()
     username = options.user
     settings = get_appsettings(options)
 
@@ -101,29 +101,32 @@
 
                 if query_role.count() == 0:
                     # Role not found in db?
                     print(f"Role matching {options.rolename} does not exist in database")
                     sys.exit(1)
 
                 role = query_role.first()
+                assert role is not None
 
                 user = User(
                     username=username,
                     password=cast(str, options.password),
                     email=cast(str, options.email),
                     settings_role=role,
                     roles=[role],
                 )
                 session.add(user)
 
                 print(f"User {username} created with password {options.password} and role {options.rolename}")
 
         else:
             # If user exists (assuming username are unique)
-            user = query.first()
+            first_user = query.first()
+            assert first_user is not None
+            user = first_user
 
             if options.password is not None:
                 print(f"Password set to: {options.password}")
                 user.password = f"{options.password}"
 
             if options.email is not None:
                 user.email = options.email
```

## c2cgeoportal_geoportal/scripts/pcreate.py

```diff
@@ -28,15 +28,15 @@
 
 import json
 import os
 import re
 import subprocess
 import sys
 from argparse import ArgumentParser
-from typing import Any, Dict, List, Optional, Type, Union, cast
+from typing import Any, Optional, Union, cast
 
 import pkg_resources
 import requests
 import yaml
 from cookiecutter.log import configure_logger
 from cookiecutter.main import cookiecutter
 
@@ -103,15 +103,15 @@
 class PCreateCommand:
     """
     Wrapper around cookiecutter with appropriated context creator for our scaffolds.
 
     This is a port of Pyramid 1 PCreateCommand using cookiecutter as a backend.
     """
 
-    def __init__(self, argv: List[str], quiet: bool = False) -> None:
+    def __init__(self, argv: list[str], quiet: bool = False) -> None:
         self.quiet = quiet
         self.parser = get_argparser()
         self.args = self.parser.parse_args(argv[1:])
         self.scaffolds = self.all_scaffolds()
 
     def run(self) -> int:
         if self.args.list:
@@ -157,30 +157,30 @@
             for scaffold in scaffolds:
                 self.out(f"  {scaffold}")
         else:
             self.out("No scaffolds available")
         return 0
 
     @staticmethod
-    def all_scaffolds() -> List[str]:
+    def all_scaffolds() -> list[str]:
         return os.listdir(SCAFFOLDS_DIR)
 
     def out(self, msg: str) -> None:
         if not self.quiet:
             print(msg)
 
-    def get_context(self) -> Dict[str, Union[str, int]]:
+    def get_context(self) -> dict[str, Union[str, int]]:
         output_dir = self.output_path
         project_name = os.path.basename(output_dir)
         if self.args.package_name is None:
             pkg_name = _bad_chars_re.sub("", project_name.lower().replace("-", "_"))
         else:
             pkg_name = self.args.package_name
 
-        context: Dict[str, Union[str, int]] = {
+        context: dict[str, Union[str, int]] = {
             "project": project_name,
             "package": pkg_name,
             "authtkt_secret": gen_authtkt_secret(),
         }
         context.update(self.read_project_file())
         if os.environ.get("CI") == "true":
             context["authtkt_secret"] = (  # nosec
@@ -237,29 +237,29 @@
         context["geomapfish_major_version_tag_env"] = "${" + geomapfish_major_version_tag + "}"
         context["geomapfish_main_version"] = os.environ["MAJOR_VERSION"]
         context["geomapfish_main_version_dash"] = os.environ["MAJOR_VERSION"].replace(".", "-")
         context["geomapfish_main_minor_version"] = os.environ["MAJOR_MINOR_VERSION"]
 
         return context
 
-    def read_project_file(self) -> Dict[str, Union[str, int]]:
+    def read_project_file(self) -> dict[str, Union[str, int]]:
         project_file = os.path.join(self.output_path, "project.yaml")
         if os.path.exists(project_file):
             with open(project_file, encoding="utf8") as f:
                 project = yaml.safe_load(f)
-                return cast(Dict[str, Union[str, int]], project.get("template_vars", {}))
+                return cast(dict[str, Union[str, int]], project.get("template_vars", {}))
         else:
             return {}
 
     @staticmethod
     def get_var(
-        context: Dict[str, Any],
+        context: dict[str, Any],
         name: str,
         prompt: str,
-        type_: Optional[Type[Any]] = None,
+        type_: Optional[type[Any]] = None,
     ) -> None:
         if name.upper() in os.environ and os.environ[name.upper()] != "":
             value = os.environ.get(name.upper())
         else:
             value = context.get(name)
 
         if value is None:
@@ -271,28 +271,30 @@
             except ValueError:
                 print(f"The attribute {name}={value} is not a {type_}")
                 sys.exit(1)
 
         context[name] = value
 
     @staticmethod
-    def epsg2bbox(srid: int) -> Optional[List[str]]:
+    def epsg2bbox(srid: int) -> Optional[list[str]]:
         try:
-            r = requests.get(f"https://epsg.io/?format=json&q={srid}")
+            r = requests.get(f"https://epsg.io/?format=json&q={srid}", timeout=60)
             bbox = r.json()["results"][0]["bbox"]
             r = requests.get(
                 "https://epsg.io/trans?s_srs=4326&t_srs={srid}&data={bbox[1]},{bbox[0]}".format(
                     srid=srid, bbox=bbox
-                )
+                ),
+                timeout=60,
             )
             r1 = r.json()[0]
             r = requests.get(
                 "https://epsg.io/trans?s_srs=4326&t_srs={srid}&data={bbox[3]},{bbox[2]}".format(
                     srid=srid, bbox=bbox
-                )
+                ),
+                timeout=60,
             )
             r2 = r.json()[0]
             return [r1["x"], r2["y"], r2["x"], r1["y"]]
         except requests.RequestException:
             print("Failed to establish a connection to epsg.io.")
         except json.JSONDecodeError:
             print("epsg.io doesn't return a correct json.")
```

## c2cgeoportal_geoportal/scripts/theme2fts.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2014-2021, Camptocamp SA
+# Copyright (c) 2014-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -26,15 +26,16 @@
 # either expressed or implied, of the FreeBSD Project.
 
 
 import gettext
 import os
 import sys
 from argparse import ArgumentParser, Namespace
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Set
+from collections.abc import Iterator
+from typing import TYPE_CHECKING, Any, Optional
 
 import pyramid.config
 import transaction
 from sqlalchemy import func
 from sqlalchemy.orm.session import Session
 
 from c2cgeoportal_geoportal.lib.bashcolor import Color, colorize
@@ -109,15 +110,15 @@
     To import all the themes, layer groups and layers names into the full-text search table.
 
     Done by interface and by language.
     """
 
     def __init__(self, session: Session, settings: pyramid.config.Configurator, options: Namespace):
         self.options = options
-        self.imported: Set[Any] = set()
+        self.imported: set[Any] = set()
         package = settings["package"]
 
         self.fts_languages = settings["fulltextsearch"]["languages"]
         self.languages = settings["available_locale_names"]
         self.fts_normalizer = Normalize(settings["fulltextsearch"])
 
         fts_missing_langs = [lang for lang in self.languages if lang not in self.fts_languages]
@@ -136,15 +137,15 @@
             Role,
             Theme,
         )
 
         self.session = session
         self.session.execute(FullTextSearch.__table__.delete().where(FullTextSearch.from_theme))
 
-        self._: Dict[str, gettext.NullTranslations] = {}
+        self._: dict[str, gettext.NullTranslations] = {}
         for lang in self.languages:
             try:
                 self._[lang] = gettext.translation(
                     f"{package}_geoportal-client",
                     options.locale_folder.format(package=package),
                     [lang],
                 )
@@ -155,16 +156,16 @@
         query = self.session.query(Interface)
         if options.interfaces is not None:
             query = query.filter(Interface.name.in_(options.interfaces))
         else:
             query = query.filter(Interface.name.notin_(options.exclude_interfaces))
         self.interfaces = query.all()
 
-        self.public_theme: Dict[int, List[int]] = {}
-        self.public_group: Dict[int, List[int]] = {}
+        self.public_theme: dict[int, list[int]] = {}
+        self.public_group: dict[int, list[int]] = {}
         for interface in self.interfaces:
             self.public_theme[interface.id] = []
             self.public_group[interface.id] = []
 
         for theme in self.session.query(Theme).filter_by(public=True).all():
             self._add_theme(theme)
 
@@ -186,15 +187,15 @@
             interface.id,
             role.id if role is not None else None,
         )
         if key not in self.imported:
             self.imported.add(key)
             for lang in self.languages:
                 fts = FullTextSearch()
-                fts.label = self._[lang].gettext(item.name)
+                fts.label = self._render_label(item, lang)
                 fts.role = role
                 fts.interface = interface
                 fts.lang = lang
                 fts.public = role is None
                 fts.ts = func.to_tsvector(
                     self.fts_languages[lang],
                     " ".join(
@@ -285,7 +286,62 @@
         else:
             fill = interface in layer.interfaces and not layer.public and self._layer_visible(layer, role)
 
         if fill and self.options.layers:
             self._add_fts(layer, interface, "add_layer", role)
 
         return fill
+
+    def _render_label(
+        self,
+        item: "c2cgeoportal_commons.models.main.TreeItem",
+        lang: str,
+    ) -> str:
+        patterns = item.get_metadata("searchLabelPattern")
+        if not patterns:
+            return self._[lang].gettext(item.name)
+        pattern = patterns[0]
+        assert isinstance(pattern.value, str)
+        tree_paths = list(self._get_paths(item))
+        # Remove paths where the last element isn't a theme
+        tree_paths = [p for p in tree_paths if p[-1].item_type == "theme"]
+        result = None
+        current_result = None
+        if tree_paths:
+            for path in tree_paths:
+                if len(path) == 2:
+                    current_result = pattern.value.format(
+                        name=self._[lang].gettext(item.name),
+                        theme=self._[lang].gettext(path[-1].name),
+                        parent=self._[lang].gettext(path[1].name),
+                    )
+                elif len(path) > 2:
+                    current_result = pattern.value.format(
+                        name=self._[lang].gettext(item.name),
+                        theme=self._[lang].gettext(path[-1].name),
+                        parent=self._[lang].gettext(path[1].name),
+                        block=self._[lang].gettext(path[-2].name),
+                    )
+                if result and current_result != result:
+                    sys.stderr.write(
+                        f"WARNING: the item {item.name} (id: {item.id}) has a label pattern and inconsistent "
+                        f"multiple parents\n"
+                    )
+                    return self._[lang].gettext(item.name)
+                result = current_result
+        return result or pattern.value.format(
+            name=self._[lang].gettext(item.name),
+            theme=self._[lang].gettext(item.name),
+        )
+
+    def _get_paths(
+        self,
+        item: "c2cgeoportal_commons.models.main.TreeItem",
+    ) -> Iterator[list["c2cgeoportal_commons.models.main.TreeItem"]]:
+        if item is None:
+            return
+        if any(item.parents):
+            for parent in item.parents:
+                for path in self._get_paths(parent):
+                    yield [item, *path]
+        else:
+            yield [item]
```

## c2cgeoportal_geoportal/scripts/urllogin.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2021, Camptocamp SA
+# Copyright (c) 2012-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## c2cgeoportal_geoportal/templates/login.html

```diff
@@ -1,8 +1,8 @@
-<!DOCTYPE html>
+<!doctype html>
 <html lang="${lang}">
   <head>
     <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
     <meta name="Content-Language" content="${lang}" />
     <title>${_('Login to Geoportal Application')}</title>
     <style>
       body {
```

## c2cgeoportal_geoportal/templates/notlogin.html

```diff
@@ -1,8 +1,8 @@
-<!DOCTYPE html>
+<!doctype html>
 <html lang="${lang}">
   <head>
     <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
     <meta name="Content-Language" content="${lang}" />
     <title>${_('Login to Geoportal Application')}</title>
     <style>
       body {
```

## c2cgeoportal_geoportal/views/__init__.py

```diff
@@ -1,10 +1,8 @@
-# -*- coding: utf-8 -*-
-
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,15 +21,14 @@
 # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
-from typing import Dict, List
 
 import pyramid.config
 import pyramid.request
 from pyramid.httpexceptions import HTTPFound
 
 
 def add_ending_slash(request: pyramid.request.Request) -> HTTPFound:
@@ -45,15 +42,15 @@
     def redirect_view(request: pyramid.request.Request) -> HTTPFound:
         return HTTPFound(location=request.route_url(to))
 
     config.add_route(name, from_, request_method="GET")
     config.add_view(redirect_view, route_name=name)
 
 
-def restrict_headers(headers: Dict[str, str], whitelist: List[str], blacklist: List[str]) -> Dict[str, str]:
+def restrict_headers(headers: dict[str, str], whitelist: list[str], blacklist: list[str]) -> dict[str, str]:
     """
     Filter headers with a whitelist then a blacklist.
 
     Some default pyramid headers will be added back by pyramid.
     """
     if len(whitelist) > 0:
         headers = {key: value for key, value in headers.items() if key in whitelist}
```

## c2cgeoportal_geoportal/views/dynamic.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2021, Camptocamp SA
+# Copyright (c) 2018-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,15 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import re
 import urllib.parse
-from typing import Any, Dict, List, Union, cast
+from typing import Any, Union, cast
 
 import pyramid.request
 from pyramid.httpexceptions import HTTPNotFound
 from pyramid.view import view_config
 from sqlalchemy import func
 
 from c2cgeoportal_commons import models
@@ -48,33 +48,35 @@
     """The dynamic vies that provide the configuration of the client application."""
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
         self.settings = request.registry.settings
         self.interfaces_config = self.settings["interfaces_config"]
 
-    def get(self, value: Dict[str, Any], interface: str) -> Dict[str, Any]:
-        return cast(Dict[str, Any], self.interfaces_config.get(interface, {}).get(value, {}))
+    def get(self, value: dict[str, Any], interface: str) -> dict[str, Any]:
+        return cast(dict[str, Any], self.interfaces_config.get(interface, {}).get(value, {}))
+
+    @CACHE_REGION.cache_on_arguments()
+    def _fulltextsearch_groups(self) -> list[str]:
+        assert models.DBSession is not None
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
-    def _fulltextsearch_groups(self) -> List[str]:  # pylint: disable=no-self-use
         return [
             group[0]
             for group in models.DBSession.query(func.distinct(main.FullTextSearch.layer_name))
             .filter(main.FullTextSearch.layer_name.isnot(None))
             .all()
         ]
 
     def _interface(
         self,
-        interface_config: Dict[str, Any],
+        interface_config: dict[str, Any],
         interface_name: str,
         original_interface_name: str,
-        dynamic: Dict[str, Any],
-    ) -> Dict[str, Any]:
+        dynamic: dict[str, Any],
+    ) -> dict[str, Any]:
         """
         Get the interface configuration.
 
         Arguments:
 
             interface_config: Current interface configuration
             interface_name: Interface name (we use in the configuration)
@@ -105,39 +107,39 @@
                 name: self.request.static_url(static_["name"]) + static_.get("append", "")
                 for name, static_ in interface_config.get("static", {}).items()
             }
         )
 
         for constant, config in interface_config.get("routes", {}).items():
             route_name = original_interface_name if config.get("currentInterface", False) else config["name"]
-            params: Dict[str, str] = {}
+            params: dict[str, str] = {}
             params.update(config.get("params", {}))
             for name, dyn in config.get("dynamic_params", {}).items():
                 params[name] = dynamic[dyn]
             constants[constant] = self.request.route_url(
                 route_name, *config.get("elements", []), _query=params, **config.get("kw", {})
             )
 
         return constants
 
     @view_config(route_name="dynamic", renderer="json")  # type: ignore
-    def dynamic(self) -> Dict[str, Any]:
+    def dynamic(self) -> dict[str, Any]:
         original_interface_name = self.request.params.get("interface")
         interface_name = self.request.get_organization_interface(original_interface_name)
 
         if interface_name not in self.interfaces_config:
             raise HTTPNotFound("Interface {} doesn't exists in the 'interfaces_config'.")
 
         interface_config = self.interfaces_config[interface_name]
         lang_urls_suffix = interface_config.get("lang_urls_suffix", "")
 
         i18next_configuration = self.settings.get("i18next", {})
         i18next_configuration.setdefault("backend", {})
         if "loadPath" not in i18next_configuration["backend"]:
-            path: List[str] = [
+            path: list[str] = [
                 self.request.route_url("base").rstrip("/"),
                 "static-{{ns}}",
                 get_cache_version(),
                 "locales",
                 "{{lng}}.json",
             ]
             i18next_configuration["backend"]["loadPath"] = "/".join(path)
@@ -157,15 +159,15 @@
         }
 
         constants = self._interface(interface_config, interface_name, original_interface_name, dynamic)
 
         do_redirect = False
         url = None
         if "redirect_interface" in interface_config:
-            no_redirect_query: Dict[str, Union[str, List[str]]] = {"no_redirect": "t"}
+            no_redirect_query: dict[str, Union[str, list[str]]] = {"no_redirect": "t"}
             if "query" in self.request.params:
                 query = urllib.parse.parse_qs(self.request.params["query"][1:], keep_blank_values=True)
                 no_redirect_query.update(query)
             else:
                 query = {}
             theme = None
             if "path" in self.request.params:
```

## c2cgeoportal_geoportal/views/entry.py

```diff
@@ -24,16 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import glob
 import logging
-import os
-from typing import Any, Dict, List, Optional
+from typing import Any, Optional
 
 import pyramid.request
 from pyramid.i18n import TranslationStringFactory
 from pyramid.view import view_config
 
 from c2cgeoportal_geoportal.lib.caching import get_region
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
@@ -45,27 +44,27 @@
 
 class Entry:
     """All the entry points views."""
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
 
-    @view_config(route_name="testi18n", renderer="testi18n.html")  # type: ignore
-    def testi18n(self) -> Dict[str, Any]:
+    @view_config(route_name="testi18n", renderer="testi18n.html")  # type: ignore[misc]
+    def testi18n(self) -> dict[str, Any]:
         _ = self.request.translate
         return {"title": _("title i18n")}
 
-    def get_ngeo_index_vars(self) -> Dict[str, Any]:
+    def get_ngeo_index_vars(self) -> dict[str, Any]:
         set_common_headers(self.request, "index", Cache.PUBLIC_NO, content_type="text/html")
         # Force urllogin to be converted to cookie when requesting the main HTML page
         self.request.user  # noqa
         return {}
 
     @staticmethod
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
+    @CACHE_REGION.cache_on_arguments()
     def get_apijs(api_name: Optional[str]) -> str:
         with open("/etc/static-ngeo/api.js", encoding="utf-8") as api_file:
             api = api_file.read().split("\n")
         sourcemap = api.pop(-1)
         if api_name:
             api += [
                 f"if (window.{api_name} === undefined && window.geomapfishapp) {{",
@@ -78,48 +77,41 @@
 
     @view_config(route_name="apijs")  # type: ignore
     def apijs(self) -> pyramid.response.Response:
         self.request.response.text = self.get_apijs(self.request.registry.settings["api"].get("name"))
         set_common_headers(self.request, "api", Cache.PUBLIC, content_type="application/javascript")
         return self.request.response
 
-    def favicon(self) -> Dict[str, Any]:
+    def favicon(self) -> dict[str, Any]:
         set_common_headers(self.request, "index", Cache.PUBLIC, content_type="image/vnd.microsoft.icon")
         return {}
 
-    def robot_txt(self) -> Dict[str, Any]:
+    def robot_txt(self) -> dict[str, Any]:
         set_common_headers(self.request, "index", Cache.PUBLIC, content_type="text/plain")
         return {}
 
-    def apijsmap(self) -> Dict[str, Any]:
+    def apijsmap(self) -> dict[str, Any]:
         set_common_headers(self.request, "api", Cache.PUBLIC, content_type="application/octet-stream")
         return {}
 
-    def apicss(self) -> Dict[str, Any]:
+    def apicss(self) -> dict[str, Any]:
         set_common_headers(self.request, "api", Cache.PUBLIC, content_type="text/css")
         return {}
 
-    def apihelp(self) -> Dict[str, Any]:
+    def apihelp(self) -> dict[str, Any]:
         set_common_headers(self.request, "apihelp", Cache.PUBLIC)
         return {}
 
 
-def _get_ngeo_resources(pattern: str) -> List[str]:
+def _get_ngeo_resources(pattern: str) -> list[str]:
     """Return the list of ngeo dist files matching the pattern."""
-    results = glob.glob(f"/opt/c2cgeoportal/geoportal/node_modules/ngeo/dist/{pattern}")
-    if not results:
-        LOG.error(
-            "No file found for pattern %s, in: [%s]",
-            pattern,
-            ", ".join(os.listdir("/opt/c2cgeoportal/geoportal/node_modules/ngeo/dist/")),
-        )
-    return results
+    return glob.glob(f"/opt/c2cgeoportal/geoportal/node_modules/ngeo/dist/{pattern}")
 
 
-def canvas_view(request: pyramid.request.Request, interface_config: Dict[str, Any]) -> Dict[str, Any]:
+def canvas_view(request: pyramid.request.Request, interface_config: dict[str, Any]) -> dict[str, Any]:
     """Get view used as entry point of a canvas interface."""
 
     js_files = _get_ngeo_resources(f"{interface_config.get('layout', interface_config['name'])}*.js")
     css_files = _get_ngeo_resources(f"{interface_config.get('layout', interface_config['name'])}*.css")
     css = "\n    ".join(
         [
             f'<link href="{request.static_url(css)}" rel="stylesheet" crossorigin="anonymous">'
```

## c2cgeoportal_geoportal/views/fulltextsearch.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,22 +23,21 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import re
-from typing import cast
 
 import pyramid.request
 from geoalchemy2.shape import to_shape
 from geojson import Feature, FeatureCollection
 from pyramid.httpexceptions import HTTPBadRequest, HTTPInternalServerError
 from pyramid.view import view_config
-from sqlalchemy import and_, desc, func, or_
+from sqlalchemy import ColumnElement, and_, desc, func, or_
 
 from c2cgeoportal_commons.models import DBSession
 from c2cgeoportal_commons.models.main import FullTextSearch, Interface
 from c2cgeoportal_geoportal import locale_negotiator
 from c2cgeoportal_geoportal.lib.caching import get_region
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
 from c2cgeoportal_geoportal.lib.fulltextsearch import Normalize
@@ -55,20 +54,24 @@
         self.request = request
         set_common_headers(request, "fulltextsearch", Cache.PUBLIC_NO)
         self.settings = request.registry.settings.get("fulltextsearch", {})
         self.languages = self.settings.get("languages", {})
         self.fts_normalizer = Normalize(self.settings)
 
     @staticmethod
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
+    @CACHE_REGION.cache_on_arguments()
     def _get_interface_id(interface: str) -> int:
-        return cast(int, DBSession.query(Interface).filter_by(name=interface).one().id)
+        assert DBSession is not None
 
-    @view_config(route_name="fulltextsearch", renderer="geojson")  # type: ignore
+        return DBSession.query(Interface).filter_by(name=interface).one().id
+
+    @view_config(route_name="fulltextsearch", renderer="geojson")  # type: ignore[misc]
     def fulltextsearch(self) -> FeatureCollection:
+        assert DBSession is not None
+
         lang = locale_negotiator(self.request)
 
         try:
             language = self.languages[lang]
         except KeyError:
             return HTTPInternalServerError(detail=f"{lang!s} not defined in languages")
 
@@ -90,15 +93,15 @@
             return HTTPBadRequest(detail="partitionlimit value is incorrect")
         partitionlimit = min(partitionlimit, maxlimit)
 
         terms_array = [
             IGNORED_STARTUP_CHARS_RE.sub("", elem) for elem in IGNORED_CHARS_RE.sub(" ", terms).split(" ")
         ]
         terms_ts = "&".join(w + ":*" for w in terms_array if w != "")
-        _filter = FullTextSearch.ts.op("@@")(func.to_tsquery(language, terms_ts))
+        _filter: ColumnElement[bool] = FullTextSearch.ts.op("@@")(func.to_tsquery(language, terms_ts))
 
         if self.request.user is None:
             _filter = and_(_filter, FullTextSearch.public.is_(True))
         else:
             _filter = and_(
                 _filter,
                 or_(
```

## c2cgeoportal_geoportal/views/geometry_processing.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -29,15 +29,15 @@
 from typing import Optional
 
 import pyramid.request
 from geoalchemy2.shape import from_shape, to_shape
 from geojson import loads
 from pyramid.httpexceptions import HTTPBadRequest
 from pyramid.view import view_config
-from shapely.geometry import asShape
+from shapely.geometry import shape
 from shapely.geometry.base import BaseGeometry
 from sqlalchemy import func
 
 from c2cgeoportal_commons.models import DBSession
 
 
 class GeometryProcessing:
@@ -48,14 +48,16 @@
     """
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
 
     @view_config(route_name="difference", renderer="geojson")  # type: ignore
     def difference(self) -> Optional[BaseGeometry]:
+        assert DBSession is not None
+
         body = loads(self.request.body)
         if (
             "geometries" not in body
             or not isinstance(body["geometries"], list)
             or len(body["geometries"]) != 2
         ):
             raise HTTPBadRequest(
@@ -65,11 +67,11 @@
             }
             """
             )
 
         return to_shape(
             DBSession.query(
                 func.ST_Difference(
-                    from_shape(asShape(body["geometries"][0])), from_shape(asShape(body["geometries"][1]))
+                    from_shape(shape(body["geometries"][0])), from_shape(shape(body["geometries"][1]))
                 )
             ).scalar()
         )
```

## c2cgeoportal_geoportal/views/layers.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2022, Camptocamp SA
+# Copyright (c) 2012-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,40 +24,42 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import json
 import logging
 import os
+from collections.abc import Generator
 from datetime import datetime
-from typing import TYPE_CHECKING, Any, Dict, Generator, List, Optional, Set, Tuple, TypedDict, cast
+from typing import TYPE_CHECKING, Any, Optional, TypedDict, cast
 
+import geoalchemy2.elements
 import geojson.geometry
 import pyramid.request
 import pyramid.response
+import shapely.geometry
 import sqlalchemy.ext.declarative
+import sqlalchemy.orm
 from geoalchemy2 import Geometry
-from geoalchemy2 import func as ga_func
 from geoalchemy2.shape import from_shape, to_shape
 from geojson.feature import Feature, FeatureCollection
 from papyrus.protocol import Protocol, create_filter
 from papyrus.xsd import XSDGenerator
 from pyramid.httpexceptions import (
     HTTPBadRequest,
     HTTPException,
     HTTPForbidden,
     HTTPInternalServerError,
     HTTPNotFound,
 )
 from pyramid.view import view_config
-from shapely.geometry import asShape
-from shapely.geos import TopologicalError
-from shapely.ops import cascaded_union
+from shapely import unary_union
+from shapely.errors import TopologicalError
 from sqlalchemy import Enum, Numeric, String, Text, Unicode, UnicodeText, exc, func
-from sqlalchemy.orm.exc import MultipleResultsFound, NoResultFound
+from sqlalchemy.orm.exc import MultipleResultsFound, NoResultFound  # type: ignore[attr-defined]
 from sqlalchemy.orm.properties import ColumnProperty
 from sqlalchemy.orm.util import class_mapper
 from sqlalchemy.sql import and_, or_
 
 from c2cgeoportal_commons import models
 from c2cgeoportal_geoportal.lib import get_roles_id
 from c2cgeoportal_geoportal.lib.caching import get_region
@@ -79,15 +81,15 @@
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
         self.settings = request.registry.settings.get("layers", {})
         self.layers_enum_config = self.settings.get("enum")
 
     @staticmethod
-    def _get_geom_col_info(layer: "main.Layer") -> Tuple[str, int]:
+    def _get_geom_col_info(layer: "main.Layer") -> tuple[str, int]:
         """
         Return information about the layer's geometry column.
 
         Namely a ``(name, srid)`` tuple, where ``name`` is the name of the geometry column,
         and ``srid`` its srid.
 
         This function assumes that the names of geometry attributes in the mapped class are the same as those
@@ -103,14 +105,16 @@
         raise HTTPInternalServerError(f'Failed getting geometry column info for table "{layer.geo_table!s}".')
 
     @staticmethod
     def _get_layer(layer_id: int) -> "main.Layer":
         """Return a ``Layer`` object for ``layer_id``."""
         from c2cgeoportal_commons.models.main import Layer  # pylint: disable=import-outside-toplevel
 
+        assert models.DBSession is not None
+
         layer_id = int(layer_id)
         try:
             query = models.DBSession.query(Layer, Layer.geo_table)
             query = query.filter(Layer.id == layer_id)
             layer, geo_table = query.one()
         except NoResultFound:
             raise HTTPNotFound(f"Layer {layer_id:d} not found") from None
@@ -150,20 +154,23 @@
     def _get_protocol_for_request(self, **kwargs: Any) -> Protocol:
         """Return a papyrus ``Protocol`` for the first layer id found in the ``layer_id`` matchdict."""
         layer = self._get_layer_for_request()
         return self._get_protocol_for_layer(layer, **kwargs)
 
     def _proto_read(self, layer: "main.Layer") -> FeatureCollection:
         """Read features for the layer based on the self.request."""
+
         from c2cgeoportal_commons.models.main import (  # pylint: disable=import-outside-toplevel
             Layer,
             RestrictionArea,
             Role,
         )
 
+        assert models.DBSession is not None
+
         proto = self._get_protocol_for_layer(layer)
         if layer.public:
             return proto.read(self.request)
         user = self.request.user
         if user is None:
             raise HTTPForbidden()
         cls = proto.mapped_class
@@ -180,21 +187,21 @@
                 return proto.read(self.request)
             use_srid = srid
             collect_ra.append(to_shape(ra))
         if not collect_ra:
             raise HTTPForbidden()
 
         filter1_ = create_filter(self.request, cls, geom_attr)
-        ra = cascaded_union(collect_ra)
-        filter2_ = ga_func.ST_Contains(from_shape(ra, use_srid), getattr(cls, geom_attr))
+        ra = unary_union(collect_ra)
+        filter2_ = func.ST_Contains(from_shape(ra, use_srid), getattr(cls, geom_attr))
         filter_ = filter2_ if filter1_ is None else and_(filter1_, filter2_)
 
         feature = proto.read(self.request, filter=filter_)
         if isinstance(feature, HTTPException):
-            raise feature  # pylint: disable=raising-non-exception
+            raise feature
         return feature
 
     @view_config(route_name="layers_read_many", renderer="geojson")  # type: ignore
     def read_many(self) -> FeatureCollection:
         set_common_headers(self.request, "layers", Cache.PRIVATE_NO)
 
         features = []
@@ -209,14 +216,16 @@
     def read_one(self) -> Feature:
         from c2cgeoportal_commons.models.main import (  # pylint: disable=import-outside-toplevel
             Layer,
             RestrictionArea,
             Role,
         )
 
+        assert models.DBSession is not None
+
         set_common_headers(self.request, "layers", Cache.PRIVATE_NO)
 
         layer = self._get_layer_for_request()
         protocol = self._get_protocol_for_layer(layer)
         feature_id = self.request.matchdict.get("feature_id")
         feature = protocol.read(self.request, id=feature_id)
         if not isinstance(feature, Feature):
@@ -224,18 +233,18 @@
         if layer.public:
             return feature
         if self.request.user is None:
             raise HTTPForbidden()
         geom = feature.geometry
         if not geom or isinstance(geom, geojson.geometry.Default):
             return feature
-        shape = asShape(geom)
+        shape = shapely.geometry.shape(geom)
         srid = self._get_geom_col_info(layer)[1]
         spatial_elt = from_shape(shape, srid=srid)
-        allowed = models.DBSession.query(func.count(RestrictionArea.id))
+        allowed = models.DBSession.query(func.count(RestrictionArea.id))  # pylint: disable=not-callable
         allowed = allowed.join(RestrictionArea.roles)
         allowed = allowed.join(RestrictionArea.layers)
         allowed = allowed.filter(Role.id.in_(get_roles_id(self.request)))
         allowed = allowed.filter(Layer.id == layer.id)
         allowed = allowed.filter(
             or_(RestrictionArea.area.is_(None), RestrictionArea.area.ST_Contains(spatial_elt))
         )
@@ -269,20 +278,24 @@
 
         self.request.response.cache_control.no_cache = True
 
         layer = self._get_layer_for_request()
 
         def check_geometry(_: Any, feature: Feature, obj: Any) -> None:
             del obj  # unused
+            assert models.DBSession is not None
+
             geom = feature.geometry
             if geom and not isinstance(geom, geojson.geometry.Default):
-                shape = asShape(geom)
+                shape = shapely.geometry.shape(geom)
                 srid = self._get_geom_col_info(layer)[1]
                 spatial_elt = from_shape(shape, srid=srid)
-                allowed = models.DBSession.query(func.count(RestrictionArea.id))
+                allowed = models.DBSession.query(
+                    func.count(RestrictionArea.id)  # pylint: disable=not-callable
+                )
                 allowed = allowed.join(RestrictionArea.roles)
                 allowed = allowed.join(RestrictionArea.layers)
                 allowed = allowed.filter(RestrictionArea.readwrite.is_(True))
                 allowed = allowed.filter(Role.id.in_(get_roles_id(self.request)))
                 allowed = allowed.filter(Layer.id == layer.id)
                 allowed = allowed.filter(
                     or_(RestrictionArea.area.is_(None), RestrictionArea.area.ST_Contains(spatial_elt))
@@ -294,26 +307,27 @@
                 if self._get_validation_setting(layer):
                     self._validate_geometry(spatial_elt)
 
         protocol = self._get_protocol_for_layer(layer, before_create=check_geometry)
         try:
             features = protocol.create(self.request)
             if isinstance(features, HTTPException):
-                raise features  # pylint: disable=raising-bad-type
+                raise features
             if features is not None:
                 for feature in features.features:  # pylint: disable=no-member
                     self._log_last_update(layer, feature)
             return features
         except TopologicalError as e:
             self.request.response.status_int = 400
             return {"error_type": "validation_error", "message": str(e)}
         except exc.IntegrityError as e:
             LOG.error(str(e))
+            assert e.orig is not None
             self.request.response.status_int = 400
-            return {"error_type": "integrity_error", "message": str(e.orig.diag.message_primary)}
+            return {"error_type": "integrity_error", "message": str(e.orig.diag.message_primary)}  # type: ignore[attr-defined]
 
     @view_config(route_name="layers_update", renderer="geojson")  # type: ignore
     def update(self) -> Feature:
         from c2cgeoportal_commons.models.main import (  # pylint: disable=import-outside-toplevel
             Layer,
             RestrictionArea,
             Role,
@@ -326,31 +340,33 @@
 
         self.request.response.cache_control.no_cache = True
 
         feature_id = self.request.matchdict.get("feature_id")
         layer = self._get_layer_for_request()
 
         def check_geometry(_: Any, feature: Feature, obj: Any) -> None:
+            assert models.DBSession is not None
+
             # we need both the "original" and "new" geometry to be
             # within the restriction area
             geom_attr, srid = self._get_geom_col_info(layer)
             geom_attr = getattr(obj, geom_attr)
             geom = feature.geometry
-            allowed = models.DBSession.query(func.count(RestrictionArea.id))
+            allowed = models.DBSession.query(func.count(RestrictionArea.id))  # pylint: disable=not-callable
             allowed = allowed.join(RestrictionArea.roles)
             allowed = allowed.join(RestrictionArea.layers)
             allowed = allowed.filter(RestrictionArea.readwrite.is_(True))
             allowed = allowed.filter(Role.id.in_(get_roles_id(self.request)))
             allowed = allowed.filter(Layer.id == layer.id)
             allowed = allowed.filter(
                 or_(RestrictionArea.area.is_(None), RestrictionArea.area.ST_Contains(geom_attr))
             )
             spatial_elt = None
             if geom and not isinstance(geom, geojson.geometry.Default):
-                shape = asShape(geom)
+                shape = shapely.geometry.shape(geom)
                 spatial_elt = from_shape(shape, srid=srid)
                 allowed = allowed.filter(
                     or_(RestrictionArea.area.is_(None), RestrictionArea.area.ST_Contains(spatial_elt))
                 )
             if allowed.scalar() == 0:
                 raise HTTPForbidden()
 
@@ -366,19 +382,22 @@
             self._log_last_update(layer, feature)
             return cast(Feature, feature)
         except TopologicalError as e:
             self.request.response.status_int = 400
             return {"error_type": "validation_error", "message": str(e)}
         except exc.IntegrityError as e:
             LOG.error(str(e))
+            assert e.orig is not None
             self.request.response.status_int = 400
-            return {"error_type": "integrity_error", "message": str(e.orig.diag.message_primary)}
+            return {"error_type": "integrity_error", "message": str(e.orig.diag.message_primary)}  # type: ignore[attr-defined]
 
     @staticmethod
-    def _validate_geometry(geom: Geometry) -> None:
+    def _validate_geometry(geom: Optional[geoalchemy2.elements.WKBElement]) -> None:
+        assert models.DBSession is not None
+
         if geom is not None:
             simple = models.DBSession.query(func.ST_IsSimple(func.ST_GeomFromEWKB(geom))).scalar()
             if not simple:
                 raise TopologicalError("Not simple")
             valid = models.DBSession.query(func.ST_IsValid(func.ST_GeomFromEWKB(geom))).scalar()
             if not valid:
                 reason = models.DBSession.query(func.ST_IsValidReason(func.ST_GeomFromEWKB(geom))).scalar()
@@ -394,83 +413,87 @@
             setattr(feature, last_update_user, self.request.user.id)
 
     @staticmethod
     def get_metadata(layer: "main.Layer", key: str, default: Optional[str] = None) -> Optional[str]:
         metadata = layer.get_metadata(key)
         if len(metadata) == 1:
             metadata = metadata[0]
-            return cast(str, metadata.value)
+            return metadata.value
         return default
 
     def _get_validation_setting(self, layer: "main.Layer") -> bool:
         # The validation UIMetadata is stored as a string, not a boolean
         should_validate = self.get_metadata(layer, "geometryValidation", None)
         if should_validate:
             return should_validate.lower() != "false"
         return cast(bool, self.settings.get("geometry_validation", False))
 
     @view_config(route_name="layers_delete")  # type: ignore
     def delete(self) -> pyramid.response.Response:
+        assert models.DBSession is not None
+
         from c2cgeoportal_commons.models.main import (  # pylint: disable=import-outside-toplevel
             Layer,
             RestrictionArea,
             Role,
         )
 
         if self.request.user is None:
             raise HTTPForbidden()
 
         feature_id = self.request.matchdict.get("feature_id")
         layer = self._get_layer_for_request()
 
         def security_cb(_: Any, obj: Any) -> None:
+            assert models.DBSession is not None
+
             geom_attr = getattr(obj, self._get_geom_col_info(layer)[0])
-            allowed = models.DBSession.query(func.count(RestrictionArea.id))
+            allowed = models.DBSession.query(func.count(RestrictionArea.id))  # pylint: disable=not-callable
             allowed = allowed.join(RestrictionArea.roles)
             allowed = allowed.join(RestrictionArea.layers)
             allowed = allowed.filter(RestrictionArea.readwrite.is_(True))
             allowed = allowed.filter(Role.id.in_(get_roles_id(self.request)))
             allowed = allowed.filter(Layer.id == layer.id)
             allowed = allowed.filter(
                 or_(RestrictionArea.area.is_(None), RestrictionArea.area.ST_Contains(geom_attr))
             )
             if allowed.scalar() == 0:
                 raise HTTPForbidden()
 
         protocol = self._get_protocol_for_layer(layer, before_delete=security_cb)
         response = protocol.delete(self.request, feature_id)
         if isinstance(response, HTTPException):
-            raise response  # pylint: disable=raising-non-exception
+            raise response
         set_common_headers(self.request, "layers", Cache.PRIVATE_NO, response=response)
         return response
 
     @view_config(route_name="layers_metadata", renderer="xsd")  # type: ignore
     def metadata(self) -> pyramid.response.Response:
         set_common_headers(self.request, "layers", Cache.PRIVATE)
 
         layer = self._get_layer_for_request()
         if not layer.public and self.request.user is None:
             raise HTTPForbidden()
 
         return get_layer_class(layer, with_last_update_columns=True)
 
     @view_config(route_name="layers_enumerate_attribute_values", renderer="json")  # type: ignore
-    def enumerate_attribute_values(self) -> Dict[str, Any]:
+    def enumerate_attribute_values(self) -> dict[str, Any]:
         set_common_headers(self.request, "layers", Cache.PUBLIC)
 
         if self.layers_enum_config is None:
             raise HTTPInternalServerError("Missing configuration")
         layername = self.request.matchdict["layer_name"]
         fieldname = self.request.matchdict["field_name"]
         # TODO check if layer is public or not
 
-        return cast(Dict[str, Any], self._enumerate_attribute_values(layername, fieldname))
+        return cast(dict[str, Any], self._enumerate_attribute_values(layername, fieldname))
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
-    def _enumerate_attribute_values(self, layername: str, fieldname: str) -> Dict[str, Any]:
+    @CACHE_REGION.cache_on_arguments()
+    def _enumerate_attribute_values(self, layername: str, fieldname: str) -> dict[str, Any]:
         if layername not in self.layers_enum_config:
             raise HTTPBadRequest(f"Unknown layer: {layername!s}")
 
         layerinfos = self.layers_enum_config[layername]
         if fieldname not in layerinfos["attributes"]:
             raise HTTPBadRequest(f"Unknown attribute: {fieldname!s}")
         dbsession_name = layerinfos.get("dbsession", "dbsession")
@@ -481,44 +504,47 @@
             )
         values = sorted(self.query_enumerate_attribute_values(dbsession, layerinfos, fieldname))
         enum = {"items": [{"value": value[0]} for value in values]}
         return enum
 
     @staticmethod
     def query_enumerate_attribute_values(
-        dbsession: sqlalchemy.orm.Session, layerinfos: Dict[str, Any], fieldname: str
-    ) -> Set[Tuple[str, ...]]:
+        dbsession: sqlalchemy.orm.scoped_session[sqlalchemy.orm.Session],
+        layerinfos: dict[str, Any],
+        fieldname: str,
+    ) -> set[tuple[str, ...]]:
         attrinfos = layerinfos["attributes"][fieldname]
         table = attrinfos["table"]
-        layertable = get_table(table, session=dbsession)
+        layertable = get_table(table, session=dbsession())
         column = attrinfos.get("column_name", fieldname)
         attribute = getattr(layertable.columns, column)
         # For instance if `separator` is a "," we consider that the column contains a
         # comma separate list of values e.g.: "value1,value2".
         if "separator" in attrinfos:
             separator = attrinfos["separator"]
             attribute = func.unnest(func.string_to_array(func.string_agg(attribute, separator), separator))
-        return set(cast(List[Tuple[str, ...]], dbsession.query(attribute).order_by(attribute).all()))
+        return set(cast(list[tuple[str, ...]], dbsession.query(attribute).order_by(attribute).all()))
 
 
-def get_layer_class(
-    layer: "main.Layer", with_last_update_columns: bool = False
-) -> sqlalchemy.ext.declarative.ConcreteBase:
+def get_layer_class(layer: "main.Layer", with_last_update_columns: bool = False) -> type:
     """
     Get the SQLAlchemy class to edit a GeoMapFish layer.
 
-    Arguments:
+    Keyword Arguments:
 
         layer: The GeoMapFish layer
         with_last_update_columns: False to just have a class to access to the table and be able to
            modify the last_update_columns, True to have a correct class to build the UI
            (without the hidden column).
 
     Returns: SQLAlchemy class
     """
+
+    assert layer.geo_table is not None
+
     # Exclude the columns used to record the last features update
     exclude = [] if layer.exclude_properties is None else layer.exclude_properties.split(",")
     if with_last_update_columns:
         last_update_date = Layers.get_metadata(layer, "lastUpdateDateColumn")
         if last_update_date is not None:
             exclude.append(last_update_date)
         last_update_user = Layers.get_metadata(layer, "lastUpdateUserColumn")
@@ -556,39 +582,41 @@
                 table.schema,
                 table.name,
                 layer.name,
                 layer.id,
                 ", ".join(column_properties),
             )
 
-    return cls
+    return cast(type, cls)
 
 
 class ColumnProperties(TypedDict, total=False):
     """Collected metadata information related to an editing attribute."""
 
     name: str
     type: str
     nillable: bool
     srid: int
-    enumeration: List[str]
+    enumeration: list[str]
     restriction: str
     maxLength: int  # noqa
     fractionDigits: int  # noqa
     totalDigits: int  # noqa
 
 
-def get_layer_metadata(layer: "main.Layer") -> List[ColumnProperties]:
+def get_layer_metadata(layer: "main.Layer") -> list[ColumnProperties]:
     """Get the metadata related to a layer."""
+
+    assert models.DBSession is not None
+
     cls = get_layer_class(layer, with_last_update_columns=True)
-    edit_columns: List[ColumnProperties] = []
+    edit_columns: list[ColumnProperties] = []
 
     for column_property in class_mapper(cls).iterate_properties:
         if isinstance(column_property, ColumnProperty):
-
             if len(column_property.columns) != 1:
                 raise NotImplementedError
 
             column = column_property.columns[0]
 
             # Exclude columns that are primary keys
             if not column.primary_key:
@@ -610,15 +638,15 @@
                 if column.nullable:
                     properties["nillable"] = True
 
                 properties["name"] = k
                 properties["restriction"] = "enumeration"
                 properties["type"] = "xsd:string"
                 properties["enumeration"] = []
-                for value in query:
+                for value in query:  # pylint: disable=not-an-iterable
                     properties["enumeration"].append(value[0])
 
                 edit_columns.append(properties)
     return edit_columns
 
 
 def _convert_column_type(column_type: object) -> ColumnProperties:
```

## c2cgeoportal_geoportal/views/login.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2022, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -25,37 +25,38 @@
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import json
 import logging
 import secrets
+import string
 import sys
 import urllib.parse
-from typing import Any, Dict, List, Optional, Tuple, Union
+from typing import Any, Optional, Union
 
 import pyotp
 import pyramid.request
 import pyramid.response
 from pyramid.httpexceptions import (
     HTTPBadRequest,
     HTTPForbidden,
     HTTPFound,
     HTTPUnauthorized,
     exception_response,
 )
 from pyramid.response import Response
 from pyramid.security import forget, remember
 from pyramid.view import forbidden_view_config, view_config
-from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.orm.exc import NoResultFound  # type: ignore[attr-defined]
 
 from c2cgeoportal_commons import models
 from c2cgeoportal_commons.lib.email_ import send_email_config
 from c2cgeoportal_commons.models import static
-from c2cgeoportal_geoportal import is_valid_referrer
+from c2cgeoportal_geoportal import is_allowed_url, is_valid_referrer
 from c2cgeoportal_geoportal.lib import get_setting, is_intranet, oauth2
 from c2cgeoportal_geoportal.lib.caching import get_region
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
 from c2cgeoportal_geoportal.lib.functionality import get_functionality
 
 LOG = logging.getLogger(__name__)
 CACHE_REGION = get_region("std")
@@ -74,43 +75,43 @@
         self.lang = request.locale_name
 
         authentication_settings = self.settings.get("authentication", {})
 
         self.two_factor_auth = authentication_settings.get("two_factor", False)
         self.two_factor_issuer_name = authentication_settings.get("two_factor_issuer_name")
 
-    def _functionality(self) -> Dict[str, List[Union[str, int, float, bool, List[Any], Dict[str, Any]]]]:
+    def _functionality(self) -> dict[str, list[Union[str, int, float, bool, list[Any], dict[str, Any]]]]:
         functionality = {}
         for func_ in get_setting(self.settings, ("functionalities", "available_in_templates"), []):
             functionality[func_] = get_functionality(func_, self.request, is_intranet(self.request))
         return functionality
 
     def _referer_log(self) -> None:
         if not hasattr(self.request, "is_valid_referer"):
             self.request.is_valid_referer = is_valid_referrer(self.request)
         if not self.request.is_valid_referer:
-            LOG.info("Invalid referer for %s: %s", self.request.path_qs, repr(self.request.referer))
+            LOG.info("Invalid referrer for %s: %s", self.request.path_qs, repr(self.request.referrer))
 
     @forbidden_view_config(renderer="login.html")  # type: ignore
-    def loginform403(self) -> Union[Dict[str, Any], pyramid.response.Response]:
+    def loginform403(self) -> Union[dict[str, Any], pyramid.response.Response]:
         if self.request.authenticated_userid is not None:
             return HTTPForbidden()
 
         set_common_headers(self.request, "login", Cache.PRIVATE_NO)
 
         return {
             "lang": self.lang,
             "login_params": {
                 "came_from": (f"{self.request.path}?{urllib.parse.urlencode(self.request.GET)}")
             },
             "two_fa": self.two_factor_auth,
         }
 
     @view_config(route_name="loginform", renderer="login.html")  # type: ignore
-    def loginform(self) -> Dict[str, Any]:
+    def loginform(self) -> dict[str, Any]:
         set_common_headers(self.request, "login", Cache.PUBLIC)
 
         return {
             "lang": self.lang,
             "login_params": {"came_from": self.request.params.get("came_from") or "/"},
             "two_fa": self.two_factor_auth,
         }
@@ -119,21 +120,24 @@
     def _validate_2fa_totp(user: static.User, otp: str) -> bool:
         if pyotp.TOTP(user.tech_data.get("2fa_totp_secret", "")).verify(otp):
             return True
         return False
 
     @view_config(route_name="login")  # type: ignore
     def login(self) -> pyramid.response.Response:
+        assert models.DBSession is not None
+
         self._referer_log()
 
         login = self.request.POST.get("login")
         password = self.request.POST.get("password")
         if login is None or password is None:
             raise HTTPBadRequest("'login' and 'password' should be available in request params.")
         username = self.request.registry.validate_user(self.request, login, password)
+        user: Optional[static.User]
         if username is not None:
             user = models.DBSession.query(static.User).filter(static.User.username == username).one()
             if self.two_factor_auth:
                 if "2fa_totp_secret" not in user.tech_data:
                     user.is_password_changed = False
                 if not user.is_password_changed:
                     user.tech_data["2fa_totp_secret"] = pyotp.random_base32()
@@ -187,17 +191,30 @@
                 )
 
             LOG.info("User '%s' logged in.", username)
             if self.request.GET.get("type") == "oauth2":
                 self._oauth2_login(user)
 
             headers = remember(self.request, username)
+
             came_from = self.request.params.get("came_from")
             if came_from:
+                if not came_from.startswith("/"):
+                    allowed_hosts = self.request.registry.settings.get("authorized_referers", [])
+                    came_from_hostname, ok = is_allowed_url(self.request, came_from, allowed_hosts)
+                    if not ok:
+                        message = (
+                            f"Invalid hostname '{came_from_hostname}' in 'came_from' parameter, "
+                            f"is not the current host '{self.request.host}' "
+                            f"or part of allowed hosts: {', '.join(allowed_hosts)}"
+                        )
+                        LOG.debug(message)
+                        return HTTPBadRequest(message)
                 return HTTPFound(location=came_from, headers=headers)
+
             headers.append(("Content-Type", "text/json"))
             return set_common_headers(
                 self.request,
                 "login",
                 Cache.PRIVATE_NO,
                 response=Response(json.dumps(self._user(self.request.get_user(username))), headers=headers),
             )
@@ -232,16 +249,29 @@
             self.request.body,
             self.request.headers,
         )
         if hasattr(self.request, "tm"):
             self.request.tm.commit()
         LOG.debug("OAuth create_authorization_response return\nstatus: %s\nbody:\n%s", status, body)
 
+        location = headers.get("Location")
+        location_hostname = urllib.parse.urlparse(location).hostname
+        allowed_hosts = self.request.registry.settings.get("allowed_hosts", [])
+        location_hostname, ok = is_allowed_url(self.request, location, allowed_hosts)
+        if not ok:
+            message = (
+                f"Invalid location hostname '{location_hostname}', "
+                f"is not the current host '{self.request.host}' "
+                f"or part of allowed_hosts: {', '.join(allowed_hosts)}"
+            )
+            LOG.debug(message)
+            return HTTPBadRequest(message)
+
         if status == 302:
-            raise HTTPFound(location=headers["Location"])
+            raise HTTPFound(location=location)
         if status != 200:
             if body:
                 raise exception_response(status, details=body)
             raise exception_response(status)
         return set_common_headers(
             self.request,
             "login",
@@ -260,15 +290,15 @@
         LOG.info("User '%s' (%s) logging out.", self.request.user.username, self.request.user.id)
 
         headers.append(("Content-Type", "text/json"))
         return set_common_headers(
             self.request, "login", Cache.PRIVATE_NO, response=Response("true", headers=headers)
         )
 
-    def _user(self, user: Optional[static.User] = None) -> Dict[str, Any]:
+    def _user(self, user: Optional[static.User] = None) -> dict[str, Any]:
         result = {
             "functionalities": self._functionality(),
             "is_intranet": is_intranet(self.request),
             "two_factor_enable": self.two_factor_auth,
         }
         user = self.request.user if user is None else user
         if user is not None:
@@ -278,21 +308,23 @@
                     "email": user.email,
                     "roles": [{"name": r.name, "id": r.id} for r in user.roles],
                 }
             )
         return result
 
     @view_config(route_name="loginuser", renderer="json")  # type: ignore
-    def loginuser(self) -> Dict[str, Any]:
+    def loginuser(self) -> dict[str, Any]:
         LOG.info("Client IP address: %s", self.request.client_addr)
         set_common_headers(self.request, "login", Cache.PRIVATE_NO)
         return self._user()
 
     @view_config(route_name="change_password", renderer="json")  # type: ignore
     def change_password(self) -> pyramid.response.Response:
+        assert models.DBSession is not None
+
         set_common_headers(self.request, "login", Cache.PRIVATE_NO)
 
         login = self.request.POST.get("login")
         old_password = self.request.POST.get("oldPassword")
         new_password = self.request.POST.get("newPassword")
         new_password_confirm = self.request.POST.get("confirmNewPassword")
         otp = self.request.POST.get("otp")
@@ -317,14 +349,15 @@
             if self.two_factor_auth:
                 if not self._validate_2fa_totp(user, otp):
                     LOG.info("The second factor is wrong for user '%s'.", login)
                     raise HTTPUnauthorized("See server logs for details")
         else:
             user = self.request.user
 
+        assert user is not None
         if self.request.registry.validate_user(self.request, user.username, old_password) is None:
             LOG.info("The old password is wrong for user '%s'.", user.username)
             raise HTTPUnauthorized("See server logs for details")
 
         user.password = new_password
         user.is_password_changed = True
         models.DBSession.flush()
@@ -337,25 +370,28 @@
             "login",
             Cache.PRIVATE_NO,
             response=Response(json.dumps(self._user(user)), headers=headers),
         )
 
     @staticmethod
     def generate_password() -> str:
-        all_chars = "123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
-
-        password = ""  # nosec
-        for _ in range(8):
-            password += secrets.choice(all_chars)
-
-        return password
+        allchars = "".join(
+            [
+                string.ascii_letters * 2,
+                string.digits * 2,
+                string.punctuation,  # One time to have less punctuation char
+            ]
+        )
+        return "".join(secrets.choice(allchars) for i in range(8))
 
     def _loginresetpassword(
         self,
-    ) -> Tuple[Optional[static.User], Optional[str], Optional[str], Optional[str]]:
+    ) -> tuple[Optional[static.User], Optional[str], Optional[str], Optional[str]]:
+        assert models.DBSession is not None
+
         username = self.request.POST.get("login")
         if username is None:
             raise HTTPBadRequest("'login' should be available in request params.")
         try:
             user = models.DBSession.query(static.User).filter(static.User.username == username).one()
         except NoResultFound:
             return None, None, None, f"The login '{username}' does not exist."
@@ -365,15 +401,15 @@
 
         password = self.generate_password()
         user.set_temp_password(password)
 
         return user, username, password, None
 
     @view_config(route_name="loginresetpassword", renderer="json")  # type: ignore
-    def loginresetpassword(self) -> Dict[str, Any]:
+    def loginresetpassword(self) -> dict[str, Any]:
         set_common_headers(self.request, "login", Cache.PRIVATE_NO)
 
         user, username, password, error = self._loginresetpassword()
         if error is not None:
             LOG.info(error)
             return {"success": True}
 
@@ -393,14 +429,44 @@
             password=password,
             application_url=self.request.route_url("base"),
             current_url=self.request.current_route_url(),
         )
 
         return {"success": True}
 
+    @view_config(route_name="oauth2introspect")  # type: ignore
+    def oauth2introspect(self) -> pyramid.response.Response:
+        LOG.debug(
+            "Call OAuth create_introspect_response with:\nurl: %s\nmethod: %s\nbody:\n%s",
+            self.request.current_route_url(_query=self.request.GET),
+            self.request.method,
+            self.request.body,
+        )
+        headers, body, status = oauth2.get_oauth_client(
+            self.request.registry.settings
+        ).create_introspect_response(
+            self.request.current_route_url(_query=self.request.GET),
+            self.request.method,
+            self.request.body,
+            self.request.headers,
+        )
+        LOG.debug("OAuth create_introspect_response return status: %s", status)
+
+        # All requests to /token will return a json response, no redirection.
+        if status != 200:
+            if body:
+                raise exception_response(status, detail=body)
+            raise exception_response(status)
+        return set_common_headers(
+            self.request,
+            "login",
+            Cache.PRIVATE_NO,
+            response=Response(body, headers=headers.items()),
+        )
+
     @view_config(route_name="oauth2token")  # type: ignore
     def oauth2token(self) -> pyramid.response.Response:
         LOG.debug(
             "Call OAuth create_token_response with:\nurl: %s\nmethod: %s\nbody:\n%s",
             self.request.current_route_url(_query=self.request.GET),
             self.request.method,
             self.request.body,
@@ -410,42 +476,66 @@
             self.request.method,
             self.request.body,
             self.request.headers,
             {},
         )
         LOG.debug("OAuth create_token_response return status: %s", status)
 
-        if hasattr(self.request, "tm"):
-            self.request.tm.commit()
-
         # All requests to /token will return a json response, no redirection.
         if status != 200:
             if body:
                 raise exception_response(status, detail=body)
             raise exception_response(status)
         return set_common_headers(
             self.request,
             "login",
             Cache.PRIVATE_NO,
             response=Response(body, headers=headers.items()),
         )
 
+    @view_config(route_name="oauth2revoke_token")  # type: ignore
+    def oauth2revoke_token(self) -> pyramid.response.Response:
+        LOG.debug(
+            "Call OAuth create_revocation_response with:\nurl: %s\nmethod: %s\nbody:\n%s",
+            self.request.create_revocation_response(_query=self.request.GET),
+            self.request.method,
+            self.request.body,
+        )
+        headers, body, status = oauth2.get_oauth_client(
+            self.request.registry.settings
+        ).create_authorize_response(
+            self.request.current_route_url(_query=self.request.GET),
+            self.request.method,
+            self.request.body,
+            self.request.headers,
+        )
+        if status != 200:
+            if body:
+                raise exception_response(status, detail=body)
+            raise exception_response(status)
+        return set_common_headers(
+            self.request,
+            "login",
+            Cache.PRIVATE_NO,
+            response=Response(body, headers=headers.items()),
+        )
+
     @view_config(route_name="oauth2loginform", renderer="login.html")  # type: ignore
-    def oauth2loginform(self) -> Dict[str, Any]:
+    def oauth2loginform(self) -> dict[str, Any]:
         set_common_headers(self.request, "login", Cache.PUBLIC)
 
         if self.request.user:
             self._oauth2_login(self.request.user)
 
         login_param = {"type": "oauth2"}
         login_param.update(self.request.params)
         return {
             "lang": self.lang,
             "login_params": login_param,
             "two_fa": self.two_factor_auth,
         }
 
     @view_config(route_name="notlogin", renderer="notlogin.html")  # type: ignore
-    def notlogin(self) -> Dict[str, Any]:
+    def notlogin(self) -> dict[str, Any]:
         set_common_headers(self.request, "login", Cache.PUBLIC)
 
         return {"lang": self.lang}
```

## c2cgeoportal_geoportal/views/mapserverproxy.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,17 +23,17 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
-from typing import Any, Dict, Set
+from typing import Any
 
-from pyramid.httpexceptions import HTTPFound, HTTPInternalServerError, HTTPUnauthorized
+from pyramid.httpexceptions import HTTPForbidden, HTTPFound, HTTPInternalServerError, HTTPUnauthorized
 from pyramid.request import Request
 from pyramid.response import Response
 from pyramid.view import view_config
 
 from c2cgeoportal_commons.lib.url import Url
 from c2cgeoportal_commons.models import main
 from c2cgeoportal_geoportal.lib import get_roles_id, get_roles_name
@@ -46,15 +46,15 @@
 CACHE_REGION = get_region("std")
 LOG = logging.getLogger(__name__)
 
 
 class MapservProxy(OGCProxy):
     """Proxy for OGC (WMS/WFS) servers."""
 
-    params: Dict[str, str] = {}
+    params: dict[str, str] = {}
 
     def __init__(self, request: Request) -> None:
         OGCProxy.__init__(self, request)
         self.user = self.request.user
 
     @view_config(route_name="mapserverproxy")  # type: ignore
     @view_config(route_name="mapserverproxy_post")  # type: ignore
@@ -63,15 +63,15 @@
     def proxy(self) -> Response:
         if self.user is None and "authentication_required" in self.request.params:
             LOG.debug("proxy() detected authentication_required")
             if self.request.registry.settings.get("basicauth", "False").lower() == "true":
                 raise HTTPUnauthorized(
                     headers={"WWW-Authenticate": 'Basic realm="Access to restricted layers"'}
                 )
-            raise HTTPUnauthorized(headers={"WWW-Authenticate": 'Bearer realm="Access to restricted layers"'})
+            raise HTTPForbidden("Basic auth is not enabled")
 
         # We have a user logged in. We need to set group_id and possible layer_name in the params. We set
         # layer_name when either QUERY_PARAMS or LAYERS is set in the WMS params, i.e. for GetMap and
         # GetFeatureInfo requests. For GetLegendGraphic requests we do not send layer_name, but MapServer
         # should not use the DATA string for GetLegendGraphic.
 
         if self.ogc_server.auth == main.OGCSERVER_AUTH_STANDARD:
@@ -96,23 +96,22 @@
         # Get method
         method = self.request.method
 
         # we want the browser to cache GetLegendGraphic and
         # DescribeFeatureType requests
         use_cache = False
 
-        errors: Set[str] = set()
+        errors: set[str] = set()
         if method == "GET":
             # For GET requests, params are added only if the self.request
             # parameter is actually provided.
             if "request" not in self.lower_params:
                 self.params = {}
             else:
                 if self.ogc_server.type != main.OGCSERVER_TYPE_QGISSERVER or "user_id" not in self.params:
-
                     use_cache = self.lower_params["request"] in ("getlegendgraphic",)
 
                     # no user_id and role_id or cached queries
                     if use_cache and "user_id" in self.params:
                         del self.params["user_id"]
                     if use_cache and "role_ids" in self.params:
                         del self.params["role_ids"]
@@ -163,15 +162,15 @@
             and response.status_code < 400
         ):
             response.status_code = 400
 
         return response
 
     def _proxy_callback(
-        self, cache_control: Cache, url: Url, params: Dict[str, str], **kwargs: Any
+        self, cache_control: Cache, url: Url, params: dict[str, str], **kwargs: Any
     ) -> Response:
         if self.request.matched_route.name.endswith("_path"):
             if self.request.matchdict["path"] == ("favicon.ico",):
                 return HTTPFound("/favicon.ico")
             url = url.clone()
             url.path = self.request.path
```

## c2cgeoportal_geoportal/views/memory.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2021, Camptocamp SA
+# Copyright (c) 2018-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,44 +24,44 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
 import time
-from typing import Any, Dict, cast
+from typing import Any, cast
 
 import pyramid.request
 from c2cwsgiutils import broadcast
 from c2cwsgiutils.auth import auth_view
 from c2cwsgiutils.debug import get_size
 from pyramid.view import view_config
 
 from c2cgeoportal_geoportal.lib.caching import MEMORY_CACHE_DICT
 from c2cgeoportal_geoportal.views import raster
 
 LOG = logging.getLogger(__name__)
 
 
 @view_config(route_name="memory", renderer="fast_json")  # type: ignore
-def memory(request: pyramid.request.Request) -> Dict[str, Any]:
+def memory(request: pyramid.request.Request) -> dict[str, Any]:
     """Offer an authenticated view throw c2cwsgiutils to provide some memory information."""
     auth_view(request)
-    return cast(Dict[str, Any], _memory())
+    return cast(dict[str, Any], _memory())
 
 
 def _nice_type_name(obj: Any, dogpile_cache: bool = False) -> str:
     # See: https://dogpilecache.sqlalchemy.org/en/latest/api.html#dogpile.cache.api.CachedValue
     if dogpile_cache:
         obj, _ = obj
     type_ = type(obj)
     return f"{type_.__module__}.{type_.__name__}"
 
 
-def _process_dict(dict_: Dict[str, Any], dogpile_cache: bool = False) -> Dict[str, Any]:
+def _process_dict(dict_: dict[str, Any], dogpile_cache: bool = False) -> dict[str, Any]:
     # Timeout after one minute, must be set to a bit less that the timeout of the broadcast
     timeout = time.monotonic() + 20
 
     return {
         "elements": sorted(
             (
                 {
@@ -78,12 +78,12 @@
         "id": id(dict_),
         "size_kb": get_size(dict_) / 1024 if time.monotonic() < timeout else -1,
         "timeout": time.monotonic() > timeout,
     }
 
 
 @broadcast.decorator(expect_answers=True, timeout=110)
-def _memory() -> Dict[str, Any]:
+def _memory() -> dict[str, Any]:
     return {
         "raster_data": _process_dict(raster.Raster.data),
         "memory_cache": _process_dict(MEMORY_CACHE_DICT, True),
     }
```

## c2cgeoportal_geoportal/views/ogcproxy.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2022, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -22,19 +22,19 @@
 # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import logging
-from typing import Dict, Optional, Set, cast
+from typing import Optional
 
 import pyramid.request
 from pyramid.httpexceptions import HTTPBadRequest
-from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.orm.exc import NoResultFound  # type: ignore[attr-defined]
 
 from c2cgeoportal_commons.lib.url import Url, get_url2
 from c2cgeoportal_commons.models import DBSession, main
 from c2cgeoportal_geoportal.lib.caching import get_region
 from c2cgeoportal_geoportal.views.proxy import Proxy
 
 CACHE_REGION = get_region("std")
@@ -56,59 +56,65 @@
 
         # reset possible value of role_id and user_id
         if "role_id" in self.params:
             del self.params["role_id"]
         if "user_id" in self.params:
             del self.params["user_id"]
 
+        main_ogc_server = self.request.registry.settings.get("main_ogc_server")
+
         self.lower_params = self._get_lower_params(self.params)
 
         # We need original case for OGCSERVER parameter value
         self.lower_key_params = {k.lower(): v for k, v in self.params.items()}
 
         if "ogcserver" in request.matchdict:
             self.ogc_server = self._get_ogcserver_byname(request.matchdict["ogcserver"])
         elif "ogcserver" in self.lower_key_params:
             self.ogc_server = self._get_ogcserver_byname(self.lower_key_params["ogcserver"])
+        elif main_ogc_server is not None:
+            self.ogc_server = self._get_ogcserver_byname(main_ogc_server)
         elif not has_default_ogc_server:
             raise HTTPBadRequest("The querystring argument 'ogcserver' is required")
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
-    def _get_ogcserver_byname(self, name: str) -> main.OGCServer:  # pylint: disable=no-self-use
+    @CACHE_REGION.cache_on_arguments()
+    def _get_ogcserver_byname(self, name: str) -> main.OGCServer:
+        assert DBSession is not None
+
         try:
             result = DBSession.query(main.OGCServer).filter(main.OGCServer.name == name).one()
             DBSession.expunge(result)
-            return cast(main.OGCServer, result)
+            return result
         except NoResultFound:
             raise HTTPBadRequest(  # pylint: disable=raise-missing-from
                 f"The OGC Server '{name}' does not exist (existing: "
                 f"{','.join([t[0] for t in DBSession.query(main.OGCServer.name).all()])})."
             )
 
-    def _get_wms_url(self, errors: Set[str]) -> Optional[Url]:
+    def _get_wms_url(self, errors: set[str]) -> Optional[Url]:
         ogc_server = self.ogc_server
         url = get_url2(f"The OGC server '{ogc_server.name}'", ogc_server.url, self.request, errors)
         if errors:
             LOG.error("\n".join(errors))
         return url
 
-    def _get_wfs_url(self, errors: Set[str]) -> Optional[Url]:
+    def _get_wfs_url(self, errors: set[str]) -> Optional[Url]:
         ogc_server = self.ogc_server
         url = get_url2(
             f"The OGC server (WFS) '{ogc_server.name}'",
             ogc_server.url_wfs or ogc_server.url,
             self.request,
             errors,
         )
         if errors:
             LOG.error("\n".join(errors))
         return url
 
-    def get_headers(self) -> Dict[str, str]:
-        headers: Dict[str, str] = super().get_headers()
+    def get_headers(self) -> dict[str, str]:
+        headers: dict[str, str] = super().get_headers()
         if self.ogc_server.type == main.OGCSERVER_TYPE_QGISSERVER:
             if self.request.matched_route.name.endswith("_path"):
                 headers["X-Qgis-Service-Url"] = self.request.current_route_url(path=[], _query={})
             else:
                 headers["X-Qgis-Service-Url"] = self.request.current_route_url(
                     _query={"ogcserver": self.ogc_server.name}
                 )
```

## c2cgeoportal_geoportal/views/pdfreport.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,15 +23,15 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import logging
 from json import dumps, loads
-from typing import Any, Dict, List, Union
+from typing import Any, Union
 
 import pyramid.request
 import pyramid.response
 from pyramid.httpexceptions import HTTPBadRequest, HTTPForbidden
 from pyramid.view import view_config
 
 from c2cgeoportal_commons import models
@@ -49,31 +49,31 @@
 
     layername = None
 
     def __init__(self, request: pyramid.request.Request):
         OGCProxy.__init__(self, request)
         self.config = self.request.registry.settings.get("pdfreport", {})
 
-    def _do_print(self, spec: Dict[str, Any]) -> pyramid.response.Response:
+    def _do_print(self, spec: dict[str, Any]) -> pyramid.response.Response:
         """Create and get report PDF."""
         headers = dict(self.request.headers)
         headers["Content-Type"] = "application/json"
         response = self._proxy(
             Url(f"{self.config['print_url']}/buildreport.{spec['outputFormat']}"),
             method="POST",
             body=dumps(spec).encode("utf-8"),
             headers=headers,
         )
 
         return self._build_response(response, response.content, Cache.PRIVATE_NO, "pdfreport")
 
     @staticmethod
     def _build_map(
-        mapserv_url: str, vector_request_url: str, srs: str, map_config: Dict[str, Any]
-    ) -> Dict[str, Any]:
+        mapserv_url: str, vector_request_url: str, srs: str, map_config: dict[str, Any]
+    ) -> dict[str, Any]:
         backgroundlayers = map_config["backgroundlayers"]
         imageformat = map_config["imageformat"]
         return {
             "projection": srs,
             "dpi": 254,
             "rotation": 0,
             "bbox": [0, 0, 1000000, 1000000],
@@ -99,14 +99,16 @@
                     "imageFormat": imageformat,
                 },
             ],
         }
 
     @view_config(route_name="pdfreport", renderer="json")  # type: ignore
     def get_report(self) -> pyramid.response.Response:
+        assert models.DBSession is not None
+
         self.layername = self.request.matchdict["layername"]
         layer_config = self.config["layers"].get(self.layername)
 
         multiple = layer_config.get("multiple", False)
         ids = self.request.matchdict["ids"]
         if multiple:
             ids = ids.split(",")
@@ -221,15 +223,15 @@
                         "mapserv_url": mapserv_url,
                         "vector_request_url": vector_request_url,
                     }
                 )
 
         return self._do_print(spec)
 
-    def walker(self, spec: Union[Dict[str, Any], List[Dict[str, Any]]], name: str, value: Any) -> None:
+    def walker(self, spec: Union[dict[str, Any], list[dict[str, Any]]], name: str, value: Any) -> None:
         if isinstance(spec, dict):
             for k, v in spec.items():
                 if isinstance(v, str):
                     if v == name:
                         spec[k] = value
                 else:
                     self.walker(v, name, value)
```

## c2cgeoportal_geoportal/views/printproxy.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -25,15 +25,14 @@
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import json
 import logging
 import urllib.parse
-from typing import Dict, List, Tuple
 
 import pyramid.request
 import pyramid.response
 import requests
 from pyramid.httpexceptions import HTTPBadGateway, HTTPFound
 from pyramid.view import view_config
 
@@ -64,22 +63,22 @@
         query_string = urllib.parse.urlencode(params)
 
         resp, content = self._capabilities(
             templates, query_string, self.request.method, self.request.referrer
         )
 
         response = self._build_response(resp, content, Cache.PRIVATE, "print")
-        # Mapfish print will check the referer header to return the capabilities.
-        response.vary += ("Referer",)
+        # Mapfish print will check the referrer header to return the capabilities.
+        response.vary += ("Referrer", "Referer")
         return response
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
+    @CACHE_REGION.cache_on_arguments()
     def _capabilities(
-        self, templates: List[str], query_string: Dict[str, str], method: str, referrer: str
-    ) -> Tuple[requests.Response, str]:
+        self, templates: list[str], query_string: dict[str, str], method: str, referrer: str
+    ) -> tuple[requests.Response, str]:
         del query_string  # Just for caching
         del method  # Just for caching
         del referrer  # Just for caching
         # get URL
         _url = self.request.get_organization_print_url() + "/capabilities.json"
 
         response = self._proxy(Url(_url))
```

## c2cgeoportal_geoportal/views/profile.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2021, Camptocamp SA
+# Copyright (c) 2012-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -24,15 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import math
 from decimal import Decimal
-from typing import Any, Dict, List, Tuple
+from typing import Any
 
 import geojson
 import pyramid.request
 from pyramid.httpexceptions import HTTPNotFound
 from pyramid.i18n import TranslationStringFactory
 from pyramid.view import view_config
 
@@ -45,39 +45,39 @@
 class Profile(Raster):
     """All the view concerned the profile."""
 
     def __init__(self, request: pyramid.request.Request):
         Raster.__init__(self, request)
 
     @view_config(route_name="profile.json", renderer="fast_json")  # type: ignore
-    def json(self) -> Dict[str, Any]:
+    def json(self) -> dict[str, Any]:
         """Answer to /profile.json."""
         _, points = self._compute_points()
         set_common_headers(self.request, "profile", Cache.PUBLIC_NO)
         return {"profile": points}
 
-    def _compute_points(self) -> Tuple[List[str], List[Dict[str, Any]]]:
+    def _compute_points(self) -> tuple[list[str], list[dict[str, Any]]]:
         """Compute the alt=fct(dist) array."""
         geom = geojson.loads(self.request.params["geom"], object_hook=geojson.GeoJSON.to_instance)
 
-        layers: List[str]
+        layers: list[str]
         if "layers" in self.request.params:
             rasters = {}
             layers = self.request.params["layers"].split(",")
             for layer in layers:
                 if layer in self.rasters:
                     rasters[layer] = self.rasters[layer]
                 else:
                     raise HTTPNotFound(f"Layer {layer!s} not found")
         else:
             rasters = self.rasters
             layers = list(rasters.keys())
             layers.sort()
 
-        points: List[Dict[str, Any]] = []
+        points: list[dict[str, Any]] = []
 
         dist = 0
         prev_coord = None
         coords = self._create_points(geom.coordinates, int(self.request.params["nbPoints"]))
         for coord in coords:
             if prev_coord is not None:
                 dist += self._dist(prev_coord, coord)
@@ -91,31 +91,31 @@
             rounded_dist = Decimal(str(dist)).quantize(Decimal("0.1"))
             points.append({"dist": rounded_dist, "values": values, "x": coord[0], "y": coord[1]})
             prev_coord = coord
 
         return layers, points
 
     @staticmethod
-    def _dist(coord1: Tuple[float, float], coord2: Tuple[float, float]) -> float:
+    def _dist(coord1: tuple[float, float], coord2: tuple[float, float]) -> float:
         """Compute the distance between 2 points."""
         return math.sqrt(math.pow(coord1[0] - coord2[0], 2.0) + math.pow(coord1[1] - coord2[1], 2.0))
 
-    def _create_points(self, coords: List[Tuple[float, float]], nb_points: int) -> List[Tuple[float, float]]:
+    def _create_points(self, coords: list[tuple[float, float]], nb_points: int) -> list[tuple[float, float]]:
         """Add some points in order to reach roughly the asked number of points."""
         total_length = 0
         prev_coord = None
         for coord in coords:
             if prev_coord is not None:
                 total_length += self._dist(prev_coord, coord)
             prev_coord = coord
 
         if total_length == 0.0:
             return coords
 
-        result: List[Tuple[float, float]] = []
+        result: list[tuple[float, float]] = []
         prev_coord = None
         for coord in coords:
             if prev_coord is not None:
                 cur_length = self._dist(prev_coord, coord)
                 cur_nb_points = max(int(nb_points * cur_length / total_length + 0.5), 1)
                 dx = (coord[0] - prev_coord[0]) / float(cur_nb_points)
                 dy = (coord[1] - prev_coord[1]) / float(cur_nb_points)
```

## c2cgeoportal_geoportal/views/proxy.py

```diff
@@ -1,10 +1,8 @@
-# -*- coding: utf-8 -*-
-
-# Copyright (c) 2011-2022, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -26,15 +24,15 @@
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
 import sys
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Optional, Union
 
 import pyramid.request
 import pyramid.response
 import requests
 from pyramid.httpexceptions import HTTPBadGateway, exception_response
 
 from c2cgeoportal_commons.lib.url import Url
@@ -43,31 +41,31 @@
 from c2cgeoportal_geoportal.views import restrict_headers
 
 LOG = logging.getLogger(__name__)
 CACHE_REGION = get_region("std")
 
 
 class Proxy:
-    """Some methodes used by all the proxy."""
+    """Some methods used by all the proxy."""
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
         self.host_forward_host = request.registry.settings.get("host_forward_host", [])
         self.headers_whitelist = request.registry.settings.get("headers_whitelist", [])
         self.headers_blacklist = request.registry.settings.get("headers_blacklist", [])
         self.http_options = self.request.registry.settings.get("http_options", {})
 
     def _proxy(
         self,
         url: Url,
-        params: Optional[Dict[str, str]] = None,
+        params: Optional[dict[str, str]] = None,
         method: Optional[str] = None,
         cache: bool = False,
         body: Optional[bytes] = None,
-        headers: Optional[Dict[str, str]] = None,
+        headers: Optional[dict[str, str]] = None,
     ) -> requests.models.Response:
         # Get query string
         params = dict(self.request.params) if params is None else params
         url = url.clone().add_query(params, True)
 
         LOG.debug("Send query to URL:\n%s.", url)
 
@@ -145,15 +143,15 @@
                 "Error '%s' in response of URL:",
                 "%s",
                 "Status: %d",
                 "Method: %s",
                 "--- With headers ---",
                 "%s",
             ]
-            args2: List[Union[str, int]] = [
+            args2: list[Union[str, int]] = [
                 response.reason,
                 url.url(),
                 response.status_code,
                 method,
                 "\n".join(
                     [
                         f"{h}: {v if h not in ('Authorization', 'Cookies') else '***'}"
@@ -170,26 +168,26 @@
 
             raise exception_response(response.status_code)
         if not response.headers.get("Content-Type", "").startswith("image/"):
             LOG.debug("Get result for URL: %s:\n%s.", url, body)
 
         return response
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
+    @CACHE_REGION.cache_on_arguments()
     def _proxy_cache(self, method: str, *args: Any, **kwargs: Any) -> pyramid.response.Response:
         # Method is only for the cache
         del method
         kwargs["cache"] = True
         return self._proxy(*args, **kwargs)
 
     def _proxy_response(
         self,
         service_name: str,
         url: Url,
-        headers_update: Optional[Dict[str, str]] = None,
+        headers_update: Optional[dict[str, str]] = None,
         public: bool = False,
         **kwargs: Any,
     ) -> pyramid.response.Response:
         if headers_update is None:
             headers_update = {}
         cache = kwargs.get("cache", False)
         if cache is True:
@@ -208,16 +206,16 @@
 
     def _build_response(
         self,
         response: pyramid.response.Response,
         content: bytes,
         cache_control: Cache,
         service_name: str,
-        headers: Optional[Dict[str, str]] = None,
-        headers_update: Optional[Dict[str, str]] = None,
+        headers: Optional[dict[str, str]] = None,
+        headers_update: Optional[dict[str, str]] = None,
         content_type: Optional[str] = None,
     ) -> pyramid.response.Response:
         if headers_update is None:
             headers_update = {}
         headers = response.headers if headers is None else headers
 
         # Hop-by-hop Headers are not supported by WSGI
@@ -246,15 +244,15 @@
         response = pyramid.response.Response(content, status=response.status_code, headers=headers)
 
         return set_common_headers(
             self.request, service_name, cache_control, response=response, content_type=content_type
         )
 
     @staticmethod
-    def _get_lower_params(params: Dict[str, str]) -> Dict[str, str]:
-        return dict((k.lower(), str(v).lower()) for k, v in params.items())
+    def _get_lower_params(params: dict[str, str]) -> dict[str, str]:
+        return {k.lower(): str(v).lower() for k, v in params.items()}
 
-    def get_headers(self) -> Dict[str, str]:
-        headers: Dict[str, str] = self.request.headers
+    def get_headers(self) -> dict[str, str]:
+        headers: dict[str, str] = self.request.headers
         if "Cookie" in headers:
             headers.pop("Cookie")
         return headers
```

## c2cgeoportal_geoportal/views/raster.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2021, Camptocamp SA
+# Copyright (c) 2012-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -27,15 +27,15 @@
 
 
 import decimal
 import logging
 import math
 import os
 import traceback
-from typing import TYPE_CHECKING, Any, Dict, Optional, Tuple
+from typing import TYPE_CHECKING, Any, Optional
 
 import numpy
 import pyramid.request
 import zope.event.classhandler
 from pyramid.httpexceptions import HTTPBadRequest, HTTPNotFound
 from pyramid.view import view_config
 from rasterio.io import DatasetReader
@@ -48,15 +48,15 @@
 
 LOG = logging.getLogger(__name__)
 
 
 class Raster:
     """All the view concerned the raster (point, not the profile profile)."""
 
-    data: Dict[str, "fiona.collection.Collection"] = {}
+    data: dict[str, "fiona.collection.Collection"] = {}
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
         self.rasters = self.request.registry.settings["raster"]
 
         @zope.event.classhandler.handler(InvalidateCacheEvent)  # type: ignore
         def handle(event: InvalidateCacheEvent) -> None:
@@ -77,15 +77,15 @@
         if not math.isfinite(result):
             raise HTTPBadRequest(
                 f"'{name}' ({self.request.params[name]}) parameters should be a finite number"
             )
         return result
 
     @view_config(route_name="raster", renderer="fast_json")  # type: ignore
-    def raster(self) -> Dict[str, Any]:
+    def raster(self) -> dict[str, Any]:
         lon = self._get_required_finite_float_param("lon")
         lat = self._get_required_finite_float_param("lat")
 
         if "layers" in self.request.params:
             rasters = {}
             layers = self.request.params["layers"].split(",")
             for layer in layers:
@@ -99,15 +99,15 @@
         result = {}
         for ref in list(rasters.keys()):
             result[ref] = self._get_raster_value(rasters[ref], ref, lon, lat)
 
         set_common_headers(self.request, "raster", Cache.PUBLIC_NO)
         return result
 
-    def _get_data(self, layer: Dict[str, Any], name: str) -> "fiona.collection.Collection":
+    def _get_data(self, layer: dict[str, Any], name: str) -> "fiona.collection.Collection":
         if name not in self.data:
             path = layer["file"]
             if layer.get("type", "shp_index") == "shp_index":
                 # Avoid loading if not needed
                 from fiona.collection import Collection  # pylint: disable=import-outside-toplevel
 
                 self.data[name] = Collection(path)
@@ -116,15 +116,15 @@
                 import rasterio  # pylint: disable=import-outside-toplevel
 
                 self.data[name] = rasterio.open(path)
 
         return self.data[name]
 
     def _get_raster_value(
-        self, layer: Dict[str, Any], name: str, lon: float, lat: float
+        self, layer: dict[str, Any], name: str, lon: float, lat: float
     ) -> Optional[decimal.Decimal]:
         data = self._get_data(layer, name)
         type_ = layer.get("type", "shp_index")
         if type_ == "shp_index":
             tiles = list(data.filter(mask={"type": "Point", "coordinates": [lon, lat]}))
 
             if not tiles:
@@ -148,30 +148,30 @@
         elif result is not None:
             result_d = decimal.Decimal(str(result))
 
         return result_d
 
     @staticmethod
     def _get_value(
-        layer: Dict[str, Any], name: str, dataset: DatasetReader, lon: float, lat: float
+        layer: dict[str, Any], name: str, dataset: DatasetReader, lon: float, lat: float
     ) -> Optional[numpy.float32]:
         index = dataset.index(lon, lat)
 
         shape = dataset.shape
         result: Optional[numpy.float32]
         if 0 <= index[0] < shape[0] and 0 <= index[1] < shape[1]:
 
-            def get_index(index_: int) -> Tuple[int, int]:
+            def get_index(index_: int) -> tuple[int, int]:
                 return index_, index_ + 1
 
             result = dataset.read(1, window=(get_index(index[0]), get_index(index[1])))[0][0]
             result = None if result == layer.get("nodata", dataset.nodata) else result
         else:
             LOG.debug(
-                "Out of index for layer: %s (%s), " "lon/lat: %dx%d, index: %dx%d, shape: %dx%d.",
+                "Out of index for layer: %s (%s), lon/lat: %dx%d, index: %dx%d, shape: %dx%d.",
                 name,
                 layer["file"],
                 lon,
                 lat,
                 index[0],
                 index[1],
                 dataset.shape[0],
```

## c2cgeoportal_geoportal/views/resourceproxy.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2021, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## c2cgeoportal_geoportal/views/shortener.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2022, Camptocamp SA
+# Copyright (c) 2013-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -26,24 +26,24 @@
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
 import random
 import string
 from datetime import datetime
-from typing import Dict
 from urllib.parse import urlparse
 
 import pyramid.request
 from pyramid.httpexceptions import HTTPBadRequest, HTTPFound, HTTPInternalServerError, HTTPNotFound
 from pyramid.view import view_config
 
 from c2cgeoportal_commons.lib.email_ import send_email_config
 from c2cgeoportal_commons.models import DBSession
 from c2cgeoportal_commons.models.static import Shorturl
+from c2cgeoportal_geoportal import is_allowed_url
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
 
 logger = logging.getLogger(__name__)
 
 
 class Shortener:
     """All the views conserne the shortener."""
@@ -53,55 +53,55 @@
         self.settings = request.registry.settings.get("shortener", {})
         self.short_bases = [self.request.route_url("shortener_get", ref="")]
         if "base_url" in self.settings:
             self.short_bases.append(self.settings["base_url"])
 
     @view_config(route_name="shortener_get")  # type: ignore
     def get(self) -> HTTPFound:
+        assert DBSession is not None
+
         ref = self.request.matchdict["ref"]
         short_urls = DBSession.query(Shorturl).filter(Shorturl.ref == ref).all()
 
         if len(short_urls) != 1:
             raise HTTPNotFound(f"Ref '{ref!s}' not found")
 
         short_urls[0].nb_hits += 1
         short_urls[0].last_hit = datetime.now()
 
         set_common_headers(self.request, "shortener", Cache.PUBLIC_NO)
         return HTTPFound(location=short_urls[0].url)
 
     @view_config(route_name="shortener_create", renderer="json")  # type: ignore
-    def create(self) -> Dict[str, str]:
+    def create(self) -> dict[str, str]:
+        assert DBSession is not None
 
         if "url" not in self.request.params:
             raise HTTPBadRequest("The parameter url is required")
 
         url = self.request.params["url"]
 
         # see: https://httpd.apache.org/docs/2.2/mod/core.html#limitrequestline
         if len(url) > 8190:
             raise HTTPBadRequest(f"The parameter url is too long ({len(url)} > {8190})")
 
-        # Check that it is an internal URL...
-        uri_parts = urlparse(url)
-        if "allowed_hosts" in self.settings:
-            if uri_parts.netloc not in self.settings["allowed_hosts"]:
-                raise HTTPBadRequest(
-                    f"The requested host '{uri_parts.netloc}' is not part of allowed hosts: "
-                    f"{', '.join(self.settings['allowed_hosts'])}"
-                )
-        else:
-            hostname = uri_parts.hostname
-            if hostname != self.request.server_name:
-                raise HTTPBadRequest(
-                    f"The requested host '{hostname!s}' should be '{self.request.server_name!s}'"
-                )
+        allowed_hosts = self.settings.get("allowed_hosts", [])
+        url_hostname, ok = is_allowed_url(self.request, url, allowed_hosts)
+        if not ok:
+            message = (
+                f"Invalid requested host '{url_hostname}', "
+                f"is not the current host '{self.request.host}' "
+                f"or part of allowed hosts: {', '.join(allowed_hosts)}"
+            )
+            logging.debug(message)
+            raise HTTPBadRequest(message)
 
         shortened = False
 
+        uri_parts = urlparse(url)
         for base in self.short_bases:
             base_parts = urlparse(base)
             if uri_parts.path.startswith(base_parts.path):
                 shortened = True
                 ref = uri_parts.path.split("/")[-1]
 
         tries = 0
```

## c2cgeoportal_geoportal/views/theme.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2022, Camptocamp SA
+# Copyright (c) 2011-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -31,77 +31,83 @@
 import logging
 import os
 import re
 import sys
 import time
 from collections import Counter
 from math import sqrt
-from typing import Any, Dict, List, Optional, Set, Tuple, Union, cast
+from typing import Any, Optional, Union, cast
 
 import dogpile.cache.api
+import pyramid.httpexceptions
 import pyramid.request
 import requests
 import sqlalchemy
 import sqlalchemy.orm.query
 from c2cwsgiutils.auth import auth_view
 from defusedxml import lxml
 from lxml import etree  # nosec
 from owslib.wms import WebMapService
 from pyramid.view import view_config
 from sqlalchemy.orm import subqueryload
-from sqlalchemy.orm.exc import NoResultFound
+from sqlalchemy.orm.exc import NoResultFound  # type: ignore[attr-defined]
 
 from c2cgeoportal_commons import models
 from c2cgeoportal_commons.lib.url import Url, get_url2
-from c2cgeoportal_commons.models import main
+from c2cgeoportal_commons.models import cache_invalidate_cb, main
+from c2cgeoportal_geoportal import is_allowed_url
 from c2cgeoportal_geoportal.lib import get_roles_id, get_typed, get_types_map, is_intranet
 from c2cgeoportal_geoportal.lib.caching import get_region
 from c2cgeoportal_geoportal.lib.common_headers import Cache, set_common_headers
 from c2cgeoportal_geoportal.lib.functionality import get_mapserver_substitution_params
 from c2cgeoportal_geoportal.lib.layers import (
     get_private_layers,
     get_protected_layers,
     get_protected_layers_query,
 )
 from c2cgeoportal_geoportal.lib.wmstparsing import TimeInformation, parse_extent
-from c2cgeoportal_geoportal.views import restrict_headers
 from c2cgeoportal_geoportal.views.layers import get_layer_metadata
 
 LOG = logging.getLogger(__name__)
 CACHE_REGION = get_region("std")
+CACHE_OGC_SERVER_REGION = get_region("ogc-server")
 TIMEOUT = int(os.environ.get("C2CGEOPORTAL_THEME_TIMEOUT", "300"))
 
-Metadata = Union[str, int, float, bool, List[Any], Dict[str, Any]]
+Metadata = Union[str, int, float, bool, list[Any], dict[str, Any]]
 
 
-def get_http_cached(http_options: Dict[str, Any], url: str, headers: Dict[str, str]) -> Tuple[bytes, str]:
+def get_http_cached(
+    http_options: dict[str, Any], url: str, headers: dict[str, str], cache: bool = True
+) -> tuple[bytes, str]:
     """Get the content of the URL with a cash (dogpile)."""
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
-    def do_get_http_cached(url: str) -> Tuple[bytes, str]:
+    @CACHE_OGC_SERVER_REGION.cache_on_arguments()
+    def do_get_http_cached(url: str) -> tuple[bytes, str]:
         response = requests.get(url, headers=headers, timeout=TIMEOUT, **http_options)
         response.raise_for_status()
         LOG.info("Get url '%s' in %.1fs.", url, response.elapsed.total_seconds())
         return response.content, response.headers.get("Content-Type", "")
 
-    return do_get_http_cached(url)  # type: ignore
+    if cache:
+        return do_get_http_cached(url)  # type: ignore[no-any-return]
+    return do_get_http_cached.refresh(url)  # type: ignore[attr-defined,no-any-return]
 
 
 class DimensionInformation:
     """Used to collect the dimensions information."""
 
     URL_PART_RE = re.compile(r"[a-zA-Z0-9_\-\+~\.]*$")
 
     def __init__(self) -> None:
-        self._dimensions: Dict[str, str] = {}
+        self._dimensions: dict[str, str] = {}
 
-    def merge(self, layer: main.Layer, layer_node: Dict[str, Any], mixed: bool) -> Set[str]:
+    def merge(self, layer: main.Layer, layer_node: dict[str, Any], mixed: bool) -> set[str]:
         errors = set()
 
-        dimensions: Dict[str, str] = {}
+        dimensions: dict[str, str] = {}
         dimensions_filters = {}
         for dimension in layer.dimensions:
             if (
                 not isinstance(layer, main.LayerWMS)
                 and dimension.value is not None
                 and not self.URL_PART_RE.match(dimension.value)
             ):
@@ -128,69 +134,69 @@
                 elif self._dimensions[name] != value and value is not None:
                     errors.add(
                         f"The layer '{layer.name}' has a wrong dimension value '{value}' for '{name}', "
                         f"expected '{self._dimensions[name]}' or empty."
                     )
         return errors
 
-    def get_dimensions(self) -> Dict[str, str]:
+    def get_dimensions(self) -> dict[str, str]:
         return self._dimensions
 
 
 class Theme:
     """All the views concerning the themes."""
 
     def __init__(self, request: pyramid.request.Request):
         self.request = request
         self.settings = request.registry.settings
         self.http_options = self.settings.get("http_options", {})
-        self.headers_whitelist = self.settings.get("headers_whitelist", [])
-        self.headers_blacklist = self.settings.get("headers_blacklist", [])
         self.metadata_type = get_types_map(
             self.settings.get("admin_interface", {}).get("available_metadata", [])
         )
 
-        self._ogcservers_cache = None
-        self._treeitems_cache = None
-        self._layerswms_cache = None
-        self._layerswmts_cache = None
-        self._layergroup_cache = None
-        self._themes_cache = None
+        self._ogcservers_cache: Optional[list[main.OGCServer]] = None
+        self._treeitems_cache: Optional[list[main.TreeItem]] = None
+        self._layerswms_cache: Optional[list[main.LayerWMS]] = None
+        self._layerswmts_cache: Optional[list[main.LayerWMTS]] = None
+        self._layergroup_cache: Optional[list[main.LayerGroup]] = None
+        self._themes_cache: Optional[list[main.Theme]] = None
 
     def _get_metadata(
-        self, item: main.TreeItem, metadata: str, errors: Set[str]
-    ) -> Union[None, str, int, float, bool, List[Any], Dict[str, Any]]:
+        self, item: main.TreeItem, metadata: str, errors: set[str]
+    ) -> Union[None, str, int, float, bool, list[Any], dict[str, Any]]:
         metadatas = item.get_metadata(metadata)
         return (
             None
             if not metadatas
             else get_typed(
                 metadata, metadatas[0].value, self.metadata_type, self.request, errors, layer_name=item.name
             )
         )
 
-    def _get_metadata_list(self, item: main.TreeItem, errors: Set[str]) -> Dict[str, Metadata]:
-        metadatas: Dict[str, Metadata] = {}
+    def _get_metadata_list(self, item: main.TreeItem, errors: set[str]) -> dict[str, Metadata]:
+        metadatas: dict[str, Metadata] = {}
         metadata: main.Metadata
         for metadata in item.metadatas:
             value = get_typed(metadata.name, metadata.value, self.metadata_type, self.request, errors)
             if value is not None:
                 metadatas[metadata.name] = value
 
         return metadatas
 
     async def _wms_getcap(
-        self, ogc_server: main.OGCServer, preload: bool = False
-    ) -> Tuple[Optional[Dict[str, Dict[str, Any]]], Set[str]]:
-        @CACHE_REGION.cache_on_arguments()  # type: ignore
-        def build_web_map_service(ogc_server_id: int) -> Tuple[Optional[Dict[str, Dict[str, Any]]], Set[str]]:
+        self, ogc_server: main.OGCServer, preload: bool = False, cache: bool = True
+    ) -> tuple[Optional[dict[str, dict[str, Any]]], set[str]]:
+        LOG.debug("Get the WMS Capabilities of %s, preload: %s, cache: %s", ogc_server.name, preload, cache)
+
+        @CACHE_OGC_SERVER_REGION.cache_on_arguments()
+        def build_web_map_service(ogc_server_id: int) -> tuple[Optional[dict[str, dict[str, Any]]], set[str]]:
             del ogc_server_id  # Just for cache
 
             if url is None:
-                raise RuntimeError("Url is None")
+                raise RuntimeError("URL is None")
 
             version = url.query.get("VERSION", "1.1.1")
             layers = {}
             try:
                 wms = WebMapService(None, xml=content, version=version)
             except Exception as e:
                 error = (
@@ -216,40 +222,46 @@
                     "info": info,
                     "timepositions": wms_layer.timepositions,
                     "defaulttimeposition": wms_layer.defaulttimeposition,
                     "children": [layer.name for layer in wms_layer.layers],
                 }
 
             del wms
-            LOG.debug("Run garbage collection: %s", ", ".join([str(gc.collect(n)) for n in range(3)]))
 
             return {"layers": layers}, set()
 
-        result = build_web_map_service.get(ogc_server.id)
-        if result != dogpile.cache.api.NO_VALUE:
-            return result  # type: ignore
+        if cache:
+            result = build_web_map_service.get(ogc_server.id)  # type: ignore[attr-defined]
+            if result != dogpile.cache.api.NO_VALUE:
+                return result  # type: ignore[no-any-return]
 
         try:
-            url, content, errors = await self._wms_getcap_cached(ogc_server)
+            url, content, errors = await self._wms_getcap_cached(ogc_server, cache=cache)
         except requests.exceptions.RequestException as exception:
-            error = (
-                f"Unable to get the WMS Capabilities for OGC server '{ogc_server.name}', "
-                f"return the error: {exception.response.status_code} {exception.response.reason}"
-            )
+            if exception.response is None:
+                error = (
+                    f"Unable to get the WMS Capabilities for OGC server '{ogc_server.name}', "
+                    f"return the error: {exception}"
+                )
+            else:
+                error = (
+                    f"Unable to get the WMS Capabilities for OGC server '{ogc_server.name}', "
+                    f"return the error: {exception.response.status_code} {exception.response.reason}"
+                )
             LOG.exception(error)
             return None, {error}
         if errors or preload:
             return None, errors
 
-        return build_web_map_service(ogc_server.id)  # type: ignore
+        return build_web_map_service.refresh(ogc_server.id)  # type: ignore
 
     async def _wms_getcap_cached(
-        self, ogc_server: main.OGCServer
-    ) -> Tuple[Optional[Url], Optional[bytes], Set[str]]:
-        errors: Set[str] = set()
+        self, ogc_server: main.OGCServer, cache: bool = True
+    ) -> tuple[Optional[Url], Optional[bytes], set[str]]:
+        errors: set[str] = set()
         url = get_url2(f"The OGC server '{ogc_server.name}'", ogc_server.url, self.request, errors)
         if errors or url is None:
             return url, None, errors
 
         # Add functionality params
         if (
             ogc_server.auth == main.OGCSERVER_AUTH_STANDARD
@@ -265,31 +277,23 @@
                 "ROLE_IDS": "0",
                 "USER_ID": "0",
             },
         )
 
         LOG.debug("Get WMS GetCapabilities for URL: %s", url)
 
-        # Forward request to target (without Host Header)
-        headers = dict(self.request.headers)
+        headers = {}
 
         # Add headers for Geoserver
         if ogc_server.auth == main.OGCSERVER_AUTH_GEOSERVER:
             headers["sec-username"] = "root"
             headers["sec-roles"] = "root"
 
-        if url.hostname != "localhost" and "Host" in headers:
-            headers.pop("Host")
-
-        headers = restrict_headers(headers, self.headers_whitelist, self.headers_blacklist)
-
         try:
-            content, content_type = await asyncio.get_event_loop().run_in_executor(
-                None, get_http_cached, self.http_options, url, headers
-            )
+            content, content_type = get_http_cached(self.http_options, url.url(), headers, cache=cache)
         except Exception:
             error = f"Unable to GetCapabilities from URL {url}"
             errors.add(error)
             LOG.error(error, exc_info=True)
             return url, None, errors
 
         # With wms 1.3 it returns text/xml also in case of error :-(
@@ -303,44 +307,49 @@
             )
             errors.add(error)
             LOG.error(error)
             return url, None, errors
 
         return url, content, errors
 
-    def _create_layer_query(self, interface: str) -> sqlalchemy.orm.query.Query:
+    def _create_layer_query(self, interface: str) -> sqlalchemy.orm.query.RowReturningQuery[tuple[str]]:
         """Create an SQLAlchemy query for Layer and for the role identified to by ``role_id``."""
-        query = models.DBSession.query(main.Layer.name).filter(main.Layer.public.is_(True))
+
+        assert models.DBSession is not None
+
+        query: sqlalchemy.orm.query.RowReturningQuery[tuple[str]] = models.DBSession.query(
+            main.Layer.name
+        ).filter(main.Layer.public.is_(True))
 
         if interface is not None:
             query = query.join(main.Layer.interfaces)
             query = query.filter(main.Interface.name == interface)
 
-        query2 = get_protected_layers_query(self.request, None, what=main.LayerWMS.name)
+        query2 = get_protected_layers_query(self.request, None, what=main.LayerWMS.name)  # type: ignore[arg-type]
         if interface is not None:
             query2 = query2.join(main.Layer.interfaces)
             query2 = query2.filter(main.Interface.name == interface)
         query = query.union(query2)
-        query3 = get_protected_layers_query(self.request, None, what=main.LayerWMTS.name)
+        query3 = get_protected_layers_query(self.request, None, what=main.LayerWMTS.name)  # type: ignore[arg-type]
         if interface is not None:
             query3 = query3.join(main.Layer.interfaces)
             query3 = query3.filter(main.Interface.name == interface)
         query = query.union(query3)
 
         return query
 
-    def _get_layer_metadata_urls(self, layer: main.Layer) -> List[str]:
-        metadata_urls: List[str] = []
+    def _get_layer_metadata_urls(self, layer: main.Layer) -> list[str]:
+        metadata_urls: list[str] = []
         if layer.metadataUrls:
             metadata_urls = layer.metadataUrls
         for child_layer in layer.layers:
             metadata_urls.extend(self._get_layer_metadata_urls(child_layer))
         return metadata_urls
 
-    def _get_layer_resolution_hint_raw(self, layer: main.Layer) -> Tuple[Optional[float], Optional[float]]:
+    def _get_layer_resolution_hint_raw(self, layer: main.Layer) -> tuple[Optional[float], Optional[float]]:
         resolution_hint_min = None
         resolution_hint_max = None
         if layer.scaleHint:
             # scaleHint is based upon a pixel diagonal length whereas we use
             # resolutions based upon a pixel edge length. There is a sqrt(2)
             # ratio between edge and diagonal of a square.
             resolution_hint_min = float(layer.scaleHint["min"]) / sqrt(2)
@@ -364,29 +373,29 @@
                 else (
                     resolution_hint_max if resolution[1] is None else max(resolution_hint_max, resolution[1])
                 )
             )
 
         return (resolution_hint_min, resolution_hint_max)
 
-    def _get_layer_resolution_hint(self, layer: main.Layer) -> Tuple[float, float]:
+    def _get_layer_resolution_hint(self, layer: main.Layer) -> tuple[float, float]:
         resolution_hint_min, resolution_hint_max = self._get_layer_resolution_hint_raw(layer)
         return (
             0.0 if resolution_hint_min is None else resolution_hint_min,
             999999999 if resolution_hint_max is None else resolution_hint_max,
         )
 
     async def _layer(
         self,
         layer: main.Layer,
         time_: Optional[TimeInformation] = None,
         dim: Optional[DimensionInformation] = None,
         mixed: bool = True,
-    ) -> Tuple[Optional[Dict[str, Any]], Set[str]]:
-        errors: Set[str] = set()
+    ) -> tuple[Optional[dict[str, Any]], set[str]]:
+        errors: set[str] = set()
         layer_info = {"id": layer.id, "name": layer.name, "metadata": self._get_metadata_list(layer, errors)}
         if re.search("[/?#]", layer.name):
             errors.add(f"The layer has an unsupported name '{layer.name}'.")
         if isinstance(layer, main.LayerWMS) and re.search("[/?#]", layer.layer):
             errors.add(f"The layer has an unsupported layers '{layer.layer}'.")
         if layer.geo_table:
             errors |= self._fill_editable(layer_info, layer)
@@ -419,20 +428,20 @@
             layer_info["type"] = "VectorTiles"
             self._vectortiles_layers(layer_info, layer, errors)
 
         return None if errors else layer_info, errors
 
     @staticmethod
     def _merge_time(
-        time_: TimeInformation, layer_theme: Dict[str, Any], layer: main.Layer, wms: Dict[str, Dict[str, Any]]
-    ) -> Set[str]:
+        time_: TimeInformation, layer_theme: dict[str, Any], layer: main.Layer, wms: dict[str, dict[str, Any]]
+    ) -> set[str]:
         errors = set()
         wmslayer = layer.layer
 
-        def merge_time(wms_layer_obj: Dict[str, Any]) -> None:
+        def merge_time(wms_layer_obj: dict[str, Any]) -> None:
             extent = parse_extent(wms_layer_obj["timepositions"], wms_layer_obj["defaulttimeposition"])
             time_.merge(layer_theme, extent, layer.time_mode, layer.time_widget)
 
         try:
             if wmslayer in wms["layers"]:
                 wms_layer_obj = wms["layers"][wmslayer]
 
@@ -456,15 +465,17 @@
                         )
 
         except ValueError:  # pragma no cover
             errors.add(f"Error while handling time for layer '{layer.name}': {sys.exc_info()[1]}")
 
         return errors
 
-    def _fill_editable(self, layer_theme: Dict[str, Any], layer: main.Layer) -> Set[str]:
+    def _fill_editable(self, layer_theme: dict[str, Any], layer: main.Layer) -> set[str]:
+        assert models.DBSession is not None
+
         errors = set()
         try:
             if self.request.user:
                 count = (
                     models.DBSession.query(main.RestrictionArea)
                     .join(main.RestrictionArea.roles)
                     .filter(main.Role.id.in_(get_roles_id(self.request)))
@@ -478,27 +489,27 @@
         except Exception as exception:
             LOG.exception(str(exception))
             errors.add(str(exception))
         return errors
 
     def _fill_child_layer(
         self,
-        layer_theme: Dict[str, Any],
+        layer_theme: dict[str, Any],
         layer_name: str,
-        wms: Dict[str, Dict[str, Any]],
+        wms: dict[str, dict[str, Any]],
     ) -> None:
         wms_layer_obj = wms["layers"][layer_name]
         if not wms_layer_obj["children"]:
             layer_theme["childLayers"].append(wms["layers"][layer_name]["info"])
         else:
             for child_layer in wms_layer_obj["children"]:
                 self._fill_child_layer(layer_theme, child_layer, wms)
 
     async def _fill_wms(
-        self, layer_theme: Dict[str, Any], layer: main.Layer, errors: Set[str], mixed: bool
+        self, layer_theme: dict[str, Any], layer: main.Layer, errors: set[str], mixed: bool
     ) -> None:
         wms, wms_errors = await self._wms_layers(layer.ogc_server)
         errors |= wms_errors
         if wms is None:
             return
 
         layer_theme["imageType"] = layer.ogc_server.image_type
@@ -538,40 +549,40 @@
                 ]
                 if max_resolutions_hint:
                     layer_theme["maxResolutionHint"] = max(max_resolutions_hint)
 
         if mixed:
             layer_theme["ogcServer"] = layer.ogc_server.name
 
-    def _fill_wmts(self, layer_theme: Dict[str, Any], layer: main.Layer, errors: Set[str]) -> None:
+    def _fill_wmts(self, layer_theme: dict[str, Any], layer: main.Layer, errors: set[str]) -> None:
         url = get_url2(f"The WMTS layer '{layer.name}'", layer.url, self.request, errors=errors)
         layer_theme["url"] = url.url() if url is not None else None
 
         if layer.style:
             layer_theme["style"] = layer.style
         if layer.matrix_set:
             layer_theme["matrixSet"] = layer.matrix_set
 
         layer_theme["layer"] = layer.layer
         layer_theme["imageType"] = layer.image_type
 
-    def _vectortiles_layers(self, layer_theme: Dict[str, Any], layer: main.Layer, errors: Set[str]) -> None:
+    def _vectortiles_layers(self, layer_theme: dict[str, Any], layer: main.Layer, errors: set[str]) -> None:
         style = get_url2(f"The VectorTiles layer '{layer.name}'", layer.style, self.request, errors=errors)
         layer_theme["style"] = style.url() if style is not None else None
         if layer.xyz:
             layer_theme["xyz"] = layer.xyz
 
     @staticmethod
     def _layer_included(tree_item: main.TreeItem) -> bool:
         return isinstance(tree_item, main.Layer)
 
-    def _get_ogc_servers(self, group: main.LayerGroup, depth: int) -> Set[Union[str, bool]]:
+    def _get_ogc_servers(self, group: main.LayerGroup, depth: int) -> set[Union[str, bool]]:
         """Get unique identifier for each child by recursing on all the children."""
 
-        ogc_servers: Set[Union[str, bool]] = set()
+        ogc_servers: set[Union[str, bool]] = set()
 
         # escape loop
         if depth > 30:
             LOG.error("Error: too many recursions with group '%s'", group.name)
             return ogc_servers
 
         # recurse on children
@@ -584,31 +595,31 @@
 
         if isinstance(group, main.LayerWMTS):
             ogc_servers.add(False)
 
         return ogc_servers
 
     @staticmethod
-    def is_mixed(ogc_servers: List[Union[str, bool]]) -> bool:
+    def is_mixed(ogc_servers: list[Union[str, bool]]) -> bool:
         return len(ogc_servers) != 1 or ogc_servers[0] is False
 
     async def _group(
         self,
         path: str,
         group: main.LayerGroup,
-        layers: List[str],
+        layers: list[str],
         depth: int = 1,
         min_levels: int = 1,
         mixed: bool = True,
         time_: Optional[TimeInformation] = None,
         dim: Optional[DimensionInformation] = None,
-        wms_layers: Optional[List[str]] = None,
-        layers_name: Optional[List[str]] = None,
+        wms_layers: Optional[list[str]] = None,
+        layers_name: Optional[list[str]] = None,
         **kwargs: Any,
-    ) -> Tuple[Optional[Dict[str, Any]], Set[str]]:
+    ) -> tuple[Optional[dict[str, Any]], set[str]]:
         if wms_layers is None:
             wms_layers = []
         if layers_name is None:
             layers_name = []
         children = []
         errors = set()
 
@@ -683,38 +694,40 @@
                         )
 
             group_theme["mixed"] = mixed
             if org_depth == 1:
                 if not mixed:
                     assert time_ is not None
                     assert dim is not None
-                    group_theme["ogcServer"] = cast(List[Any], ogc_servers)[0]
+                    group_theme["ogcServer"] = cast(list[Any], ogc_servers)[0]
                     if time_.has_time() and time_.layer is None:
                         group_theme["time"] = time_.to_dict()
 
                     group_theme["dimensions"] = dim.get_dimensions()
 
             return group_theme, errors
         return None, errors
 
-    def _layers(self, interface: str) -> List[str]:
+    def _layers(self, interface: str) -> list[str]:
         query = self._create_layer_query(interface=interface)
         return [name for (name,) in query.all()]
 
     async def _wms_layers(
         self, ogc_server: main.OGCServer
-    ) -> Tuple[Optional[Dict[str, Dict[str, Any]]], Set[str]]:
+    ) -> tuple[Optional[dict[str, dict[str, Any]]], set[str]]:
         # retrieve layers metadata via GetCapabilities
         wms, wms_errors = await self._wms_getcap(ogc_server)
         if wms_errors:
             return None, wms_errors
 
         return wms, set()
 
     def _load_tree_items(self) -> None:
+        assert models.DBSession is not None
+
         # Populate sqlalchemy session.identity_map to reduce the number of database requests.
         self._ogcservers_cache = models.DBSession.query(main.OGCServer).all()
         self._treeitems_cache = models.DBSession.query(main.TreeItem).all()
         self._layerswms_cache = (
             models.DBSession.query(main.LayerWMS)
             .options(subqueryload(main.LayerWMS.dimensions), subqueryload(main.LayerWMS.metadatas))
             .all()
@@ -737,16 +750,19 @@
                 subqueryload(main.Theme.children_relation),
             )
             .all()
         )
 
     async def _themes(
         self, interface: str = "desktop", filter_themes: bool = True, min_levels: int = 1
-    ) -> Tuple[List[Dict[str, Any]], Set[str]]:
+    ) -> tuple[list[dict[str, Any]], set[str]]:
         """Return theme information for the role identified by ``role_id``."""
+
+        assert models.DBSession is not None
+
         self._load_tree_items()
         errors = set()
         layers = self._layers(interface)
 
         themes = models.DBSession.query(main.Theme)
         themes = themes.filter(main.Theme.public.is_(True))
         auth_themes = models.DBSession.query(main.Theme)
@@ -793,34 +809,34 @@
                     "metadata": self._get_metadata_list(theme, errors),
                 }
                 export_themes.append(theme_theme)
 
         return export_themes, errors
 
     @staticmethod
-    def _get_functionalities(theme: main.Theme) -> Dict[str, List[str]]:
-        result: Dict[str, List[str]] = {}
+    def _get_functionalities(theme: main.Theme) -> dict[str, list[str]]:
+        result: dict[str, list[str]] = {}
         for functionality in theme.functionalities:
             if functionality.name in result:
                 result[functionality.name].append(functionality.value)
             else:
                 result[functionality.name] = [functionality.value]
         return result
 
     @view_config(route_name="invalidate", renderer="json")  # type: ignore
-    def invalidate_cache(self) -> Dict[str, bool]:
+    def invalidate_cache(self) -> dict[str, bool]:
         auth_view(self.request)
         models.cache_invalidate_cb()
         return {"success": True}
 
     async def _get_children(
-        self, theme: main.Theme, layers: List[str], min_levels: int
-    ) -> Tuple[List[Dict[str, Any]], Set[str]]:
+        self, theme: main.Theme, layers: list[str], min_levels: int
+    ) -> tuple[list[dict[str, Any]], set[str]]:
         children = []
-        errors: Set[str] = set()
+        errors: set[str] = set()
         for item in theme.children:
             if isinstance(item, main.LayerGroup):
                 group_theme, gp_errors = await self._group(
                     f"{theme.name}/{item.name}", item, layers, min_levels=min_levels
                 )
                 errors |= gp_errors
                 if group_theme is not None:
@@ -834,78 +850,76 @@
                 elif item.name in layers:
                     layer_theme, l_errors = await self._layer(item, dim=DimensionInformation())
                     errors |= l_errors
                     if layer_theme is not None:
                         children.append(layer_theme)
         return children, errors
 
-    @CACHE_REGION.cache_on_arguments()  # type: ignore
-    def _get_layers_enum(self) -> Dict[str, Dict[str, str]]:
+    @CACHE_REGION.cache_on_arguments()
+    def _get_layers_enum(self) -> dict[str, dict[str, str]]:
         layers_enum = {}
         if "enum" in self.settings.get("layers", {}):
             for layer_name, layer in list(self.settings["layers"]["enum"].items()):
-                layer_enum: Dict[str, str] = {}
+                layer_enum: dict[str, str] = {}
                 layers_enum[layer_name] = layer_enum
                 for attribute in list(layer["attributes"].keys()):
                     layer_enum[attribute] = self.request.route_url(
                         "layers_enumerate_attribute_values",
                         layer_name=layer_name,
                         field_name=attribute,
                         path="",
                     )
         return layers_enum
 
-    def _get_role_ids(self) -> Optional[Set[int]]:
+    def _get_role_ids(self) -> Optional[set[int]]:
         return None if self.request.user is None else {role.id for role in self.request.user.roles}
 
     async def _wfs_get_features_type(
-        self, wfs_url: Url, ogc_server_name: str, preload: bool = False
-    ) -> Tuple[Optional[etree.Element], Set[str]]:
+        self, wfs_url: Url, ogc_server: main.OGCServer, preload: bool = False, cache: bool = True
+    ) -> tuple[Optional[etree.Element], set[str]]:  # pylint: disable=c-extension-no-member
         errors = set()
 
         wfs_url.add_query(
             {
                 "SERVICE": "WFS",
                 "VERSION": "1.0.0",
                 "REQUEST": "DescribeFeatureType",
                 "ROLE_IDS": "0",
                 "USER_ID": "0",
             }
         )
 
-        LOG.debug("WFS DescribeFeatureType for the URL: %s", wfs_url)
+        LOG.debug("WFS DescribeFeatureType for the URL: %s", wfs_url.url())
 
-        # forward request to target (without Host Header)
-        headers = dict(self.request.headers)
-        if wfs_url.hostname != "localhost" and "Host" in headers:
-            headers.pop("Host")
+        headers = {}
 
-        headers = restrict_headers(headers, self.headers_whitelist, self.headers_blacklist)
+        # Add headers for Geoserver
+        if ogc_server.auth == main.OGCSERVER_AUTH_GEOSERVER:
+            headers["sec-username"] = "root"
+            headers["sec-roles"] = "root"
 
         try:
-            content, _ = await asyncio.get_event_loop().run_in_executor(
-                None, get_http_cached, self.http_options, wfs_url, headers
-            )
+            content, _ = get_http_cached(self.http_options, wfs_url.url(), headers, cache)
         except requests.exceptions.RequestException as exception:
             error = (
                 f"Unable to get WFS DescribeFeatureType from the URL '{wfs_url.url()}' for "
-                f"OGC server {ogc_server_name}, "
+                f"OGC server {ogc_server.name}, "
                 + (
                     f"return the error: {exception.response.status_code} {exception.response.reason}"
                     if exception.response is not None
                     else f"{exception}"
                 )
             )
             errors.add(error)
             LOG.exception(error)
             return None, errors
         except Exception:
             error = (
                 f"Unable to get WFS DescribeFeatureType from the URL {wfs_url} for "
-                f"OGC server {ogc_server_name}"
+                f"OGC server {ogc_server.name}"
             )
             errors.add(error)
             LOG.exception(error)
             return None, errors
 
         if preload:
             return None, errors
@@ -915,16 +929,16 @@
         except Exception as e:
             errors.add(
                 f"Error '{e!s}' on reading DescribeFeatureType from URL {wfs_url}:\n{content.decode()}"
             )
             return None, errors
 
     def get_url_internal_wfs(
-        self, ogc_server: main.OGCServer, errors: Set[str]
-    ) -> Tuple[Optional[Url], Optional[Url], Optional[Url]]:
+        self, ogc_server: main.OGCServer, errors: set[str]
+    ) -> tuple[Optional[Url], Optional[Url], Optional[Url]]:
         # required to do every time to validate the url.
         if ogc_server.auth != main.OGCSERVER_AUTH_NOAUTH:
             url: Optional[Url] = Url(
                 self.request.route_url("mapserverproxy", _query={"ogcserver": ogc_server.name})
             )
             url_wfs: Optional[Url] = url
             url_internal_wfs = get_url2(
@@ -944,51 +958,59 @@
                 )
                 if ogc_server.url_wfs is not None
                 else url
             )
             url_internal_wfs = url_wfs
         return url_internal_wfs, url, url_wfs
 
-    async def preload(self, errors: Set[str]) -> None:
+    async def _preload(self, errors: set[str]) -> None:
+        assert models.DBSession is not None
         tasks = set()
+
         for ogc_server in models.DBSession.query(main.OGCServer).all():
-            # Don't load unused OGC servers, required for Landigpage, because the related OGC server
+            # Don't load unused OGC servers, required for landing page, because the related OGC server
             # will be on error in those functions.
             nb_layers = (
-                models.DBSession.query(sqlalchemy.func.count(main.LayerWMS.id))
+                models.DBSession.query(
+                    sqlalchemy.func.count(main.LayerWMS.id)  # pylint: disable=not-callable
+                )
                 .filter(main.LayerWMS.ogc_server_id == ogc_server.id)
                 .one()
             )
             LOG.debug("%i layers for OGC server '%s'", nb_layers[0], ogc_server.name)
             if nb_layers[0] > 0:
                 LOG.debug("Preload OGC server '%s'", ogc_server.name)
                 url_internal_wfs, _, _ = self.get_url_internal_wfs(ogc_server, errors)
                 if url_internal_wfs is not None:
-                    if ogc_server.wfs_support:
-                        tasks.add(self._wfs_get_features_type(url_internal_wfs, ogc_server.name, True))
-                    tasks.add(self._wms_getcap(ogc_server, True))
+                    tasks.add(self.preload_ogc_server(ogc_server, url_internal_wfs))
 
         await asyncio.gather(*tasks)
 
+    async def preload_ogc_server(
+        self, ogc_server: main.OGCServer, url_internal_wfs: Url, cache: bool = True
+    ) -> None:
+        if ogc_server.wfs_support:
+            await self._get_features_attributes(url_internal_wfs, ogc_server, cache=cache)
+        await self._wms_getcap(ogc_server, False, cache=cache)
+
     async def _get_features_attributes(
-        self, url_internal_wfs: Url, ogc_server_name: str
-    ) -> Tuple[Optional[Dict[str, Dict[Any, Dict[str, Any]]]], Optional[str], Set[str]]:
-        @CACHE_REGION.cache_on_arguments()  # type: ignore
+        self, url_internal_wfs: Url, ogc_server: main.OGCServer, cache: bool = True
+    ) -> tuple[Optional[dict[str, dict[Any, dict[str, Any]]]], Optional[str], set[str]]:
+        @CACHE_OGC_SERVER_REGION.cache_on_arguments()
         def _get_features_attributes_cache(
             url_internal_wfs: Url, ogc_server_name: str
-        ) -> Tuple[Optional[Dict[str, Dict[Any, Dict[str, Any]]]], Optional[str], Set[str]]:
+        ) -> tuple[Optional[dict[str, dict[Any, dict[str, Any]]]], Optional[str], set[str]]:
             del url_internal_wfs  # Just for cache
-            all_errors: Set[str] = set()
-            LOG.debug("Run garbage collection: %s", ", ".join([str(gc.collect(n)) for n in range(3)]))
+            all_errors: set[str] = set()
             if errors:
                 all_errors |= errors
                 return None, None, all_errors
-            assert feature_type
+            assert feature_type is not None
             namespace: str = feature_type.attrib.get("targetNamespace")
-            types: Dict[Any, Dict[str, Any]] = {}
+            types: dict[Any, dict[str, Any]] = {}
             elements = {}
             for child in feature_type.getchildren():
                 if child.tag == "{http://www.w3.org/2001/XMLSchema}element":
                     name = child.attrib["name"]
                     type_namespace, type_ = child.attrib["type"].split(":")
                     if type_namespace not in child.nsmap:
                         LOG.info(
@@ -1031,112 +1053,126 @@
                                 ", ".join([str(k) for k in child.nsmap.keys()]),
                                 ogc_server_name,
                             )
                         for key, value in children.attrib.items():
                             if key not in ("name", "type", "namespace"):
                                 attrib[name][key] = value
                     types[child.attrib["name"]] = attrib
-            attributes: Dict[str, Dict[Any, Dict[str, Any]]] = {}
+            attributes: dict[str, dict[Any, dict[str, Any]]] = {}
             for name, type_ in elements.items():
                 if type_ in types:
                     attributes[name] = types[type_]
                 elif (type_ == "Character") and (name + "Type") in types:
                     LOG.debug(
-                        "Due MapServer strange result the type 'ms:Character' is fallbacked to type '%sType'"
-                        " for feature '%s', This is a strange comportement of MapServer when we use the "
-                        'METADATA "gml_types" "auto"',
+                        'Due to MapServer weird behavior when using METADATA "gml_types" "auto"'
+                        "the type 'ms:Character' is returned as type '%sType' for feature '%s'.",
                         name,
                         name,
                     )
                     attributes[name] = types[name + "Type"]
                 else:
                     LOG.warning(
                         "The provided type '%s' does not exist, available types are %s.",
                         type_,
                         ", ".join(types.keys()),
                     )
 
             return attributes, namespace, all_errors
 
-        result = _get_features_attributes_cache.get(url_internal_wfs, ogc_server_name)
-        if result != dogpile.cache.api.NO_VALUE:
-            return result  # type: ignore
+        if cache:
+            result = _get_features_attributes_cache.get(  # type: ignore[attr-defined]
+                url_internal_wfs,
+                ogc_server.name,
+            )
+            if result != dogpile.cache.api.NO_VALUE:
+                return result  # type: ignore[no-any-return]
+
+        feature_type, errors = await self._wfs_get_features_type(url_internal_wfs, ogc_server, False, cache)
 
-        feature_type, errors = await self._wfs_get_features_type(url_internal_wfs, ogc_server_name)
-        return _get_features_attributes_cache(url_internal_wfs, ogc_server_name)  # type: ignore
+        return _get_features_attributes_cache.refresh(  # type: ignore[attr-defined,no-any-return]
+            url_internal_wfs,
+            ogc_server.name,
+        )
 
-    @view_config(route_name="themes", renderer="json")  # type: ignore
-    def themes(self) -> Dict[str, Union[Dict[str, Dict[str, Any]], List[str]]]:
+    @view_config(route_name="themes", renderer="json")  # type: ignore[misc]
+    def themes(self) -> dict[str, Union[dict[str, dict[str, Any]], list[str]]]:
         interface = self.request.params.get("interface", "desktop")
         sets = self.request.params.get("set", "all")
         min_levels = int(self.request.params.get("min_levels", 1))
         group = self.request.params.get("group")
         background_layers_group = self.request.params.get("background")
 
         set_common_headers(self.request, "themes", Cache.PRIVATE)
 
-        async def get_theme() -> Dict[str, Union[Dict[str, Any], List[str]]]:
+        async def get_theme() -> dict[str, Union[dict[str, Any], list[str]]]:
+            assert models.DBSession is not None
+
             export_themes = sets in ("all", "themes")
             export_group = group is not None and sets in ("all", "group")
             export_background = background_layers_group is not None and sets in ("all", "background")
 
-            result: Dict[str, Union[Dict[str, Any], List[Any]]] = {}
-            all_errors: Set[str] = set()
+            result: dict[str, Union[dict[str, Any], list[Any]]] = {}
+            all_errors: set[str] = set()
             LOG.debug("Start preload")
             start_time = time.time()
-            await self.preload(all_errors)
+            await self._preload(all_errors)
             LOG.debug("End preload")
             # Don't log if it looks to be already preloaded.
             if (time.time() - start_time) > 1:
                 LOG.info("Do preload in %.3fs.", time.time() - start_time)
+            LOG.debug("Run garbage collection: %s", ", ".join([str(gc.collect(n)) for n in range(3)]))
             result["ogcServers"] = {}
             for ogc_server in models.DBSession.query(main.OGCServer).all():
                 nb_layers = (
-                    models.DBSession.query(sqlalchemy.func.count(main.LayerWMS.id))
+                    models.DBSession.query(
+                        sqlalchemy.func.count(main.LayerWMS.id)  # pylint: disable=not-callable
+                    )
                     .filter(main.LayerWMS.ogc_server_id == ogc_server.id)
                     .one()
                 )
                 if nb_layers[0] == 0:
-                    # QGIS Server langing page requires an OGC server that can't be used here.
+                    # QGIS Server landing page requires an OGC server that can't be used here.
                     continue
 
+                LOG.debug("Process OGC server '%s'", ogc_server.name)
+
                 url_internal_wfs, url, url_wfs = self.get_url_internal_wfs(ogc_server, all_errors)
 
                 attributes = None
                 namespace = None
                 if ogc_server.wfs_support and not url_internal_wfs:
                     all_errors.add(
                         f"The OGC server '{ogc_server.name}' is configured to support WFS "
                         "but no internal WFS URL is found."
                     )
                 if ogc_server.wfs_support and url_internal_wfs:
                     attributes, namespace, errors = await self._get_features_attributes(
-                        url_internal_wfs, ogc_server.name
+                        url_internal_wfs, ogc_server
                     )
                     # Create a local copy (don't modify the cache)
                     if attributes is not None:
                         attributes = dict(attributes)
                     all_errors |= errors
 
                     all_private_layers = get_private_layers([ogc_server.id]).values()
                     protected_layers_name = [
                         layer.name for layer in get_protected_layers(self.request, [ogc_server.id]).values()
                     ]
-                    private_layers_name: List[str] = []
+                    private_layers_name: list[str] = []
                     for layers in [
                         v.layer for v in all_private_layers if v.name not in protected_layers_name
                     ]:
                         private_layers_name.extend(layers.split(","))
 
                     if attributes is not None:
                         for name in private_layers_name:
                             if name in attributes:
                                 del attributes[name]
 
-                result["ogcServers"][ogc_server.name] = {
+                result["ogcServers"][ogc_server.name] = {  # type: ignore[call-overload]
                     "url": url.url() if url else None,
                     "urlWfs": url_wfs.url() if url_wfs else None,
                     "type": ogc_server.type,
                     "credential": ogc_server.auth != main.OGCSERVER_AUTH_NOAUTH,
                     "imageType": ogc_server.image_type,
                     "wfsSupport": ogc_server.wfs_support,
                     "isSingleTile": ogc_server.is_single_tile,
@@ -1161,51 +1197,97 @@
                 all_errors |= errors
 
             result["errors"] = list(all_errors)
             if all_errors:
                 LOG.info("Theme errors:\n%s", "\n".join(all_errors))
             return result
 
-        @CACHE_REGION.cache_on_arguments()  # type: ignore
+        @CACHE_REGION.cache_on_arguments()
         def get_theme_anonymous(
             intranet: bool,
             interface: str,
             sets: str,
             min_levels: str,
             group: str,
             background_layers_group: str,
             host: str,
-        ) -> Dict[str, Union[Dict[str, Dict[str, Any]], List[str]]]:
+        ) -> dict[str, Union[dict[str, dict[str, Any]], list[str]]]:
             # Only for cache key
             del intranet, interface, sets, min_levels, group, background_layers_group, host
             return asyncio.run(get_theme())
 
         if self.request.user is None:
             return cast(
-                Dict[str, Union[Dict[str, Dict[str, Any]], List[str]]],
+                dict[str, Union[dict[str, dict[str, Any]], list[str]]],
                 get_theme_anonymous(
                     is_intranet(self.request),
                     interface,
                     sets,
                     min_levels,
                     group,
                     background_layers_group,
                     self.request.headers.get("Host"),
                 ),
             )
         return asyncio.run(get_theme())
 
     async def _get_group(
         self, group: main.LayerGroup, interface: main.Interface
-    ) -> Tuple[Optional[Dict[str, Any]], Set[str]]:
+    ) -> tuple[Optional[dict[str, Any]], set[str]]:
+        assert models.DBSession is not None
+
         layers = self._layers(interface)
         try:
-            group_db = models.DBSession.query(main.LayerGroup).filter(main.LayerGroup.name == group).one()
+            group_db = models.DBSession.query(main.LayerGroup).filter(main.LayerGroup.name == group).one()  # type: ignore[arg-type]
+            assert isinstance(group_db, main.LayerGroup)
             return await self._group(group_db.name, group_db, layers, depth=2, dim=DimensionInformation())
         except NoResultFound:
             return (
                 None,
                 {
                     f"Unable to find the Group named: {group}, Available Groups: "
                     f"{', '.join([i[0] for i in models.DBSession.query(main.LayerGroup.name).all()])}"
                 },
             )
+
+    @view_config(route_name="ogc_server_clear_cache", renderer="json")  # type: ignore[misc]
+    def ogc_server_clear_cache_view(self) -> dict[str, Any]:
+        assert models.DBSession is not None
+
+        self._ogc_server_clear_cache(
+            models.DBSession.query(main.OGCServer).filter_by(id=self.request.matchdict.get("id")).one()
+        )
+        came_from = self.request.params.get("came_from")
+        allowed_hosts = self.request.registry.settings.get("admin_interface", {}).get("allowed_hosts", [])
+        came_from_hostname, ok = is_allowed_url(self.request, came_from, allowed_hosts)
+        if not ok:
+            message = (
+                f"Invalid hostname '{came_from_hostname}' in 'came_from' parameter, "
+                f"is not the current host '{self.request.host}' "
+                f"or part of allowed hosts: {', '.join(allowed_hosts)}"
+            )
+            LOG.debug(message)
+            raise pyramid.httpexceptions.HTTPBadRequest(message)
+        if came_from:
+            raise pyramid.httpexceptions.HTTPFound(location=came_from)
+        return {"success": True}
+
+    def _ogc_server_clear_cache(self, ogc_server: main.OGCServer) -> None:
+        errors: set[str] = set()
+        url_internal_wfs, _, _ = self.get_url_internal_wfs(ogc_server, errors)
+        if errors:
+            LOG.error(
+                "Error while getting the URL of the OGC Server %s:\n%s", ogc_server.id, "\n".join(errors)
+            )
+            return
+        if url_internal_wfs is None:
+            return
+
+        asyncio.run(self._async_cache_invalidate_ogc_server_cb(ogc_server, url_internal_wfs))
+
+    async def _async_cache_invalidate_ogc_server_cb(
+        self, ogc_server: main.OGCServer, url_internal_wfs: Url
+    ) -> None:
+        # Fill the cache
+        await self.preload_ogc_server(ogc_server, url_internal_wfs, False)
+
+        cache_invalidate_cb()
```

## c2cgeoportal_geoportal/views/tinyowsproxy.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2015-2021, Camptocamp SA
+# Copyright (c) 2015-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,15 +23,15 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 
 import logging
-from typing import Any, Dict, Optional, Set, Tuple
+from typing import Any
 
 import pyramid.request
 from defusedxml import ElementTree
 from pyramid.httpexceptions import HTTPBadRequest, HTTPForbidden, HTTPInternalServerError, HTTPUnauthorized
 from pyramid.view import view_config
 
 from c2cgeoportal_commons import models
@@ -50,31 +50,30 @@
 
 
 class TinyOWSProxy(OGCProxy):
     """Proxy for the tiny OWN server."""
 
     def __init__(self, request: pyramid.request.Request):
         OGCProxy.__init__(self, request, has_default_ogc_server=True)
+
+        assert models.DBSession is not None
         self.settings = request.registry.settings.get("tinyowsproxy", {})
 
         assert "tinyows_url" in self.settings, "tinyowsproxy.tinyows_url must be set"
         self.ogc_server = (
             models.DBSession.query(main.OGCServer)
             .filter(main.OGCServer.name == self.settings["ogc_server"])
             .one()
         )
 
         self.user = self.request.user
 
         # params hold the parameters we are going to send to TinyOWS
         self.lower_params = self._get_lower_params(dict(self.request.params))
 
-    def _get_wfs_url(self, errors: Set[str]) -> Optional[Url]:
-        return Url(self.settings.get("tinyows_url"))
-
     @view_config(route_name="tinyowsproxy")  # type: ignore
     def proxy(self) -> pyramid.response.Response:
         if self.user is None:
             raise HTTPUnauthorized(
                 "Authentication required", headers=[("WWW-Authenticate", 'Basic realm="TinyOWS"')]
             )
 
@@ -98,63 +97,58 @@
         if operation is None or operation == "":
             operation = "getcapabilities"
 
         if operation == "describefeaturetype":
             # for DescribeFeatureType we require that exactly one type-name
             # is given, otherwise we would have to filter the result
             if len(typenames) != 1:
-                raise HTTPBadRequest(
-                    "Exactly one type-name must be given for " "DescribeFeatureType requests"
-                )
+                raise HTTPBadRequest("Exactly one type-name must be given for DescribeFeatureType requests")
 
         if not self._is_allowed(typenames):
             raise HTTPForbidden("No access rights for at least one of the given type-names")
 
         # we want clients to cache GetCapabilities and DescribeFeatureType req.
         use_cache = method == "GET" and operation in ("getcapabilities", "describefeaturetype")
         cache_control = Cache.PRIVATE if use_cache else Cache.PRIVATE_NO
 
-        errors: Set[str] = set()
         url = Url(self.settings.get("tinyows_url"))
-        if url is None:
-            LOG.error("Error getting the URL:\n%s", "\n".join(errors))
-            raise HTTPInternalServerError()
 
         response = self._proxy_callback(
             operation,
             cache_control,
             url=url,
             params=dict(self.request.params),
             cache=use_cache,
             headers=self._get_headers(),
             body=self.request.body,
         )
         return response
 
-    def _is_allowed(self, typenames: Set[str]) -> bool:
+    def _is_allowed(self, typenames: set[str]) -> bool:
         """Check if the current user has the rights to access the given type-names."""
         writable_layers = set()
         for gmflayer in list(get_writable_layers(self.request, [self.ogc_server.id]).values()):
+            assert isinstance(gmflayer, main.LayerWMS)
             for ogclayer in gmflayer.layer.split(","):
                 writable_layers.add(ogclayer.lower())
         return typenames.issubset(writable_layers)
 
-    def _get_headers(self) -> Dict[str, str]:
+    def _get_headers(self) -> dict[str, str]:
         headers = OGCProxy.get_headers(self)
         if "tinyows_host" in self.settings:
             headers["Host"] = self.settings.get("tinyows_host")
         return headers
 
     def _proxy_callback(
         self, operation: str, cache_control: Cache, *args: Any, **kwargs: Any
     ) -> pyramid.response.Response:
         response = self._proxy(*args, **kwargs)
         content = response.content.decode()
 
-        errors: Set[str] = set()
+        errors: set[str] = set()
         url = super()._get_wfs_url(errors)
         if url is None:
             LOG.error("Error getting the URL:\n%s", "\n".join(errors))
             raise HTTPInternalServerError()
 
         if operation == "getcapabilities":
             content = filter_wfst_capabilities(content, url, self.request)
@@ -168,21 +162,21 @@
     @staticmethod
     def _filter_urls(content: str, online_resource: str, proxy_online_resource: str) -> str:
         if online_resource is not None and proxy_online_resource is not None:
             return content.replace(online_resource, proxy_online_resource)
         return content
 
     @staticmethod
-    def _parse_body(body: str) -> Tuple[str, Set[str]]:
+    def _parse_body(body: str) -> tuple[str, set[str]]:
         """Read the WFS-T request body and extract the referenced type-names and request method."""
         xml = ElementTree.fromstring(body)
         wfs_request = normalize_tag(xml.tag)
 
         # get the type names
-        typenames: Set[str] = set()
+        typenames: set[str] = set()
         for child in xml:
             tag = normalize_tag(child.tag)
             if tag == "typename":
                 typenames.add(child.text)
             elif tag in ("query", "lock", "update", "delete"):
                 typenames.add(child.get("typeName"))
             elif tag == "insert":
```

## c2cgeoportal_geoportal/views/vector_tiles.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2021, Camptocamp SA
+# Copyright (c) 2021-2024, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -23,14 +23,15 @@
 
 # The views and conclusions contained in the software and documentation are those
 # of the authors and should not be interpreted as representing official policies,
 # either expressed or implied, of the FreeBSD Project.
 
 import logging
 
+import sqlalchemy
 from pyramid.httpexceptions import HTTPNotFound
 from pyramid.request import Request
 from pyramid.response import Response
 from pyramid.view import view_config
 from tilecloud import TileCoord
 from tilecloud.grid.free import FreeTileGrid
 
@@ -44,14 +45,16 @@
     """All the views concerning the vector tiles."""
 
     def __init__(self, request: Request) -> None:
         self.request = request
 
     @view_config(route_name="vector_tiles")  # type: ignore
     def vector_tiles(self) -> Response:
+        assert DBSession is not None
+
         settings = self.request.registry.settings["vector_tiles"]
         grid = FreeTileGrid(settings["resolutions"], max_extent=settings["extent"], tile_size=256)
 
         layer_name = self.request.matchdict["layer_name"]
 
         z = int(self.request.matchdict["z"])
         x = int(self.request.matchdict["x"])
@@ -67,14 +70,14 @@
         if layer is None:
             raise HTTPNotFound(f"Not found any vector tile layer named {layer_name}")
 
         raw_sql = layer[0].format(
             envelope=f"ST_MakeEnvelope({minx}, {miny}, {maxx}, {maxy}, {settings['srid']})"
         )
 
-        result = DBSession.execute(raw_sql)
-        for row in result:
+        result = DBSession.execute(sqlalchemy.text(raw_sql))
+        for row in result:  # pylint: disable=not-an-iterable
             set_common_headers(self.request, "vector_tiles", Cache.PUBLIC)
             response = self.request.response
             response.content_type = "application/vnd.mapbox-vector-tile"
             response.body = row[0].tobytes()
             return response
```

## tests/__init__.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2019, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -44,24 +44,25 @@
     warnings.simplefilter("ignore", category=sqlalchemy.exc.SAWarning)
 
 
 class DummyRequest(PyramidDummyRequest):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.client_addr = "1.1.1.1"
-        self.referer = None
+        self.referrer = None
         if self.registry.settings is None:
             self.registry.settings = {}
 
 
 def setup_common():
     logging.getLogger("c2cgeoportal_geoportal").setLevel(logging.DEBUG)
 
     caching.init_region({"backend": "dogpile.cache.null"}, "std")
     caching.init_region({"backend": "dogpile.cache.null"}, "obj")
+    caching.init_region({"backend": "dogpile.cache.null"}, "ogc-server")
 
 
 def create_dummy_request(additional_settings=None, *args, **kargs):
     if additional_settings is None:
         additional_settings = {}
     request = DummyRequest(*args, **kargs)
     request.registry.settings = {
```

## tests/test_cachebuster.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2019, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -54,18 +54,18 @@
         from c2cgeoportal_geoportal.lib.cacheversion import CachebusterTween
 
         registry = pyramid.registry.Registry()
         registry.settings = {"cache_path": ["test"]}
         ctf = CachebusterTween(handler, registry)
         request = MyRequest("/test/123456/build.css")
         ctf(request)
-        self.assertEqual(request.path_info, "/test/build.css")
+        assert request.path_info == "/test/build.css"
 
     def test_noreplace(self):
         from c2cgeoportal_geoportal.lib.cacheversion import CachebusterTween
 
         registry = pyramid.registry.Registry()
         registry.settings = {"cache_path": ["test"]}
         ctf = CachebusterTween(handler, registry)
         request = MyRequest("/test2/123456/build.css")
         ctf(request)
-        self.assertEqual(request.path_info, "/test2/123456/build.css")
+        assert request.path_info == "/test2/123456/build.css"
```

## tests/test_caching.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2015-2019, Camptocamp SA
+# Copyright (c) 2015-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## tests/test_checker.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2019, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## tests/test_decimaljson.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2011-2019, Camptocamp SA
+# Copyright (c) 2011-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## tests/test_headerstween.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2018-2019, Camptocamp SA
+# Copyright (c) 2018-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## tests/test_i18n.py

```diff
@@ -24,8 +24,8 @@
     )
     def test_available_locale_names(self, isdir_mock, listdir_mock, exists_mock):
         locales = available_locale_names()
         self.assertEqual(set(locales), {"de", "en", "fr"})
 
     def test_available_locale_names_no_dir(self):
         locales = available_locale_names()
-        self.assertEqual(locales, [])
+        assert locales == []
```

## tests/test_init.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012-2019, Camptocamp SA
+# Copyright (c) 2012-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -27,14 +27,15 @@
 
 # pylint: disable=missing-docstring,attribute-defined-outside-init,protected-access
 
 
 from unittest import TestCase
 from unittest.mock import patch
 
+import pytest
 from c2c.template.config import config
 from pyramid import testing
 from tests import DummyRequest
 
 import c2cgeoportal_geoportal
 from c2cgeoportal_geoportal import (
     call_hook,
@@ -42,15 +43,14 @@
     default_user_validator,
     is_valid_referrer,
     set_user_validator,
 )
 
 
 class TestIncludeme(TestCase):
-
     config = None
 
     def setup_method(self, _):
         # the c2cgeoportal includeme function requires a number
         # of settings
         self.config = testing.setUp(
             settings={
@@ -81,79 +81,92 @@
 
     def test_set_user_validator_directive(self):
         self.config.include(c2cgeoportal_geoportal.includeme)
         self.assertTrue(self.config.set_user_validator.__func__.__docobj__ is set_user_validator)
 
     def test_default_user_validator(self):
         self.config.include(c2cgeoportal_geoportal.includeme)
-        self.assertEqual(self.config.registry.validate_user, default_user_validator)
+        assert self.config.registry.validate_user == default_user_validator
 
     def test_user_validator_overwrite(self):
         self.config.include(c2cgeoportal_geoportal.includeme)
 
         def custom_validator(username, password):
             del username  # Unused
             del password  # Unused
             return False
 
         self.config.set_user_validator(custom_validator)
-        self.assertEqual(self.config.registry.validate_user, custom_validator)
+        assert self.config.registry.validate_user == custom_validator
+
+
+@pytest.mark.parametrize(
+    "authorized,value,expected",
+    [
+        ("example.com", "http://example.com/app?k=v", True),
+        ("example.com", "http://example.com/app?k=v#link", True),
+        ("example.com", "http://example.com/app#link", True),
+        ("example.com", "http://example.com/app", True),
+        ("example.com", "http://example.com/app/", True),
+        ("example.com", "http://example.com/app/x/y", True),
+        ("example.com", "http://example.com/app/x/y", True),
+        ("example.com", "http://other.com", False),
+        ("example.com", "http://example.com.bad.org/app/x/y", False),
+        ("example.com:8080", "http://example.com:8080/app", True),
+        ("example.com:8080", "http://example.com/app", False),
+        ("example.com", "http://example.com:8080/app", False),
+        ("other.com", "http://example-test.com", True),
+    ],
+)
+def test_is_valid_referrer(authorized, value, expected):
+    r = DummyRequest()
+    r.referrer = value
+    r.host = "example-test.com"
+    assert is_valid_referrer(r, {"authorized_referers": [authorized]}) == expected
 
 
 class TestReferer(TestCase):
     """
-    Check that accessing something with a bad HTTP referer is equivalent to a not authenticated query.
+    Check that accessing something with a bad HTTP referrer is equivalent to a not authenticated query.
     """
 
     BASE1 = "http://example.com/app"
     BASE2 = "http://friend.com/app2"
-    SETTINGS = {"authorized_referers": [BASE1, BASE2]}
+    SETTINGS = {"authorized_referers": ["friend.com"]}
     USER = "toto"
 
-    def _get_user(self, to, ref, method="GET"):
+    def _get_user(self, to, ref, method="GET", host="example.com"):
         class MockRequest:
             def __init__(self, to, ref, method):
                 self.path_qs = to
-                self.referer = ref
+                self.referrer = ref
                 self.user_ = TestReferer.USER
                 self.method = method
+                self.host = host
 
-        config._config = {"schema": "main", "schema_static": "main_static", "srid": 21781}
+        config._config = {
+            "schema": "main",
+            "schema_static": "main_static",
+            "srid": 21781,
+            "authorized_referers": ["example.com"],
+        }
         get_user = create_get_user_from_request(self.SETTINGS)
         return get_user(MockRequest(to=to, ref=ref, method=method))
 
-    def test_match_url(self):
-        def match(reference, value, expected):
-            r = DummyRequest()
-            r.referer = value
-            self.assertEqual(is_valid_referrer(r, {"authorized_referers": [reference]}), expected)
-
-        match("http://example.com/app/", "http://example.com/app?k=v", True)
-        match("http://example.com/app/", "http://example.com/app?k=v#link", True)
-        match("http://example.com/app/", "http://example.com/app#link", True)
-        match("http://example.com/app/", "http://example.com/app", True)
-        match("http://example.com/app", "http://example.com/app/", True)
-        match("http://example.com/app", "http://example.com/app/x/y", True)
-        match("http://example.com", "http://example.com/app/x/y", True)
-        match("http://example.com", "http://other.com", False)
-        match("http://example.com", "https://example.com", False)
-        match("http://example.com/app", "http://example.com/", False)
-        match("http://example.com", "http://example.com.bad.org/app/x/y", False)
-
     def test_positive(self):
-        self.assertEqual(self._get_user(to=self.BASE1 + "/1", ref=self.BASE1), self.USER)
-        self.assertEqual(self._get_user(to=self.BASE1 + "/2", ref=self.BASE1 + "/3"), self.USER)
-        self.assertEqual(self._get_user(to=self.BASE1 + "/4", ref=self.BASE2 + "/5"), self.USER)
+        assert self._get_user(to=self.BASE1 + "/1", ref=self.BASE1) == self.USER
+        assert self._get_user(to=self.BASE1 + "/2", ref=self.BASE1 + "/3") == self.USER
+        assert self._get_user(to=self.BASE1 + "/4", ref=self.BASE2 + "/5") == self.USER
 
     def test_no_ref(self):
-        self.assertEqual(self._get_user(to=self.BASE1, ref=None), self.USER)
-        self.assertIsNone(self._get_user(to=self.BASE1, ref=""))
+        assert self._get_user(to=self.BASE1, ref=None) == self.USER
+        assert self._get_user(to=self.BASE1, ref="") is None
 
-        self.assertEqual(self._get_user(to=self.BASE1, ref=None, method="POST"), self.USER)
-        self.assertIsNone(self._get_user(to=self.BASE1, ref="", method="POST"))
+        assert self._get_user(to=self.BASE1, ref=None, method="POST") == self.USER
+        assert self._get_user(to=self.BASE1, ref="", method="POST") is None
 
     def test_bad_ref(self):
         self.assertIsNone(self._get_user(to=self.BASE1, ref="http://bad.com/hacker"))
 
 
 def hook(tracer):
     tracer["called"] = True
```

## tests/test_locale_negociator.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2019, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -35,35 +35,35 @@
 
 class TestLocalNegociator(TestCase):
     def test_lang_param(self):
         from c2cgeoportal_geoportal import locale_negotiator
 
         request = DummyRequest(params=dict(lang="fr"))
         lang = locale_negotiator(request)
-        self.assertEqual(lang, "fr")
+        assert lang == "fr"
 
     def test_lang_is_not_available(self):
         from pyramid.request import Request
         from pyramid.threadlocal import get_current_registry
 
         from c2cgeoportal_geoportal import locale_negotiator
 
         request = Request.blank("/")
         request.registry = get_current_registry()
         request.registry.settings = {"default_locale_name": "de", "available_locale_names": ["de", "es"]}
 
         request.headers["accept-language"] = "en-us,en;q=0.3,fr;q=0.7"
         lang = locale_negotiator(request)
-        self.assertEqual(lang, "de")
+        assert lang == "de"
 
     def test_lang_is_available(self):
         from pyramid.request import Request
         from pyramid.threadlocal import get_current_registry
 
         from c2cgeoportal_geoportal import locale_negotiator
 
         request = Request.blank("/")
         request.registry = get_current_registry()
         request.registry.settings = {"default_locale_name": "de", "available_locale_names": ["de", "es"]}
         request.accept_language = "en-us,en;q=0.3,es;q=0.7"
         lang = locale_negotiator(request)
-        self.assertEqual(lang, "es")
+        assert lang == "es"
```

## tests/test_mapserverproxy_route_predicate.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2019, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -33,15 +33,14 @@
 from pyramid.request import Request
 from pyramid.threadlocal import get_current_registry
 
 from c2cgeoportal_geoportal import MapserverproxyRoutePredicate
 
 
 class TestMapserverproxyRoutePredicate(TestCase):
-
     predicate = MapserverproxyRoutePredicate(None, None)
 
     def test_hide_capabilities_unset(self):
         request = Request.blank("/test")
         request.registry = get_current_registry()
         request.registry.settings = {}
         self.assertTrue(self.predicate(None, request))
```

## tests/test_raster.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2021, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -49,17 +49,17 @@
             }
         }
         raster = Raster(request)
 
         request.params["lon"] = "565000"
         request.params["lat"] = "218000"
         result = raster.raster()
-        self.assertEqual(result["dem1"], None)
-        self.assertEqual(result["dem2"], None)
-        self.assertEqual(result["dem3"], None)
+        assert result["dem1"] == None
+        assert result["dem2"] == None
+        assert result["dem3"] == None
 
         request.params["lon"] = "548000"
         request.params["lat"] = "216000"
         result = raster.raster()
         self.assertAlmostEqual(result["dem1"], Decimal("1171.6"))
         self.assertAlmostEqual(result["dem2"], Decimal("1172"))
         self.assertAlmostEqual(result["dem3"], Decimal("1171.62"))
@@ -93,35 +93,35 @@
         }
         raster = Raster(request)
 
         # Upper left
         request.params["lon"] = "547990.0"
         request.params["lat"] = "216009.1"
         result = raster.raster()
-        self.assertEqual(result["dem5"], Decimal("1164.2"))
+        assert result["dem5"] == Decimal("1164.2")
         request.params["lon"] = "547990.9"
         request.params["lat"] = "216010.0"
         result = raster.raster()
-        self.assertEqual(result["dem5"], Decimal("1164.2"))
+        assert result["dem5"] == Decimal("1164.2")
 
         # Lower right
         request.params["lon"] = "547996.0"
         request.params["lat"] = "216003.1"
         result = raster.raster()
-        self.assertEqual(result["dem5"], Decimal("1180.77"))
+        assert result["dem5"] == Decimal("1180.77")
         request.params["lon"] = "547996.9"
         request.params["lat"] = "216004.0"
         result = raster.raster()
-        self.assertEqual(result["dem5"], Decimal("1180.77"))
+        assert result["dem5"] == Decimal("1180.77")
 
         # Out
         request.params["lon"] = "547997.4"
         request.params["lat"] = "216003.5"
         result = raster.raster()
-        self.assertEqual(result["dem5"], None)
+        assert result["dem5"] == None
 
     def test_raster_vrt(self):
         from decimal import Decimal
 
         from tests import DummyRequest
 
         from c2cgeoportal_geoportal.views.raster import Raster
@@ -138,15 +138,15 @@
         }
         raster = Raster(request)
 
         # Upper left
         request.params["lon"] = "547990.4"
         request.params["lat"] = "216009.5"
         result = raster.raster()
-        self.assertEqual(result["dem6"], Decimal("1164.2"))
+        assert result["dem6"] == Decimal("1164.2")
 
     def test_absolute_path(self):
         import fiona
 
         with fiona.open("/opt/c2cgeoportal/geoportal/tests/data/dem_absolute.shp") as collection:
             tiles = [e for e in collection.filter(mask={"type": "Point", "coordinates": [548000, 216000]})]
 
@@ -173,15 +173,15 @@
         profile = Profile(request)
 
         request.params["nbPoints"] = "3"
         request.params["geom"] = (
             '{"type":"LineString",' '"coordinates":[[548009.5,215990],[547990,216009.5]]}'
         )
         result = profile.json()
-        self.assertEqual(len(result["profile"]), 4)
+        assert len(result["profile"]) == 4
         self.assertAlmostEqual(result["profile"][0]["y"], 215990)
         self.assertAlmostEqual(result["profile"][0]["values"]["dem2"], None)
         self.assertAlmostEqual(result["profile"][0]["values"]["dem"], None)
         self.assertAlmostEqual(result["profile"][0]["dist"], Decimal("0.0"))
         self.assertAlmostEqual(result["profile"][0]["x"], 548009.5)
         self.assertAlmostEqual(result["profile"][1]["y"], 215996.5)
         self.assertAlmostEqual(result["profile"][1]["values"]["dem2"], 1181)
@@ -197,15 +197,15 @@
         self.assertAlmostEqual(result["profile"][3]["values"]["dem"], 1164)
         self.assertAlmostEqual(result["profile"][3]["values"]["dem2"], 1164)
         self.assertAlmostEqual(result["profile"][3]["dist"], Decimal("27.6"))
         self.assertAlmostEqual(result["profile"][3]["x"], 547990.0)
 
         request.params["layers"] = "dem"
         result = profile.json()
-        self.assertEqual(len(result["profile"]), 4)
+        assert len(result["profile"]) == 4
         self.assertAlmostEqual(result["profile"][0]["y"], 215990)
         self.assertAlmostEqual(result["profile"][0]["values"]["dem"], None)
         self.assertAlmostEqual(result["profile"][0]["dist"], Decimal("0.0"))
         self.assertAlmostEqual(result["profile"][0]["x"], 548009.5)
         self.assertAlmostEqual(result["profile"][1]["y"], 215996.5)
         self.assertAlmostEqual(result["profile"][1]["values"]["dem"], 1181)
         self.assertAlmostEqual(result["profile"][1]["dist"], Decimal("9.2"))
@@ -218,34 +218,34 @@
         self.assertAlmostEqual(result["profile"][3]["values"]["dem"], 1164)
         self.assertAlmostEqual(result["profile"][3]["dist"], Decimal("27.6"))
         self.assertAlmostEqual(result["profile"][3]["x"], 547990.0)
 
         # test length = 0
         request.params["geom"] = '{"type":"LineString",' '"coordinates":[[548000,216000]]}'
         result = profile.json()
-        self.assertEqual(len(result["profile"]), 1)
+        assert len(result["profile"]) == 1
         self.assertAlmostEqual(result["profile"][0]["y"], 216000)
         self.assertAlmostEqual(result["profile"][0]["values"]["dem"], 1172)
         self.assertAlmostEqual(result["profile"][0]["dist"], Decimal("0.0"))
         self.assertAlmostEqual(result["profile"][0]["x"], 548000)
 
         # test cur_nb_points < 1
         request.params["geom"] = (
             '{"type":"LineString",' '"coordinates":[[548000,216000],[548001,216001],[548009,216009]]}'
         )
         result = profile.json()
-        self.assertEqual(len(result["profile"]), 5)
+        assert len(result["profile"]) == 5
         self.assertAlmostEqual(result["profile"][0]["y"], 216000)
         self.assertAlmostEqual(result["profile"][0]["values"]["dem"], 1172)
         self.assertAlmostEqual(result["profile"][0]["dist"], Decimal("0.0"))
         self.assertAlmostEqual(result["profile"][0]["x"], 548000)
         self.assertAlmostEqual(result["profile"][1]["y"], 216001.0)
         self.assertAlmostEqual(result["profile"][1]["values"]["dem"], 1167)
         self.assertAlmostEqual(result["profile"][1]["dist"], Decimal("1.4"))
-        self.assertEqual(result["profile"][1]["x"], 548001.0)
+        assert result["profile"][1]["x"] == 548001.0
         self.assertAlmostEqual(result["profile"][2]["y"], 216003.66666666666)
         self.assertAlmostEqual(result["profile"][2]["values"]["dem"], 1155)
         self.assertAlmostEqual(result["profile"][2]["dist"], Decimal("5.2"))
         self.assertAlmostEqual(result["profile"][2]["x"], 548003.6666666666)
         self.assertAlmostEqual(result["profile"][3]["y"], 216006.33333333334)
         self.assertAlmostEqual(result["profile"][3]["values"]["dem"], 1154)
         self.assertAlmostEqual(result["profile"][3]["dist"], Decimal("9"))
```

## tests/test_wmstparsing.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2013-2019, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
@@ -117,63 +117,63 @@
 
 
 class TestParseDate(TestCase):
     def test_parse_date_year(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         date = _parse_date("2010")
-        self.assertEqual("year", date[0])
+        assert "year" == date[0]
         self.assertEqual(datetime.datetime(2010, 0o1, 0o1, tzinfo=isodate.UTC), date[1])
 
     def test_parse_date_month(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         date = _parse_date("2010-02")
-        self.assertEqual("month", date[0])
+        assert "month" == date[0]
         self.assertEqual(datetime.datetime(2010, 0o2, 0o1, tzinfo=isodate.UTC), date[1])
 
     def test_parse_date(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         date = _parse_date("2010-02-03")
-        self.assertEqual("day", date[0])
+        assert "day" == date[0]
         self.assertEqual(datetime.datetime(2010, 0o2, 0o3, tzinfo=isodate.UTC), date[1])
 
     def test_parse_datetime(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         date = _parse_date("2010-02-03T12:34")
-        self.assertEqual("second", date[0])
+        assert "second" == date[0]
         self.assertEqual(datetime.datetime(2010, 0o2, 0o3, 12, 34, tzinfo=isodate.UTC), date[1])
 
     def test_parse_datetime_tz(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         date = _parse_date("2010-02-03T12:34Z")
-        self.assertEqual("second", date[0])
+        assert "second" == date[0]
         self.assertEqual(datetime.datetime(2010, 0o2, 0o3, 12, 34, tzinfo=isodate.UTC), date[1])
 
     def test_unsupported_format(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_date
 
         self.assertRaises(ValueError, _parse_date, "2010-02-03 12:34")
 
 
 class TestFormat(TestCase):
     def test_format(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _format_date
 
         dt = datetime.datetime(2010, 0o2, 0o1, 00, 00)
-        self.assertEqual("2010-02-01T00:00:00Z", _format_date(dt))
+        assert "2010-02-01T00:00:00Z" == _format_date(dt)
 
     def test_format_tz(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _format_date, _parse_date
 
         dt = _parse_date("2010-02-03T12:34:00+01:00")
-        self.assertEqual("2010-02-03T12:34:00+01:00", _format_date(dt[1]))
+        assert "2010-02-03T12:34:00+01:00" == _format_date(dt[1])
 
 
 class TestParseDuration(TestCase):
     def test_year(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import _parse_duration
 
         self.assertEqual((2, 0, 0, 0), _parse_duration("P2Y"))
@@ -215,17 +215,17 @@
     def test_merge_modes(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import TimeInformation
 
         ti = TimeInformation()
         self.assertFalse(ti.has_time())
         self.assertTrue(ti.to_dict() is None)
         ti.merge_mode("single")
-        self.assertEqual(ti.mode, "single")
+        assert ti.mode == "single"
         ti.merge_mode("single")
-        self.assertEqual(ti.mode, "single")
+        assert ti.mode == "single"
 
     def test_merge_different_modes(self):
         from c2cgeoportal_geoportal.lib.wmstparsing import TimeInformation
 
         ti = TimeInformation()
         ti.merge_mode("single")
         self.assertRaises(ValueError, ti.merge_mode, "range")
```

## tests/xmlstr.py

```diff
@@ -1,10 +1,8 @@
-# -*- coding: utf-8 -*-
-
-# Copyright (c) 2013-2019, Camptocamp SA
+# Copyright (c) 2013-2023, Camptocamp SA
 # All rights reserved.
 
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 
 # 1. Redistributions of source code must retain the above copyright notice, this
 #    list of conditions and the following disclaimer.
```

## Comparing `c2cgeoportal_geoportal-2.7.1.83.dist-info/METADATA` & `c2cgeoportal_geoportal-2.9.dist-info/METADATA`

 * *Files 9% similar despite different names*

```diff
@@ -1,61 +1,61 @@
 Metadata-Version: 2.1
 Name: c2cgeoportal-geoportal
-Version: 2.7.1.83
+Version: 2.9
 Summary: c2cgeoportal geoportal
 Home-page: https://github.com/camptocamp/c2cgeoportal/
 Author: Camptocamp
 Author-email: info@camptocamp.com
+License: UNKNOWN
 Keywords: web gis geoportail c2cgeoportal geocommune pyramid
+Platform: UNKNOWN
 Classifier: Development Status :: 6 - Mature
 Classifier: Environment :: Web Environment
 Classifier: Framework :: Pyramid
 Classifier: Intended Audience :: Other Audience
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.10
 Classifier: Topic :: Scientific/Engineering :: GIS
 Classifier: Typing :: Typed
+Requires-Python: >=3.10
+Description-Content-Type: text/markdown
+Requires-Dist: Fiona
+Requires-Dist: GeoAlchemy2
+Requires-Dist: Mako
+Requires-Dist: OWSLib (>=0.6.0)
+Requires-Dist: PyYAML
+Requires-Dist: SQLAlchemy
+Requires-Dist: Shapely
 Requires-Dist: alembic
 Requires-Dist: bottle
 Requires-Dist: c2cgeoportal-commons[upgrade]
 Requires-Dist: c2cwsgiutils
-Requires-Dist: c2c.template (>=2.0.7)
 Requires-Dist: defusedxml
 Requires-Dist: dogpile.cache (>=0.6)
-Requires-Dist: Fiona
-Requires-Dist: GeoAlchemy2
 Requires-Dist: geojson
 Requires-Dist: isodate
 Requires-Dist: lingua
-Requires-Dist: Mako
-Requires-Dist: OWSLib (>=0.6.0)
 Requires-Dist: papyrus
 Requires-Dist: psycopg2
 Requires-Dist: pycryptodome
 Requires-Dist: pyotp
 Requires-Dist: pyramid
 Requires-Dist: pyramid-debugtoolbar
 Requires-Dist: pyramid-mako
 Requires-Dist: pyramid-multiauth
 Requires-Dist: pyramid-tm
 Requires-Dist: python-dateutil
-Requires-Dist: PyYAML
 Requires-Dist: rasterio
-Requires-Dist: requests
 Requires-Dist: redis
-Requires-Dist: Shapely
-Requires-Dist: SQLAlchemy
+Requires-Dist: requests
 Requires-Dist: transaction
-Requires-Dist: jinja2 (>=2.11.3)
-Requires-Dist: pygments (>=2.7.4)
-Requires-Dist: setuptools (>=65.5.1)
-Requires-Dist: requests (>=2.31.0)
 
 c2cgeoportal is the server part of `GeoMapFish <http://geomapfish.org/>`_,
 the client part is `ngeo <https://github.com/camptocamp/ngeo/>`_.
 
 Read the `Documentation <https://camptocamp.github.io/c2cgeoportal/master/>`_.
 
 `Sources <https://github.com/camptocamp/c2cgeoportal/>`_
+
```

## Comparing `c2cgeoportal_geoportal-2.7.1.83.dist-info/entry_points.txt` & `c2cgeoportal_geoportal-2.9.dist-info/entry_points.txt`

 * *Files 1% similar despite different names*

```diff
@@ -22,7 +22,8 @@
 c2cgeoportal+ini = c2cgeoportal_geoportal.lib.loader:Loader
 
 [pyramid.scaffold]
 c2cgeoportal_advance_create = c2cgeoportal_geoportal.scaffolds:TemplateAdvanceCreate
 c2cgeoportal_advance_update = c2cgeoportal_geoportal.scaffolds:TemplateAdvanceUpdate
 c2cgeoportal_create = c2cgeoportal_geoportal.scaffolds:TemplateCreate
 c2cgeoportal_update = c2cgeoportal_geoportal.scaffolds:TemplateUpdate
+
```

## Comparing `c2cgeoportal_geoportal-2.7.1.83.dist-info/RECORD` & `c2cgeoportal_geoportal-2.9.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,185 +1,192 @@
-c2cgeoportal_geoportal/__init__.py,sha256=9s5YOvb5qlaQf_TmonFKXMwx6a-pLAG2brbRrb4Kbuc,32401
+c2cgeoportal_geoportal/__init__.py,sha256=6w39HV0M0GBROVvF7Ljf_TFcrr1ca6Psf8G3k-3hCYk,34096
 c2cgeoportal_geoportal/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-c2cgeoportal_geoportal/resources.py,sha256=6CMHJveA-nDBNHBO0MudHCu2tn0AdKXmLKrTv8Ulz08,2182
-c2cgeoportal_geoportal/lib/__init__.py,sha256=jsDLoTJT5ZTZuXB7tuAgprayqzzORyC3dbGyqNQnbvE,10290
-c2cgeoportal_geoportal/lib/authentication.py,sha256=OlqVnfzNeSrA7cnCTk3hPkSNEWBBrTtwb2KifcsLSU4,8997
+c2cgeoportal_geoportal/resources.py,sha256=n42Gns8DKw32GstDoUdNgud6xdAidaRwgAuNHqGH-c4,2158
+c2cgeoportal_geoportal/lib/__init__.py,sha256=AZFDoUZOBu8ul6KhJ8wiEqdTb8O4aDjAKQMRUUWW1Jk,10331
+c2cgeoportal_geoportal/lib/authentication.py,sha256=SbOR6eYJhP6AU4cq7t5miAIFiaOL7wKWpYUUJQycvls,8899
 c2cgeoportal_geoportal/lib/bashcolor.py,sha256=LQgOgtFUvgJ4Ed3-YW3RPjvhBMZBbXBBkUZKE4unRCI,1889
-c2cgeoportal_geoportal/lib/cacheversion.py,sha256=M_0Ci0HPQASkcHbnvG33G9SOsFdRMKSHUP5G5Yt1yvI,2948
-c2cgeoportal_geoportal/lib/caching.py,sha256=rA-WnWgkX_iBmxhoz_WdDL37VSjjSXsLnRqdgKx1QFU,6688
-c2cgeoportal_geoportal/lib/check_collector.py,sha256=-x5iFUMw0NfPalG1RI6WoKTiW1BlUvHTiAJy_2mMu2s,3414
-c2cgeoportal_geoportal/lib/checker.py,sha256=ZdpACmoeeiNO16wM0oZc3bHkXgH8-0lYpWa7b_-937E,12323
-c2cgeoportal_geoportal/lib/common_headers.py,sha256=qwIWaNA_wMeJ2UrbtBFG0v3R26HgEn8npBRtSbjeyTE,6458
-c2cgeoportal_geoportal/lib/dbreflection.py,sha256=XWShaJrAE2vDAzAh-z2YfIVBrGiIzJ_WZEzd2Thne5I,9629
-c2cgeoportal_geoportal/lib/filter_capabilities.py,sha256=jsmP6yiIE6nuT2pbP32CudrSx0wgC-S_NVZcSfpKmUU,14172
-c2cgeoportal_geoportal/lib/fulltextsearch.py,sha256=6mUdf4EydFiI7gjx2vmcc4yyRRFs4cH3gg_XdBePAww,2271
-c2cgeoportal_geoportal/lib/functionality.py,sha256=DqqLx3dwBY7QxpQgcDGh8NuxE1-sWVuSPk5k3bNE2bM,6293
+c2cgeoportal_geoportal/lib/cacheversion.py,sha256=OgQccoLGKNs8VAVizR2cedV6XtnZkBHpeFkahkS9g1o,2919
+c2cgeoportal_geoportal/lib/caching.py,sha256=u61HnMh5_45EN12Zl2BJ4cXo09gANP6_LfmSSdxj8Jo,7165
+c2cgeoportal_geoportal/lib/check_collector.py,sha256=48MCnvwM_q-gf5IoTL7ygXJKDr7MX0aSeIwU5in_gqU,3408
+c2cgeoportal_geoportal/lib/checker.py,sha256=vn9CapmBNRnP7PCsLkdp074chHGYhtdU_Dy5UFYWDPg,12598
+c2cgeoportal_geoportal/lib/common_headers.py,sha256=rZ8zKlocxLUfwd0_7JZeS5W-1d62rFvO1IP33jGxpPI,6488
+c2cgeoportal_geoportal/lib/dbreflection.py,sha256=xW7sAJt8ZTom5JjyOVl-51dyCYltsq8081STyOJ9T3Q,9800
+c2cgeoportal_geoportal/lib/filter_capabilities.py,sha256=00Zd2ZJrtv8fCjsbSIv5hm_XgzKWz6uyuIY9Kj_VprM,14271
+c2cgeoportal_geoportal/lib/fulltextsearch.py,sha256=DrqO51QbDp56VpZa__2-8vp8U39izvLpyGhRCLTCaYc,2265
+c2cgeoportal_geoportal/lib/functionality.py,sha256=WGvuh7rVIuCakIMyYqU0Hjpm0VRo2Zyxj7j57dU7Jtk,6298
 c2cgeoportal_geoportal/lib/headers.py,sha256=d6lelDs1fDh5xO8Dz34r-TRgSETY2bb1eEIDuk6FJHM,2622
-c2cgeoportal_geoportal/lib/i18n.py,sha256=VB1xn7c_jV-E10vvphM_h14gzSk1q5_G26BcJDSOtfE,1876
-c2cgeoportal_geoportal/lib/layers.py,sha256=P-ZMC63gKdGmiTDn0WP2ZB3AJGGL05YhuckVzaayXTY,4655
-c2cgeoportal_geoportal/lib/lingua_extractor.py,sha256=VBW05twqBlMFtVUzoPKKYkkYBOKqxET27UOt7_SlSBY,36888
-c2cgeoportal_geoportal/lib/loader.py,sha256=VXT8N0Upzwydi_TZkBLj9j75V7BTfR1GxzXEABXsTQ8,2546
-c2cgeoportal_geoportal/lib/metrics.py,sha256=j1vmGEqV7RtIwk2w83bUHvAnkk_nSPDsoFHjqDsLiSU,4524
-c2cgeoportal_geoportal/lib/oauth2.py,sha256=8IJ4tKIzxbX9wfHBMMajyQt_SQrGgj64ZHqIirDbJSY,37216
-c2cgeoportal_geoportal/lib/wmstparsing.py,sha256=YTfXRUxbRHys6jhmIhtpBJq-xrSYLqkLBfi33kAiXbY,12423
-c2cgeoportal_geoportal/lib/xsd.py,sha256=vInVayMaucYZx9Hz4TBSN1jlSNza4H6hpPI0_W6-k0o,6043
+c2cgeoportal_geoportal/lib/i18n.py,sha256=MoEPu4mj02KeuTJQDA1Y1btK6Ll7d089dzjRTLmedfs,1852
+c2cgeoportal_geoportal/lib/layers.py,sha256=kh4NxqaEq_kqiNWH6_DGZVD5ycv-rbMpobIJOd_FcD8,4943
+c2cgeoportal_geoportal/lib/lingua_extractor.py,sha256=JE2LLWOeWGPp-Vaq7hAOV8sBXCNxWAOba5PQoHAPsA4,37438
+c2cgeoportal_geoportal/lib/loader.py,sha256=41_LDYiN6rWAFdktKNKbBPlO0mJINPB4N43yvm-_gqc,2628
+c2cgeoportal_geoportal/lib/metrics.py,sha256=5HryUs6Rk6cmVvag5_FN-W2gcwsyJt3Xf9105TSO4mQ,4847
+c2cgeoportal_geoportal/lib/oauth2.py,sha256=WKRmHO93cY67o6pUOD9xRF0HXgTCUumbpro36tXeg_8,41090
+c2cgeoportal_geoportal/lib/wmstparsing.py,sha256=TDYsQ3WlN3795Ov2jrM76RRHg9wUAyzjfWLF5G-Id48,12399
+c2cgeoportal_geoportal/lib/xsd.py,sha256=sEFM9dCwXAKCIhjAFKW88C_3p0ys0AdDh53q5PlPpTQ,6173
 c2cgeoportal_geoportal/scaffolds/advance_create/cookiecutter.json,sha256=1LVOM-j_nd00J89q0EI3bQUvIysbidApaVHDibA2ydk,524
 c2cgeoportal_geoportal/scaffolds/advance_create/ci/config.yaml,sha256=LiDYqdnRyOXmGoSuvjMBxwfL7tYd1i1PXx5u8TU-Hs8,592
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.dockerignore,sha256=rPtGQNYXYoj-D94VwnVT_x-HvqldTNoz2oT7DjGpyqk,147
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.eslintrc.yaml,sha256=txdVU8ikuADtWxCHWjyOBtT8wiXzf-LhT9ZMVtBiwhY,241
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/.prospector.yaml,sha256=OI6NLGh_3tp2-GOvcX2mzVKGwnHU-KG8S8p-BGt_zmY,325
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Dockerfile,sha256=DAXA2MYs6ammgocOMOsxPNLShaa9pPaH3XzNkWvIzSU,2567
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Dockerfile,sha256=SlCcdNe2ajQ0ZSN-Z6Q9bDK4KkQPt9K-US36F8Nw9Ns,2561
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/Makefile,sha256=ctHZV0-kh9voLpmgVK_ya68GI5VAKmxN9UiZVZKPyBo,147
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.ini,sha256=KpgEj3uVRBdgiTjaQDqUjy_C0z5s8t2DUPFPTUSm7_w,985
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/alembic.yaml,sha256=9HMFJ_UekLUzXM5bPtixNNkeHMalo50hKjkxM_2tG2E,458
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/development.ini,sha256=62pVRUxGPkxDZJktkureizEjyP3K4McQB4X7noDVzA8,3068
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/gunicorn.conf.py,sha256=8T4TWZyQOHt4Lukuv9XDOaXHZORjKtUjqwvYfAn9lJI,4129
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/development.ini,sha256=NNBSPTGrK9D5kwR1WV1yV1wXQuPFBSQG5QkW16-OcVo,3042
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/gunicorn.conf.py,sha256=CmhZ6m4l3GgiF_Wwm9wfSUuot6DKFSkttmb-ZW_U1Vk,4999
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/language_mapping,sha256=jZNiCuWh5-LsU0oDmNviVfNyNqZibBXNc_rsv_OpUuE,27
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-client.cfg,sha256=Q5OugT3Ns7HEFxcBCejDHEkMtEUGhk__6-yONGg2ImM,117
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/lingua-server.cfg,sha256=1mRNwhmqmxlJwKucLauitmY9MHgWAyCr4N6TaqHkKsU,107
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/production.ini,sha256=ptWxF3jAE1A3IAQ7KdYSpGbPdAm3g-S-SIFXdZuFk3o,1137
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/requirements.txt,sha256=UBEL-rSwDi2z7Q7RMYTqLKNgHxrgohoBmoTlKRMTCUU,57
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/requirements.txt,sha256=n6hSj_r5f8NmSamv1Jo7Ly6bxby8ziEeXoMmY_psgtY,55
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/setup.py,sha256=dZ-f23wZNh4TuHXCmyHRrlWR0kTVN3PKTT1FQilDeDk,694
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tsconfig.json,sha256=NBfOaqGnwNeVW7Z9Yk3eHeX9NhqA7MteCb3oS3DKJXk,186
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.api.js,sha256=NvT4Zf2OJ9pFrbPq1s1peTbHv1HaZZhC6gCj5aTgGCA,1769
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.apps.js,sha256=kC_M97UW0nzSDL3c3gMO0rFm1qzDuOK0GgVK73wq2i0,2438
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.api.js,sha256=-EU0m2mrBLePj7xxHpPTe3pa1tG0z1JmRlRO_hmf_6k,1966
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.apps.js,sha256=mP0pjYtgKVvaLDhaVSzBUJIseVvdS_kbQL1yNMokrQQ,2472
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.commons.js,sha256=-sHSSMcvPSbZAwmBYAp6RK-iQgwn0vrySTkFe3Pvero,553
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/webpack.config.js,sha256=IFHj1YVu2aitTtQWVV6E5BaU0YDHz1qeoixaLbtRXPA,643
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/tools/extract-messages.js,sha256=FWT7FwFg5HOmtgO5H9W5MTeWI30TfcBeeSnyiMvP2oo,1201
-c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py,sha256=aoVN3PZLKHHzHBzgNKzW-DhSZoJPwzC0nHKpc3NEQl8,1587
+c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/__init__.py,sha256=GEqdw3Q7gov4KlUsZNcEIbk86HipezUMVHTzzQJSdBk,1282
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/authentication.py,sha256=mjPjpZfgPPeMneKe4u95aPYIJlWcUpbSsR5-3ObWirA,426
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/dev.py,sha256=2Et_4LUWO_82DAYsPxEnH5yCX0YVY2XPhv9pzOTl8Zs,387
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/models.py,sha256=_IYgNpp7ZRKcH30eo-d--qbb11ojx7Tv2qJdVGIlsjQ,284
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/multi_organization.py,sha256=qNxledzv8JeIWTFFF8-XO163qmxztiBY_NhxLvEOCAM,158
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/resources.py,sha256=8Ey8_zvzge1A9yid7LDggHZlulbWsm21gM6Mf9LgzlI,270
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/subscribers.py,sha256=8ChZ7xVzcaOqRXIErrO4JtJqEnGWJ3y1C6Tu0ExjwGs,1352
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/api/index.js,sha256=rxXFRQeGxBTLmhOUmFpIaGZda1Gk5Qi_VsXdbaOfwXo,260
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static-ngeo/js/{{cookiecutter.package}}module.js,sha256=TYZUcLOinHKhzn-l35pwqe0kNOhX90TzFOVj1KyaVaI,614
 c2cgeoportal_geoportal/scaffolds/advance_create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/views/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 c2cgeoportal_geoportal/scaffolds/advance_update/cookiecutter.json,sha256=1LVOM-j_nd00J89q0EI3bQUvIysbidApaVHDibA2ydk,524
-c2cgeoportal_geoportal/scaffolds/advance_update/{{cookiecutter.project}}/geoportal/CONST_Makefile,sha256=7TcsromZPyreV_kQFVqt4r7rFHiiF09M-3JPm7iOKkA,4287
+c2cgeoportal_geoportal/scaffolds/advance_update/{{cookiecutter.project}}/geoportal/CONST_Makefile,sha256=0s9CTP21J_Y5bBuCoGZKEvSI4PPrmguf66UCN2WP6KI,3993
 c2cgeoportal_geoportal/scaffolds/create/cookiecutter.json,sha256=1LVOM-j_nd00J89q0EI3bQUvIysbidApaVHDibA2ydk,524
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.dockerignore,sha256=aU-IzKK1qmFAJNiCLYT6yB6LVTEsDBcO5nBW3q8M-MQ,351
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.editorconfig,sha256=cpHwgH23FLEQ6gV2O0Xa-iKxCaaVHhTKiFA91moh1sQ,297
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.gitignore,sha256=NNaSfLn7_4sIXta39BzRfGQJfUqBq-U4lbgtkXStgkY,449
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.pre-commit-config.yaml,sha256=0ZYa8KRkUPB-W_g9EGJ_I8UCRGrSkcVbgOzAw3pLCa0,773
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierignore,sha256=PcDfauWwzv1pnJgC9HR1zvv06Q01CwzGzzc0iLSNcZk,9
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.prettierrc.yaml,sha256=WbjZCtw0hBlDB2FYJanFJzAvUsNTxgwn62YBZ-Xbwkw,43
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile,sha256=I7zAT84Zl0wnySi-tNtdcmEAKwdJE_EssMRh0cYpygU,3360
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Makefile,sha256=XIQPnoU13Rbs2aW4o_J-XCS1VJb_AaEw4RB6X7FYgCI,715
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst,sha256=PvydIFv4NS8CMqmLrCTm2TvIS0GNkWgiI-VwQvWBF5o,423
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build,sha256=wQlAoqaLdWq5LovlQmBPZ074GQOm2j9b3KbfK5seKzI,6167
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml,sha256=5RIgWl2euVaLISVCrNQaFZlVlslLPcDVK8YEZCYzHE4,12310
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml,sha256=xmO_qOwrz1Ebwv6sUsf3MDZ90yIGdLlxXp7kqditos4,2526
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml,sha256=BHj_UT6RpGEz-sue2MrTVOCENtKYSWZ_YTSbp5ud28E,2429
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default,sha256=yQZ3xFUFnn6gDXNkRyCRrduKtZqSM5VvcZAalk9oC74,2573
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.project,sha256=ka5r1Lv081fSIjGzGxQS9Jeck1CvK9bjYl-qEzCSapQ,1537
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Dockerfile,sha256=ASxEFbS3N5sfg4JdxUMf9xnsywP9wKylqZ9T-hSJaNk,3163
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/Makefile,sha256=Z_afZKPzCAOPjRc80BPh39yjYOmlNNVeAfWzcAxOP8w,3079
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/README.rst,sha256=QJcaUtT05atb5x8SJYflSt0YIJkbAz0Zh39_FYtyFks,423
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/build,sha256=CjYe1cIL-TsKPbdxy1zStTUEGguILXpyUC63X2_Cy8c,7010
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-db.yaml,sha256=JE5fBz3d3kYoBeUbCDvbKYNhu8QOzD0KLDeJD8AKMZI,534
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-lib.yaml,sha256=JvKjynSM2cEC-CgJKAGSBuSikiFLtqsI281-TtOBi1E,12962
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose-qgis.yaml,sha256=jllE7NrAnwljsyknDZWYl2FA9s-R-K_KBaJS3ubhJZE,590
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.override.sample.yaml,sha256=Pt1oPeHvIDkqO7EjYUPRffbSMQGbUPZQJxqcnPX1iiA,2522
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/docker-compose.yaml,sha256=jUpbs89PVJCRTQ6KFSUnfFE_RxHt9r787lIFtbmi_aQ,2396
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.default,sha256=ThvJkKm-Q1pWoC9bOyutULthuKFR90v0d0LoB5xpy-Y,3129
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/env.project,sha256=EoeIag5EnozSNMSETW7G9-dGPnG5NIfRhcxU5ihM_rU,2070
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/project.yaml,sha256=3tNtVcoIug5LNZoZsUpjm_YRCZQMAKzYWNL9ZdjkPC8,495
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/pyproject.toml,sha256=SLg_mHQE8AqfBREmQ7bdGI9PrWALqfgeHazoqOt4Ma0,57
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/run_alembic.sh,sha256=NuOhKZtrcv-UWVDkmTiNaT6Wcls9fXoHcO0oQjAdI6o,233
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/pyproject.toml,sha256=RnvMmtD40v3rju1HoIOX7pQfVHUKPptxaVDoZxuF7oU,107
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/run_alembic.sh,sha256=VcrDFPAGlrxXtn4N8RcPhI90uZ8shDrGowALuwx8gnM,235
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/setup.cfg,sha256=_Oj7PwahkYUSneIrjn2mXwo0m6b27dTCZhAwWXFWqUA,221
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/spell-ignore-words.txt,sha256=KTgED03w1otAkv8iINTId8NbctCOmms6-AE99xnv4uE,13
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/main.yaml,sha256=qe-eeRDRyRyrSokCvbEcMzvbQMFi10cUEZt9i52uuUs,1257
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/rebuild.yaml,sha256=CFRzu5Eh6BBI5VX8OeG-u7UXTY6X_Eh2iESsbQ1sJmg,1287
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml,sha256=zOrcFS_Fhf3jUB5qxeq3Kgqg7aSa2PqalhJe69sHZuo,2216
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml,sha256=V8VoRZraesWsS3MwXyEVsJ0VmzvZ_EQepwVtvgag2_0,532
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt,sha256=ae22jZH3ftR2mGsZJg7B0yRJrvfSfpZJlG3x_qxmQ8g,18
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml,sha256=PMI4CgXk1m_DNCAZViRC-QLcLo8ANL5uacBt8Ahp29w,10666
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/spell-ignore-words.txt,sha256=xREYVDbYmOz5vpSU0A6Lijb_I--zz6JSTmirxyX0dwI,30
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/main.yaml,sha256=yQSffMviSVUPQ0ueIe8iv_O_jagmrISEnelLBIjY_F8,1581
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/rebuild.yaml,sha256=e8M5nzn6rYPhPcTiLh-p7fXPewWVCjeDtQJxpKvSbpE,1287
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/.github/workflows/update_l10n.yaml,sha256=y_Jrf2aQf4qp2aNuQnWjTWIFwxz-WWoQIq_ZXGO_HvU,2243
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/config.yaml,sha256=D60Qw2XxSF66PAFAjiZatEDI0Jjh2Le91X4FKnCAMgE,488
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/docker-compose-check,sha256=7lnVTaaoUrC5MPGpwH2IWbzYc2KaeQMWguahsoY9Rf8,615
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/ci/requirements.txt,sha256=KiMF9186A5MJgDroGnqlsah_wTPvUYdm441sOke-J_Y,35
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/vars.yaml,sha256=_RxginY3mlqI8TGqHjCxkAPGuMwVxWhIsiz_xrw9vxE,11877
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/locale/en/LC_MESSAGES/{{cookiecutter.package}}_geoportal-client.po,sha256=hKLs5f7EJz05ACRtyTlCtssCo99PMuj-FfOJXchMZFk,162
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/robot.txt.tmpl,sha256=JR_vIqMlHq1oSgyWPN2mtZyEpsqhjKQQecaW2pxvK54,88
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/desktop.css,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/iframe_api.css,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/css/mobile.css,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_left.png,sha256=ExK_hOKzWaD4rgrSFy3xw88JrJai5n8JEXy-dEmvSLo,13799
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/banner_right.png,sha256=t65I5iM-wl_7a6k3NLbVT5d725siXigH2dsOhtmC3PU,6018
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/blank.png,sha256=zp8uuLPeZ13bYveFL5dI20zQMqzo_0SSMZGNV49JZfI,259
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-blue.png,sha256=aALxnIGsafvssGB3fEmLWUNb7X3xz7JQlnoxUJhkNgg,758
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-gold.png,sha256=O5qV6Vb1Y9QMiszH34x5PA1wX_SnVZ6Qhv7vsy8zr-g,703
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker-green.png,sha256=ucJpwxgJnaA4dUnDk779X1ZLxnYowMOTAq_CMeGw8PQ,753
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/geoportal/{{cookiecutter.package}}_geoportal/static/images/markers/marker.png,sha256=wj0-D2abaL-A-OIoUbEeuSwMc_e1zf8zE4lVpra9xYY,601
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/demo.map.tmpl,sha256=mFtC2pzbN3-KQpZxQbhV8fMeQaZikMyZ5N-A9RXaxYE,7269
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts.conf,sha256=uG3B6GUKIvTRVLO025Ecm5lh27sEMpmmzWUzFjNh8Qg,351
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl,sha256=mza6KiSJG7fgaG4G-USDTg47Jo65bnXNcXdXNxfclJ4,2716
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.conf,sha256=xRv4CqlYGLUm5t2y4G2PVCQKMRgufX0snvNz2-uBJVY,187
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/mapserver.map.tmpl,sha256=1kpzZv7rME0MbXw-2rQAvoh1_AshvbVFTzMqb6bXAnc,2698
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/tinyows.xml.tmpl,sha256=hI6mHamiwQW40t2Rf-NRHwOtkPdxL4YrkVS7MlUYPb8,816
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt,sha256=q_uKVshkZPX6J376w3UhJ30Ij4hJtYF2jNwfRZJRuE4,2892
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/Readme.txt,sha256=cOp2unb8vqlUqADg501IDzQbyLGZodCXyGH19fCEVUo,2891
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/data/TM_EUROPE_BORDERS-0.3.sql,sha256=pYpbBi2P61thQtpochj_-tl_kQIIVAJgZsemTYdRUBo,1588593
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arial.ttf,sha256=NcDzVZ2NtWnjbDEJW4pg1EFkPZX1kTneQOI_ragZuDM,275572
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbd.ttf,sha256=QESqa1vrvDaYAga0WwqqqlaBVSpIvK20F0bV0dcf17Q,286620
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Arialbi.ttf,sha256=Lzcc2dlrOsVEUZ2FwW3EPOrN_Oo1CQ7o3fPsWFfFAyg,224692
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Ariali.ttf,sha256=cK3iMxdaamZ15FAUYa-TJub3ix_994fKDaWrD8jJz9Y,206132
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Bold.ttf,sha256=aL3Veh4eYmY6CzcsciQgS4KomCC5zzA5Ezf2HwxecSM,415132
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-BoldItalic.ttf,sha256=i-2wEn6RSsOt4je0AtM-VzrMS9ugueOYEnLK40_5hXo,290436
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Italic.ttf,sha256=fWFOfubTLPuiYxv5hrx-xlodmXO7QUy55a632thch4c,279268
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/NotoSans-Regular.ttf,sha256=nptMU70lytnATTcPEzpeMtFm0NVOKprWy6SjH804LVs,414820
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdana.ttf,sha256=lu0UlJyktzks_yNbnEHVXBJTgqu-DA08K53WaJfK4Ms,139640
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanab.ttf,sha256=yPUGW6kWgPWWrzsDeOLD5xO5WlI749Vq4YXKK49fCyM,136032
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanai.ttf,sha256=kbWRhmVvUpclMaEUM8hm_VbmLsTmHiYhotunDI8ZqCg,154264
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/mapserver/fonts/Verdanaz.ttf,sha256=aY4iD0j0pA53r36zSVjI_QLx4Yw7o_Nl2Tv6LtRHTIA,153324
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml,sha256=t2rHGwJEUNrK6Vjm6xisDFtss9WX4nhs3AxSaa5ToBo,10002
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml,sha256=OnuzNqaike4mxa7IH_fqIsE2RtAUSAfViwALvk-IKZM,8707
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml,sha256=3yKujKVwi0u-sASgEIC8DuyOdH2r6ZdByU1Nb-JBbP0,9562
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml,sha256=wR4Ow4DpzESUa8d620nRGXFhIa9Qf7JZ6MVN3WDyEkI,6880
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/config.yaml.tmpl,sha256=M_NRPwa8Cu9C-023JUvcMA7WKMpFJjQVd7hzf3svR9o,4774
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Landscape.jrxml,sha256=LWasD8pgHCedWvKcByvnzzASgae3XzNH3MGqG-rEpSM,10262
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A3_Portrait.jrxml,sha256=WVXAQAvaKYDEFE3cS6gwEeHsN_n-EKmsq9y0oiu05HU,8967
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Landscape.jrxml,sha256=eO4CQt8iCyWVDs2pGPm6dYEQtjA6PADcqe0t5tagR1Y,9822
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/A4_Portrait.jrxml,sha256=pNgpWqChIMOVP9AEcloSRlNjgWRaxtgCRMxNyRDP9Bw,7096
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/config.yaml.tmpl,sha256=QxH5xgjetuB_d3z0ktD5ZKctyNDAb8K9Ku0Y6yaOO24,4914
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/legend.jrxml,sha256=qRxN0MC4KIyxxLNiCdriO0FEUZerzrkTu-cSjexx7dE,5310
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation.properties,sha256=n7F7W9ELl53JsNCDMwoFIlWravXB-K4VCQdo_Yjanx8,98
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/localisation_fr.properties,sha256=OBh4sWxMNW8dNgcXr7VpTW8HemJIQoxRmPBLZ9MDVmI,102
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/logo.png,sha256=ExK_hOKzWaD4rgrSFy3xw88JrJai5n8JEXy-dEmvSLo,13799
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/north.svg,sha256=rnHO-cNiy9ZyfwvI-o2dYipzuu-vh9rn0nE45FjfOPo,2925
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/print/print-apps/{{cookiecutter.package}}/results.jrxml,sha256=gf5grUvt-oG_H0LnsNvBWMDGqvH3uuW_wfy0O-n5ui4,1309
 c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/qgisserver/pg_service.conf.tmpl,sha256=WcjfsfsfNLHAfbg84HgEIb64EDnnJJWGnyAdPTXD0PI,296
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup,sha256=AkEBTh11f4R0xrhbtvIYebBz9Ss-NY6ftOKdJ-aCFYc,4243
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore,sha256=Tsw4hSNeELxL3y7kiZ_d04vdJDagAa1yXr_xSqnqDB4,4433
-c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl,sha256=y-X8uAZP9mEq3k6NygBI_FynZeEQ_IatFPXkzWs5UAQ,6181
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-backup,sha256=PBADpXM1zM5BeItviHsKcqDtcVMpMSYKKz-uarBSZ10,4274
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/scripts/db-restore,sha256=9f6IFkLdP-N-8ulX6Wugpc2gWQoTLQ0WaPGhT5m03ck,4436
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tests/test_app.py,sha256=yV7Cnsjps2AIG7kiSmDUirev1uVea6BOcaDFyR2_FWI,1540
+c2cgeoportal_geoportal/scaffolds/create/{{cookiecutter.project}}/tilegeneration/config.yaml.tmpl,sha256=OK6ZFMlYMx1wcx8leK42LA8p0P56HuEAP8fupuxDI34,6181
 c2cgeoportal_geoportal/scaffolds/update/cookiecutter.json,sha256=x3FFn3b67GPGCsjg36iGXCudjaTSfwGHcwHS6HHVpPQ,539
-c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml,sha256=GUyQ0qiRKH58NwOGTwSQPSTZYL345FmOEDUZa0cReaM,6781
-c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt,sha256=UzHIap481u42nqAMkqbd9qVGRNFwoJ3U0SlzxVQI8mU,36854
-c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml,sha256=kEV-oJhGdH4hkgfHb9MO5cyeEDtn9T8idujBh8E2MW4,21112
-c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml,sha256=gVGStyIS_L3TbJcnoDIKSSOQAOw_S5cWHZEi3h72AoY,45687
-c2cgeoportal_geoportal/scripts/__init__.py,sha256=2tzCcNqb09Pb8ULVfDQbRWkaB_KYgyk72OdTiezhnA0,2863
-c2cgeoportal_geoportal/scripts/c2cupgrade.py,sha256=MLgayT8FBS2EyuPAYEGayRm_mkwXwMv6LO4EXo7GABk,36312
+c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/.upgrade.yaml,sha256=_ctFv4lgUP4_7LozPND8jKwixN5jeaiB0bGSrnH4jV4,2559
+c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_CHANGELOG.txt,sha256=2jvNZcUeY7pBe2vEqk5b325l6XgIKPbbPATP9eaeS5Q,8351
+c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/CONST_create_template/tests/test_testapp.py,sha256=Mxx4z7TnM3VHF8xxEorZjIw9uQRNGM7y5EHW7VYaEb8,1796
+c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_config-schema.yaml,sha256=91V2N7jfKTXMHfaVijVEQmAk0doHqQ0hpTFP5NnlYhI,21333
+c2cgeoportal_geoportal/scaffolds/update/{{cookiecutter.project}}/geoportal/CONST_vars.yaml,sha256=ijp8e3rrQ9ckPMGykc7wGy3GN_asx3rbuey-9vus700,47879
+c2cgeoportal_geoportal/scripts/__init__.py,sha256=81XIct5hy9-X5uWm3z4XCSUWQoFH-Y3nfUBg1Peu1BQ,2857
+c2cgeoportal_geoportal/scripts/c2cupgrade.py,sha256=djLEs8SR5C9KJ5mbHjjlEWKsDKUesz9QIhkcuHyee2g,36742
 c2cgeoportal_geoportal/scripts/create_demo_theme.py,sha256=3RmUnFj1V9A3KMCCSYplhemN4faNQbnJgDmeunQ_VSo,3081
-c2cgeoportal_geoportal/scripts/manage_users.py,sha256=-9ExER-kYHh6OMsoOAuLhnjEOLoAjzzbGEcVZoZwnSg,5468
-c2cgeoportal_geoportal/scripts/pcreate.py,sha256=ovvVvbT-Kvb3gUj7eAjyvIV3UGFWR_QpVBOh7BGIiuU,11528
-c2cgeoportal_geoportal/scripts/theme2fts.py,sha256=_qEYDiu-cvet7A-2Hk-93FPzAnZH7LYZTWQXt1OCph0,11450
-c2cgeoportal_geoportal/scripts/urllogin.py,sha256=6SrFmQNYEtoZJ_jaVQ83F3JNoegl8BKTG-z-WkJPoy4,3299
-c2cgeoportal_geoportal/templates/login.html,sha256=0xcwQQDM2uv3Li0qnS91eyjsVtK0ZGiPNld7DXKadco,2475
-c2cgeoportal_geoportal/templates/notlogin.html,sha256=cJx7z50IKQl7Fb9KXv03iSxh6pgff0dbnxa9FIHNkxM,1528
+c2cgeoportal_geoportal/scripts/manage_users.py,sha256=Ih3X_V_xUw59Ums4a1x6qQQtz9VtE7PaxAj-tiZIOPg,5586
+c2cgeoportal_geoportal/scripts/pcreate.py,sha256=bZQPrJt3iiKGJ-aZnxsl_aiJ2V65L-Aa__0nOU8xlS4,11580
+c2cgeoportal_geoportal/scripts/theme2fts.py,sha256=Tx1jUfDUwNtwZ5TCyfpldZIbIkzZiQ3dq-kv_YQ9yFE,13737
+c2cgeoportal_geoportal/scripts/urllogin.py,sha256=Cp4yTMOqCJqVhx6iHRfA0POroJwdyZ3RzZ1oInIGV_I,3299
+c2cgeoportal_geoportal/templates/login.html,sha256=Jy8CUw2KrSviePknsvWJLDqCUXam-vPhnMUv7UcD4Pc,2475
+c2cgeoportal_geoportal/templates/notlogin.html,sha256=XLCwJ8q7hqk6GIaxwhyMOaMZZZvsD_MMZaCERO8n2AY,1528
 c2cgeoportal_geoportal/templates/testi18n.html,sha256=Br6Vf5zTDdaH0L07saV_8dIIT3C9xnSqh4quzTELo2s,369
-c2cgeoportal_geoportal/views/__init__.py,sha256=S74TlEcDZPp_eK-u5NsMcBIkj-LSOPskf8HVjVnGWYc,2694
+c2cgeoportal_geoportal/views/__init__.py,sha256=KNfldZFuKFfNjGJsE2HyW3gUfWUY5IKSPlQbwZpLH3Y,2639
 c2cgeoportal_geoportal/views/dev.py,sha256=e1oZkKwwQvssMOzg3Zao3Jm4WNIFVwEI3EOR1Xj3-_Y,2533
-c2cgeoportal_geoportal/views/dynamic.py,sha256=jbb76Al9gOwvtDmvuAAbOqKondkfGiP1pApA0f0rYzk,8589
-c2cgeoportal_geoportal/views/entry.py,sha256=PW3g4DiwWHhQWdl22egCOcgC2A5aXblNnc67_e50oHI,5995
-c2cgeoportal_geoportal/views/fulltextsearch.py,sha256=Yo3GW-O-Vk6o90tGQek99Gqd5lEtwscnBKw1ylhKNF0,8330
-c2cgeoportal_geoportal/views/geometry_processing.py,sha256=OlvpcDSrvqy-xykmycWh5X-MMVJsiuWew4Sfdy4ykA8,2952
+c2cgeoportal_geoportal/views/dynamic.py,sha256=dwDw4p4wPFVl_e8EkrNKne9ZKad1vXYyWuvmMUrzuBs,8575
+c2cgeoportal_geoportal/views/entry.py,sha256=dMPi8UiFbYkfr-SYFFx1J00cYaBODLOPeSf6qIrg9S8,5727
+c2cgeoportal_geoportal/views/fulltextsearch.py,sha256=uiidVzz-mQ-_eF1GL3ZCWd67-p-PNnqE7QZkBxsro4Q,8397
+c2cgeoportal_geoportal/views/geometry_processing.py,sha256=WNlwMUft_kDMj4VFJSi9O5PZPlZ64oiGXUiO2Hl6d0M,2984
 c2cgeoportal_geoportal/views/i18n.py,sha256=7Avpt-aVEVlS3SrwtZkvuJ8_0gBZvVrCviyaIZBx7jY,5292
-c2cgeoportal_geoportal/views/layers.py,sha256=EqaICEToh5MOdp9h7gG60peuV6PBAyw6euqliA174LU,28850
-c2cgeoportal_geoportal/views/login.py,sha256=BugfdgTg4f73yo6e1uSshEYu0MZhwS9YaLo0c9JYPrM,19104
-c2cgeoportal_geoportal/views/mapserverproxy.py,sha256=Oyc9T_L9-yNYKrOszp28vLFgxzDTTwHGYVhLdCGWy70,8203
-c2cgeoportal_geoportal/views/memory.py,sha256=nb2repOnil0PdziEjCLOZ-84LFKLkdAlKTnnMQoXDdA,3627
-c2cgeoportal_geoportal/views/ogcproxy.py,sha256=M9hkxgIga29SoJ4VNwkzkiOkQiOsyyXMrMUwSN0W73U,5065
-c2cgeoportal_geoportal/views/pdfreport.py,sha256=0cNXsfUmIlbvsgjVyg7031cY6OBwA6c6bAfYvSDMeRE,9576
-c2cgeoportal_geoportal/views/printproxy.py,sha256=DxKQkb87k3HMm7hfhdmxjYFR3v67WEGaVFlXv5mezGM,5897
-c2cgeoportal_geoportal/views/profile.py,sha256=9ZXIsjJoV3_uRx0H3iQ0256xiu5OpIaMPAMmKEbaBuk,5394
-c2cgeoportal_geoportal/views/proxy.py,sha256=mxvBva4oEGh6O5IT2Q6BTzftl-P2_MhNIiVe3j6Ar8Q,10453
-c2cgeoportal_geoportal/views/raster.py,sha256=7diNkV-YGtg4di_QDV-Bbbe6phB76bPYLnmnE4ZBXc0,7570
-c2cgeoportal_geoportal/views/resourceproxy.py,sha256=aKOJUOI5Em2Z3BI61I2br_sUmx8ospFv_RExxmqkyXA,3181
-c2cgeoportal_geoportal/views/shortener.py,sha256=I9GjjlkR9sX5CwsRSsY9PLjyLue_c_nHgVrFnh3gTBQ,6206
-c2cgeoportal_geoportal/views/theme.py,sha256=xwOVGLFA0X7UMJ2MEVuwvaB-q1NSpFYCJ7dExhc4ATY,51588
-c2cgeoportal_geoportal/views/tinyowsproxy.py,sha256=tbMQTt97U1e3_YLqD_sd3TQh-xkZadpEYH8kHSUK1dY,8171
-c2cgeoportal_geoportal/views/vector_tiles.py,sha256=PkNqvXhcE_IgtWU9sjG2gj8SFlbKkb_h6rU0K0wEe-s,3455
-tests/__init__.py,sha256=suzy8wAvOM-z2yewf6Ij-r4v0kWCEll94nCWJqcBAKQ,3752
-tests/test_cachebuster.py,sha256=FBMDqBjN5avLwmp6I751HZPplnLTRHVwYQuy6ltOmaM,2941
-tests/test_caching.py,sha256=UXAEAsuspHU96LLjMxXqvRRK9eda3-0I09-XBBxG-XE,12493
-tests/test_checker.py,sha256=kOIOapaOvXzxL_1V2ru1Jgkg0RQ7VUF4iBOzD20G7b0,3638
-tests/test_decimaljson.py,sha256=yrI5cQAenW0jXJljfh36mLH5m3MvdOw_9J06Wa5mpeY,2223
-tests/test_headerstween.py,sha256=J0-frpbB2tJqUBWkT0JVOWlnePxXaQtd-FUtBC7W4Aw,2524
-tests/test_i18n.py,sha256=_gh-bR6GnpIfvrUwSKSY8plMchw9u_LZ0iSM8V1Me5o,1003
-tests/test_init.py,sha256=e5vZFPBrJS-d9WWJgHDt2bBrfAxN94BbgpW2-clJgmU,7357
-tests/test_locale_negociator.py,sha256=6kL0xkp9TakBp5nCAoa9I5Y2XWXVJv9Fk_y4tIWpQ8M,3071
-tests/test_mapserverproxy_route_predicate.py,sha256=CrYzEnYjowvDJxJp56gEAaUEk5vXVxqI3JscOAfr3T0,3044
-tests/test_raster.py,sha256=oRyOc90WixD9Y-iR3pMdkHuR0JwKART9DxNH5QwyilM,12074
-tests/test_wmstparsing.py,sha256=ZAlL6OQkYmzFTKu70OQ6Xej-7ZNB7UltSs2V_PbXDac,9135
-tests/xmlstr.py,sha256=vIvIFWIE2GFUMfAtG0hTMZC2jx-pQBuzOOq2FjQlyjA,6010
-c2cgeoportal_geoportal-2.7.1.83.dist-info/METADATA,sha256=z-fCtr8oTTA0fZzUYPl5BwYkONXQlee6CMOwBUpR5B0,2003
-c2cgeoportal_geoportal-2.7.1.83.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
-c2cgeoportal_geoportal-2.7.1.83.dist-info/entry_points.txt,sha256=_EqfKA_CKejpkgK0xWDTB9K8an0TKqIWHoyCJrRpU80,1414
-c2cgeoportal_geoportal-2.7.1.83.dist-info/top_level.txt,sha256=PJIbY7Nx51dDrJ052f5mDA7c6Tehm5aD-Gb32L_CtJA,29
-c2cgeoportal_geoportal-2.7.1.83.dist-info/RECORD,,
+c2cgeoportal_geoportal/views/layers.py,sha256=UpQHOj3mdP64-qZUypOhZTRThERxoHHX7fhd2aDTNRg,29623
+c2cgeoportal_geoportal/views/login.py,sha256=qBe6MwoazLiUagAsGUd9EiRjMpzyeN1gRlGJ5KVZ3S8,22884
+c2cgeoportal_geoportal/views/mapserverproxy.py,sha256=iq-PHHNj4cQ8qtB0AKngVUFiH0Gf3fhoYmYW9ovBmjI,8156
+c2cgeoportal_geoportal/views/memory.py,sha256=Pjkhv4BPjUTzPjp8mD8JNKog1g1KdnbtcLU-I9NnoK8,3621
+c2cgeoportal_geoportal/views/ogcproxy.py,sha256=cyVkDTM8U2Sbq8UYzICFHzLD8zaUe0ypFCGakNVNibY,5244
+c2cgeoportal_geoportal/views/pdfreport.py,sha256=e1q1g8dVMZ5oY9usR56H99ujGgNzzhrDTgKXLhV-m8Y,9609
+c2cgeoportal_geoportal/views/printproxy.py,sha256=Ug8EclG2JKnwZ0GdTcF7EfRsMng9U5ENF6rXnh0yRfg,5856
+c2cgeoportal_geoportal/views/profile.py,sha256=lKMBzrt0wVtUyDghgtbiocn4yUajAOOGL9LyuDtM5Ns,5375
+c2cgeoportal_geoportal/views/proxy.py,sha256=QKUynku2O27h-bVHtU06UyDaqf_cmzblUD7WgiB9s2E,10393
+c2cgeoportal_geoportal/views/raster.py,sha256=L3Xvm9meQkk_C-iHdmsImeAaq2qOwetdbYt9ZLuZK9g,7554
+c2cgeoportal_geoportal/views/resourceproxy.py,sha256=Wxzb0HkWQtL5JZmbNFfTP9-m83vKImsURGIotC3qbXc,3181
+c2cgeoportal_geoportal/views/shortener.py,sha256=SugyZhhuwqphHuZvCZEb7ZOaRSmwWq2IifuV5G34f5M,6137
+c2cgeoportal_geoportal/views/theme.py,sha256=q-AXtdYQHr8Tee9mi-q1XnKfF3xfXkyKA3iwldqmVwE,54869
+c2cgeoportal_geoportal/views/tinyowsproxy.py,sha256=iLe8Oz0GHtpnHarNW_FsmeagIAB6ANJ1C3C9hNMbgGM,7913
+c2cgeoportal_geoportal/views/vector_tiles.py,sha256=brmbwmOOUFIF-bQZnIw8Zcc3aV61hxdDEQ875HoD3Mw,3568
+tests/__init__.py,sha256=KxmbgvRWDSJoEDH1cXnDIjbfBsgCzs2KdkTPuzYMq84,3826
+tests/test_cachebuster.py,sha256=asI1X_qI0MGklYuKuWyqvCPVbvhQcUe4fX91Dk-hUsE,2923
+tests/test_caching.py,sha256=8exM2zAPPIoJLalFi8l3e1KA_l2WSwWGjTXDYN_tC9o,12493
+tests/test_checker.py,sha256=NaU6Ejg9XbwS2cwqXCtz5mJPRdBIPZb3d1MkXVufr0k,3638
+tests/test_decimaljson.py,sha256=CQrkqWs66kmq1iYur5kjzKhvdhw9b4TMcKEsuVayxA4,2223
+tests/test_headerstween.py,sha256=3PkfTbsUq2C7fEsckO_4aYu9-XGBSeOgf86ENSqx76o,2524
+tests/test_i18n.py,sha256=-mAW0UyeNF9uqkq6O_Z0mK8gGwlHlTWI0gb9Ri_bk1M,994
+tests/test_init.py,sha256=5w29KyGL5b1dLMJUKrmw2EfzTg9NwFddEgnfHN3YE0w,7494
+tests/test_locale_negociator.py,sha256=JDRzF8_yzsgYOWHlyd_7ezOqSCvudKjeN2QjExS0a4A,3044
+tests/test_mapserverproxy_route_predicate.py,sha256=SzILSSzIuilzIkUYVPZiVzLwW1duQvCxxEvxSLk4p1o,3043
+tests/test_raster.py,sha256=82NJ2MXgZlMqs0ytN-VgNw376iURdk4PkAg__dyh5ns,11948
+tests/test_wmstparsing.py,sha256=xjA8nJuXFl3H5Bfs4sJw_8qX8E8qvAALK7Hs2-DTP2A,9054
+tests/xmlstr.py,sha256=rkTKSU4FGjupBKLx75H8o-goB0KbQrxDvdpc6xVX_uQ,5985
+c2cgeoportal_geoportal-2.9.dist-info/METADATA,sha256=1E1Zk9Hcc-atmeX_fYq803TGEUx3jh2HWTAc-Vr23eA,1922
+c2cgeoportal_geoportal-2.9.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+c2cgeoportal_geoportal-2.9.dist-info/entry_points.txt,sha256=w0xGr1Bo8q5GBFiP4JgqbSIg-bNhG7bsGoEaGSTfzaE,1415
+c2cgeoportal_geoportal-2.9.dist-info/top_level.txt,sha256=PJIbY7Nx51dDrJ052f5mDA7c6Tehm5aD-Gb32L_CtJA,29
+c2cgeoportal_geoportal-2.9.dist-info/RECORD,,
```

