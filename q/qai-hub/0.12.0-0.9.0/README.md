# Comparing `tmp/qai_hub-0.12.0-py3-none-any.whl.zip` & `tmp/qai_hub-0.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,27 +1,27 @@
-Zip file size: 76791 bytes, number of entries: 25
--rw-r--r--  2.0 unx      271 b- defN 24-May-06 23:29 qai_hub/__init__.py
--rw-r--r--  2.0 unx    17023 b- defN 24-May-06 23:29 qai_hub/_cli.py
--rw-r--r--  2.0 unx       23 b- defN 24-May-06 23:29 qai_hub/_version.py
--rw-r--r--  2.0 unx     4095 b- defN 24-May-06 23:29 qai_hub/api_status_codes.py
--rw-r--r--  2.0 unx   119732 b- defN 24-May-06 23:29 qai_hub/client.py
--rw-r--r--  2.0 unx     1126 b- defN 24-May-06 23:29 qai_hub/hub.py
--rw-r--r--  2.0 unx    26381 b- defN 24-May-06 23:29 qai_hub/public_api_pb2.py
--rw-r--r--  2.0 unx   107195 b- defN 24-May-06 23:29 qai_hub/public_api_pb2.pyi
--rw-r--r--  2.0 unx    54180 b- defN 24-May-06 23:29 qai_hub/public_rest_api.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 23:29 qai_hub/py.typed
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 23:29 qai_hub/test/__init__.py
--rw-r--r--  2.0 unx    15142 b- defN 24-May-06 23:29 qai_hub/test/test_cli.py
--rw-r--r--  2.0 unx    10689 b- defN 24-May-06 23:29 qai_hub/test/test_client.py
--rw-r--r--  2.0 unx      687 b- defN 24-May-06 23:29 qai_hub/test/test_public_rest_api.py
--rw-r--r--  2.0 unx     5661 b- defN 24-May-06 23:29 qai_hub/test/test_zipped_model.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-06 23:29 qai_hub/util/__init__.py
--rw-r--r--  2.0 unx     1443 b- defN 24-May-06 23:29 qai_hub/util/aimet_helpers.py
--rw-r--r--  2.0 unx     3816 b- defN 24-May-06 23:29 qai_hub/util/dataset_entries_converters.py
--rw-r--r--  2.0 unx     1402 b- defN 24-May-06 23:29 qai_hub/util/session.py
--rw-r--r--  2.0 unx     4997 b- defN 24-May-06 23:29 qai_hub/util/zipped_model.py
--rw-r--r--  2.0 unx     2625 b- defN 24-May-06 23:29 qai_hub-0.12.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-06 23:29 qai_hub-0.12.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       47 b- defN 24-May-06 23:29 qai_hub-0.12.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        8 b- defN 24-May-06 23:29 qai_hub-0.12.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2027 b- defN 24-May-06 23:29 qai_hub-0.12.0.dist-info/RECORD
-25 files, 378662 bytes uncompressed, 73535 bytes compressed:  80.6%
+Zip file size: 75067 bytes, number of entries: 25
+-rw-r--r--  2.0 unx      271 b- defN 24-Feb-23 21:57 qai_hub/__init__.py
+-rw-r--r--  2.0 unx    16292 b- defN 24-Feb-23 21:57 qai_hub/_cli.py
+-rw-r--r--  2.0 unx       22 b- defN 24-Feb-23 21:57 qai_hub/_version.py
+-rw-r--r--  2.0 unx     4095 b- defN 24-Feb-23 21:57 qai_hub/api_status_codes.py
+-rw-r--r--  2.0 unx   117437 b- defN 24-Feb-23 21:57 qai_hub/client.py
+-rw-r--r--  2.0 unx     1126 b- defN 24-Feb-23 21:57 qai_hub/hub.py
+-rw-r--r--  2.0 unx    25527 b- defN 24-Feb-23 21:57 qai_hub/public_api_pb2.py
+-rw-r--r--  2.0 unx   102682 b- defN 24-Feb-23 21:57 qai_hub/public_api_pb2.pyi
+-rw-r--r--  2.0 unx    51470 b- defN 24-Feb-23 21:57 qai_hub/public_rest_api.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 21:57 qai_hub/py.typed
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 21:57 qai_hub/test/__init__.py
+-rw-r--r--  2.0 unx    14314 b- defN 24-Feb-23 21:57 qai_hub/test/test_cli.py
+-rw-r--r--  2.0 unx    10389 b- defN 24-Feb-23 21:57 qai_hub/test/test_client.py
+-rw-r--r--  2.0 unx      687 b- defN 24-Feb-23 21:57 qai_hub/test/test_public_rest_api.py
+-rw-r--r--  2.0 unx     5661 b- defN 24-Feb-23 21:57 qai_hub/test/test_zipped_model.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 21:57 qai_hub/util/__init__.py
+-rw-r--r--  2.0 unx     1443 b- defN 24-Feb-23 21:57 qai_hub/util/aimet_helpers.py
+-rw-r--r--  2.0 unx     3816 b- defN 24-Feb-23 21:57 qai_hub/util/dataset_entries_converters.py
+-rw-r--r--  2.0 unx     1011 b- defN 24-Feb-23 21:57 qai_hub/util/session.py
+-rw-r--r--  2.0 unx     4997 b- defN 24-Feb-23 21:57 qai_hub/util/zipped_model.py
+-rw-r--r--  2.0 unx     2626 b- defN 24-Feb-23 21:57 qai_hub-0.9.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Feb-23 21:57 qai_hub-0.9.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       47 b- defN 24-Feb-23 21:57 qai_hub-0.9.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        8 b- defN 24-Feb-23 21:57 qai_hub-0.9.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2022 b- defN 24-Feb-23 21:57 qai_hub-0.9.0.dist-info/RECORD
+25 files, 366035 bytes uncompressed, 71821 bytes compressed:  80.4%
```

## zipnote {}

```diff
@@ -54,23 +54,23 @@
 
 Filename: qai_hub/util/session.py
 Comment: 
 
 Filename: qai_hub/util/zipped_model.py
 Comment: 
 
-Filename: qai_hub-0.12.0.dist-info/METADATA
+Filename: qai_hub-0.9.0.dist-info/METADATA
 Comment: 
 
-Filename: qai_hub-0.12.0.dist-info/WHEEL
+Filename: qai_hub-0.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: qai_hub-0.12.0.dist-info/entry_points.txt
+Filename: qai_hub-0.9.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: qai_hub-0.12.0.dist-info/top_level.txt
+Filename: qai_hub-0.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: qai_hub-0.12.0.dist-info/RECORD
+Filename: qai_hub-0.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## qai_hub/_cli.py

```diff
@@ -78,20 +78,14 @@
         )
         job_parser.add_argument(
             "--input_specs",
             action="store",
             help="Input specs for compile jobs.",
             required=False,
         )
-        job_parser.add_argument(
-            "--calibration_data",
-            action="store",
-            help="Dataset ID of quantization calibration data.",
-            required=False,
-        )
 
     # Jobs that only profile
     if job_type in ["profile"]:
         job_parser.add_argument(
             "--model",
             action="store",
             help="Model ID of target model in Hub or path to a target model file on disk.",
@@ -398,15 +392,14 @@
 def run_cli(args: argparse.Namespace) -> None:
     if args.profile:
         set_config_path(args.profile)
 
     clone_job: Optional[hub.Job] = None
     compile_options: str = ""
     profile_options: str = ""
-    calibration_data: Optional[hub.Dataset] = None
     name: Optional[str] = None
     model: Union[SourceModel, str] = ""
     input_specs: Optional[hub.InputSpecs] = None
 
     if args.command == "configure":
         # Data to write to the configuration file
         if args.api_token is None:
@@ -435,16 +428,14 @@
         list_devices(parse_device(args))
 
     elif args.command == "submit-compile-and-profile-jobs":
         if args.clone is not None:
             raise ValueError("Cloned job has to be a compile or profile job")
         if args.compile_options is not None:
             compile_options = args.compile_options
-        if args.calibration_data is not None:
-            calibration_data = hub.get_dataset(args.calibration_data)
         if args.profile_options is not None:
             profile_options = args.profile_options
         if args.name:
             name = args.name
 
         device_params = parse_device(args)
         device = get_device(device_params)
@@ -460,15 +451,14 @@
         hub.submit_compile_and_profile_jobs(
             model=model,
             name=name,
             input_specs=input_specs,
             device=device,
             compile_options=compile_options,
             profile_options=profile_options,
-            calibration_data=calibration_data,
         )
 
     elif args.command == "submit-profile-job":
         if args.clone is not None:
             maybe_clone_job = hub.get_job(args.clone)
             if isinstance(maybe_clone_job, hub.ProfileJob):
                 clone_job = maybe_clone_job
@@ -509,25 +499,18 @@
         if args.clone is not None:
             maybe_clone_job = hub.get_job(args.clone)
             if isinstance(maybe_clone_job, hub.CompileJob):
                 clone_job = maybe_clone_job
             else:
                 raise ValueError("Cloned job has to be a compile job")
 
-        if args.calibration_data is not None:
-            calibration_data = hub.get_dataset(args.calibration_data)
-        elif clone_job is not None:
-            assert isinstance(clone_job, hub.CompileJob)
-            calibration_data = clone_job.calibration_dataset
-
         if args.compile_options is not None:
             compile_options = args.compile_options
         elif clone_job is not None:
             compile_options = clone_job.options
-
         if args.name:
             name = args.name
         elif clone_job is not None:
             name = clone_job.name
 
         device_params = parse_device(args)
         # Only fall-back to clone job device if no device info is provided
@@ -551,15 +534,14 @@
 
         hub.submit_compile_job(
             model=model,
             name=name,
             device=device,
             options=compile_options,
             input_specs=input_specs,
-            calibration_data=calibration_data,
         )
 
     else:
         get_cli_parser().print_help()
 
 
 def main() -> None:
```

## qai_hub/_version.py

```diff
@@ -1 +1 @@
-__version__ = "0.12.0"
+__version__ = "0.9.0"
```

## qai_hub/client.py

```diff
@@ -49,15 +49,14 @@
     zip_model,
 )
 
 if TYPE_CHECKING:
     # Evaluate to False in general. Only import to resolve Sphinx autodoc
     # typehints forward declaration warnings
     import coremltools
-    import onnx
     import torch
 
 MISSING_METRIC_VALUE = None
 
 IS_WINDOWS = sys.platform in ["win32", "msys", "cygwin"]
 
 ASSEMBLE_JSON_FILE = "assemble.json"
@@ -172,16 +171,16 @@
             "compile_peak_memory": profile_pb.peak_memory_usage,
             "compile_memory_increase_range": MISSING_METRIC_VALUE,
             "compile_memory_peak_range": MISSING_METRIC_VALUE,
             "first_load_memory_increase_range": MISSING_METRIC_VALUE,
             "first_load_memory_peak_range": MISSING_METRIC_VALUE,
             "warm_load_memory_increase_range": MISSING_METRIC_VALUE,
             "warm_load_memory_peak_range": MISSING_METRIC_VALUE,
-            "inference_memory_increase_range": MISSING_METRIC_VALUE,
-            "inference_memory_peak_range": MISSING_METRIC_VALUE,
+            "inference_load_memory_increase_range": MISSING_METRIC_VALUE,
+            "inference_load_memory_peak_range": MISSING_METRIC_VALUE,
         }
 
     return {
         "execution_summary": execution_summary,
         "execution_detail": layer_details,
     }
 
@@ -222,23 +221,20 @@
     out_fields = [s if isinstance(s, str) else format_key_pair(*s) for s in out_fields]
     return "\n".join(out_fields)
 
 
 def requires_compilation(model_type: SourceModelType) -> bool:
     return (
         model_type == SourceModelType.TORCHSCRIPT
+        or model_type == SourceModelType.ONNX
         or model_type == SourceModelType.AIMET_ONNX
         or model_type == SourceModelType.AIMET_PT
     )
 
 
-def allows_compilation(model_type: SourceModelType) -> bool:
-    return model_type == SourceModelType.ONNX or requires_compilation(model_type)
-
-
 def _get_source_model_type_from_model_type(model_type: api_pb.ModelType.ValueType):
     if model_type not in api_pb.ModelType.values():
         model_type = api_pb.ModelType.MODEL_TYPE_UNSPECIFIED
     return SourceModelType(model_type)
 
 
 def _is_in_zip(zip: ZipFile, filename: str) -> bool:
@@ -546,16 +542,14 @@
         elif e.status_code == api_status_codes.HTTP_500_INTERNAL_SERVER_ERROR:
             long_message = _visible_textbox(
                 "The error suggests that Qualcomm AI Hub is experiencing a service failure. "
                 "Please contact support at ai-hub-support@qti.qualcomm.com."
             )
 
             raise InternalError(f"Internal API failure.\n{long_message}") from None
-        elif e.status_code == api_status_codes.HTTP_400_BAD_REQUEST:
-            raise UserError(__get_exception_string(e)) from None
         elif e.status_code == api_status_codes.HTTP_426_UPGRADE_REQUIRED:
             raise UserError(_visible_textbox(__get_exception_string(e))) from None
         elif e.status_code == api_status_codes.HTTP_429_TOO_MANY_REQUESTS:
             raise RateLimitedError(__get_exception_string(e)) from None
         else:
             # Re-raise, let the function catch it, or let it bubble up
             raise
@@ -719,20 +713,17 @@
     attributes: str|List[str]
         Additional device attributes. The selected device is compatible with all
         attributes specified. Supported attributes are:
 
             * ``"format:phone"``
             * ``"format:tablet"``
             * ``"framework:tflite"``
-            * ``"framework:qnn"``
-            * ``"framework:onnx"``
             * ``"vendor:google"``
             * ``"vendor:samsung"``
             * ``"vendor:xiaomi"``
-            * ``"vendor:oneplus"``
 
             * ``"os:android"``
 
             * ``"chipset:qualcomm-snapdragon-429"``
             * ``"chipset:qualcomm-snapdragon-670"``
             * ``"chipset:qualcomm-snapdragon-678"``
             * ``"chipset:qualcomm-snapdragon-730"``
@@ -752,15 +743,15 @@
 
         import qai_hub as hub
 
     Select a target device for Samsung Galaxy S23 Ultra with specifically Android 13:
 
         device = hub.Device("Samsung Galaxy S23 Ultra", "13")
 
-    Select a target device with OS major version 11::
+    Select a target device with OS major version 12::
 
         device = hub.Device(os="[11,12)", attributes="os:android")
 
     Select a target device with a Snapdragon 8 Gen 2 chipset::
 
         device = hub.Device(attributes="chipset:qualcomm-snapdragon-8gen2")
 
@@ -1047,15 +1038,15 @@
         - ONNX: Extension .onnx
         - ONNX (ORT model format): Extension .ort
         - QNN Binary: Extension .bin
         - AIMET Model: Directory ending with .aimet
     """
     if isinstance(model, Model):
         return model.model_type
-    elif isinstance(model, (str, Path)):
+    if isinstance(model, (str, Path)):
         path = str(model)
         _, suffix = os.path.splitext(path)
         model_type = filepath_to_model_type(path)
         if model_type:
             return model_type
         if suffix == ".zip":
             with tempfile.TemporaryDirectory() as tmp_dir:
@@ -1095,18 +1086,14 @@
         return SourceModelType.MLMODEL
     elif isinstance(model, bytes) and model[4:8] == b"TFL3":
         return SourceModelType.TFLITE
     elif type(model).__name__ == "ModelProto":
         return SourceModelType.ONNX
     elif isinstance(model, bytes) and model[4:8] == b"ORTM":
         return SourceModelType.ORT
-    elif model is None:
-        raise UserError(
-            "Model passed in was 'None' (make sure this is not the target of a failed compile job)"
-        )
     else:
         module_name_list = [model_type.__module__ for model_type in type(model).mro()]
         if "torch.nn.modules.module" in module_name_list:
             raise UserError("The torch model must be traced.")
         raise UserError(
             f"Unsupported model type. The following types are supported {error_message}"
         )
@@ -1592,46 +1579,14 @@
         # job name has been updated on Hub.
         self.name = job_name
 
     @abstractmethod
     def download_results(self, artifacts_dir: str) -> JobResult:
         raise NotImplementedError
 
-    def get_sharing(self) -> List[str]:
-        """
-        Get the list of email addresses of users that this job has been shared with.
-        """
-        response = _api_call(api.get_job_sharing, self._owner.config, self.job_id)
-        return response.email
-
-    def disable_sharing(self) -> None:
-        """
-        Disable all sharing for this job.
-        """
-        _api_call(api.disable_job_sharing, self._owner.config, self.job_id)
-
-    def modify_sharing(
-        self, add_emails: List[str] = [], delete_emails: List[str] = []
-    ) -> None:
-        """
-        Modifies the list of users that the job is shared with.
-        """
-        if not add_emails and not delete_emails:
-            raise UserError(
-                "Either add_emails or delete_emails must be specified and non-empty"
-            )
-
-        _api_call(
-            api.modify_job_sharing,
-            self._owner.config,
-            self.job_id,
-            add_emails,
-            delete_emails,
-        )
-
 
 class CompileJob(Job):
     """
     Compile job for a model, a set of input specs, and a set of device.
 
     A compile job should not be constructed directly. It is constructed by the hub client
     through :py:func:`qai_hub.submit_compile_job`, :py:func:`qai_hub.get_job`, or
@@ -2707,19 +2662,15 @@
                 api.utils.tensor_type_list_pb_to_list_shapes(
                     compile_job_pb.target_tensor_type_list
                 )
             )
             date = self._creation_date_from_timestamp(compile_job_pb)
             device = _dev_pb_to_dev(compile_job_pb.device)
             compatible_devices = _devs_pb_to_devs(compile_job_pb.devices)
-            dataset = dataset or (
-                self._make_dataset(compile_job_pb.calibration_dataset)
-                if compile_job_pb.calibration_dataset.dataset_id
-                else None
-            )
+            dataset = dataset or self._make_dataset(compile_job_pb.calibration_dataset)
 
             return CompileJob(
                 job_pb=job_pb,
                 owner=self,
                 shapes=shapes,
                 device=device,
                 compatible_devices=compatible_devices,
@@ -2946,29 +2897,24 @@
                 model_type == SourceModelType.TFLITE
                 and "framework:tflite" not in d.attributes
             ):
                 raise UserError(f"device {d} does not support TFLite model input")
             if (
                 not compile_job
                 and model_type == SourceModelType.ONNX
-                and "framework:onnx" not in d.attributes
+                and "framework:tflite" not in d.attributes
             ):
+                # We are not supporting .onnx files in ONNX runtime.
+                # They need to be converted to .ort
                 raise UserError(f"device {d} does not support ONNX model input")
             if (
                 model_type == SourceModelType.ORT
                 and "framework:onnx" not in d.attributes
             ):
                 raise UserError(f"device {d} does not support ORT model input")
-            if (
-                model_type == SourceModelType.QNN_LIB_AARCH64_ANDROID
-                or model_type == SourceModelType.QNN_LIB_X86_64_LINUX
-                or model_type == SourceModelType.QNN_BIN
-            ) and "framework:qnn" not in d.attributes:
-                raise UserError(f"device {d} does not support QNN model input")
-
         return devices
 
     def submit_compile_job(
         self,
         model: Model | SourceModel | str | Path,
         device: Device | List[Device],
         name: str | None = None,
@@ -3008,18 +2954,16 @@
             `input_specs=dict(a=(1,2), b=(1, 3))`. When using the resulting
             target model (e.g. a Core ML model) from this profile job, the
             inputs must have keys `a` and `b`, not `x` and `y`. Similarly, if
             this target model is used in an inference job
             (see :py:func:`qai_hub.submit_inference_job`), the dataset must
             have entries `a`, `b` in this order, not `x`, `y`
 
-            If `model` is an ONNX model, `input_specs` are optional.
-            `input_specs` can be used to overwrite the model's input names
-            and the dynamic extents for the input shapes.
-            If input_specs is not None, it must be compatible with
+            If `model` is an ONNX model, `input_specs` are
+            optional. If input_specs is not None, it must be compatible with
             the model, or the server will return an error.
 
         options:
             Cli-like flag options. See :ref:`api_compile_options`.
 
         single_compile:
             If True, create a single job on a single device compatible with all devices.
@@ -3055,15 +2999,15 @@
                                          name="mobilenet (1, 3, 224, 224)",
                                          input_specs=dict(x=input_specs))
 
         For more examples, see :ref:`compile_examples`.
         """
         # Determine the model type
         model_type = _determine_model_type(model)
-        if not allows_compilation(model_type):
+        if not requires_compilation(model_type):
             raise UserError("Input model type cannot be compiled.")
         devices = self._check_devices(device, model_type, compile_job=True)
         self._check_input_specs(model_type=model_type, input_specs=input_specs)
         model = self._upload_model(model, model_type=model_type)
         tensor_type_list_pb = api.utils.input_shapes_to_tensor_type_list_pb(input_specs)
 
         # Get Dataset
@@ -3148,15 +3092,15 @@
     ) -> ProfileJob | List[ProfileJob]:
         """
         Submits a profiling job.
 
         Parameters
         ----------
         model:
-            Model to profile. Must not be a PyTorch, an ONNX, or an ORT model
+            Model to profile. Must not be a PyTorch or an ONNX model
 
         device:
             Devices on which to run the profile job.
 
         name:
             Optional name for the job. Job names need not be unique.
 
@@ -3307,17 +3251,15 @@
 
         For more examples, see :ref:`inference_examples`.
         """
 
         # Determine the model type
         model_type = _determine_model_type(model)
         if requires_compilation(model_type):
-            raise UserError(
-                "Supplied model type cannot be profiled until is has been compiled."
-            )
+            raise UserError("TorchScript and ONNX models cannot be used for inference.")
 
         devices = self._check_devices(device, model_type)
         self._check_data_entries(inputs)
         model = self._upload_model(model, model_type=model_type)
         dataset = self._upload_dataset(inputs)
 
         job_name = name if name else model.name
@@ -3403,18 +3345,16 @@
             `input_specs=dict(a=(1,2), b=(1, 3))`. When using the resulting
             target model (e.g. a Core ML model) from this profile job, the
             inputs must have keys `a` and `b`, not `x` and `y`. Similarly, if
             this target model is used in an inference job
             (see :py:func:`qai_hub.submit_inference_job`), the dataset must
             have entries `a`, `b` in this order, not `x`, `y`
 
-            If `model` is an ONNX model, `input_specs` are optional.
-            `input_specs` can be used to overwrite the model's input names
-            and the dynamic extents for the input shapes.
-            If input_specs is not None, it must be compatible with
+            If `model` is a Core ML or TFLite model, `input_specs` is
+            optional. If input_specs is not None, it must be compatible with
             the model, or the server will return an error.
 
         single_compile:
             If True, create a single job on a single device compatible with all devices.
             If False, create a single job for each device
 
         compile_options:
@@ -3428,16 +3368,16 @@
             PTQ will be applied to the model during translation.
 
         retry:
             If job creation fails due to rate-limiting, keep retrying periodically until creation succeeds.
 
         Returns
         -------
-        jobs: Tuple[CompileJob | None, ProfileJob | None] | List[Tuple[CompileJob | None, ProfileJob | None]
-            Returns a tuple of CompileJob and ProfileJob.
+        job: Job | List[Job]
+            Returns the profile jobs.
 
         Examples
         --------
         Submit a traced Torch model for profiling as a QNN Model Library on a
         Samsung Galaxy S23::
 
             import qai_hub as hub
@@ -3454,47 +3394,46 @@
                 name="mobilenet (1, 3, 224, 224)",
                 input_specs=dict(x=input_shapes),
                 compile_options="--target_runtime qnn_lib_aarch64_android"
             )
 
         For more examples, see :ref:`compile_examples` and ref:`profile_examples`.
         """
-        devices = [device] if isinstance(device, Device) else device
-        num_jobs = len(devices)
+        num_jobs = 1 if isinstance(device, Device) else len(device)
         model_type = _determine_model_type(model)
-        if not allows_compilation(model_type):
+        if not requires_compilation(model_type):
             # Ignoring type because the above predicate ensures that model is a TargetModel
-            pjobs: Any = self.submit_profile_job(model, devices, name, profile_options)  # type: ignore
+            pjobs: Any = self.submit_profile_job(model, device, name, profile_options)  # type: ignore
             if isinstance(pjobs, ProfileJob):
                 pjobs = [pjobs]
             assert isinstance(pjobs, List)
             cjobs: Any = [None] * num_jobs
         else:
             cjobs = self.submit_compile_job(
                 model,
-                devices,
+                device,
                 name,
                 input_specs,
                 compile_options.strip(),
                 single_compile=single_compile,
                 calibration_data=calibration_data,
                 retry=retry,
             )
             if isinstance(cjobs, CompileJob):
                 cjobs = [cjobs] * num_jobs
             assert isinstance(cjobs, List)
             pjobs = []
-            for cjob, dev in zip(cjobs, devices):
+            for cjob in cjobs:
                 assert isinstance(cjob, CompileJob)
                 model = cjob.get_target_model()
                 if model is not None:
                     job_name = name if name else cjob.name
                     pjob = self.submit_profile_job(
                         model,
-                        dev,
+                        cjob.device,
                         job_name,
                         profile_options.strip(),
                         retry=retry,
                     )
                 else:
                     pjob = None
                 pjobs.append(pjob)
```

## qai_hub/public_api_pb2.py

```diff
@@ -10,15 +10,15 @@
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x18qai_hub/public_api.proto\x12\x0bqai_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x1d\n\x0cSharedAccess\x12\r\n\x05\x65mail\x18\x01 \x03(\t\"=\n\x12SharedAccessChange\x12\x11\n\tadd_email\x18\x01 \x03(\t\x12\x14\n\x0cremove_email\x18\x02 \x03(\t\"\x9c\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x36\n\x06\x66ields\x18\x03 \x03(\x0b\x32&.qai_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"-\n\x0fJobPublicUpdate\x12\x11\n\x04name\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\x07\n\x05_name\"1\n\rServiceStatus\x12\x14\n\x07message\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\n\n\x08_message\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"G\n\x08UserList\x12 \n\x05users\x18\x01 \x03(\x0b\x32\x11.qai_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"T\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12&\n\x07members\x18\x03 \x01(\x0b\x32\x15.qai_hub.api.UserList\"O\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\x12\x17\n\x0fsoc_description\x18\x04 \x01(\t\"M\n\nDeviceList\x12$\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x13.qai_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xf8\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12%\n\x05owner\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x12\x16\n\tread_only\x18\x07 \x01(\x08H\x06\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_completeB\x0c\n\n_read_only\"P\n\x0b\x44\x61tasetList\x12&\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x14.qai_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"D\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12\'\n\x05\x64type\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.TensorDtype\"M\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12,\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x17.qai_hub.api.TensorType\"B\n\x13NamedTensorTypeList\x12+\n\x05types\x18\x01 \x03(\x0b\x32\x1c.qai_hub.api.NamedTensorType\"\x8e\x03\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12%\n\x05owner\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12/\n\nmodel_type\x18\x05 \x01(\x0e\x32\x16.qai_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x12\x18\n\x0bproducer_id\x18\x07 \x01(\tH\x06\x88\x01\x01\x12\x16\n\tread_only\x18\x08 \x01(\x08H\x07\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_completeB\x0e\n\x0c_producer_idB\x0c\n\n_read_only\"J\n\tModelList\x12\"\n\x06models\x18\x01 \x03(\x0b\x32\x12.qai_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xf1\x06\n\nCompileJob\x12\x16\n\x0e\x63ompile_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12!\n\x05model\x18\x04 \x01(\x0b\x32\x12.qai_hub.api.Model\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12#\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x13.qai_hub.api.Device\x12(\n\x07\x64\x65vices\x18\x07 \x01(\x0b\x32\x17.qai_hub.api.DeviceList\x12:\n\x10tensor_type_list\x18\x08 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x0c\n\x04name\x18\t \x01(\t\x12\x0f\n\x07options\x18\n \x01(\t\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12-\n\x0ctarget_model\x18\x0c \x01(\x0b\x32\x12.qai_hub.api.ModelH\x01\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\r \x01(\x08H\x02\x88\x01\x01\x12\x31\n\rcreation_time\x18\x0e \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\x0f \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\x10 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x35\n\x11last_updated_time\x18\x11 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x12 \x01(\tH\x03\x88\x01\x01\x12\x41\n\x17target_tensor_type_list\x18\x13 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x36\n\x13\x63\x61libration_dataset\x18\x14 \x01(\x0b\x32\x14.qai_hub.api.DatasetH\x04\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0f\n\r_target_modelB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_urlB\x16\n\x14_calibration_dataset\"\xad\x07\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12!\n\x05model\x18\x04 \x01(\x0b\x32\x12.qai_hub.api.Model\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12#\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x13.qai_hub.api.Device\x12:\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12%\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x14.qai_hub.api.Dataset\x12-\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x12.qai_hub.api.ModelH\x03\x88\x01\x01\x12\x36\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x12.qai_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x12\x35\n\x11last_updated_time\x18\x14 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x15 \x01(\tH\x06\x88\x01\x01\x12\x18\n\x10includes_compile\x18\x16 \x01(\x08\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_url\"\xa6\x04\n\x0cInferenceJob\x12\x18\n\x10inference_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12!\n\x05model\x18\x03 \x01(\x0b\x32\x12.qai_hub.api.Model\x12#\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x13.qai_hub.api.Device\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12%\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x14.qai_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\t\x12\x35\n\x11last_updated_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x0e \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0c\n\n_admin_url\"\xf0\x01\n\x03Job\x12.\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x17.qai_hub.api.ProfileJobH\x00\x12\x32\n\rinference_job\x18\x02 \x01(\x0b\x32\x19.qai_hub.api.InferenceJobH\x00\x12.\n\x0b\x63ompile_job\x18\x04 \x01(\x0b\x32\x17.qai_hub.api.CompileJobH\x00\x12\x18\n\x0bhub_version\x18\x03 \x01(\tH\x01\x88\x01\x01\x12\x16\n\tread_only\x18\x05 \x01(\x08H\x02\x88\x01\x01\x42\x05\n\x03jobB\x0e\n\x0c_hub_versionB\x0c\n\n_read_only\"R\n\x0eProfileJobList\x12%\n\x04jobs\x18\x01 \x03(\x0b\x32\x17.qai_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"D\n\x07JobList\x12\x1e\n\x04jobs\x18\x01 \x03(\x0b\x32\x10.qai_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"v\n\x10\x43ompileJobResult\x12\x16\n\x0e\x63ompile_job_id\x18\x01 \x01(\t\x12\x37\n\x0e\x63ompile_detail\x18\x02 \x01(\x0b\x32\x1a.qai_hub.api.CompileDetailH\x00\x88\x01\x01\x42\x11\n\x0f_compile_detail\"h\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x30\n\x07profile\x18\x02 \x01(\x0b\x32\x1a.qai_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"\x85\x01\n\x12InferenceJobResult\x12\x18\n\x10inference_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\x12/\n\x06\x64\x65tail\x18\x03 \x01(\x0b\x32\x1a.qai_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\t\n\x07_detail\"\xd0\x01\n\tJobResult\x12;\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1d.qai_hub.api.ProfileJobResultH\x00\x12?\n\x14inference_job_result\x18\x02 \x01(\x0b\x32\x1f.qai_hub.api.InferenceJobResultH\x00\x12;\n\x12\x63ompile_job_result\x18\x03 \x01(\x0b\x32\x1d.qai_hub.api.CompileJobResultH\x00\x42\x08\n\x06result\"\xe8\x02\n\x08VizGraph\x12-\n\ngraph_type\x18\x01 \x01(\x0e\x32\x19.qai_hub.api.VizGraphType\x12+\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x18.qai_hub.api.VizSubgraph\x12\x39\n\nparameters\x18\x04 \x03(\x0b\x32%.qai_hub.api.VizGraph.ParametersEntry\x12\x33\n\x07tensors\x18\x05 \x03(\x0b\x32\".qai_hub.api.VizGraph.TensorsEntry\x1aH\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12$\n\x05value\x18\x02 \x01(\x0b\x32\x15.qai_hub.api.VizValue:\x02\x38\x01\x1a\x46\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12%\n\x05value\x18\x02 \x01(\x0b\x32\x16.qai_hub.api.VizTensor:\x02\x38\x01\"@\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12#\n\x05nodes\x18\x02 \x03(\x0b\x32\x14.qai_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x82\x02\n\tVizTensor\x12$\n\x05\x64type\x18\x02 \x01(\x0e\x32\x15.qai_hub.api.VizDtype\x12$\n\x05shape\x18\x03 \x01(\x0b\x32\x15.qai_hub.api.VizShape\x12:\n\nparameters\x18\x04 \x03(\x0b\x32&.qai_hub.api.VizTensor.ParametersEntry\x12#\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x15.qai_hub.api.VizValue\x1aH\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12$\n\x05value\x18\x02 \x01(\x0b\x32\x15.qai_hub.api.VizValue:\x02\x38\x01\"\x8c\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12\x38\n\nattributes\x18\x07 \x03(\x0b\x32$.qai_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aL\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.qai_hub.api.VizAttribute:\x02\x38\x01\"\xd8\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x37\n\x0bstring_list\x18\x06 \x01(\x0b\x32 .qai_hub.api.VizValue.StringListH\x00\x12\x39\n\x0cinteger_list\x18\x07 \x01(\x0b\x32!.qai_hub.api.VizValue.IntegerListH\x00\x12\x35\n\nfloat_list\x18\x08 \x01(\x0b\x32\x1f.qai_hub.api.VizValue.FloatListH\x00\x12\x33\n\tbool_list\x18\t \x01(\x0b\x32\x1e.qai_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"h\n\x0cVizAttribute\x12&\n\x05value\x18\x01 \x01(\x0b\x32\x15.qai_hub.api.VizValueH\x00\x12(\n\x06tensor\x18\x02 \x01(\x0b\x32\x16.qai_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\xcf\x02\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x12\x1d\n\x15\x64\x65legate_reported_ops\x18\t \x03(\t\x12\x1d\n\x10\x65xecution_cycles\x18\n \x01(\x04H\x02\x88\x01\x01\x42\x11\n\x0f_execution_timeB\r\n\x0b_segment_idB\x13\n\x11_execution_cycles\"\xaf\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12.\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"3\n\x15RuntimeConfigProperty\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"U\n\rRuntimeConfig\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x36\n\nproperties\x18\x02 \x03(\x0b\x32\".qai_hub.api.RuntimeConfigProperty\",\n\x0bToolVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"\xc4\x0c\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12/\n\rlayer_details\x18\x04 \x03(\x0b\x32\x18.qai_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x43\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12\x45\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12\x45\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12\x45\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x33\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1a.qai_hub.api.SegmentDetail\x12\x32\n\x0eruntime_config\x18# \x03(\x0b\x32\x1a.qai_hub.api.RuntimeConfig\x12/\n\rtool_versions\x18$ \x03(\x0b\x32\x18.qai_hub.api.ToolVersion\x1aU\n\x0bMemoryUsage\x12$\n\x08increase\x18\x01 \x01(\x0b\x32\x12.qai_hub.api.Range\x12 \n\x04peak\x18\x02 \x01(\x0b\x32\x12.qai_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory\"@\n\rCompileDetail\x12/\n\rtool_versions\x18\x01 \x03(\x0b\x32\x18.qai_hub.api.ToolVersion*\xd8\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1f\n\x1bJOB_STATE_RUNNING_INFERENCE\x10P*\xd5\x01\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01\x12\x16\n\x12TENSOR_DTYPE_INT32\x10\x02\x12\x16\n\x12TENSOR_DTYPE_INT64\x10\x03\x12\x15\n\x11TENSOR_DTYPE_INT8\x10\x04\x12\x16\n\x12TENSOR_DTYPE_UINT8\x10\x05\x12\x16\n\x12TENSOR_DTYPE_INT16\x10\x06\x12\x17\n\x13TENSOR_DTYPE_UINT16\x10\x07*\xaf\x03\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05\x12\x13\n\x0fMODEL_TYPE_ONNX\x10\x06\x12\x12\n\x0eMODEL_TYPE_ORT\x10\x07\x12\x18\n\x14MODEL_TYPE_MLPACKAGE\x10\x08\x12\x16\n\x12MODEL_TYPE_TETRART\x10\t\x12&\n\"MODEL_TYPE_QNN_LIB_AARCH64_ANDROID\x10\n\x12\x16\n\x12MODEL_TYPE_QNN_BIN\x10\x0b\x12\x19\n\x15MODEL_TYPE_AIMET_ONNX\x10\x0c\x12\x17\n\x13MODEL_TYPE_AIMET_PT\x10\r\x12#\n\x1fMODEL_TYPE_QNN_LIB_X86_64_LINUX\x10\x0e*g\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x14\n\x10JOB_TYPE_PROFILE\x10\x01\x12\x16\n\x12JOB_TYPE_INFERENCE\x10\x02\x12\x14\n\x10JOB_TYPE_COMPILE\x10\x03*\xe9\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x1b\n\x17VIZ_GRAPH_TYPE_ESPRESSO\x10\x03\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n\x12\x17\n\x13VIZ_GRAPH_TYPE_ONNX\x10\x0b\x12\x16\n\x12VIZ_GRAPH_TYPE_ORT\x10\x0c\x12\x16\n\x12VIZ_GRAPH_TYPE_QNN\x10\x14*\xe8\x06\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x16\n\x12VIZ_DTYPE_BFLOAT16\x10\x10\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12\x12\n\x0eVIZ_DTYPE_INT4\x10?\x12\x13\n\x0fVIZ_DTYPE_QINT4\x10\x46\x12\x13\n\x0fVIZ_DTYPE_QINT8\x10G\x12\x14\n\x10VIZ_DTYPE_QINT16\x10H\x12\x14\n\x10VIZ_DTYPE_QINT32\x10I\x12\x14\n\x10VIZ_DTYPE_QUINT4\x10P\x12\x14\n\x10VIZ_DTYPE_QUINT8\x10Q\x12\x15\n\x11VIZ_DTYPE_QUINT16\x10R\x12\x15\n\x11VIZ_DTYPE_QUINT32\x10S\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x18qai_hub/public_api.proto\x12\x0bqai_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x9c\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x36\n\x06\x66ields\x18\x03 \x03(\x0b\x32&.qai_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"-\n\x0fJobPublicUpdate\x12\x11\n\x04name\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\x07\n\x05_name\"1\n\rServiceStatus\x12\x14\n\x07message\x18\x01 \x01(\tH\x00\x88\x01\x01\x42\n\n\x08_message\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"G\n\x08UserList\x12 \n\x05users\x18\x01 \x03(\x0b\x32\x11.qai_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"T\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12&\n\x07members\x18\x03 \x01(\x0b\x32\x15.qai_hub.api.UserList\"O\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\x12\x17\n\x0fsoc_description\x18\x04 \x01(\t\"M\n\nDeviceList\x12$\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x13.qai_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xd2\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12%\n\x05owner\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_complete\"P\n\x0b\x44\x61tasetList\x12&\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x14.qai_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"D\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12\'\n\x05\x64type\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.TensorDtype\"M\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12,\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x17.qai_hub.api.TensorType\"B\n\x13NamedTensorTypeList\x12+\n\x05types\x18\x01 \x03(\x0b\x32\x1c.qai_hub.api.NamedTensorType\"\xe8\x02\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12%\n\x05owner\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12/\n\nmodel_type\x18\x05 \x01(\x0e\x32\x16.qai_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x12\x18\n\x0bproducer_id\x18\x07 \x01(\tH\x06\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_completeB\x0e\n\x0c_producer_id\"J\n\tModelList\x12\"\n\x06models\x18\x01 \x03(\x0b\x32\x12.qai_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xf1\x06\n\nCompileJob\x12\x16\n\x0e\x63ompile_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12!\n\x05model\x18\x04 \x01(\x0b\x32\x12.qai_hub.api.Model\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12#\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x13.qai_hub.api.Device\x12(\n\x07\x64\x65vices\x18\x07 \x01(\x0b\x32\x17.qai_hub.api.DeviceList\x12:\n\x10tensor_type_list\x18\x08 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x0c\n\x04name\x18\t \x01(\t\x12\x0f\n\x07options\x18\n \x01(\t\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12-\n\x0ctarget_model\x18\x0c \x01(\x0b\x32\x12.qai_hub.api.ModelH\x01\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\r \x01(\x08H\x02\x88\x01\x01\x12\x31\n\rcreation_time\x18\x0e \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\x0f \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\x10 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x35\n\x11last_updated_time\x18\x11 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x12 \x01(\tH\x03\x88\x01\x01\x12\x41\n\x17target_tensor_type_list\x18\x13 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x36\n\x13\x63\x61libration_dataset\x18\x14 \x01(\x0b\x32\x14.qai_hub.api.DatasetH\x04\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0f\n\r_target_modelB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_urlB\x16\n\x14_calibration_dataset\"\xad\x07\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12!\n\x05model\x18\x04 \x01(\x0b\x32\x12.qai_hub.api.Model\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12#\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x13.qai_hub.api.Device\x12:\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32 .qai_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12%\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x14.qai_hub.api.Dataset\x12-\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x12.qai_hub.api.ModelH\x03\x88\x01\x01\x12\x36\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x12.qai_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x12\x35\n\x11last_updated_time\x18\x14 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x15 \x01(\tH\x06\x88\x01\x01\x12\x18\n\x10includes_compile\x18\x16 \x01(\x08\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_url\"\xa6\x04\n\x0cInferenceJob\x12\x18\n\x10inference_job_id\x18\x01 \x01(\t\x12\x1f\n\x04user\x18\x02 \x01(\x0b\x32\x11.qai_hub.api.User\x12!\n\x05model\x18\x03 \x01(\x0b\x32\x12.qai_hub.api.Model\x12#\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x13.qai_hub.api.Device\x12(\n\tjob_state\x18\x05 \x01(\x0e\x32\x15.qai_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12%\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x14.qai_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\t\x12\x35\n\x11last_updated_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x0e \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0c\n\n_admin_url\"\xca\x01\n\x03Job\x12.\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x17.qai_hub.api.ProfileJobH\x00\x12\x32\n\rinference_job\x18\x02 \x01(\x0b\x32\x19.qai_hub.api.InferenceJobH\x00\x12.\n\x0b\x63ompile_job\x18\x04 \x01(\x0b\x32\x17.qai_hub.api.CompileJobH\x00\x12\x18\n\x0bhub_version\x18\x03 \x01(\tH\x01\x88\x01\x01\x42\x05\n\x03jobB\x0e\n\x0c_hub_version\"R\n\x0eProfileJobList\x12%\n\x04jobs\x18\x01 \x03(\x0b\x32\x17.qai_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"D\n\x07JobList\x12\x1e\n\x04jobs\x18\x01 \x03(\x0b\x32\x10.qai_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"*\n\x10\x43ompileJobResult\x12\x16\n\x0e\x63ompile_job_id\x18\x01 \x01(\t\"h\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x30\n\x07profile\x18\x02 \x01(\x0b\x32\x1a.qai_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"\x85\x01\n\x12InferenceJobResult\x12\x18\n\x10inference_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\x12/\n\x06\x64\x65tail\x18\x03 \x01(\x0b\x32\x1a.qai_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\t\n\x07_detail\"\xd0\x01\n\tJobResult\x12;\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1d.qai_hub.api.ProfileJobResultH\x00\x12?\n\x14inference_job_result\x18\x02 \x01(\x0b\x32\x1f.qai_hub.api.InferenceJobResultH\x00\x12;\n\x12\x63ompile_job_result\x18\x03 \x01(\x0b\x32\x1d.qai_hub.api.CompileJobResultH\x00\x42\x08\n\x06result\"\xe8\x02\n\x08VizGraph\x12-\n\ngraph_type\x18\x01 \x01(\x0e\x32\x19.qai_hub.api.VizGraphType\x12+\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x18.qai_hub.api.VizSubgraph\x12\x39\n\nparameters\x18\x04 \x03(\x0b\x32%.qai_hub.api.VizGraph.ParametersEntry\x12\x33\n\x07tensors\x18\x05 \x03(\x0b\x32\".qai_hub.api.VizGraph.TensorsEntry\x1aH\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12$\n\x05value\x18\x02 \x01(\x0b\x32\x15.qai_hub.api.VizValue:\x02\x38\x01\x1a\x46\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12%\n\x05value\x18\x02 \x01(\x0b\x32\x16.qai_hub.api.VizTensor:\x02\x38\x01\"@\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12#\n\x05nodes\x18\x02 \x03(\x0b\x32\x14.qai_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x82\x02\n\tVizTensor\x12$\n\x05\x64type\x18\x02 \x01(\x0e\x32\x15.qai_hub.api.VizDtype\x12$\n\x05shape\x18\x03 \x01(\x0b\x32\x15.qai_hub.api.VizShape\x12:\n\nparameters\x18\x04 \x03(\x0b\x32&.qai_hub.api.VizTensor.ParametersEntry\x12#\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x15.qai_hub.api.VizValue\x1aH\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12$\n\x05value\x18\x02 \x01(\x0b\x32\x15.qai_hub.api.VizValue:\x02\x38\x01\"\x8c\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12\x38\n\nattributes\x18\x07 \x03(\x0b\x32$.qai_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aL\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.qai_hub.api.VizAttribute:\x02\x38\x01\"\xd8\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x37\n\x0bstring_list\x18\x06 \x01(\x0b\x32 .qai_hub.api.VizValue.StringListH\x00\x12\x39\n\x0cinteger_list\x18\x07 \x01(\x0b\x32!.qai_hub.api.VizValue.IntegerListH\x00\x12\x35\n\nfloat_list\x18\x08 \x01(\x0b\x32\x1f.qai_hub.api.VizValue.FloatListH\x00\x12\x33\n\tbool_list\x18\t \x01(\x0b\x32\x1e.qai_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"h\n\x0cVizAttribute\x12&\n\x05value\x18\x01 \x01(\x0b\x32\x15.qai_hub.api.VizValueH\x00\x12(\n\x06tensor\x18\x02 \x01(\x0b\x32\x16.qai_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\xcf\x02\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x12\x1d\n\x15\x64\x65legate_reported_ops\x18\t \x03(\t\x12\x1d\n\x10\x65xecution_cycles\x18\n \x01(\x04H\x02\x88\x01\x01\x42\x11\n\x0f_execution_timeB\r\n\x0b_segment_idB\x13\n\x11_execution_cycles\"\xaf\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12.\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x18.qai_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"3\n\x15RuntimeConfigProperty\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"U\n\rRuntimeConfig\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x36\n\nproperties\x18\x02 \x03(\x0b\x32\".qai_hub.api.RuntimeConfigProperty\",\n\x0bToolVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"\xc4\x0c\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12/\n\rlayer_details\x18\x04 \x03(\x0b\x32\x18.qai_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x43\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12\x45\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12\x45\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12\x45\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32&.qai_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x33\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1a.qai_hub.api.SegmentDetail\x12\x32\n\x0eruntime_config\x18# \x03(\x0b\x32\x1a.qai_hub.api.RuntimeConfig\x12/\n\rtool_versions\x18$ \x03(\x0b\x32\x18.qai_hub.api.ToolVersion\x1aU\n\x0bMemoryUsage\x12$\n\x08increase\x18\x01 \x01(\x0b\x32\x12.qai_hub.api.Range\x12 \n\x04peak\x18\x02 \x01(\x0b\x32\x12.qai_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory*\xd8\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1f\n\x1bJOB_STATE_RUNNING_INFERENCE\x10P*\xd5\x01\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01\x12\x16\n\x12TENSOR_DTYPE_INT32\x10\x02\x12\x16\n\x12TENSOR_DTYPE_INT64\x10\x03\x12\x15\n\x11TENSOR_DTYPE_INT8\x10\x04\x12\x16\n\x12TENSOR_DTYPE_UINT8\x10\x05\x12\x16\n\x12TENSOR_DTYPE_INT16\x10\x06\x12\x17\n\x13TENSOR_DTYPE_UINT16\x10\x07*\xaf\x03\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05\x12\x13\n\x0fMODEL_TYPE_ONNX\x10\x06\x12\x12\n\x0eMODEL_TYPE_ORT\x10\x07\x12\x18\n\x14MODEL_TYPE_MLPACKAGE\x10\x08\x12\x16\n\x12MODEL_TYPE_TETRART\x10\t\x12&\n\"MODEL_TYPE_QNN_LIB_AARCH64_ANDROID\x10\n\x12\x16\n\x12MODEL_TYPE_QNN_BIN\x10\x0b\x12\x19\n\x15MODEL_TYPE_AIMET_ONNX\x10\x0c\x12\x17\n\x13MODEL_TYPE_AIMET_PT\x10\r\x12#\n\x1fMODEL_TYPE_QNN_LIB_X86_64_LINUX\x10\x0e*g\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x14\n\x10JOB_TYPE_PROFILE\x10\x01\x12\x16\n\x12JOB_TYPE_INFERENCE\x10\x02\x12\x14\n\x10JOB_TYPE_COMPILE\x10\x03*\xe9\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x1b\n\x17VIZ_GRAPH_TYPE_ESPRESSO\x10\x03\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n\x12\x17\n\x13VIZ_GRAPH_TYPE_ONNX\x10\x0b\x12\x16\n\x12VIZ_GRAPH_TYPE_ORT\x10\x0c\x12\x16\n\x12VIZ_GRAPH_TYPE_QNN\x10\x14*\xe8\x06\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x16\n\x12VIZ_DTYPE_BFLOAT16\x10\x10\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12\x12\n\x0eVIZ_DTYPE_INT4\x10?\x12\x13\n\x0fVIZ_DTYPE_QINT4\x10\x46\x12\x13\n\x0fVIZ_DTYPE_QINT8\x10G\x12\x14\n\x10VIZ_DTYPE_QINT16\x10H\x12\x14\n\x10VIZ_DTYPE_QINT32\x10I\x12\x14\n\x10VIZ_DTYPE_QUINT4\x10P\x12\x14\n\x10VIZ_DTYPE_QUINT8\x10Q\x12\x15\n\x11VIZ_DTYPE_QUINT16\x10R\x12\x15\n\x11VIZ_DTYPE_QUINT32\x10S\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
 
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'qai_hub.public_api_pb2', globals())
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _FILEUPLOADURL_FIELDSENTRY._options = None
@@ -27,132 +27,126 @@
   _VIZGRAPH_PARAMETERSENTRY._serialized_options = b'8\001'
   _VIZGRAPH_TENSORSENTRY._options = None
   _VIZGRAPH_TENSORSENTRY._serialized_options = b'8\001'
   _VIZTENSOR_PARAMETERSENTRY._options = None
   _VIZTENSOR_PARAMETERSENTRY._serialized_options = b'8\001'
   _VIZNODE_ATTRIBUTESENTRY._options = None
   _VIZNODE_ATTRIBUTESENTRY._serialized_options = b'8\001'
-  _JOBSTATE._serialized_start=9625
-  _JOBSTATE._serialized_end=9841
-  _TENSORDTYPE._serialized_start=9844
-  _TENSORDTYPE._serialized_end=10057
-  _MODELTYPE._serialized_start=10060
-  _MODELTYPE._serialized_end=10491
-  _JOBTYPE._serialized_start=10493
-  _JOBTYPE._serialized_end=10596
-  _VIZGRAPHTYPE._serialized_start=10599
-  _VIZGRAPHTYPE._serialized_end=10832
-  _VIZDTYPE._serialized_start=10835
-  _VIZDTYPE._serialized_end=11707
-  _COMPUTEUNIT._serialized_start=11709
-  _COMPUTEUNIT._serialized_end=11818
+  _JOBSTATE._serialized_start=9275
+  _JOBSTATE._serialized_end=9491
+  _TENSORDTYPE._serialized_start=9494
+  _TENSORDTYPE._serialized_end=9707
+  _MODELTYPE._serialized_start=9710
+  _MODELTYPE._serialized_end=10141
+  _JOBTYPE._serialized_start=10143
+  _JOBTYPE._serialized_end=10246
+  _VIZGRAPHTYPE._serialized_start=10249
+  _VIZGRAPHTYPE._serialized_end=10482
+  _VIZDTYPE._serialized_start=10485
+  _VIZDTYPE._serialized_end=11357
+  _COMPUTEUNIT._serialized_start=11359
+  _COMPUTEUNIT._serialized_end=11468
   _CREATEUPDATERESPONSE._serialized_start=75
   _CREATEUPDATERESPONSE._serialized_end=229
   _FILEDOWNLOADURL._serialized_start=231
   _FILEDOWNLOADURL._serialized_end=279
-  _SHAREDACCESS._serialized_start=281
-  _SHAREDACCESS._serialized_end=310
-  _SHAREDACCESSCHANGE._serialized_start=312
-  _SHAREDACCESSCHANGE._serialized_end=373
-  _FILEUPLOADURL._serialized_start=376
-  _FILEUPLOADURL._serialized_end=532
-  _FILEUPLOADURL_FIELDSENTRY._serialized_start=487
-  _FILEUPLOADURL_FIELDSENTRY._serialized_end=532
-  _JOBPUBLICUPDATE._serialized_start=534
-  _JOBPUBLICUPDATE._serialized_end=579
-  _SERVICESTATUS._serialized_start=581
-  _SERVICESTATUS._serialized_end=630
-  _USER._serialized_start=632
-  _USER._serialized_end=750
-  _USERLIST._serialized_start=752
-  _USERLIST._serialized_end=823
-  _USERCHANGEPASSWORD._serialized_start=825
-  _USERCHANGEPASSWORD._serialized_end=889
-  _ORGANIZATION._serialized_start=891
-  _ORGANIZATION._serialized_end=975
-  _DEVICE._serialized_start=977
-  _DEVICE._serialized_end=1056
-  _DEVICELIST._serialized_start=1058
-  _DEVICELIST._serialized_end=1135
-  _DATASET._serialized_start=1138
-  _DATASET._serialized_end=1514
-  _DATASETLIST._serialized_start=1516
-  _DATASETLIST._serialized_end=1596
-  _TENSORTYPE._serialized_start=1598
-  _TENSORTYPE._serialized_end=1666
-  _NAMEDTENSORTYPE._serialized_start=1668
-  _NAMEDTENSORTYPE._serialized_end=1745
-  _NAMEDTENSORTYPELIST._serialized_start=1747
-  _NAMEDTENSORTYPELIST._serialized_end=1813
-  _MODEL._serialized_start=1816
-  _MODEL._serialized_end=2214
-  _MODELLIST._serialized_start=2216
-  _MODELLIST._serialized_end=2290
-  _COMPILEJOB._serialized_start=2293
-  _COMPILEJOB._serialized_end=3174
-  _PROFILEJOB._serialized_start=3177
-  _PROFILEJOB._serialized_end=4118
-  _INFERENCEJOB._serialized_start=4121
-  _INFERENCEJOB._serialized_end=4671
-  _JOB._serialized_start=4674
-  _JOB._serialized_end=4914
-  _PROFILEJOBLIST._serialized_start=4916
-  _PROFILEJOBLIST._serialized_end=4998
-  _JOBLIST._serialized_start=5000
-  _JOBLIST._serialized_end=5068
-  _COMPILEJOBRESULT._serialized_start=5070
-  _COMPILEJOBRESULT._serialized_end=5188
-  _PROFILEJOBRESULT._serialized_start=5190
-  _PROFILEJOBRESULT._serialized_end=5294
-  _INFERENCEJOBRESULT._serialized_start=5297
-  _INFERENCEJOBRESULT._serialized_end=5430
-  _JOBRESULT._serialized_start=5433
-  _JOBRESULT._serialized_end=5641
-  _VIZGRAPH._serialized_start=5644
-  _VIZGRAPH._serialized_end=6004
-  _VIZGRAPH_PARAMETERSENTRY._serialized_start=5860
-  _VIZGRAPH_PARAMETERSENTRY._serialized_end=5932
-  _VIZGRAPH_TENSORSENTRY._serialized_start=5934
-  _VIZGRAPH_TENSORSENTRY._serialized_end=6004
-  _VIZSUBGRAPH._serialized_start=6006
-  _VIZSUBGRAPH._serialized_end=6070
-  _VIZSHAPE._serialized_start=6072
-  _VIZSHAPE._serialized_end=6095
-  _VIZTENSOR._serialized_start=6098
-  _VIZTENSOR._serialized_end=6356
-  _VIZTENSOR_PARAMETERSENTRY._serialized_start=5860
-  _VIZTENSOR_PARAMETERSENTRY._serialized_end=5932
-  _VIZNODE._serialized_start=6359
-  _VIZNODE._serialized_end=6627
-  _VIZNODE_ATTRIBUTESENTRY._serialized_start=6551
-  _VIZNODE_ATTRIBUTESENTRY._serialized_end=6627
-  _VIZVALUE._serialized_start=6630
-  _VIZVALUE._serialized_end=7102
-  _VIZVALUE_STRINGLIST._serialized_start=6985
-  _VIZVALUE_STRINGLIST._serialized_end=7011
-  _VIZVALUE_INTEGERLIST._serialized_start=7013
-  _VIZVALUE_INTEGERLIST._serialized_end=7040
-  _VIZVALUE_FLOATLIST._serialized_start=7042
-  _VIZVALUE_FLOATLIST._serialized_end=7067
-  _VIZVALUE_BOOLLIST._serialized_start=7069
-  _VIZVALUE_BOOLLIST._serialized_end=7093
-  _VIZATTRIBUTE._serialized_start=7104
-  _VIZATTRIBUTE._serialized_end=7208
-  _LAYERDETAIL._serialized_start=7211
-  _LAYERDETAIL._serialized_end=7546
-  _SEGMENTDETAIL._serialized_start=7549
-  _SEGMENTDETAIL._serialized_end=7724
-  _RANGE._serialized_start=7726
-  _RANGE._serialized_end=7763
-  _RUNTIMECONFIGPROPERTY._serialized_start=7765
-  _RUNTIMECONFIGPROPERTY._serialized_end=7816
-  _RUNTIMECONFIG._serialized_start=7818
-  _RUNTIMECONFIG._serialized_end=7903
-  _TOOLVERSION._serialized_start=7905
-  _TOOLVERSION._serialized_end=7949
-  _PROFILEDETAIL._serialized_start=7952
-  _PROFILEDETAIL._serialized_end=9556
-  _PROFILEDETAIL_MEMORYUSAGE._serialized_start=9375
-  _PROFILEDETAIL_MEMORYUSAGE._serialized_end=9460
-  _COMPILEDETAIL._serialized_start=9558
-  _COMPILEDETAIL._serialized_end=9622
+  _FILEUPLOADURL._serialized_start=282
+  _FILEUPLOADURL._serialized_end=438
+  _FILEUPLOADURL_FIELDSENTRY._serialized_start=393
+  _FILEUPLOADURL_FIELDSENTRY._serialized_end=438
+  _JOBPUBLICUPDATE._serialized_start=440
+  _JOBPUBLICUPDATE._serialized_end=485
+  _SERVICESTATUS._serialized_start=487
+  _SERVICESTATUS._serialized_end=536
+  _USER._serialized_start=538
+  _USER._serialized_end=656
+  _USERLIST._serialized_start=658
+  _USERLIST._serialized_end=729
+  _USERCHANGEPASSWORD._serialized_start=731
+  _USERCHANGEPASSWORD._serialized_end=795
+  _ORGANIZATION._serialized_start=797
+  _ORGANIZATION._serialized_end=881
+  _DEVICE._serialized_start=883
+  _DEVICE._serialized_end=962
+  _DEVICELIST._serialized_start=964
+  _DEVICELIST._serialized_end=1041
+  _DATASET._serialized_start=1044
+  _DATASET._serialized_end=1382
+  _DATASETLIST._serialized_start=1384
+  _DATASETLIST._serialized_end=1464
+  _TENSORTYPE._serialized_start=1466
+  _TENSORTYPE._serialized_end=1534
+  _NAMEDTENSORTYPE._serialized_start=1536
+  _NAMEDTENSORTYPE._serialized_end=1613
+  _NAMEDTENSORTYPELIST._serialized_start=1615
+  _NAMEDTENSORTYPELIST._serialized_end=1681
+  _MODEL._serialized_start=1684
+  _MODEL._serialized_end=2044
+  _MODELLIST._serialized_start=2046
+  _MODELLIST._serialized_end=2120
+  _COMPILEJOB._serialized_start=2123
+  _COMPILEJOB._serialized_end=3004
+  _PROFILEJOB._serialized_start=3007
+  _PROFILEJOB._serialized_end=3948
+  _INFERENCEJOB._serialized_start=3951
+  _INFERENCEJOB._serialized_end=4501
+  _JOB._serialized_start=4504
+  _JOB._serialized_end=4706
+  _PROFILEJOBLIST._serialized_start=4708
+  _PROFILEJOBLIST._serialized_end=4790
+  _JOBLIST._serialized_start=4792
+  _JOBLIST._serialized_end=4860
+  _COMPILEJOBRESULT._serialized_start=4862
+  _COMPILEJOBRESULT._serialized_end=4904
+  _PROFILEJOBRESULT._serialized_start=4906
+  _PROFILEJOBRESULT._serialized_end=5010
+  _INFERENCEJOBRESULT._serialized_start=5013
+  _INFERENCEJOBRESULT._serialized_end=5146
+  _JOBRESULT._serialized_start=5149
+  _JOBRESULT._serialized_end=5357
+  _VIZGRAPH._serialized_start=5360
+  _VIZGRAPH._serialized_end=5720
+  _VIZGRAPH_PARAMETERSENTRY._serialized_start=5576
+  _VIZGRAPH_PARAMETERSENTRY._serialized_end=5648
+  _VIZGRAPH_TENSORSENTRY._serialized_start=5650
+  _VIZGRAPH_TENSORSENTRY._serialized_end=5720
+  _VIZSUBGRAPH._serialized_start=5722
+  _VIZSUBGRAPH._serialized_end=5786
+  _VIZSHAPE._serialized_start=5788
+  _VIZSHAPE._serialized_end=5811
+  _VIZTENSOR._serialized_start=5814
+  _VIZTENSOR._serialized_end=6072
+  _VIZTENSOR_PARAMETERSENTRY._serialized_start=5576
+  _VIZTENSOR_PARAMETERSENTRY._serialized_end=5648
+  _VIZNODE._serialized_start=6075
+  _VIZNODE._serialized_end=6343
+  _VIZNODE_ATTRIBUTESENTRY._serialized_start=6267
+  _VIZNODE_ATTRIBUTESENTRY._serialized_end=6343
+  _VIZVALUE._serialized_start=6346
+  _VIZVALUE._serialized_end=6818
+  _VIZVALUE_STRINGLIST._serialized_start=6701
+  _VIZVALUE_STRINGLIST._serialized_end=6727
+  _VIZVALUE_INTEGERLIST._serialized_start=6729
+  _VIZVALUE_INTEGERLIST._serialized_end=6756
+  _VIZVALUE_FLOATLIST._serialized_start=6758
+  _VIZVALUE_FLOATLIST._serialized_end=6783
+  _VIZVALUE_BOOLLIST._serialized_start=6785
+  _VIZVALUE_BOOLLIST._serialized_end=6809
+  _VIZATTRIBUTE._serialized_start=6820
+  _VIZATTRIBUTE._serialized_end=6924
+  _LAYERDETAIL._serialized_start=6927
+  _LAYERDETAIL._serialized_end=7262
+  _SEGMENTDETAIL._serialized_start=7265
+  _SEGMENTDETAIL._serialized_end=7440
+  _RANGE._serialized_start=7442
+  _RANGE._serialized_end=7479
+  _RUNTIMECONFIGPROPERTY._serialized_start=7481
+  _RUNTIMECONFIGPROPERTY._serialized_end=7532
+  _RUNTIMECONFIG._serialized_start=7534
+  _RUNTIMECONFIG._serialized_end=7619
+  _TOOLVERSION._serialized_start=7621
+  _TOOLVERSION._serialized_end=7665
+  _PROFILEDETAIL._serialized_start=7668
+  _PROFILEDETAIL._serialized_end=9272
+  _PROFILEDETAIL_MEMORYUSAGE._serialized_start=9091
+  _PROFILEDETAIL_MEMORYUSAGE._serialized_end=9176
 # @@protoc_insertion_point(module_scope)
```

## qai_hub/public_api_pb2.pyi

```diff
@@ -177,15 +177,17 @@
     VIZ_GRAPH_TYPE_ESPRESSO: _VizGraphType.ValueType  # 3
     """Espresso"""
 
     VIZ_GRAPH_TYPE_TFLITE: _VizGraphType.ValueType  # 10
     """Tensorflow"""
 
     VIZ_GRAPH_TYPE_ONNX: _VizGraphType.ValueType  # 11
-    """ONNX"""
+    """ONNX
+    Not currently in use
+    """
 
     VIZ_GRAPH_TYPE_ORT: _VizGraphType.ValueType  # 12
     VIZ_GRAPH_TYPE_QNN: _VizGraphType.ValueType  # 20
     """QNN"""
 
 class VizGraphType(_VizGraphType, metaclass=_VizGraphTypeEnumTypeWrapper):
     """VISUALIZATION //////////////////////////////////////////////
@@ -214,15 +216,17 @@
 VIZ_GRAPH_TYPE_ESPRESSO: VizGraphType.ValueType  # 3
 """Espresso"""
 
 VIZ_GRAPH_TYPE_TFLITE: VizGraphType.ValueType  # 10
 """Tensorflow"""
 
 VIZ_GRAPH_TYPE_ONNX: VizGraphType.ValueType  # 11
-"""ONNX"""
+"""ONNX
+Not currently in use
+"""
 
 VIZ_GRAPH_TYPE_ORT: VizGraphType.ValueType  # 12
 VIZ_GRAPH_TYPE_QNN: VizGraphType.ValueType  # 20
 """QNN"""
 
 global___VizGraphType = VizGraphType
 
@@ -424,52 +428,14 @@
         *,
         url: typing.Text = ...,
         filename: typing.Text = ...,
         ) -> None: ...
     def ClearField(self, field_name: typing_extensions.Literal["filename",b"filename","url",b"url"]) -> None: ...
 global___FileDownloadURL = FileDownloadURL
 
-class SharedAccess(google.protobuf.message.Message):
-    """
-    GET /jobs/<id>/shared_access
-    """
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-    EMAIL_FIELD_NUMBER: builtins.int
-    @property
-    def email(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]: ...
-    def __init__(self,
-        *,
-        email: typing.Optional[typing.Iterable[typing.Text]] = ...,
-        ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["email",b"email"]) -> None: ...
-global___SharedAccess = SharedAccess
-
-class SharedAccessChange(google.protobuf.message.Message):
-    """
-    PATCH /jobs/<id>/shared_access
-    """
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-    ADD_EMAIL_FIELD_NUMBER: builtins.int
-    REMOVE_EMAIL_FIELD_NUMBER: builtins.int
-    @property
-    def add_email(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
-        """Email address(es) to grant access to."""
-        pass
-    @property
-    def remove_email(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
-        """Email address(es) to revoke access from."""
-        pass
-    def __init__(self,
-        *,
-        add_email: typing.Optional[typing.Iterable[typing.Text]] = ...,
-        remove_email: typing.Optional[typing.Iterable[typing.Text]] = ...,
-        ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["add_email",b"add_email","remove_email",b"remove_email"]) -> None: ...
-global___SharedAccessChange = SharedAccessChange
-
 class FileUploadURL(google.protobuf.message.Message):
     """
     GET /models/<id>/upload_url/
     GET /datasets/<id>/upload_url/
     """
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
     class FieldsEntry(google.protobuf.message.Message):
@@ -743,15 +709,14 @@
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
     DATASET_ID_FIELD_NUMBER: builtins.int
     OWNER_FIELD_NUMBER: builtins.int
     NAME_FIELD_NUMBER: builtins.int
     CREATION_TIME_FIELD_NUMBER: builtins.int
     EXPIRATION_TIME_FIELD_NUMBER: builtins.int
     FILE_UPLOAD_COMPLETE_FIELD_NUMBER: builtins.int
-    READ_ONLY_FIELD_NUMBER: builtins.int
     dataset_id: typing.Text
     """Unique identifier of the dataset"""
 
     @property
     def owner(self) -> global___User:
         """Owner of the dataset"""
         pass
@@ -763,46 +728,37 @@
         """Timestamp at which the dataset was uploaded to Hub"""
         pass
     @property
     def expiration_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
         """Timestamp at which the dataset would expire and no longer be available"""
         pass
     file_upload_complete: builtins.bool
-    read_only: builtins.bool
-    """true iff the requesting user has permissions to modify the job.
-    This is used solely for UX purposes, the backend does an independent
-    permission check on all API calls.
-    """
-
     def __init__(self,
         *,
         dataset_id: typing.Optional[typing.Text] = ...,
         owner: typing.Optional[global___User] = ...,
         name: typing.Optional[typing.Text] = ...,
         creation_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         expiration_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         file_upload_complete: typing.Optional[builtins.bool] = ...,
-        read_only: typing.Optional[builtins.bool] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_dataset_id",b"_dataset_id","_expiration_time",b"_expiration_time","_file_upload_complete",b"_file_upload_complete","_name",b"_name","_owner",b"_owner","_read_only",b"_read_only","creation_time",b"creation_time","dataset_id",b"dataset_id","expiration_time",b"expiration_time","file_upload_complete",b"file_upload_complete","name",b"name","owner",b"owner","read_only",b"read_only"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_dataset_id",b"_dataset_id","_expiration_time",b"_expiration_time","_file_upload_complete",b"_file_upload_complete","_name",b"_name","_owner",b"_owner","_read_only",b"_read_only","creation_time",b"creation_time","dataset_id",b"dataset_id","expiration_time",b"expiration_time","file_upload_complete",b"file_upload_complete","name",b"name","owner",b"owner","read_only",b"read_only"]) -> None: ...
+    def HasField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_dataset_id",b"_dataset_id","_expiration_time",b"_expiration_time","_file_upload_complete",b"_file_upload_complete","_name",b"_name","_owner",b"_owner","creation_time",b"creation_time","dataset_id",b"dataset_id","expiration_time",b"expiration_time","file_upload_complete",b"file_upload_complete","name",b"name","owner",b"owner"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_dataset_id",b"_dataset_id","_expiration_time",b"_expiration_time","_file_upload_complete",b"_file_upload_complete","_name",b"_name","_owner",b"_owner","creation_time",b"creation_time","dataset_id",b"dataset_id","expiration_time",b"expiration_time","file_upload_complete",b"file_upload_complete","name",b"name","owner",b"owner"]) -> None: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_creation_time",b"_creation_time"]) -> typing.Optional[typing_extensions.Literal["creation_time"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_dataset_id",b"_dataset_id"]) -> typing.Optional[typing_extensions.Literal["dataset_id"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_expiration_time",b"_expiration_time"]) -> typing.Optional[typing_extensions.Literal["expiration_time"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_file_upload_complete",b"_file_upload_complete"]) -> typing.Optional[typing_extensions.Literal["file_upload_complete"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_name",b"_name"]) -> typing.Optional[typing_extensions.Literal["name"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_owner",b"_owner"]) -> typing.Optional[typing_extensions.Literal["owner"]]: ...
-    @typing.overload
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["_read_only",b"_read_only"]) -> typing.Optional[typing_extensions.Literal["read_only"]]: ...
 global___Dataset = Dataset
 
 class DatasetList(google.protobuf.message.Message):
     """
     List all jobs you own.
     GET /datasets
 
@@ -895,59 +851,49 @@
     MODEL_ID_FIELD_NUMBER: builtins.int
     OWNER_FIELD_NUMBER: builtins.int
     NAME_FIELD_NUMBER: builtins.int
     CREATION_TIME_FIELD_NUMBER: builtins.int
     MODEL_TYPE_FIELD_NUMBER: builtins.int
     FILE_UPLOAD_COMPLETE_FIELD_NUMBER: builtins.int
     PRODUCER_ID_FIELD_NUMBER: builtins.int
-    READ_ONLY_FIELD_NUMBER: builtins.int
     model_id: typing.Text
     @property
     def owner(self) -> global___User: ...
     name: typing.Text
     @property
     def creation_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     model_type: global___ModelType.ValueType
     file_upload_complete: builtins.bool
     producer_id: typing.Text
-    read_only: builtins.bool
-    """true iff the requesting user has permissions to modify the job.
-    This is used solely for UX purposes, the backend does an independent
-    permission check on all API calls.
-    """
-
     def __init__(self,
         *,
         model_id: typing.Optional[typing.Text] = ...,
         owner: typing.Optional[global___User] = ...,
         name: typing.Optional[typing.Text] = ...,
         creation_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         model_type: typing.Optional[global___ModelType.ValueType] = ...,
         file_upload_complete: typing.Optional[builtins.bool] = ...,
         producer_id: typing.Optional[typing.Text] = ...,
-        read_only: typing.Optional[builtins.bool] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_file_upload_complete",b"_file_upload_complete","_model_id",b"_model_id","_model_type",b"_model_type","_name",b"_name","_owner",b"_owner","_producer_id",b"_producer_id","_read_only",b"_read_only","creation_time",b"creation_time","file_upload_complete",b"file_upload_complete","model_id",b"model_id","model_type",b"model_type","name",b"name","owner",b"owner","producer_id",b"producer_id","read_only",b"read_only"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_file_upload_complete",b"_file_upload_complete","_model_id",b"_model_id","_model_type",b"_model_type","_name",b"_name","_owner",b"_owner","_producer_id",b"_producer_id","_read_only",b"_read_only","creation_time",b"creation_time","file_upload_complete",b"file_upload_complete","model_id",b"model_id","model_type",b"model_type","name",b"name","owner",b"owner","producer_id",b"producer_id","read_only",b"read_only"]) -> None: ...
+    def HasField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_file_upload_complete",b"_file_upload_complete","_model_id",b"_model_id","_model_type",b"_model_type","_name",b"_name","_owner",b"_owner","_producer_id",b"_producer_id","creation_time",b"creation_time","file_upload_complete",b"file_upload_complete","model_id",b"model_id","model_type",b"model_type","name",b"name","owner",b"owner","producer_id",b"producer_id"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing_extensions.Literal["_creation_time",b"_creation_time","_file_upload_complete",b"_file_upload_complete","_model_id",b"_model_id","_model_type",b"_model_type","_name",b"_name","_owner",b"_owner","_producer_id",b"_producer_id","creation_time",b"creation_time","file_upload_complete",b"file_upload_complete","model_id",b"model_id","model_type",b"model_type","name",b"name","owner",b"owner","producer_id",b"producer_id"]) -> None: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_creation_time",b"_creation_time"]) -> typing.Optional[typing_extensions.Literal["creation_time"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_file_upload_complete",b"_file_upload_complete"]) -> typing.Optional[typing_extensions.Literal["file_upload_complete"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_model_id",b"_model_id"]) -> typing.Optional[typing_extensions.Literal["model_id"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_model_type",b"_model_type"]) -> typing.Optional[typing_extensions.Literal["model_type"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_name",b"_name"]) -> typing.Optional[typing_extensions.Literal["name"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_owner",b"_owner"]) -> typing.Optional[typing_extensions.Literal["owner"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_producer_id",b"_producer_id"]) -> typing.Optional[typing_extensions.Literal["producer_id"]]: ...
-    @typing.overload
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["_read_only",b"_read_only"]) -> typing.Optional[typing_extensions.Literal["read_only"]]: ...
 global___Model = Model
 
 class ModelList(google.protobuf.message.Message):
     """
     List models user has access to.
     GET /models
 
@@ -1328,43 +1274,33 @@
     RESPONSE: message Job
     """
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
     PROFILE_JOB_FIELD_NUMBER: builtins.int
     INFERENCE_JOB_FIELD_NUMBER: builtins.int
     COMPILE_JOB_FIELD_NUMBER: builtins.int
     HUB_VERSION_FIELD_NUMBER: builtins.int
-    READ_ONLY_FIELD_NUMBER: builtins.int
     @property
     def profile_job(self) -> global___ProfileJob: ...
     @property
     def inference_job(self) -> global___InferenceJob: ...
     @property
     def compile_job(self) -> global___CompileJob: ...
     hub_version: typing.Text
-    read_only: builtins.bool
-    """true iff the requesting user has permissions to modify the job.
-    This is used solely for UX purposes, the backend does an independent
-    permission check on all API calls.
-    """
-
     def __init__(self,
         *,
         profile_job: typing.Optional[global___ProfileJob] = ...,
         inference_job: typing.Optional[global___InferenceJob] = ...,
         compile_job: typing.Optional[global___CompileJob] = ...,
         hub_version: typing.Optional[typing.Text] = ...,
-        read_only: typing.Optional[builtins.bool] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_hub_version",b"_hub_version","_read_only",b"_read_only","compile_job",b"compile_job","hub_version",b"hub_version","inference_job",b"inference_job","job",b"job","profile_job",b"profile_job","read_only",b"read_only"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_hub_version",b"_hub_version","_read_only",b"_read_only","compile_job",b"compile_job","hub_version",b"hub_version","inference_job",b"inference_job","job",b"job","profile_job",b"profile_job","read_only",b"read_only"]) -> None: ...
+    def HasField(self, field_name: typing_extensions.Literal["_hub_version",b"_hub_version","compile_job",b"compile_job","hub_version",b"hub_version","inference_job",b"inference_job","job",b"job","profile_job",b"profile_job"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing_extensions.Literal["_hub_version",b"_hub_version","compile_job",b"compile_job","hub_version",b"hub_version","inference_job",b"inference_job","job",b"job","profile_job",b"profile_job"]) -> None: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_hub_version",b"_hub_version"]) -> typing.Optional[typing_extensions.Literal["hub_version"]]: ...
     @typing.overload
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["_read_only",b"_read_only"]) -> typing.Optional[typing_extensions.Literal["read_only"]]: ...
-    @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["job",b"job"]) -> typing.Optional[typing_extensions.Literal["profile_job","inference_job","compile_job"]]: ...
 global___Job = Job
 
 class ProfileJobList(google.protobuf.message.Message):
     """Not currently used in a non-deprecated endpoint"""
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
     JOBS_FIELD_NUMBER: builtins.int
@@ -1420,28 +1356,22 @@
     REQUEST: No Data
     RESPONSE: message CompileJobResult
       Failed   -> 404 job result is not available (query CompileJob for reason)
       Success  -> 200 with CompileJobResult
     """
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
     COMPILE_JOB_ID_FIELD_NUMBER: builtins.int
-    COMPILE_DETAIL_FIELD_NUMBER: builtins.int
     compile_job_id: typing.Text
     """same as ID in URL"""
 
-    @property
-    def compile_detail(self) -> global___CompileDetail: ...
     def __init__(self,
         *,
         compile_job_id: typing.Text = ...,
-        compile_detail: typing.Optional[global___CompileDetail] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_compile_detail",b"_compile_detail","compile_detail",b"compile_detail"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_compile_detail",b"_compile_detail","compile_detail",b"compile_detail","compile_job_id",b"compile_job_id"]) -> None: ...
-    def WhichOneof(self, oneof_group: typing_extensions.Literal["_compile_detail",b"_compile_detail"]) -> typing.Optional[typing_extensions.Literal["compile_detail"]]: ...
+    def ClearField(self, field_name: typing_extensions.Literal["compile_job_id",b"compile_job_id"]) -> None: ...
 global___CompileJobResult = CompileJobResult
 
 class ProfileJobResult(google.protobuf.message.Message):
     """
     Get a profiling job's result.
     GET /jobs/<id>/result
 
@@ -2289,19 +2219,7 @@
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_execution_memory",b"_execution_memory"]) -> typing.Optional[typing_extensions.Literal["execution_memory"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_load_time",b"_load_time"]) -> typing.Optional[typing_extensions.Literal["load_time"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_warm_load_memory",b"_warm_load_memory"]) -> typing.Optional[typing_extensions.Literal["warm_load_memory"]]: ...
 global___ProfileDetail = ProfileDetail
-
-class CompileDetail(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-    TOOL_VERSIONS_FIELD_NUMBER: builtins.int
-    @property
-    def tool_versions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ToolVersion]: ...
-    def __init__(self,
-        *,
-        tool_versions: typing.Optional[typing.Iterable[global___ToolVersion]] = ...,
-        ) -> None: ...
-    def ClearField(self, field_name: typing_extensions.Literal["tool_versions",b"tool_versions"]) -> None: ...
-global___CompileDetail = CompileDetail
```

## qai_hub/public_rest_api.py

```diff
@@ -137,15 +137,14 @@
             prefix = class_name.capitalize() + " "
 
         raise APIException(
             f"{prefix}ID '{obj_id}' could not be found. It may not exist or you may not have permission to view it.",
             status_code=response.status_code,
         )
     elif response.status_code in [
-        api_status_codes.HTTP_400_BAD_REQUEST,
         api_status_codes.HTTP_403_FORBIDDEN,
         api_status_codes.HTTP_426_UPGRADE_REQUIRED,
         api_status_codes.HTTP_429_TOO_MANY_REQUESTS,
     ]:
         raise APIException(
             response.text,
             status_code=response.status_code,
@@ -781,17 +780,15 @@
     if not job_id:
         raise ValueError(f"Invalid job_id: '{job_id}'")
     header = utils.auth_header(config)
     response = create_session().get(url, headers=header)
     return utils.response_as_protobuf(response, api_pb.Job, obj_id=job_id)
 
 
-def set_job_name(
-    config: ClientConfig, job_id: str, job_name: str
-) -> api_pb.CreateUpdateResponse:
+def set_job_name(config: ClientConfig, job_id: str, job_name: str) -> None:
     """
     Set the job's name.
 
     Parameters
     ----------
     config : ClientConfig
         API authentication configuration.
@@ -805,21 +802,17 @@
     APIException
         Raised if request has failed.
     """
     url = utils.api_url(config, "jobs", job_id)
     header = utils.auth_header(config)
     update_data = api_pb.JobPublicUpdate(name=job_name)
 
-    response = create_session().patch(
-        url, headers=header, data=update_data.SerializeToString()
-    )
+    create_session().patch(url, headers=header, data=update_data.SerializeToString())
 
-    return utils.response_as_protobuf(
-        response, api_pb.CreateUpdateResponse, obj_id=job_id
-    )
+    return
 
 
 def get_job_list(
     config: ClientConfig,
     offset: int = 0,
     limit: int | None = None,
     states: List["api_pb.JobState.ValueType"] = [],
@@ -926,107 +919,14 @@
     """
     header = utils.auth_header(config)
     url = utils.api_url(config, "jobs", job_id, "vizgraph")
     response = create_session().get(url, headers=header)
     return utils.response_as_protobuf(response, api_pb.VizGraph, obj_id=job_id)
 
 
-def get_job_sharing(config: ClientConfig, job_id: str) -> api_pb.SharedAccess:
-    """
-    Get the list of users that the job is shared with.
-
-    Parameters
-    ----------
-    config : ClientConfig
-        API authentication configuration.
-    job_id : str
-        Job ID.
-
-    Raises
-    ------
-    APIException
-        Raised if request has failed.
-    """
-    header = utils.auth_header(config)
-    url = utils.api_url(config, "jobs", job_id, "shared_access")
-
-    response = create_session().get(url, headers=header)
-
-    return utils.response_as_protobuf(response, api_pb.SharedAccess, obj_id=job_id)
-
-
-def modify_job_sharing(
-    config: ClientConfig, job_id: str, add_emails: List[str], delete_emails: List[str]
-) -> api_pb.CreateUpdateResponse:
-    """
-    Modifies the list of users that the job is shared with.
-
-    All assets associated with the job will also be shared.
-    For inference and profile jobs, the corresponding compile job (if any)
-    will also be shared.
-
-    Parameters
-    ----------
-    config : ClientConfig
-        API authentication configuration.
-    job_id : str
-        Job ID.
-    add_emails : List[str]
-        List of email addresses to share with.
-    delete_emails : List[str]
-        List of email addresses to remove from sharing.
-
-    Raises
-    ------
-    APIException
-        Raised if request has failed.
-    """
-    header = utils.auth_header(config)
-    url = utils.api_url(config, "jobs", job_id, "shared_access")
-    update_data = api_pb.SharedAccessChange(
-        add_email=add_emails, remove_email=delete_emails
-    )
-
-    response = create_session().patch(
-        url, headers=header, data=update_data.SerializeToString()
-    )
-
-    return utils.response_as_protobuf(
-        response, api_pb.CreateUpdateResponse, obj_id=job_id
-    )
-
-
-def disable_job_sharing(
-    config: ClientConfig, job_id: str
-) -> api_pb.CreateUpdateResponse:
-    """
-    Disable all sharing for the specified job.
-
-    Parameters
-    ----------
-    config : ClientConfig
-        API authentication configuration.
-    job_id : str
-        Job ID.
-
-    Raises
-    ------
-    APIException
-        Raised if request has failed.
-    """
-    header = utils.auth_header(config)
-    url = utils.api_url(config, "jobs", job_id, "shared_access")
-
-    response = create_session().delete(url, headers=header)
-
-    return utils.response_as_protobuf(
-        response, api_pb.CreateUpdateResponse, obj_id=job_id
-    )
-
-
 # Workaround for mypy having trouble with globals https://github.com/python/mypy/issues/5732
 last: int
 
 
 def _upload_asset(
     upload_url: str,
     path: str | Path,
@@ -1796,17 +1696,14 @@
     "create_inference_job",
     "create_and_upload_dataset",
     "create_and_upload_model",
     "download_model",
     "download_compiled_model",
     "get_model",
     "get_model_list",
-    "get_job_sharing",
-    "modify_job_sharing",
-    "disable_job_sharing",
 ]
 
 
 def download_dataset_info(
     config: ClientConfig, dataset_id: str
 ) -> api_pb.FileDownloadURL:
     """
```

## qai_hub/test/test_cli.py

```diff
@@ -116,22 +116,14 @@
     mock_get_devices = mock.create_autospec(qai_hub.get_devices, return_value=devices)
     with mock.patch("qai_hub.get_devices", mock_get_devices):
         args = get_cli_parser().parse_args(["list-devices"] + input_args)
         run_cli(args)
         mock_get_devices.assert_called_once_with(**expected_results)
 
 
-@pytest.fixture
-def mock_dataset():
-    return mock.Mock(
-        spec=qai_hub.Dataset,
-        dataset_id="dabcd1234",
-    )
-
-
 @pytest.mark.parametrize(
     "input_args, expected_results",
     [
         (
             [
                 "--device",
                 "android",
@@ -145,27 +137,25 @@
             dict(
                 model="model.tflite",
                 name=None,
                 compile_options="blah",
                 profile_options="blah",
                 input_specs=None,
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             ["--device", "android", "--model", "model.tflite"],
             dict(
                 model="model.tflite",
                 name=None,
                 compile_options="",
                 profile_options="",
                 input_specs=None,
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--device",
                 "android",
                 "--model",
@@ -176,15 +166,14 @@
             dict(
                 model="model.tflite",
                 name=None,
                 compile_options="",
                 profile_options="",
                 input_specs={"a": (1, 224, 224), "b": (20, 20)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--device",
                 "android",
                 "--model",
@@ -195,15 +184,14 @@
             dict(
                 model="model.tflite",
                 name=None,
                 compile_options="",
                 profile_options="",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--device",
                 "android",
                 "--model",
@@ -216,26 +204,25 @@
             dict(
                 model="model.tflite",
                 name="fancy_tflite",
                 compile_options="",
                 profile_options="",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
     ],
 )
 def test_compile_and_profile_jobs(input_args, expected_results):
     mock_submit_compile_and_profile_jobs = mock.create_autospec(
-        qai_hub.submit_compile_and_profile_jobs, mock_dataset, return_value=None
+        qai_hub.submit_compile_and_profile_jobs, return_value=None
     )
 
     def mock_get_job(job_id):
-        assert job_id == "dabcd1234"
+        assert job_id == "abcd1234"
         ret = mock.Mock(
             spec=qai_hub.ProfileJob,
             job_id=job_id,
             device=qai_hub.Device("android"),
             model="model.tflite",  # string for ease of testing
             target_model=None,
             date=datetime.now(),
@@ -274,15 +261,14 @@
             ],
             dict(
                 model="model.pt",
                 name=None,
                 options="",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--device",
                 "android",
                 "--model",
@@ -294,105 +280,92 @@
             ],
             dict(
                 model="model.pt",
                 name="fancy_pt",
                 options="",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--clone",
-                "jabcd1234",
+                "abcd1234",
                 "--name",
                 "fancy_pt_override",
             ],
             dict(
                 model="model.pt",
                 name="fancy_pt_override",
                 options="--target_runtime tflite",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--clone",
-                "jabcd1234",
+                "abcd1234",
                 "--compile_options",
                 "",
             ],
             dict(
                 model="model.pt",
                 name="fancy_pt",
                 options="",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android"),
-                calibration_data=None,
             ),
         ),
         (
             [
                 "--clone",
-                "jabcd1234",
+                "abcd1234",
                 "--model",
                 "model_override.pt",
                 "--compile_options",
                 " --quantize_full_type int8",
                 "--device",
                 "android_override",
-                "--calibration_data",
-                "dabcd1234",
             ],
             dict(
                 model="model_override.pt",
                 name="fancy_pt",
                 options=" --quantize_full_type int8",
                 input_specs={"a": (1, 224, 224)},
                 device=qai_hub.Device("android_override"),
-                calibration_data=mock_dataset,
             ),
         ),
     ],
 )
 def test_compile_job(input_args, expected_results):
     mock_submit_compile_job = mock.create_autospec(
         qai_hub.submit_compile_job, return_value=None
     )
 
     def mock_get_job(job_id):
-        assert job_id == "jabcd1234"
+        assert job_id == "abcd1234"
         ret = mock.Mock(
             spec=qai_hub.CompileJob,
             job_id=job_id,
             device=qai_hub.Device("android"),
             model="model.pt",  # string for ease of testing
             target_model=None,
             date=datetime.now(),
             options="--target_runtime tflite",
             verbose=False,
             shapes={"a": (1, 224, 224)},
-            calibration_dataset=None,
         )
         # Mock uses name= argument for something else
         ret.name = "fancy_pt"
         return ret
 
-    def mock_get_dataset(dataset_id):
-        assert dataset_id == "dabcd1234"
-        return mock_dataset
-
     with mock.patch("qai_hub.submit_compile_job", mock_submit_compile_job), mock.patch(
         "qai_hub.get_job", mock_get_job
-    ), mock.patch("qai_hub.get_dataset", mock_get_dataset), mock.patch(
-        "os.path.isfile", return_value=True
-    ):
+    ), mock.patch("os.path.isfile", return_value=True):
         args = get_cli_parser().parse_args(
             ["submit-compile-job"] + input_args,
         )
         run_cli(args)
         mock_submit_compile_job.assert_called_once_with(**expected_results)
 
 
@@ -423,29 +396,29 @@
                 options="",
                 device=qai_hub.Device("android"),
             ),
         ),
         (
             [
                 "--clone",
-                "jabcd1234",
+                "abcd1234",
                 "--name",
                 "fancy_tflite_override",
             ],
             dict(
                 model="model.tflite",
                 name="fancy_tflite_override",
                 options="",
                 device=qai_hub.Device("android"),
             ),
         ),
         (
             [
                 "--clone",
-                "jabcd1234",
+                "abcd1234",
                 "--model",
                 "model_override.tflite",
                 "--profile_options",
                 "--compute_unit cpu",
                 "--device",
                 "android_override",
             ],
@@ -460,15 +433,15 @@
 )
 def test_profile_job(input_args, expected_results):
     mock_submit_profile_job = mock.create_autospec(
         qai_hub.submit_profile_job, return_value=None
     )
 
     def mock_get_job(job_id):
-        assert job_id == "jabcd1234"
+        assert job_id == "abcd1234"
         ret = mock.Mock(
             spec=qai_hub.ProfileJob,
             job_id=job_id,
             device=qai_hub.Device("android"),
             model="model.tflite",  # string for ease of testing
             target_model=None,
             date=datetime.now(),
```

## qai_hub/test/test_client.py

```diff
@@ -184,39 +184,35 @@
         ("framework:tflite", "os:android", "10.", SourceModelType.MLMODEL, False),
         ("framework:onnx", "os:android", "10.1", SourceModelType.MLMODEL, False),
         # .mlmodelc is supported only on iOS and macOS
         ("framework:coreml", "os:macos", "12.1", SourceModelType.MLMODELC, True),
         ("framework:coreml", "os:ios", "15.1", SourceModelType.MLMODELC, True),
         ("framework:tflite", "os:android", "10.", SourceModelType.MLMODELC, False),
         ("framework:onnx", "os:android", "10.1", SourceModelType.MLMODELC, False),
-        # .onnx is supported with ONNX runtime on Android
+        # .onnx is supported with tflite framework
         ("framework:coreml", "os:macos", "12.1", SourceModelType.ONNX, False),
         ("framework:coreml", "os:ios", "15.1", SourceModelType.ONNX, False),
-        ("framework:tflite", "os:macos", "12.1", SourceModelType.ONNX, False),
-        ("framework:tflite", "os:ios", "15.1", SourceModelType.ONNX, False),
-        # supported only for compile jobs with tflite
-        ("framework:tflite", "os:android", "10.", SourceModelType.ONNX, False),
-        ("framework:onnx", "os:android", "10.1", SourceModelType.ONNX, True),
-        ("framework:onnx", "os:windows", "11", SourceModelType.ONNX, True),
+        ("framework:onnx", "os:macos", "12.1", SourceModelType.ONNX, False),
+        ("framework:tflite", "os:ios", "15.1", SourceModelType.ONNX, True),
+        ("framework:tflite", "os:android", "10.", SourceModelType.ONNX, True),
+        ("framework:onnx", "os:android", "10.1", SourceModelType.ONNX, False),
         # .ort is supported with ONNX runtime
         ("framework:coreml", "os:macos", "12.1", SourceModelType.ORT, False),
         ("framework:coreml", "os:ios", "15.1", SourceModelType.ORT, False),
-        ("framework:tflite", "os:macos", "12.1", SourceModelType.ORT, False),
-        ("framework:tflite", "os:ios", "15.1", SourceModelType.ORT, False),
+        ("framework:onnx", "os:macos", "12.1", SourceModelType.ORT, True),
+        ("framework:onnx", "os:ios", "15.1", SourceModelType.ORT, True),
         ("framework:tflite", "os:android", "10.", SourceModelType.ORT, False),
         ("framework:onnx", "os:android", "10.1", SourceModelType.ORT, True),
-        ("framework:onnx", "os:windows", "11", SourceModelType.ORT, True),
         # .tflite is supported with tflite framework
         ("framework:coreml", "os:macos", "12.1", SourceModelType.TFLITE, False),
         ("framework:coreml", "os:ios", "15.1", SourceModelType.TFLITE, False),
         ("framework:tflite", "os:macos", "12.1", SourceModelType.TFLITE, True),
         ("framework:tflite", "os:ios", "15.1", SourceModelType.TFLITE, True),
         ("framework:tflite", "os:android", "10.", SourceModelType.TFLITE, True),
         ("framework:onnx", "os:android", "10.1", SourceModelType.TFLITE, False),
-        ("framework:onnx", "os:windows", "11", SourceModelType.TFLITE, False),
     ],
 )
 def test_model_type_device_check(
     framework, os_type, os_version, model_type, supported, monkeypatch
 ):
     device = Device(attributes=[framework, os_type], os=os_version)
     monkeypatch.setattr(
```

## qai_hub/util/session.py

```diff
@@ -19,31 +19,20 @@
             logging.info(f"Retry attempt number: {MAX_RETRIES - total}")
 
 
 def create_session():
     session = requests.Session()
     retries = LogRetry(
         total=MAX_RETRIES,
-        # Enable exponential back-off
-        backoff_factor=1,
-        # Retry for these statuses
         status_forcelist=[
             429,  # Too many requests
             500,  # Internal Server Error
             502,  # Bad Gateway
             503,  # Service Unavailable
             504,  # Gateway Timeout
         ],
-        # Retry on connection errors
-        connect=MAX_RETRIES,
-        # Retry on read errors
-        read=MAX_RETRIES,
-        # Don't retry on redirect (default)
-        redirect=None,
-        # Retry on errors other than connection, read, redirect or status.
-        other=MAX_RETRIES,
     )
 
     session.mount("http://", HTTPAdapter(max_retries=retries))
     session.mount("https://", HTTPAdapter(max_retries=retries))
 
     return session
```

## Comparing `qai_hub-0.12.0.dist-info/METADATA` & `qai_hub-0.9.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: qai-hub
-Version: 0.12.0
+Version: 0.9.0
 Summary: Python API for Qualcomm AI Hub.
 Home-page: https://aihub.qualcomm.com/
 Author: Qualcomm Technologies, Inc.
 Author-email: ai-hub-support@qti.qualcomm.com
 License: BSD License
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
@@ -16,30 +16,30 @@
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Software Development
 Requires-Python: >=3.7
+Requires-Dist: requests
 Requires-Dist: deprecation
-Requires-Dist: h5py <4,>=2.10.0
-Requires-Dist: numpy <2,>=1.22.0
 Requires-Dist: packaging >=20.0
-Requires-Dist: prettytable >=3.9.0
-Requires-Dist: protobuf <4,>=3.20
-Requires-Dist: requests
 Requires-Dist: requests-toolbelt
 Requires-Dist: tqdm
+Requires-Dist: protobuf <4,>=3.15
+Requires-Dist: numpy <2,>=1.22.0
+Requires-Dist: h5py <4,>=3.6.0
+Requires-Dist: prettytable >=3.9.0
 Provides-Extra: coremltools
 Requires-Dist: coremltools ==6.2 ; extra == 'coremltools'
 Provides-Extra: onnx
 Requires-Dist: onnx ==1.13.1 ; extra == 'onnx'
 Provides-Extra: torch
-Requires-Dist: torch >=1.13 ; extra == 'torch'
-Requires-Dist: torchvision >=0.14 ; extra == 'torch'
+Requires-Dist: torch ==2.0.1 ; extra == 'torch'
+Requires-Dist: torchvision ==0.15.2 ; extra == 'torch'
 
 Qualcomm AI Hub
 ================
 
 `Qualcomm AI Hub <https://aihub.qualcomm.com>`_ simplifies deploying AI models
 for vision, audio, and speech applications to edge devices.
```

## Comparing `qai_hub-0.12.0.dist-info/RECORD` & `qai_hub-0.9.0.dist-info/RECORD`

 * *Files 25% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 qai_hub/__init__.py,sha256=dypPlGFcYRNv21nwydpRPuw0Fut0_MlCs_OIRHhPc8Y,271
-qai_hub/_cli.py,sha256=V8_G7HA2BSpG38B9J6LX6M_dGY2VKWGeNyOCnt4fdzc,17023
-qai_hub/_version.py,sha256=eHjt9DPsMbptabS2yGx9Yhbyzq5hFSUHXb7zc8Q_8-o,23
+qai_hub/_cli.py,sha256=Q687qyjdBgiLdW1gyBXic01BzKcWBvEf2qYelwyu-6E,16292
+qai_hub/_version.py,sha256=H9NWRZb7NbeRRPLP_V1fARmLNXranorVM-OOY-8_2ug,22
 qai_hub/api_status_codes.py,sha256=1Bo8lC_zSjBEz-bkEEZY8qfhrVRC-CfVOtVS77JOLGQ,4095
-qai_hub/client.py,sha256=6ZEI-W80ewI7sQBj272dDvHJ6eFppOb5qzHQFTpXqus,119732
+qai_hub/client.py,sha256=mzjUdh1WxGK28cfauSUzv2Qq0RNZeeTAdALuWOojK60,117437
 qai_hub/hub.py,sha256=hvqA-d79I4pNdYJ0PRfymlz52__yX2aK74xaYgw_tfc,1126
-qai_hub/public_api_pb2.py,sha256=r5fA_k3GIk-TqXfPwfmQbXlV751TMLOfpQLWa1ftGP4,26381
-qai_hub/public_api_pb2.pyi,sha256=j5GXZsyW0PqOi8kAGXPqSlTywlrOGyPq-pwshdBKD84,107195
-qai_hub/public_rest_api.py,sha256=QTOFLeuovhUYVIV9BNODtONEcvs7DVSbNXGSaMPp8j0,54180
+qai_hub/public_api_pb2.py,sha256=s_YVVTZkUCmS_8pc8ohXoivo0017qCXwdZB1IOzuWlo,25527
+qai_hub/public_api_pb2.pyi,sha256=DNicjgvcqsxcjN5-vQQ3xqOF59ZaUG12ywK1sM1HYNk,102682
+qai_hub/public_rest_api.py,sha256=C4H3iRx2-7eLrD1Nc9hLm1lCMnBG3ufrAZWweIyBZI4,51470
 qai_hub/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 qai_hub/test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-qai_hub/test/test_cli.py,sha256=KawFSsVs3onHaxCB9u7iQlPJx6RGM1DslFjyrNcF8rI,15142
-qai_hub/test/test_client.py,sha256=7UhxZSBhzmVicTq9qrbaRKGCQ7EhDCX1_WBnPK2pGQQ,10689
+qai_hub/test/test_cli.py,sha256=mqiBS6M61PqZy0yrd1T4la7jNLWvTMXakEv1WQe_4gM,14314
+qai_hub/test/test_client.py,sha256=XCrmfkMUfPN6AkFCEUcEc_XXqi81pxCKQR3dF0U5-2s,10389
 qai_hub/test/test_public_rest_api.py,sha256=gNd3YhzCgdAECsIv9VJIUfP5ZcAkafxbpl5cxxrloVQ,687
 qai_hub/test/test_zipped_model.py,sha256=426WoekBAqL-jtkbW2ysLH8MrTF5EDBqtKzjqkIIIJM,5661
 qai_hub/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 qai_hub/util/aimet_helpers.py,sha256=-jxzGvjgdpTLfWXtzWPZXtjn667y9I0OGuLJh-fkrXI,1443
 qai_hub/util/dataset_entries_converters.py,sha256=kgw7FtM_ISb_JExuTv_DmK9Erdq4FO4zv4tDu4TO77o,3816
-qai_hub/util/session.py,sha256=EN1NagQhhOrpbzMZDnUEf9zvJtxyGv0z3qVJO2wS0t0,1402
+qai_hub/util/session.py,sha256=0jrkR5zsSBoX7HNzE9bJOudSho1m-WNqvrFEGQDl1ag,1011
 qai_hub/util/zipped_model.py,sha256=vWQXWL-XPzF1RCw6K6Wz2kAShbSG1ZwD4R1fTPVswhw,4997
-qai_hub-0.12.0.dist-info/METADATA,sha256=V0GehIExeuWGSsn5asoOSy-WXaSxuIBqWn8iBtq1yMQ,2625
-qai_hub-0.12.0.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
-qai_hub-0.12.0.dist-info/entry_points.txt,sha256=iJLKebMFLFVhet0b4r8E2Yx7Bh_cL_PSO_70P7PRbpM,47
-qai_hub-0.12.0.dist-info/top_level.txt,sha256=13-amLNeG-vKkCQ619MxSkTZHX2NRqGvLopPlHUPPPg,8
-qai_hub-0.12.0.dist-info/RECORD,,
+qai_hub-0.9.0.dist-info/METADATA,sha256=TaJgIFkdifYVDckBgffigpzgcJvUzm9CzKvBvVOxnx8,2626
+qai_hub-0.9.0.dist-info/WHEEL,sha256=Xo9-1PvkuimrydujYJAjF7pCkriuXBpUPEjma1nZyJ0,92
+qai_hub-0.9.0.dist-info/entry_points.txt,sha256=iJLKebMFLFVhet0b4r8E2Yx7Bh_cL_PSO_70P7PRbpM,47
+qai_hub-0.9.0.dist-info/top_level.txt,sha256=13-amLNeG-vKkCQ619MxSkTZHX2NRqGvLopPlHUPPPg,8
+qai_hub-0.9.0.dist-info/RECORD,,
```

