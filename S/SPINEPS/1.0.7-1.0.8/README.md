# Comparing `tmp/spineps-1.0.7-py3-none-any.whl.zip` & `tmp/spineps-1.0.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,39 +1,39 @@
-Zip file size: 6224027 bytes, number of entries: 37
+Zip file size: 6224163 bytes, number of entries: 37
 -rwxr-xr-x  2.0 unx      132 b- defN 80-Jan-01 00:00 spineps/.vscode/settings.json
 -rwxr-xr-x  2.0 unx     5039 b- defN 80-Jan-01 00:00 spineps/Unet3D/pl_unet.py
 -rwxr-xr-x  2.0 unx     6069 b- defN 80-Jan-01 00:00 spineps/Unet3D/unet3D.py
 -rwxr-xr-x  2.0 unx      391 b- defN 80-Jan-01 00:00 spineps/__init__.py
--rwxr-xr-x  2.0 unx    12023 b- defN 80-Jan-01 00:00 spineps/entrypoint.py
+-rwxr-xr-x  2.0 unx    12266 b- defN 80-Jan-01 00:00 spineps/entrypoint.py
 -rwxr-xr-x  2.0 unx  1267496 b- defN 80-Jan-01 00:00 spineps/example/figures/example_semantic.png
 -rwxr-xr-x  2.0 unx  6533274 b- defN 80-Jan-01 00:00 spineps/example/figures/pipeline_processflow.png
 -rwxr-xr-x  2.0 unx     1399 b- defN 80-Jan-01 00:00 spineps/example/helper_parallel.py
 -rwxr-xr-x  2.0 unx     3846 b- defN 80-Jan-01 00:00 spineps/example/template_roll_out.py
--rwxr-xr-x  2.0 unx     6834 b- defN 80-Jan-01 00:00 spineps/models.py
+-rwxr-xr-x  2.0 unx     6874 b- defN 80-Jan-01 00:00 spineps/models.py
 -rwxr-xr-x  2.0 unx    22855 b- defN 80-Jan-01 00:00 spineps/phase_instance.py
 -rw-r--r--  2.0 unx    15099 b- defN 80-Jan-01 00:00 spineps/phase_post.py
 -rw-r--r--  2.0 unx     2125 b- defN 80-Jan-01 00:00 spineps/phase_pre.py
 -rwxr-xr-x  2.0 unx     6386 b- defN 80-Jan-01 00:00 spineps/phase_semantic.py
 -rwxr-xr-x  2.0 unx     3227 b- defN 80-Jan-01 00:00 spineps/seg_enums.py
--rwxr-xr-x  2.0 unx    14964 b- defN 80-Jan-01 00:00 spineps/seg_model.py
+-rwxr-xr-x  2.0 unx    15182 b- defN 80-Jan-01 00:00 spineps/seg_model.py
 -rwxr-xr-x  2.0 unx     3079 b- defN 80-Jan-01 00:00 spineps/seg_modelconfig.py
 -rwxr-xr-x  2.0 unx     3292 b- defN 80-Jan-01 00:00 spineps/seg_pipeline.py
 -rwxr-xr-x  2.0 unx    27696 b- defN 80-Jan-01 00:00 spineps/seg_run.py
 -rwxr-xr-x  2.0 unx     7099 b- defN 80-Jan-01 00:00 spineps/seg_utils.py
 -rwxr-xr-x  2.0 unx       51 b- defN 80-Jan-01 00:00 spineps/utils/__init__.py
 -rw-r--r--  2.0 unx      997 b- defN 80-Jan-01 00:00 spineps/utils/citation_reminder.py
 -rwxr-xr-x  2.0 unx     4752 b- defN 80-Jan-01 00:00 spineps/utils/data_iterators.py
 -rwxr-xr-x  2.0 unx     9762 b- defN 80-Jan-01 00:00 spineps/utils/default_preprocessor.py
 -rwxr-xr-x  2.0 unx     5340 b- defN 80-Jan-01 00:00 spineps/utils/export_prediction.py
 -rwxr-xr-x  2.0 unx     3200 b- defN 80-Jan-01 00:00 spineps/utils/filepaths.py
 -rwxr-xr-x  2.0 unx     3843 b- defN 80-Jan-01 00:00 spineps/utils/get_network_from_plans.py
 -rwxr-xr-x  2.0 unx     6516 b- defN 80-Jan-01 00:00 spineps/utils/inference_api.py
 -rwxr-xr-x  2.0 unx    12509 b- defN 80-Jan-01 00:00 spineps/utils/plans_handler.py
--rwxr-xr-x  2.0 unx    22544 b- defN 80-Jan-01 00:00 spineps/utils/predictor.py
+-rwxr-xr-x  2.0 unx    22693 b- defN 80-Jan-01 00:00 spineps/utils/predictor.py
 -rwxr-xr-x  2.0 unx     8032 b- defN 80-Jan-01 00:00 spineps/utils/proc_functions.py
 -rwxr-xr-x  2.0 unx     3196 b- defN 80-Jan-01 00:00 spineps/utils/sliding_window_prediction.py
--rwxr-xr-x  2.0 unx     9155 b- defN 80-Jan-01 00:00 spineps-1.0.7.dist-info/LICENSE
--rw-r--r--  2.0 unx    12280 b- defN 80-Jan-01 00:00 spineps-1.0.7.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 spineps-1.0.7.dist-info/WHEEL
--rw-r--r--  2.0 unx       58 b- defN 80-Jan-01 00:00 spineps-1.0.7.dist-info/entry_points.txt
-?rw-r--r--  2.0 unx     3122 b- defN 16-Jan-01 00:00 spineps-1.0.7.dist-info/RECORD
-37 files, 8047770 bytes uncompressed, 6219069 bytes compressed:  22.7%
+-rwxr-xr-x  2.0 unx     9155 b- defN 80-Jan-01 00:00 spineps-1.0.8.dist-info/LICENSE
+-rw-r--r--  2.0 unx    12280 b- defN 80-Jan-01 00:00 spineps-1.0.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 spineps-1.0.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       58 b- defN 80-Jan-01 00:00 spineps-1.0.8.dist-info/entry_points.txt
+?rw-r--r--  2.0 unx     3122 b- defN 16-Jan-01 00:00 spineps-1.0.8.dist-info/RECORD
+37 files, 8048420 bytes uncompressed, 6219205 bytes compressed:  22.7%
```

## zipnote {}

```diff
@@ -90,23 +90,23 @@
 
 Filename: spineps/utils/proc_functions.py
 Comment: 
 
 Filename: spineps/utils/sliding_window_prediction.py
 Comment: 
 
-Filename: spineps-1.0.7.dist-info/LICENSE
+Filename: spineps-1.0.8.dist-info/LICENSE
 Comment: 
 
-Filename: spineps-1.0.7.dist-info/METADATA
+Filename: spineps-1.0.8.dist-info/METADATA
 Comment: 
 
-Filename: spineps-1.0.7.dist-info/WHEEL
+Filename: spineps-1.0.8.dist-info/WHEEL
 Comment: 
 
-Filename: spineps-1.0.7.dist-info/entry_points.txt
+Filename: spineps-1.0.8.dist-info/entry_points.txt
 Comment: 
 
-Filename: spineps-1.0.7.dist-info/RECORD
+Filename: spineps-1.0.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## spineps/entrypoint.py

```diff
@@ -59,14 +59,15 @@
     )
     parser.add_argument(
         "-non4",
         action="store_true",
         help="Does not apply n4 bias field correction",
     )
     #
+    parser.add_argument("-cpu", action="store_true", help="Use CPU instead of GPU (will take way longer)")
     parser.add_argument("-run_cprofiler", "-rcp", action="store_true", help="Runs a cprofiler over the entire action")
     parser.add_argument("-verbose", "-v", action="store_true", help="Prints much more stuff, may fully clutter your terminal")
     return parser
 
 
 @citation_reminder
 def entry_point():
@@ -179,21 +180,21 @@
     input_path = str(input_path)
     if not input_path.endswith(".nii.gz"):
         input_path += ".nii.gz"
     assert os.path.isfile(input_path), f"-input does not exist or is not a file, got {input_path}"  # noqa: PTH113
 
     if "/" in str(opt.model_semantic):
         # given path
-        model_semantic = get_segmentation_model(opt.model_semantic).load()
+        model_semantic = get_segmentation_model(opt.model_semantic, use_cpu=opt.cpu).load()
     else:
-        model_semantic = get_semantic_model(opt.model_semantic).load()
+        model_semantic = get_semantic_model(opt.model_semantic, use_cpu=opt.cpu).load()
     if "/" in str(opt.model_instance):
-        model_instance = get_segmentation_model(opt.model_instance).load()
+        model_instance = get_segmentation_model(opt.model_instance, use_cpu=opt.cpu).load()
     else:
-        model_instance = get_instance_model(opt.model_instance).load()
+        model_instance = get_instance_model(opt.model_instance, use_cpu=opt.cpu).load()
 
     bids_sample = BIDS_FILE(input_path, dataset=dataset, verbose=True)
 
     kwargs = {
         "img_ref": bids_sample,
         "model_semantic": model_semantic,
         "model_instance": model_instance,
@@ -243,25 +244,25 @@
     assert input_dir.exists(), f"-input does not exist, {input_dir}"
     assert input_dir.is_dir(), f"-input is not a directory, got {input_dir}"
 
     # Model semantic
     if opt.model_semantic == "auto":
         model_semantic = None
     elif "/" in str(opt.model_semantic):
-        model_semantic = get_segmentation_model(opt.model_semantic).load()
+        model_semantic = get_segmentation_model(opt.model_semantic, use_cpu=opt.cpu).load()
     else:
-        model_semantic = get_semantic_model(opt.model_semantic).load()
+        model_semantic = get_semantic_model(opt.model_semantic, use_cpu=opt.cpu).load()
 
     # Model Instance
     if opt.model_instance == "auto":
         model_instance = None
     elif "/" in str(opt.model_instance):
-        model_instance = get_segmentation_model(opt.model_instance).load()
+        model_instance = get_segmentation_model(opt.model_instance, use_cpu=opt.cpu).load()
     else:
-        model_instance = get_instance_model(opt.model_instance).load()
+        model_instance = get_instance_model(opt.model_instance, use_cpu=opt.cpu).load()
 
     assert model_instance is not None, "-model_vert was None"
 
     kwargs = {
         "dataset_path": input_dir,
         "model_semantic": model_semantic,
         "model_instance": model_instance,
```

## spineps/models.py

```diff
@@ -8,15 +8,15 @@
 from spineps.seg_modelconfig import load_inference_config
 from spineps.utils.filepaths import get_mri_segmentor_models_dir, search_path
 
 logger = No_Logger()
 logger.override_prefix = "Models"
 
 
-def get_semantic_model(model_name: str) -> Segmentation_Model:
+def get_semantic_model(model_name: str, **kwargs) -> Segmentation_Model:
     """Finds and returns a semantic model by name
 
     Args:
         model_name (str): _description_
 
     Returns:
         Segmentation_Model: _description_
@@ -29,18 +29,18 @@
             "Found no available semantic models. Did you set one up by downloading modelweights and putting them into the folder specified by the env variable or did you want to specify with an absolute path instead?",
             Log_Type.FAIL,
         )
         raise KeyError(model_name)
     if model_name not in possible_keys:
         logger.print(f"Model with name {model_name} does not exist, options are {possible_keys}", Log_Type.FAIL)
         raise KeyError(model_name)
-    return get_segmentation_model(_modelid2folder_subreg[model_name])
+    return get_segmentation_model(_modelid2folder_subreg[model_name], **kwargs)
 
 
-def get_instance_model(model_name: str) -> Segmentation_Model:
+def get_instance_model(model_name: str, **kwargs) -> Segmentation_Model:
     """Finds and returns an instance model by name
 
     Args:
         model_name (str): _description_
 
     Returns:
         Segmentation_Model: _description_
@@ -53,15 +53,15 @@
             "Found no available instance models. Did you set one up by downloading modelweights and putting them into the folder specified by the env variable or did you want to specify with an absolute path instead?",
             Log_Type.FAIL,
         )
         raise KeyError(model_name)
     if model_name not in possible_keys:
         logger.print(f"Model with name {model_name} does not exist, options are {possible_keys}", Log_Type.FAIL)
         raise KeyError(model_name)
-    return get_segmentation_model(_modelid2folder_vert[model_name])
+    return get_segmentation_model(_modelid2folder_vert[model_name], **kwargs)
 
 
 _modelid2folder_semantic: dict[str, Path] | None = None
 _modelid2folder_instance: dict[str, Path] | None = None
 
 
 def modelid2folder_semantic() -> dict[str, Path]:
```

## spineps/seg_model.py

```diff
@@ -25,14 +25,15 @@
         ABC (_type_): _description_
     """
 
     def __init__(
         self,
         model_folder: str | Path,
         inference_config: Segmentation_Inference_Config | None = None,  # type:ignore
+        use_cpu: bool = False,
         default_verbose: bool = False,
         default_allow_tqdm: bool = True,
     ):
         """Initializes the segmentation model, finding and loading the corresponding inference config for that model
 
         Args:
             model_folder (str | Path): Path to that model's folder
@@ -40,14 +41,15 @@
             default_verbose (bool): If true, will spam a lot more when using. Defaults to True.
             default_allow_tqdm (bool, optional): If true, will showcase a progress bar while segmenting. Defaults to True.
         """
         self.name: str = ""
         assert os.path.exists(str(model_folder)), f"model_folder doesnt exist, got {model_folder}"  # noqa: PTH110
 
         self.logger = No_Logger()
+        self.use_cpu = use_cpu
 
         if inference_config is None:
             json_dir = Path(model_folder).joinpath("inference_config.json")
             self.inference_config = load_inference_config(json_dir, self.logger)
         else:
             self.inference_config = inference_config
 
@@ -57,15 +59,18 @@
         self.model_folder = str(model_folder)
         self.default_allow_tqdm = default_allow_tqdm
         self.predictor = None
 
         self.print("initialized with inference config", self.inference_config)
 
     @abstractmethod
-    def load(self, folds: tuple[str, ...] | None = None) -> Self:
+    def load(
+        self,
+        folds: tuple[str, ...] | None = None,
+    ) -> Self:
         """Loads the weights from disk
 
         Returns:
             Self: Segmentation_Model, but with loaded weights
         """
         return self
 
@@ -106,15 +111,15 @@
         verbose: bool = False,
     ) -> dict[OutputType, NII]:
         """Segments a given input with this model
 
         Args:
             input (Image_Reference | dict[InputType, Image_Reference]): input
             pad_size (int, optional): Padding in each dimension (times two more pixels in each dim). Defaults to 4.
-            step_size (float | None, optional): _description_. Defaults to 0.5.
+            step_size (float | None, optional): _description_. Defaults to None.
             resample_to_recommended (bool, optional): _description_. Defaults to True.
             verbose (bool, optional): _description_. Defaults to False.
 
         Returns:
             dict[OutputType, NII]: _description_
         """
         if self.predictor is None:
@@ -262,32 +267,33 @@
 
 
 class Segmentation_Model_NNunet(Segmentation_Model):
     def __init__(
         self,
         model_folder: str | Path,
         inference_config: Segmentation_Inference_Config | None = None,
+        use_cpu: bool = False,
         default_verbose: bool = False,
         default_allow_tqdm: bool = True,
     ):
-        super().__init__(model_folder, inference_config, default_verbose, default_allow_tqdm)
+        super().__init__(model_folder, inference_config, use_cpu, default_verbose, default_allow_tqdm)
 
     def load(self, folds: tuple[str, ...] | None = None) -> Self:
         global threads_started  # noqa: PLW0603
         if not os.path.exists(self.model_folder):  # noqa: PTH110
             self.print(f"Model weights not found in {self.model_folder}", Log_Type.FAIL)
         self.predictor = load_inf_model(
             model_folder=self.model_folder,
             step_size=self.inference_config.default_step_size,
             use_folds=folds if folds is not None else tuple([str(i) for i in range(self.inference_config.available_folds)]),
             inference_augmentation=self.inference_config.inference_augmentation,
             init_threads=not threads_started,
             allow_non_final=True,
             verbose=False,
-            ddevice="cuda",
+            ddevice="cuda" if not self.use_cpu else "cpu",
         )
         threads_started = True
         self.predictor.allow_tqdm = self.default_allow_tqdm
         self.predictor.verbose = False
         self.print("Model loaded from", self.model_folder, verbose=True)
         return self
 
@@ -307,28 +313,29 @@
 
 
 class Segmentation_Model_Unet3D(Segmentation_Model):
     def __init__(
         self,
         model_folder: str | Path,
         inference_config: Segmentation_Inference_Config | None = None,
+        use_cpu: bool = False,
         default_verbose: bool = False,
         default_allow_tqdm: bool = True,
     ):
-        super().__init__(model_folder, inference_config, default_verbose, default_allow_tqdm)
+        super().__init__(model_folder, inference_config, use_cpu, default_verbose, default_allow_tqdm)
         assert len(self.inference_config.expected_inputs) == 1, "Unet3D cannot expect more than one input"
 
     def load(self, folds: tuple[str, ...] | None = None) -> Self:  # noqa: ARG002
         assert os.path.exists(self.model_folder)  # noqa: PTH110
 
         chktpath = search_path(self.model_folder, "**/*weights*.ckpt")
         assert len(chktpath) == 1
         model = PLNet.load_from_checkpoint(checkpoint_path=chktpath[0])
         model.eval()
-        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
+        self.device = torch.device("cuda:0" if torch.cuda.is_available() and not self.use_cpu else "cpu")
         model.to(self.device)
         self.predictor = model
         self.print("Model loaded from", self.model_folder, verbose=True)
         return self
 
     def run(
         self,
```

## spineps/utils/predictor.py

```diff
@@ -52,14 +52,15 @@
             self.label_manager,
         ) = (None, None, None, None, None, None, None, None)
 
         self.tile_step_size = tile_step_size
         self.use_gaussian = use_gaussian
         self.use_mirroring = use_mirroring
         if device.type == "cuda":
+            torch.backends.cudnn.benchmark = True
             device = torch.device(type="cuda", index=0)  # set the desired GPU with CUDA_VISIBLE_DEVICES!
         if device.type != "cuda" and perform_everything_on_gpu:
             print("perform_everything_on_gpu=True is only supported for cuda devices! Setting this to False")
             perform_everything_on_gpu = False
         self.device = device
         self.perform_everything_on_gpu = perform_everything_on_gpu
 
@@ -284,15 +285,15 @@
                     if prediction is None:
                         prediction = self.predict_sliding_window_return_logits(data, network=network)
                         prediction_stacked = [prediction.to("cpu")]
                     else:
                         new_prediction = self.predict_sliding_window_return_logits(data, network=network)
                         prediction += new_prediction
                         prediction_stacked.append(new_prediction.to("cpu"))
-                        
+
                 if len(self.list_of_parameters) > 1:
                     prediction /= len(self.list_of_parameters)
 
             print("Prediction done, transferring to CPU if needed") if self.verbose else None
             prediction = prediction.to("cpu")
             self.perform_everything_on_gpu = original_perform_everything_on_gpu
         return prediction, torch.stack(prediction_stacked)
@@ -432,43 +433,45 @@
                     {"value": 0},
                     True,
                     None,
                 )
 
                 slicers = self._internal_get_sliding_window_slicers(data.shape[1:])
 
+                precision = torch.half if self.perform_everything_on_gpu else torch.float32
+
                 # preallocate results and num_predictions
                 results_device = self.device if self.perform_everything_on_gpu else torch.device("cpu")
                 if self.verbose:
                     print("preallocating arrays")
                 try:
-                    data = data.to(self.device)
+                    data = data.to(self.device, dtype=precision)
                     predicted_logits = torch.zeros(
                         (self.label_manager.num_segmentation_heads, *data.shape[1:]),
-                        dtype=torch.half,
+                        dtype=precision,
                         device=results_device,
                     )
-                    n_predictions = torch.zeros(data.shape[1:], dtype=torch.half, device=results_device)
+                    n_predictions = torch.zeros(data.shape[1:], dtype=precision, device=results_device)
                     if self.use_gaussian:
                         gaussian = compute_gaussian(
                             tuple(self.configuration_manager.patch_size),
                             sigma_scale=1.0 / 8,
                             value_scaling_factor=1000,
                             device=results_device,
                         )
                 except RuntimeError:
                     # sometimes the stuff is too large for GPUs. In that case fall back to CPU
                     results_device = torch.device("cpu")
-                    data = data.to(results_device)
+                    data = data.to(results_device, dtype=precision)
                     predicted_logits = torch.zeros(
                         (self.label_manager.num_segmentation_heads, *data.shape[1:]),
-                        dtype=torch.half,
+                        dtype=precision,
                         device=results_device,
                     )
-                    n_predictions = torch.zeros(data.shape[1:], dtype=torch.half, device=results_device)
+                    n_predictions = torch.zeros(data.shape[1:], dtype=precision, device=results_device)
                     if self.use_gaussian:
                         gaussian = compute_gaussian(
                             tuple(self.configuration_manager.patch_size),
                             sigma_scale=1.0 / 8,
                             value_scaling_factor=1000,
                             device=results_device,
                         )
```

## Comparing `spineps-1.0.7.dist-info/LICENSE` & `spineps-1.0.8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `spineps-1.0.7.dist-info/METADATA` & `spineps-1.0.8.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: SPINEPS
-Version: 1.0.7
+Version: 1.0.8
 Summary: Framework for out-of-the box whole spine MRI segmentation.
 Home-page: https://github.com/Hendrik-code/spineps
 License: Apache License Version 2.0, January 2004
 Author: Hendrik Möller
 Author-email: hendrik.moeller@tum.de
 Requires-Python: >=3.10,<4.0
 Classifier: License :: Other/Proprietary License
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: SPINEPS Version: 1.0.7 Summary: Framework for out-
+Metadata-Version: 2.1 Name: SPINEPS Version: 1.0.8 Summary: Framework for out-
 of-the box whole spine MRI segmentation. Home-page: https://github.com/Hendrik-
 code/spineps License: Apache License Version 2.0, January 2004 Author: Hendrik
 MÃ¶ller Author-email: hendrik.moeller@tum.de Requires-Python: >=3.10,<4.0
 Classifier: License :: Other/Proprietary License Classifier: Programming
 Language :: Python :: 3 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11 Classifier: Programming
 Language :: Python :: 3.12 Requires-Dist: SciPy (>=1.11.2,<2.0.0) Requires-
```

## Comparing `spineps-1.0.7.dist-info/RECORD` & `spineps-1.0.8.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,37 +1,37 @@
 spineps/.vscode/settings.json,sha256=V6JZ6stjoF4hZIA-Z7TT9di7AS6eP6IWzIR6Sut6WWs,132
 spineps/Unet3D/pl_unet.py,sha256=ZbB-ShiqwZ_kJe--Yj3tEbjtytxjdBb87Py0ZE3PvjI,5039
 spineps/Unet3D/unet3D.py,sha256=EYUsaVSxZtS4iWymC_-ZBT-PffSXpeGIIP65P1vt30c,6069
 spineps/__init__.py,sha256=oYrQPF-r-P0Og74XXcjoNwfvjlZ1ADoKj7fdzwtu-28,391
-spineps/entrypoint.py,sha256=btgUZOxOoOV8KtRL-nvG-SDX4au7e6nJzcbwYCj-sIk,12023
+spineps/entrypoint.py,sha256=gI_h3uRRBCybxf0d-YHNP3AOBcxvgaHRxpHWDZybzBM,12266
 spineps/example/figures/example_semantic.png,sha256=P6o05yJdhFAW8o7b6oX4WBQ-OgBEnbydZMpSrtqri38,1267496
 spineps/example/figures/pipeline_processflow.png,sha256=zdb-lNjs2Z6_iLAf_7lj4tKcRE8i3ChF-GHod9LZB54,6533274
 spineps/example/helper_parallel.py,sha256=SW7RSsqcQghoFf7nYCBPcVbGFaR_9KjFCAhuwI-sn8g,1399
 spineps/example/template_roll_out.py,sha256=V9g4peIF7vbcu8_T1gHw0lEzv8NBvlH5XuPbQvJp-Hs,3846
-spineps/models.py,sha256=OqLJb1QLODEkXFGa0rluHq7ki8reUvGMGln75znHOoU,6834
+spineps/models.py,sha256=QvvqT9Es0Mqm-3fc78EUqCstF-_atVp9f1X73uGQ4jc,6874
 spineps/phase_instance.py,sha256=ZoHWqR5HN1Hytbde5tvWu1T1hfwljwK5k7ISeNZ55c8,22855
 spineps/phase_post.py,sha256=GHnit86gXwKZX-8zQuWf3B8jh3lUNWSN6ldOToQ713s,15099
 spineps/phase_pre.py,sha256=m-_Y6LBLYKmSuPsZJMVxPP0XPK39cFim4OMOpcuRJQU,2125
 spineps/phase_semantic.py,sha256=omajI6so2tpOMh9eRzyHZpA3iC876KHVRHTQUxsdJhw,6386
 spineps/seg_enums.py,sha256=rAkfESJGZcrgVN-cJ4Cs7dsnBXC33ym7JLsmxDkUisM,3227
-spineps/seg_model.py,sha256=DWPeYLTkfgUmUl2pALb4z9eFBrH_cHhQviYTI2y1hvA,14964
+spineps/seg_model.py,sha256=93Bzrh_CDcqsOLgq1xoAacJ8eYeYr7wGE771l0QrdSo,15182
 spineps/seg_modelconfig.py,sha256=Gc0aL4m-hPlYkPH_1aP7lDnmGhrnGIuSbF7rpl18QUk,3079
 spineps/seg_pipeline.py,sha256=i1sev28WMPvXSH_RqTcy8CKiBcuVSKpR342bhtJRTVk,3292
 spineps/seg_run.py,sha256=s-aBBE-fQ2kAl_q-0LjNTMBuKreWhBq5k5zsMJv0YiQ,27696
 spineps/seg_utils.py,sha256=5ZF0gea6hwK_Ouvb7wxVn2gz0Cd4C-w_dl6CundK_x8,7099
 spineps/utils/__init__.py,sha256=nh5o_TYbCKBdbCua4HFv3DgejxlAjR08EDX17A7CV0o,51
 spineps/utils/citation_reminder.py,sha256=d--XwhjbObuZSxI08m6CFDBHUMyieZ2ZhqJbGAVYLCM,997
 spineps/utils/data_iterators.py,sha256=VBImbq_aQtFnV4zGZd_gcsy9In59do7WaNlg2C8PfLE,4752
 spineps/utils/default_preprocessor.py,sha256=0-nISYPoa7bVb9NhyGMDtuitzbmb4vgyUBIh3b0cSn8,9762
 spineps/utils/export_prediction.py,sha256=yMNcydKUalLcVzAQcyMMHS9BhNNGphBBGxfJ-YcKaaU,5340
 spineps/utils/filepaths.py,sha256=3oyWmFN0Qzvi12RPQoM9-sLN640GifOyjKbC4uQhrsY,3200
 spineps/utils/get_network_from_plans.py,sha256=e6Ye0jBLAz0WjF_Dz6hLaZyvxdOPSDbYmBAUslKj8o8,3843
 spineps/utils/inference_api.py,sha256=_lWUk9D4wA9aOSU9UkNzH2Z-ZNxMR-8uMXBg-USz2qA,6516
 spineps/utils/plans_handler.py,sha256=0m3RJiQH1nanHkfguYe4afqSdbT8tmWw15LT6aby8mc,12509
-spineps/utils/predictor.py,sha256=9lgLX2Cog0CV8ymR1hVVHuV-Dv1z0E8dAPH--E9GnL0,22544
+spineps/utils/predictor.py,sha256=u1Haj2cabo3aV0r3aXpkWlE5MqchGGsVHO2CIHosIjU,22693
 spineps/utils/proc_functions.py,sha256=jIxDQ27qUcF6wgN9_H0IvAeK953uUqs54bmsJo1aPUA,8032
 spineps/utils/sliding_window_prediction.py,sha256=t5wUrUNFsC4kBRP-xi83lWVaJVM9MT4qOwEchwVvMJQ,3196
-spineps-1.0.7.dist-info/LICENSE,sha256=FeyAD5MTnsPwmnLWr6_KUUlq1AyzrfURL9gMKOadUUA,9155
-spineps-1.0.7.dist-info/METADATA,sha256=lkCzvWZVmeEHcmM_b-epW60NQEwKFoTdNokUSM5pXWg,12280
-spineps-1.0.7.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
-spineps-1.0.7.dist-info/entry_points.txt,sha256=Vj9qE2iEFxEETTrmzXL3KzP5fboml22gW05a62yqZxs,58
-spineps-1.0.7.dist-info/RECORD,,
+spineps-1.0.8.dist-info/LICENSE,sha256=FeyAD5MTnsPwmnLWr6_KUUlq1AyzrfURL9gMKOadUUA,9155
+spineps-1.0.8.dist-info/METADATA,sha256=opnOhnnySYr_fH3ejjzMF39GKreroJUh2xzlVkl6xq0,12280
+spineps-1.0.8.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
+spineps-1.0.8.dist-info/entry_points.txt,sha256=Vj9qE2iEFxEETTrmzXL3KzP5fboml22gW05a62yqZxs,58
+spineps-1.0.8.dist-info/RECORD,,
```

